/* auto-generated */
window.__QA__ = {"1": {"q_num": 1, "question": "회사는 여러 대륙에 걸쳐 도시의 온도, 습도 및 대기압에 대한 데이터를 수집합니다. \n회사가 매일 각 사이트에서 수집하는 데이터의 평균 볼륨은 500GB 입니다. 각 사이트에는 \n고속 인터넷 연결이 있습니다. \n이 회사는 이러한 모든 글로벌 사이트의 데이터를 단일 Amazon S3 버킷에 최대한 빨리 \n집계하려고 합니다. 솔루션은 운영 복잡성을 최소화해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 대상 S3 버킷에서 S3 Transfer Acceleration 을 켭니다. 멀티파트 업로드를 사용하여 \n사이트 데이터를 대상 S3 버킷에 직접 업로드합니다. \nB. 각 사이트의 데이터를 가장 가까운 리전의 S3 버킷에 업로드합니다. S3 교차 리전 \n복제를 사용하여 대상 S3 버킷에 객체를 복사합니다. 그런 다음 원본 S3 버킷에서 \n데이터를 제거합니다. \nC. AWS Snowball Edge Storage Optimized 디바이스 작업을 매일 예약하여 각 사이트에서 \n가장 가까운 리전으로 데이터를 전송합니다. S3 교차 리전 복제를 사용하여 대상 S3 버킷에 \n객체를 복사합니다. \nD. 각 사이트의 데이터를 가장 가까운 리전의 Amazon EC2 인스턴스로 업로드합니다. \nAmazon Elastic Block Store(Amazon EBS) 볼륨에 데이터를 저장합니다. 정기적으로 EBS \n스냅샷을 만들어 대상 S3 버킷이 포함된 리전에 복사합니다. 해당 리전에서 EBS 볼륨을 \n복원합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/84973-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명:・ \n\n여러 글로벌 사이트의 데이터를 단일 Amazon S3 버킷에 최대한 빨리 집계하는 동시에 \n운영 복잡성을 최소화하려면 가장 적합한 솔루션은 옵션 A: 대상 S3 버킷에서 S3 전송 \n가속화를 설정하고 멀티파트 업로드를 사용하여 사이트 데이터를 대상 S3 버킷에 직접 \n업로드하는 것입니다. \n \n요약하면 옵션 A 는 여러 글로벌 사이트의 데이터를 단일 Amazon S3 버킷으로 신속하게 \n집계하는 가장 효율적이고 운영상 간단한 솔루션을 제공합니다. S3 Transfer Acceleration 및 \n멀티파트 업로드를 활용하여 회사는 복잡성을 최소화하면서 빠른 데이터 수집을 달성할 수 \n있습니다.", "answer_choice": "A"}, "2": {"q_num": 2, "question": "회사는 독점 애플리케이션의 로그 파일을 분석할 수 있는 능력이 필요합니다. 로그는 \nAmazon S3 버킷에 JSON 형식으로 저장됩니다. 쿼리는 간단하고 주문형으로 실행됩니다. \n솔루션 설계자는 기존 아키텍처에 대한 최소한의 변경으로 분석을 수행해야 합니다. \n솔루션 설계자는 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하기 위해 무엇을 해야 \n합니까? \nA. Amazon Redshift 를 사용하여 모든 콘텐츠를 한 곳에 로드하고 필요에 따라 SQL 쿼리를 \n실행합니다. \nB. Amazon CloudWatch Logs\n를 사용하여 로그를 저장합니다. Amazon CloudWatch \n콘솔에서 필요에 따라 SQL 쿼리를 실행합니다. \nC. Amazon S3 와 함께 Amazon Athena 를 직접 사용하여 필요에 따라 쿼리를 실행합니다. \nD. AWS Glue 를 사용하여 로그를 분류합니다. Amazon EMR 에서 임시 Apache Spark \n클러스터를 사용하여 필요에 따라 SQL 쿼리를 실행합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/84848-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명:・ \nS3 에 쿼리하는 건 Athena. \nAthena 가 사용 가능한 모든 리전에서 Amazon Athena 를 사용하여 표준 SQL 로 Amazon \nS3 인벤토리를 쿼리할 수 있습니다.  \nhttps://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/storage-inventory-athen\na-query.html \nAthena 로 JSON 쿼리 가능. \nAmazon Athena 를 사용하면 JSON 인코딩 값을 구문 분석하고, JSON 에서 데이터를 \n\n추출하고, 값을 검색하고, JSON 배열의 길이와 크기를 찾을 수 있습니다. \nhttps://docs.aws.amazon.com/athena/latest/ug/querying-JSON.html", "answer_choice": "C"}, "3": {"q_num": 3, "question": "회사는 AWS Organizations 를 사용하여 여러 부서의 여러 AWS 계정을 관리합니다. 관리 \n계정에는 프로젝트 보고서가 포함된 Amazon S3 버킷이 있습니다. 회사는 이 S3 버킷에 \n대한 액세스를 AWS Organizations 의 조직 내 계정 사용자로만 제한하려고 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 조직 ID 에 대한 참조와 함께 aws PrincipalOrgID 전역 조건 키를 S3 버킷 정책에 \n추가합니다. \nB. 각 부서에 대한 조직 단위(OU)를 만듭니다. aws:PrincipalOrgPaths 전역 조건 키를 S3 \n버킷 정책에 추가합니다. \nC. \nAWS \nCloudTrail\n을 \n사용하여 \nCreateAccount, \nInviteAccountToOrganization, \nLeaveOrganization 및 RemoveAccountFromOrganization 이벤트를 모니터링합니다. 그에 \n따라 S3 버킷 정책을 업데이트합니다. \nD. S3 버킷에 액세스해야 하는 각 사용자에 태그를 지정합니다. aws:PrincipalTag 전역 \n조건 키를 S3 버킷 정책에 추가합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/84838-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \nA(O) : aws:PrincipalOrgID 라는 새로운 조건 키를 권한 정책에 사용하여 조직 내의 계정에 \n해당하는 IAM 보안 주체(사용자 및 역할)만 리소스에 액세스할 수 있도록 합니다. \nhttps://aws.amazon.com/ko/about-aws/whats-new/2018/05/principal-org-id/ \nB(X) : aws:PrincipalOrgPaths 는 다중 값 조건 키입니다. 다중 값 키에는 하나 이상의 값이 \n목록 형식으로 포함됩니다. 결과는 논리적 OR 입니다. \nhttps://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/reference_policies_condition-k\neys.html \nC(X) : CloudTrail 은 리소스 내역을 기록/전송하는 서비스로 지문에서 요구하는 사항에 \n불필요. \nD(X) : 각 사용자마다 태그를 달아야 하므로 최소 운영 오버헤드라는 조건 불충족. \naws:PrincipalTag/tag-key : 문자열 연산자를 사용합니다. 이 키를 사용하여 요청한 보안 \n주체에 연결된 태그를 정책에서 지정한 태그와 비교합니다. \nhttps://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/reference_policies_condition-k\n\neys.html \n \n설명2: \naws:PrincipalOrgID 전역 키는 조직의 모든 AWS 계정에 대한 모든 계정 ID 를 나열하는 \n대신 사용할 수 있습니다. 예를 들어 다음 Amazon S3 버킷 정책은 XXX 조직의 모든 계정 \n구성원이 시험 주제 버킷에 객체를 추가하도록 허용합니다. \n{\"Version\": \"2020-09-10\", \n\"Statement\": { \n\"Sid\": \"AllowPutObject\", \n\"Effect\": \"Allow\", \n\"Principal\": \"*\", \n\"Action\": \"s3:PutObject\", \n\"Resource\": \"arn:aws:s3:::examtopics/*\", \n\"Condition\": {\"StringEquals\": \n{\"aws:PrincipalOrgID\":[\"XXX\"]}}}} \nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_condition-keys.ht\nml", "answer_choice": "A"}, "4": {"q_num": 4, "question": "애플리케이션은 VPC 의 Amazon EC2 인스턴스에서 실행됩니다. 애플리케이션은 Amazon \nS3 버킷에 저장된 로그를 처리합니다. EC2 인스턴스는 인터넷 연결 없이 S3 버킷에 \n액세스해야 합니다. \nAmazon S3 에 대한 프라이빗 네트워크 연결을 제공하는 솔루션은 무엇입니까? \nA. S3 버킷에 대한 게이트웨이 VPC 엔드포인트를 생성합니다. \nB. Amazon CloudWatch Logs 로 로그를 스트리밍합니다. 로그를 S3 버킷으로 내보냅니다. \nC. Amazon EC2 에 인스턴스 프로파일을 생성하여 S3 액세스를 허용합니다. \nD. S3 엔드포인트에 액세스하기 위한 프라이빗 링크가 있는 Amazon API Gateway API 를 \n생성합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/84980-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \nVPC-S3 간 인터넷을 통하지 않는 연결 = S3 VPC Gateway Endpoint. 정답은 A. \n \n\n설명2: \nVPC 종단점을 사용하면 공용 인터넷을 사용하는 대신 사설 네트워크를 사용하여 AWS \n서비스에 연결할 수 있습니다.", "answer_choice": "A"}, "5": {"q_num": 5, "question": "회사는 사용자 업로드 문서를 Amazon EBS 볼륨에 저장하는 단일 Amazon EC2 인스턴스를 \n사용하여 AWS 에서 웹 애플리케이션을 호스팅하고 있습니다. 더 나은 확장성과 가용성을 \n위해 이 회사는 아키텍처를 복제하고 다른 가용 영역에 두 번째 EC2 인스턴스와 EBS \n볼륨을 생성하여 Application Load Balancer 뒤에 배치했습니다. 이 변경을 완료한 후 \n사용자는 웹 사이트를 새로 고칠 때마다 문서의 일부 또는 다른 하위 집합을 볼 수 있지만 \n모든 문서를 동시에 볼 수는 없다고 보고했습니다. \n솔루션 설계자는 사용자가 모든 문서를 한 번에 볼 수 있도록 무엇을 제안해야 합니까? \nA. 두 EBS 볼륨에 모든 문서가 포함되도록 데이터를 복사합니다. \nB. 문서가 있는 서버로 사용자를 안내하도록 Application Load Balancer 를 구성합니다. \nC. 두 EBS 볼륨의 데이터를 Amazon EFS 로 복사합니다. 새 문서를 Amazon EFS 에 \n저장하도록 애플리케이션을 수정합니다. \nD. 두 서버 모두에 요청을 보내도록 Application Load Balancer 를 구성합니다. 올바른 \n서버에서 각 문서를 반환합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/84981-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \nEBS와 EFS의 가장 큰 차이점 중 하나는 EBS는 단일 AZ안에서만 접근이 가능한 저장소인 \n반면, EFS 는 다중 AZ 안에서도 접근이 가능한 저장소라는 점입니다. 위 문제에서는 초기 \n단일 AZ 에서 운영하던 EC2 및 EBS 를 복제한뒤 AZ 를 2 중화하여 멀티 EC2 및 EBS \n시스템으로 \n구성하였지만, \n각 \nAZ \n내에서 \n공유되지 \n않는 \nEBS \n저장소를 \n별도로 \n운영하였기때문에 고객들에게 일관성있는 데이터를 제공할 수 없었던 것으로 보입니다. \n이는 각 AZ 의 EC2 인스턴스가 동일한 저장소를 공유하도록 함으로써 해결할 수 있을 것 \n같습니다. 초기 EBS 에 저장되어있던 데이터들을 일관성있게 보정하여 EFS 로 일회성 \n마이그레이션을 수행한뒤 EC2 어플리케이션 서버 인스턴스가 EBS 가 아닌 EFS 에 데이터를 \n저장하도록 변경하는 것이 바람직해보입니다. \n \n설명2: \nAmazon EFS 는 AWS 클라우드에서 파일 스토리지를 제공합니다. Amazon EFS 를 사용하면 \n\n파일 시스템을 생성하고 파일 시스템을 Amazon EC2 인스턴스에 탑재한 다음 파일 \n시스템에서 데이터를 읽고 쓸 수 있습니다. Network File System 버전 4.0 및 4.1(NFSv4) \n프로토콜을 통해 VPC 에 Amazon EFS 파일 시스템을 탑재할 수 있습니다. Amazon EFS \nMount Helper 와 함께 최신 Amazon Linux, Redhat 및 Ubuntu AMI 에 있는 것과 같은 현재 \n세대 Linux NFSv4.1 클라이언트를 사용하는 것이 좋습니다. 지침은 amazon-efs-utils 도구 \n사용 단원을 참조하십시오. \n이 프로토콜을 지원하는 Amazon EC2 Linux Amazon 머신 이미지(AMI) 목록은 NFS 지원을 \n참조하십시오. 일부 AMI 의 경우 파일 시스템을 Amazon EC2 인스턴스에 탑재하려면 NFS \n클라이언트를 설치해야 합니다. 지침은 NFS 클라이언트 설치를 참조하십시오. \n여러 NFS 클라이언트에서 동시에 Amazon EFS 파일 시스템에 액세스할 수 있으므로 단일 \n연결 이상으로 확장되는 애플리케이션이 파일 시스템에 액세스할 수 있습니다. 동일한 AWS \n리전 내의 여러 가용 영역에서 실행되는 Amazon EC2 인스턴스는 파일 시스템에 액세스할 \n수 있으므로 많은 사용자가 공통 데이터 원본에 액세스하고 공유할 수 있습니다. \nhttps://docs.aws.amazon.com/efs/latest/ug/how-it-works.html#how-it-works-ec2", "answer_choice": "C"}, "6": {"q_num": 6, "question": "회사는 NFS 를 사용하여 온프레미스 네트워크 연결 스토리지에 대용량 비디오 파일을 \n저장합니다. 각 비디오 파일의 크기 범위는 1MB 에서 500GB 입니다. 총 스토리지는 \n70TB\n이며 더 이상 증가하지 않습니다. 회사는 비디오 파일을 Amazon S3\n로 \n마이그레이션하기로 결정합니다. 회사는 가능한 한 최소한의 네트워크 대역폭을 사용하면서 \n가능한 한 빨리 비디오 파일을 마이그레이션해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. S3 버킷을 생성합니다. S3 버킷에 대한 쓰기 권한이 있는 IAM 역할을 생성합니다. AWS \nCLI 를 사용하여 모든 파일을 S3 버킷에 로컬로 복사합니다. \nB. AWS Snowball Edge 작업을 생성합니다. 온프레미스에서 Snowball Edge 장치를 \n받습니다. Snowball Edge 클라이언트를 사용하여 장치로 데이터를 전송합니다. AWS 가 \n데이터를 Amazon S3 로 가져올 수 있도록 디바이스를 반환합니다.  \nC. 온프레미스에 S3 파일 게이트웨이를 배포합니다. S3 파일 게이트웨이에 연결할 퍼블릭 \n서비스 엔드포인트를 생성합니다. S3 버킷을 생성합니다. S3 파일 게이트웨이에서 새 NFS \n파일 공유를 생성합니다. 새 파일 공유가 S3 버킷을 가리키도록 합니다. 기존 NFS 파일 \n공유에서 S3 파일 게이트웨이로 데이터를 전송합니다. \nD. \n온프레미스 네트워크와 AWS \n간에 AWS Direct Connect \n연결을 설정합니다. \n온프레미스에 S3 파일 게이트웨이를 배포합니다. S3 파일 게이트웨이에 연결할 공용 \nVIF(가상 인터페이스)를 생성합니다. S3 버킷을 생성합니다. S3 파일 게이트웨이에서 새 \nNFS 파일 공유를 생성합니다. 새 파일 공유가 S3 버킷을 가리키도록 합니다. 기존 NFS \n\n파일 공유에서 S3 파일 게이트웨이로 데이터를 전송합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/84875-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \n가능한 한 최소한의 네트워크 대역폭을 사용하라 했으니 아예 오프라인에서 Snowball \nEdge 로 올리는 게 맞음. \nAWS Snowball 및 AWS Snowball Edge 는 기존 저장소에서 네트워크 대역폭이 충분하지 \n않을 때, 대용량 데이터 세트를 클라우드로 이전하는데 도움이 됩니다. \nSnowball 장치는 80TB, Snowball Edge 는 100TB 까지 한번에 이동 가능합니다. \nhttps://aws.amazon.com/ko/blogs/korea/aws-snowball-and-aws-snowball-edge-availa\nble-in-asia-pacific-seoul-region/ \n \n설명2: \nSnowball 과 Snowball Edge 의 기본적인 차이점은 제공하는 용량입니다. Snowball 은 총 \n50TB 또는 80TB 를 제공하며 그 중 42TB 또는 72TB 를 사용할 수 있고 Amazon Snowball \nEdge 는 100TB 를 제공하며 그 중 83TB 를 사용할 수 있습니다.", "answer_choice": "B"}, "7": {"q_num": 7, "question": "회사에 들어오는 메시지를 수집하는 응용 프로그램이 있습니다. 그러면 수십 개의 다른 \n애플리케이션과 마이크로서비스가 이러한 메시지를 빠르게 소비합니다. 메시지 수는 \n급격하게 변하며 때로는 초당 100,000 개로 갑자기 증가하기도 합니다. 이 회사는 솔루션을 \n분리하고 확장성을 높이고자 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. Amazon Kinesis Data Analytics 에 대한 메시지를 유지합니다. 메시지를 읽고 처리하도록 \n소비자 애플리케이션을 구성합니다. \nB. Auto Scaling 그룹의 Amazon EC2 인스턴스에 수집 애플리케이션을 배포하여 CPU \n지표를 기반으로 EC2 인스턴스 수를 확장합니다. \nC. 단일 샤드를 사용하여 Amazon Kinesis Data Streams 에 메시지를 씁니다. AWS Lambda \n함수를 사용하여 메시지를 사전 처리하고 Amazon DynamoDB 에 저장합니다. 메시지를 \n처리하기 위해 DynamoDB 에서 읽도록 소비자 애플리케이션을 구성합니다. \nD. 여러 Amazon Simple Queue Service(Amazon SOS) 구독이 있는 Amazon Simple \nNotification Service(Amazon SNS) 주제에 메시지를 게시합니다. 대기열의 메시지를 \n처리하도록 소비자 애플리케이션을 구성합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/84721-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명:・ \nhttps://aws.amazon.com/sqs/features/ \n들어오는 요청을 Amazon SQS 로 라우팅함으로써 회사는 처리 인스턴스에서 작업 요청을 \n분리할 수 있습니다. 이를 통해 대기열 크기에 따라 인스턴스 수를 확장하여 필요할 때 더 \n많은 리소스를 제공할 수 있습니다. 또한 대기열 크기를 기반으로 하는 Auto Scaling \n그룹을 사용하면 워크로드에 따라 자동으로 인스턴스 수를 늘리거나 줄일 수 있습니다. \n대기열에서 읽을 수 있도록 소프트웨어를 업데이트하면 보다 효율적인 방식으로 작업 \n요청을 처리할 수 있어 시스템 성능이 향상됩니다. \n \n솔루션을 분리 = SQS.", "answer_choice": "D"}, "8": {"q_num": 8, "question": "회사에서 분산 애플리케이션을 AWS 로 마이그레이션하고 있습니다. 애플리케이션은 다양한 \n워크로드를 처리합니다. 레거시 플랫폼은 여러 컴퓨팅 노드에서 작업을 조정하는 기본 \n서버로 구성됩니다. 이 회사는 탄력성과 확장성을 극대화하는 솔루션으로 애플리케이션을 \n현대화하려고 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 아키텍처를 어떻게 설계해야 합니까? \nA. 작업의 대상으로 Amazon Simple Queue Service(Amazon SQS) 대기열을 구성합니다. \nAuto Scaling 그룹에서 관리되는 Amazon EC2 인스턴스로 컴퓨팅 노드를 구현합니다. \n예약된 조정을 사용하도록 EC2 Auto Scaling 을 구성합니다. \nB. 작업의 대상으로 Amazon Simple Queue Service(Amazon SQS) 대기열을 구성합니다. \nAuto Scaling 그룹에서 관리되는 Amazon EC2 인스턴스로 컴퓨팅 노드를 구현합니다. \n대기열 크기에 따라 EC2 Auto Scaling 을 구성합니다.  \nC. Auto Scaling 그룹에서 관리되는 Amazon EC2 인스턴스로 기본 서버와 컴퓨팅 노드를 \n구현합니다. 작업의 대상으로 AWS CloudTrail 을 구성합니다. 기본 서버의 부하를 기반으로 \nEC2 Auto Scaling 을 구성합니다. \nD. Auto Scaling 그룹에서 관리되는 Amazon EC2 인스턴스로 기본 서버와 컴퓨팅 노드를 \n구현합니다. 작업의 대상으로 Amazon EventBridge(Amazon CloudWatch Events)를 \n구성합니다. 컴퓨팅 노드의 부하를 기반으로 EC2 Auto Scaling 을 구성합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/84679-exam-aws-certified-solut\n\nions-architect-associate-saa-c03/ \n \n설명1:・ \nA(X) : Scheduled Scaling 은 실시간 현황에 맞춰 적용되는 탄력성이 부족. \nB(O) : SQS Queue 로 갑작스레 작업이 몰려도 추후 처리하도록 보관 가능. Auto Scaling \n그룹으로 여러 EC2 인스턴스의 확장/축소를 적절하게 지원. \nC(X) : CloudTrail 은 리소스 내역을 기록/전송하는 서비스. \nD(X) : CPU 사용률에 따라 EC2 Auto Scaling 하려면 Target Tracking Policy 를 사용하면 됨. \n대상 추적 조정 정책을 사용하여 Application Load Balancer 의 RequestCountPerTarget \n지표 또는 평균 CPU 사용률 같은 지표에 따라 확장하는 것이 좋습니다. 용량이 증가할 때 \n감소하고 용량이 감소할 때 증가하는 지표를 사용하여 비례적으로 확장하거나 대상 추적을 \n사용하여 인스턴스 수를 늘릴 수 있습니다. \nhttps://docs.aws.amazon.com/ko_kr/autoscaling/ec2/userguide/as-scaling-simple-step.\nhtml \n \n설명2: \n복원력과 확장성을 극대화하기 위한 최상의 솔루션은 Amazon SQS 대기열을 작업의 \n대상으로 사용하는 것입니다. 이렇게 하면 컴퓨팅 노드에서 기본 서버가 분리되어 \n독립적으로 확장할 수 있습니다. 이는 또한 실패 시 일자리 손실을 방지하는 데 도움이 \n됩니다. 컴퓨팅 노드에 대해 Amazon EC2 인스턴스의 Auto Scaling 그룹을 사용하면 \n워크로드에 따라 자동 조정이 가능합니다. 이 경우 Amazon SQS 대기열의 크기를 기반으로 \nAuto Scaling 그룹을 구성하는 것이 좋습니다. 이는 기본 서버 또는 컴퓨팅 노드의 \n로드보다 실제 워크로드를 더 잘 나타내는 지표입니다. 이 접근 방식은 애플리케이션이 \n가변 워크로드를 처리할 수 있도록 하는 동시에 필요에 따라 컴퓨팅 노드를 자동으로 확장 \n또는 축소하여 비용을 최소화합니다.", "answer_choice": "B"}, "9": {"q_num": 9, "question": "회사는 데이터 센터에서 SMB 파일 서버를 실행하고 있습니다. 파일 서버는 파일이 생성된 \n후 처음 며칠 동안 자주 액세스하는 대용량 파일을 저장합니다. 7 일이 지나면 파일에 거의 \n액세스하지 않습니다. \n총 데이터 크기가 증가하고 있으며 회사의 총 저장 용량에 가깝습니다. 솔루션 설계자는 \n가장 최근에 액세스한 파일에 대한 저지연 액세스를 잃지 않으면서 회사의 사용 가능한 \n저장 공간을 늘려야 합니다. 솔루션 설계자는 향후 스토리지 문제를 방지하기 위해 파일 \n수명 주기 관리도 제공해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \n\nA. AWS DataSync 를 사용하여 SMB 파일 서버에서 AWS 로 7 일이 지난 데이터를 \n복사합니다. \nB. Amazon S3 파일 게이트웨이를 생성하여 회사의 스토리지 공간을 확장합니다. S3 수명 \n주기 정책을 생성하여 7 일 후에 데이터를 S3 Glacier Deep Archive 로 전환합니다.  \nC. Windows 파일 서버용 Amazon FSx 파일 시스템을 생성하여 회사의 저장 공간을 \n확장합니다. \nD. 각 사용자의 컴퓨터에 유틸리티를 설치하여 Amazon S3 에 액세스합니다. S3 수명 주기 \n정책을 생성하여 7 일 후 데이터를 S3 Glacier Flexible Retrieval 로 전환합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/84680-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \n사용 가능한 스토리지 공간을 늘림 = Storage Gateway. 답은 B. \nA(X) : AWS 에서 무슨 스토리지를 사용할 건지에 대한 언급이 없음. 또한 하이브리드 \n스토리지인 Storage Gateway 가 더 적절한 방식임. \nB(O) : 정답. 스토리지 게이트웨이는 온프레미스 스토리지와 AWS 스토리지를 합쳐 사실상 \n무제한의 스토리지를 향유하는 것을 목적으로 하는 서비스. \nAmazon S3 File Gateway 의 사용 사례로는 (a) 최근에 액세스한 데이터에 대해 빠른 로컬 \n액세스를 유지하면서 온프레미스 파일 데이터를 Amazon S3 로 마이그레이션. SMB(서버 \n메시지 블록) 버전 2 및 3 을 사용하여 게이트웨이에 연결하는 Windows 클라이언트를 \n지원합니다. \nhttps://aws.amazon.com/ko/storagegateway/faqs/?nc=sn&loc=6 \nC(X) : A 와 같은 이유로 오답. \nD(X) : SMB 사용 여부 불투명. \n \n설명2: \nAmazon S3 File Gateway 는 온프레미스 애플리케이션이 Amazon S3 클라우드 스토리지를 \n원활하게 사용할 수 있도록 하는 하이브리드 클라우드 스토리지 서비스입니다. Amazon \nS3 에 대한 파일 인터페이스를 제공하고 SMB 및 NFS 프로토콜을 지원합니다. 또한 지정된 \n기간이 지나면 데이터를 S3 Standard 에서 S3 Glacier Deep Archive 로 자동 전환할 수 있는 \nS3 수명 주기 정책을 지원합니다. 이 솔루션은 짧은 대기 시간 액세스를 유지하면서 \n회사의 사용 가능한 저장 공간을 늘리는 요구 사항을 충족합니다. \n가장 최근에 액세스한 파일에 저장하고 파일 수명 주기 관리를 제공하여 향후 스토리지 \n문제를 방지합니다.", "answer_choice": "B"}, "10": {"q_num": 10, "question": "회사는 AWS 에서 전자 상거래 웹 애플리케이션을 구축하고 있습니다. 애플리케이션은 \n처리할 Amazon API Gateway REST API 에 새 주문에 대한 정보를 보냅니다. 회사는 주문이 \n접수된 순서대로 처리되기를 원합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. API Gateway 통합을 사용하여 애플리케이션이 주문을 수신할 때 Amazon Simple \nNotification Service(Amazon SNS) 주제에 메시지를 게시합니다. AWS Lambda 함수를 \n주제에 구독하여 처리를 수행합니다. \nB. API Gateway 통합을 사용하여 애플리케이션이 주문을 수신할 때 Amazon Simple Queue \nService(Amazon SQS) FIFO 대기열에 메시지를 보냅니다. 처리를 위해 AWS Lambda \n함수를 호출하도록 SQS FIFO 대기열을 구성합니다.  \nC. API Gateway 권한 부여자를 사용하여 애플리케이션이 주문을 처리하는 동안 모든 \n요청을 차단합니다. \nD. API Gateway 통합을 사용하여 애플리케이션이 주문을 수신할 때 Amazon Simple Queue \nService(Amazon SQS) 표준 대기열에 메시지를 보냅니다. 처리를 위해 AWS Lambda \n함수를 호출하도록 SQS 표준 대기열을 구성합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/84681-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명:・ \n주문이 \n접수된 \n순서대로 \n처리되도록 \n하기 \n위한 \n최상의 \n솔루션은 \nAmazon \nSQS \nFIFO(선입선출) 대기열을 사용하는 것입니다. 이 유형의 대기열은 메시지를 보내고 받는 \n정확한 순서를 유지합니다. 이 경우 애플리케이션은 새 주문에 대한 정보를 Amazon API \nGateway REST API 로 보낼 수 있습니다. 그런 다음 API Gateway 통합을 사용하여 처리를 \n위해 메시지를 Amazon SQS FIFO 대기열로 보낼 수 있습니다. 그런 다음 AWS Lambda \n함수를 호출하여 각 주문에 필요한 처리를 수행하도록 대기열을 구성할 수 있습니다. \n이렇게 하면 주문이 접수된 정확한 순서대로 처리됩니다. \n즉. 주문한 순서대로 = FIFO", "answer_choice": "B"}, "11": {"q_num": 11, "question": "회사에 Amazon EC2 인스턴스에서 실행되고 Amazon Aurora 데이터베이스를 사용하는 \n애플리케이션이 있습니다. EC2 인스턴스는 파일에 로컬로 저장된 사용자 이름과 암호를 \n사용하여 \n데이터베이스에 \n연결합니다. \n회사는 \n자격 \n증명 \n관리의 \n운영 \n오버헤드를 \n\n최소화하려고 합니다. \n솔루션 설계자는 이 목표를 달성하기 위해 무엇을 해야 합니까? \nA. AWS Secrets Manager 를 사용합니다. 자동 회전을 켭니다.  \nB. AWS Systems Manager Parameter Store 를 사용합니다. 자동 회전을 켭니다. \nC. AWS Key Management Service(AWS KMS) 암호화 키로 암호화된 객체를 저장할 Amazon \nS3 \n버킷을 \n생성합니다. \n자격 \n증명 \n파일을 \nS3 \n버킷으로 \n마이그레이션합니다. \n애플리케이션이 S3 버킷을 가리키도록 합니다. \nD. 각 EC2 인스턴스에 대해 암호화된 Amazon Elastic Block Store(Amazon EBS) 볼륨을 \n생성합니다. 새 EBS 볼륨을 각 EC2 인스턴스에 연결합니다. 자격 증명 파일을 새 EBS \n볼륨으로 마이그레이션합니다. 애플리케이션이 새 EBS 볼륨을 가리키도록 합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/84682-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명:・ \nA(O) : Secrets Manager 는 자격증명을 저장해두고 관리할 수 있는 서비스. \nAWS Secrets Manager 는 애플리케이션, 서비스 및 IT 리소스에 대한 액세스를 보호하는 데 \n도움이 되는 보안 정보 관리 서비스입니다. 이 서비스를 사용하면 수명 주기 동안 \n데이터베이스 자격 증명, API 키 및 기타 보안 정보를 손쉽게 교체, 관리 및 검색할 수 \n있습니다. https://aws.amazon.com/ko/secrets-manager/faqs/ \nSecrets Manager 에서 보안 암호에 대한 자동 교체를 설정할 수 있습니다. \nhttps://docs.aws.amazon.com/secretsmanager/latest/userguide/rotating-secrets.html \nB(X) : Systems Manager Parameter Store 는 구성 데이터 같은 걸 코드와 분리하여 원치 \n않는 노출을 막는 것. \nQ:AWS Systems Manager parameter store 란 무엇입니까? AWS Systems Manager 는 \n데이터베이스 문자열과 같은 평문 데이터든 암호와 같은 비밀이든 관계없이 구성 데이터를 \n관리할 수 있는 중앙 스토어를 제공합니다. 따라서 비밀과 구성 데이터를 코드와 분리할 수 \n있습니다. https://aws.amazon.com/ko/systems-manager/faq/ \nC(X) : KMS 키는 S3 버킷에 저장하는 것이 아니라 Secrets Manager 등을 이용해 관리. \nD(X) : C 와 비슷한 이유로 오답.\"", "answer_choice": "A"}, "12": {"q_num": 12, "question": "글로벌 회사는 ALB(Application Load Balancer) 뒤의 Amazon EC2 인스턴스에서 웹 \n애플리케이션을 호스팅합니다. 웹 애플리케이션에는 정적 데이터와 동적 데이터가 있습니다. \n회사는 정적 데이터를 Amazon S3 버킷에 저장합니다. 회사는 정적 데이터 및 동적 \n\n데이터의 성능을 개선하고 대기 시간을 줄이기를 원합니다. 회사는 Amazon Route 53 에 \n등록된 자체 도메인 이름을 사용하고 있습니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. S3 버킷과 ALB\n를 오리진으로 포함하는 Amazon CloudFront 배포를 생성합니다. \nCloudFront 배포로 트래픽을 라우팅하도록 Route 53 을 구성합니다.  \nB. ALB 가 오리진인 Amazon CloudFront 배포를 생성합니다. S3 버킷을 엔드포인트로 \n포함하는 AWS Global Accelerator 표준 액셀러레이터를 생성합니다. CloudFront 배포로 \n트래픽을 라우팅하도록 Route 53 을 구성합니다. \nC. S3 버킷을 오리진으로 포함하는 Amazon CloudFront 배포를 생성합니다. ALB 및 \nCloudFront 배포를 엔드포인트로 포함하는 AWS Global Accelerator 표준 액셀러레이터를 \n생성합니다. 가속기 DNS 이름을 가리키는 사용자 지정 도메인 이름을 만듭니다. 사용자 \n지정 도메인 이름을 웹 애플리케이션의 끝점으로 사용합니다. \nD. ALB 가 오리진인 Amazon CloudFront 배포를 생성합니다. S3 버킷을 엔드포인트로 \n포함하는 AWS Global Accelerator 표준 액셀러레이터를 생성합니다. 두 개의 도메인 이름을 \n만듭니다. 하나의 도메인 이름이 동적 콘텐츠의 CloudFront DNS 이름을 가리키도록 합니다. \n다른 도메인 이름이 정적 콘텐츠에 대한 가속기 DNS 이름을 가리키도록 합니다. 도메인 \n이름을 웹 애플리케이션의 끝점으로 사용합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/85010-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nA(O) : 배포를 만들 때 CloudFront 가 파일에 대한 요청을 보내는 원본을 지정합니다. \nCloudFront 에서 여러 원본을 사용할 수 있습니다. 예를 들어 Amazon S3 버킷, MediaStore \n컨테이너, MediaPackage 채널, Application Load Balancer 또는 AWS Lambda 함수 URL 을 \n사용할 수 있습니다. \nhttps://docs.aws.amazon.com/ko_kr/AmazonCloudFront/latest/DeveloperGuide/Download\nDistS3AndCustomOrigins.html \nAmazon Route 53 을 구성하여 CloudFront 배포로 트래픽을 라우팅합니다. 이하 항목 참고 \nhttps://docs.aws.amazon.com/ko_kr/Route53/latest/DeveloperGuide/routing-to-cloudfro\nnt-distribution.html \nB(X) : 지문의 상황은 애플리케이션 계층에서 벌어지는 일이므로 TCP/UDP 를 사용하는 \nAWS Global Accelerator 는 부적절. \nC(X) : B 와 같은 이유로 오답. \nD(X) : B 와 같은 이유로 오답. \n \n\n설명2: \n정적 콘텐츠는 S3 의 클라우드 프런트 엣지 위치와 ALB 뒤의 동적 콘텐츠 EC2 에서 캐싱할 \n수 있습니다. 그 성능은 하나의 엔드포인트가 ALB 이고 다른 클라우드 프런트인 Global \nAccelerator 에 의해 개선될 수 있습니다. \n따라서 사용자 지정 도메인 이름 끝점과 관련하여 웹 응용 프로그램은 웹 응용 프로그램에 \n대한 사용자 지정 도메인 지점에 대한 R53 별칭 레코드입니다. \nhttps://aws.amazon.com/blogs/networking-and-content-delivery/improving-availability-a\nndperformance-for-app", "answer_choice": "A"}, "13": {"q_num": 13, "question": "회사는 AWS 인프라에 대한 월별 유지 관리를 수행합니다. 이러한 유지 관리 활동 중에 \n회사는 여러 AWS 리전에서 MySQL 용 Amazon RDS 데이터베이스에 대한 자격 증명을 \n교체해야 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 자격 증명을 AWS Secrets Manager 에 암호로 저장합니다. 필요한 리전에 대해 다중 \n리전 비밀 복제를 사용합니다. 일정에 따라 보안 암호를 교체하도록 Secrets Manager 를 \n구성합니다.  \nB. 보안 문자열 파라미터를 생성하여 AWS Systems Manager 에 자격 증명을 보안 암호로 \n저장합니다. 필요한 리전에 대해 다중 리전 비밀 복제를 사용합니다. 일정에 따라 암호를 \n교체하도록 Systems Manager 를 구성합니다. \nC. 서버 측 암호화(SSE)가 활성화된 Amazon S3 버킷에 자격 증명을 저장합니다. Amazon \nEventBridge(Amazon CloudWatch Events)를 사용하여 AWS Lambda 함수를 호출하여 자격 \n증명을 교체합니다. \nD. AWS Key Management Service(AWS KMS) 다중 리전 고객 관리형 키를 사용하여 자격 \n증명을 비밀로 암호화합니다. Amazon DynamoDB 전역 테이블에 암호를 저장합니다. AWS \nLambda 함수를 사용하여 DynamoDB 에서 암호를 검색합니다. RDS API 를 사용하여 비밀을 \n교체합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/84728-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명:・ \n다중 리전 애플리케이션에 필수 리전의 복제된 암호에 대한 액세스 권한을 부여하고 \nSecrets Manager 를 사용하여 복제본이 기본 암호와 동기화된 상태를 유지할 수 있습니다. \nSecrets Manager 를 사용하면 데이터베이스 자격 증명, API 키 및 기타 비밀을 포함한 \n\n비밀을 저장, 검색, 관리 및 교체할 수 있습니다. \nhttps://aws.amazon.com/ko/blogs/security/how-to-replicate-secrets-aws-secrets-mana\nger-multiple-regions/", "answer_choice": "A"}, "14": {"q_num": 14, "question": "회사는 Application Load Balancer 뒤의 Amazon EC2 인스턴스에서 전자 상거래 \n애플리케이션을 실행합니다. 인스턴스는 여러 가용 영역에 걸쳐 Amazon EC2 Auto Scaling \n그룹에서 실행됩니다. Auto Scaling 그룹은 CPU 사용률 메트릭을 기반으로 확장됩니다. \n전자 \n상거래 \n애플리케이션은 \n대규모 \nEC2 \n인스턴스에서 \n호스팅되는 \nMySQL \n8.0 \n데이터베이스에 트랜잭션 데이터를 저장합니다. \n애플리케이션 로드가 증가하면 데이터베이스의 성능이 빠르게 저하됩니다. 애플리케이션은 \n쓰기 트랜잭션보다 더 많은 읽기 요청을 처리합니다. 이 회사는 고가용성을 유지하면서 \n예측할 수 없는 읽기 워크로드의 수요를 충족하도록 데이터베이스를 자동으로 확장하는 \n솔루션을 원합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 리더 및 컴퓨팅 기능을 위해 단일 노드와 함께 Amazon Redshift 를 사용하십시오. \nB. 단일 AZ 배포와 함께 Amazon RDS 사용 다른 가용 영역에 리더 인스턴스를 추가하도록 \nAmazon RDS 를 구성합니다. \nC. 다중 AZ 배포와 함께 Amazon Aurora 를 사용합니다. Aurora 복제본을 사용하여 Aurora \nAuto Scaling 을 구성합니다.  \nD. EC2 스팟 인스턴스와 함께 Memcached 용 Amazon ElastiCache 를 사용합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/85019-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \nA(X) : 단일 노드에서 고가용성 불만족. RedShift 는 MySQL 과 같은 관계형 데이터베이스 \n서비스가 아니라 데이터 웨어하우스 서비스. \nB(X) : 단일 AZ 이기 때문에 고가용성 불만족. \nC(O) : Aurora 는 자동으로 3 개의 AZ 에 6 개의 복제본을 생성. 이러한 복제본은 읽기 부하 \n분산 효과가 있음. \nD(X) : 스팟 인스턴스를 사용할 때는 언제든 중지될 위험에 대비해야 함이 기본임. 즉, \n중지될 수 있는 위험이 높은 인스턴스라는 이야기. 그리고 다중 AZ 를 사용하지 않으므로 \n고가용성을 만족하지 못했음. \n \n\n설명2: \nAurora 는 RDS 에서 MySQL 보다 5 배 향상된 성능을 제공하며 쓰기보다 더 많은 읽기 \n요청을 처리합니다. 고가용성 유지 = 다중 AZ 배포.", "answer_choice": "C"}, "15": {"q_num": 15, "question": "최근에 AWS\n로 마이그레이션한 회사가 프로덕션 VPC\n로 들어오고 나가는 트래픽을 \n보호하는 솔루션을 구현하려고 합니다. 이 회사는 사내 데이터 센터에 검사 서버를 가지고 \n있었습니다. 검사 서버는 트래픽 흐름 검사 및 트래픽 필터링과 같은 특정 작업을 \n수행했습니다. 회사는 AWS 클라우드에서 동일한 기능을 갖기를 원합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 프로덕션 VPC 에서 트래픽 검사 및 트래픽 필터링에 Amazon GuardDuty 를 사용합니다. \nB. 트래픽 미러링을 사용하여 트래픽 검사 및 필터링을 위해 프로덕션 VPC 의 트래픽을 \n미러링합니다. \nC. AWS 네트워크 방화벽을 사용하여 프로덕션 VPC 에 대한 트래픽 검사 및 트래픽 \n필터링에 필요한 규칙을 생성합니다. \nD. AWS Firewall Manager 를 사용하여 프로덕션 VPC 에 대한 트래픽 검사 및 트래픽 \n필터링에 필요한 규칙을 생성합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/84731-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \nAWS Network Firewall 은 필요에 따라 검사와 필터링을 모두 지원합니다. \n \n설명2: \nA(X) : GuardDuty 는 계정 보호 서비스. \nAmazon GuardDuty 는 AWS 계정 및 워크로드에서 악의적 활동을 모니터링하고 상세한 \n보안 결과를 제공하여 가시성 및 해결을 촉진하는 위협 탐지 서비스입니다. \nhttps://aws.amazon.com/ko/guardduty/ \nB(X) : 트래픽 미러링은 네트워크 트래픽 복사 서비스. \n트래픽 미러링은 유형의 탄력적 네트워크 인터페이스에서 네트워크 트래픽을 복사하는 데 \n사용할 수 있는 Amazon VPC 기능입니다. \nhttps://docs.aws.amazon.com/vpc/latest/mirroring/what-is-traffic-mirroring.html \nC(O) : AWS Network Firewall 을 사용하면 VPC 경계에서 네트워크 트래픽을 필터링할 수 \n있습니다. \n\nhttps://docs.aws.amazon.com/ko_kr/vpc/latest/userguide/network-firewall.html \nD(X) : Firewall Manager 는 중앙에서 방화벽 규칙 관리하는 서비스. \nAWS Firewall Manager 는 AWS Organization 의 여러 계정과 애플리케이션에서 방화벽 \n규칙을 중앙에서 구성 및 관리할 수 있는 보안 관리 서비스입니다. AWS Firewall Manager 를 \n사용하면 조직의 여러 계정 및 리소스에 대한 AWS WAF 규칙, AWS Shield Advanced 보호, \nAmazon Virtual Private Cloud(VPC) 보안 그룹 및 AWS Network Firewall 및 Amazon Route \n53 Resolver DNS Firewall 규칙을 중앙에서 구성할 수 있습니다. \nhttps://aws.amazon.com/ko/firewall-manager/faqs/", "answer_choice": "C"}, "16": {"q_num": 16, "question": "회사는 AWS\n에서 데이터 레이크를 호스팅합니다. 데이터 레이크는 Amazon S3 및 \nPostgreSQL 용 Amazon RDS 의 데이터로 구성됩니다. 이 회사는 데이터 시각화를 제공하고 \n데이터 레이크 내의 모든 데이터 소스를 포함하는 보고 솔루션이 필요합니다. 회사의 관리 \n팀만 모든 시각화에 대한 전체 액세스 권한을 가져야 합니다. 나머지 회사는 제한된 액세스 \n권한만 가져야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. Amazon QuickSight 에서 분석을 생성합니다. 모든 데이터 소스를 연결하고 새 데이터 \n세트를 만듭니다. 대시보드를 게시하여 데이터를 시각화합니다. 적절한 IAM 역할과 \n대시보드를 공유합니다. \nB. Amazon QuickSight 에서 분석을 생성합니다. 모든 데이터 소스를 연결하고 새 데이터 \n세트를 만듭니다. 대시보드를 게시하여 데이터를 시각화합니다. 적절한 사용자 및 그룹과 \n대시보드를 공유합니다. \nC. Amazon S3 의 데이터에 대한 AWS Glue 테이블 및 크롤러를 생성합니다. AWS Glue 추출, \n변환 및 로드(ETL) 작업을 생성하여 보고서를 생성합니다. 보고서를 Amazon S3\n에 \n게시합니다. S3 버킷 정책을 사용하여 보고서에 대한 액세스를 제한합니다. \nD. Amazon S3 의 데이터에 대한 AWS Glue 테이블과 크롤러를 생성합니다. Amazon Athena \n연합 쿼리를 사용하여 PostgreSQL 용 Amazon RDS 내의 데이터에 액세스합니다. Amazon \nAthena 를 사용하여 보고서를 생성합니다. 보고서를 Amazon S3 에 게시합니다. S3 버킷 \n정책을 사용하여 보고서에 대한 액세스를 제한합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/84732-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \n시각화 = QuickSight. A,B 둘 중 하나가 정답. 대시보드를 그룹과 사용자와 공유해야하므로 \n\n정답은 B. \n기본적으로 Amazon QuickSight\n의 대시보드는 누구와도 공유되지 않으며 소유자만 \n액세스할 수 있습니다. 그러나 대시보드를 게시한 후에는 QuickSight 계정의 다른 사용자 \n또는 그룹과 공유할 수 있습니다. \nhttps://docs.aws.amazon.com/quicksight/latest/user/sharing-a-dashboard.html \n \n설명2: \nAmazon QuickSight 는 PostgreSQL 용 Amazon S3 및 Amazon RDS 를 비롯한 다양한 \n데이터 소스에서 대화형 대시보드 및 보고서를 생성할 수 있는 데이터 시각화 서비스입니다. \n모든 데이터 소스를 연결하고 QuickSight 에서 새 데이터 세트를 만든 다음 대시보드를 \n게시하여 데이터를 시각화할 수 있습니다. 또한 적절한 사용자 및 그룹과 대시보드를 \n공유하고 IAM 역할 및 권한을 사용하여 액세스 수준을 제어할 수 있습니다.", "answer_choice": "B"}, "17": {"q_num": 17, "question": "회사에서 새로운 비즈니스 애플리케이션을 구현하고 있습니다. 이 애플리케이션은 두 개의 \nAmazon EC2 인스턴스에서 실행되며 문서 저장을 위해 Amazon S3 버킷을 사용합니다. \n솔루션 설계자는 EC2 인스턴스가 S3 버킷에 액세스할 수 있는지 확인해야 합니다. \n솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. S3 버킷에 대한 액세스 권한을 부여하는 IAM 역할을 생성합니다. 역할을 EC2 \n인스턴스에 연결합니다. \nB. S3 버킷에 대한 액세스 권한을 부여하는 IAM 정책을 생성합니다. 정책을 EC2 \n인스턴스에 연결합니다. \nC. S3 버킷에 대한 액세스 권한을 부여하는 IAM 그룹을 생성합니다. 그룹을 EC2 \n인스턴스에 연결합니다. \nD. S3 버킷에 대한 액세스 권한을 부여하는 IAM 사용자를 생성합니다. 사용자 계정을 EC2 \n인스턴스에 연결합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/85032-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \nhttps://aws.amazon.com/premiumsupport/knowledge-center/ec2-instance-access-s3-b\nucket/ \n \n설명2: \n\nEC2 인스턴스가 S3 버킷에 액세스할 수 있는 권한이 있어야 하므로 IAM 역할을 부여해야 \n함. \nEC2 인스턴스에서 S3 버킷에 연결하려면 다음을 실행해야 합니다. \n1. Amazon S3 에 대한 액세스 권한을 부여하는 AWS Identity and Access Management(IAM) \n프로파일 역할을 생성합니다. \n2. 인스턴스에 IAM 인스턴스 프로파일을 연결합니다. \n3. S3 버킷에 대한 권한을 확인합니다. \nhttps://aws.amazon.com/ko/premiumsupport/knowledge-center/ec2-instance-access-s\n3-bucket/", "answer_choice": "A"}, "18": {"q_num": 18, "question": "애플리케이션 개발 팀은 큰 이미지를 더 작은 압축 이미지로 변환하는 마이크로서비스를 \n설계하고 있습니다. 사용자가 웹 인터페이스를 통해 이미지를 업로드하면 마이크로 \n서비스는 이미지를 Amazon S3 버킷에 저장하고, AWS Lambda 함수로 이미지를 처리 및 \n압축하고, 다른 S3 버킷에 압축된 형태로 이미지를 저장해야 합니다. \n솔루션 설계자는 내구성이 있는 상태 비저장 구성 요소를 사용하여 이미지를 자동으로 \n처리하는 솔루션을 설계해야 합니다. \n이러한 요구 사항을 충족하는 작업 조합은 무엇입니까? (2 개를 선택하세요.) \nA. Amazon Simple Queue Service(Amazon SQS) 대기열을 생성합니다. 이미지가 S3 버킷에 \n업로드될 때 SQS 대기열에 알림을 보내도록 S3 버킷을 구성합니다. \nB. Amazon Simple Queue Service(Amazon SQS) 대기열을 호출 소스로 사용하도록 Lambda \n함수를 구성합니다. SQS 메시지가 성공적으로 처리되면 대기열에서 메시지를 삭제합니다. \nC. 새 업로드에 대해 S3 버킷을 모니터링하도록 Lambda 함수를 구성합니다. 업로드된 \n이미지가 감지되면 메모리의 텍스트 파일에 파일 이름을 쓰고 텍스트 파일을 사용하여 \n처리된 이미지를 추적합니다. \nD. Amazon EC2 인스턴스를 시작하여 Amazon Simple Queue Service(Amazon SQS) \n대기열을 모니터링합니다. 항목이 대기열에 추가되면 EC2 인스턴스의 텍스트 파일에 파일 \n이름을 기록하고 Lambda 함수를 호출합니다. \nE. Amazon EventBridge(Amazon CloudWatch Events) 이벤트를 구성하여 S3 버킷을 \n모니터링합니다. 이미지가 업로드되면 추가 처리를 위해 애플리케이션 소유자의 이메일 \n주소와 함께 Amazon ample Notification Service(Amazon SNS) 주제에 알림을 보냅니다.", "answer_block": "Answer: A, B \nhttps://www.examtopics.com/discussions/amazon/view/85033-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n\n설명1:・ \nA,E 조합으로 S3 버킷->EventBridge->SNS Topic->SQS->Lambda 프로세스도 가능하긴 \n한데, A,B 조합으로 S3->SQS->Lambda 가 훨씬 운영 및 비용 효율적. \n・S3 Events -> SQS Queue \nAmazon S3 은 다음과 같은 대상으로 이벤트 알림 메시지를 보낼 수 있습니다....◎Amazon \nSimple Queue Service(Amazon SQS) 대기열 \nhttps://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/NotificationHowTo.html \n・SQS Queue -> Lambda \nLambda 함수를 사용하여 Amazon Simple Queue Service(Amazon SQS) 대기열의 메시지를 \n처리할 수 있습니다. \nhttps://docs.aws.amazon.com/ko_kr/lambda/latest/dg/with-sqs.html \n \n설명2: \nAmazon Simple Queue Service(SQS) 대기열을 생성하고 이미지가 S3 버킷에 업로드될 때 \nSQS 대기열에 알림을 보내도록 S3 버킷을 구성하면 Lambda 함수가 상태 비저장 및 \n내구성 방식으로 트리거됩니다. \nSQS 대기열을 호출 소스로 사용하도록 Lambda 함수를 구성하고 성공적으로 처리된 후 \n대기열에서 메시지를 삭제하면 Lambda 함수가 상태 비저장 및 내구성 방식으로 이미지를 \n처리합니다. \nAmazon SQS 는 마이크로서비스, 분산 시스템 및 서버리스 애플리케이션을 분리하고 확장할 \n수 있는 완전관리형 메시지 대기열 서비스입니다. SQS 는 메시지 지향 미들웨어 관리 및 \n운영과 관련된 복잡성과 오버헤드를 제거하고 개발자가 차별화 작업에 집중할 수 있도록 \n합니다. 새 이미지가 S3 버킷에 업로드되면 SQS 는 Lambda 함수를 트리거하여 이미지를 \n처리하고 압축합니다. 이미지가 처리되면 SQS 메시지가 삭제되어 Lambda 함수가 상태 \n비저장 및 내구성이 보장됩니다.", "answer_choice": "A"}, "19": {"q_num": 19, "question": "회사에 AWS 에 배포된 3 계층 웹 애플리케이션이 있습니다. 웹 서버는 VPC 의 퍼블릭 \n서브넷에 배포됩니다. 애플리케이션 서버와 데이터베이스 서버는 동일한 VPC 의 프라이빗 \n서브넷에 배포됩니다. 이 회사는 AWS Marketplace 의 타사 가상 방화벽 어플라이언스를 \n검사 VPC 에 배포했습니다. 어플라이언스는 IP 패킷을 수락할 수 있는 IP 인터페이스로 \n구성됩니다. \n솔루션 설계자는 트래픽이 웹 서버에 도달하기 전에 애플리케이션에 대한 모든 트래픽을 \n검사하기 위해 웹 애플리케이션을 어플라이언스와 통합해야 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \n\nA. 애플리케이션 VPC 의 퍼블릭 서브넷에 Network Load Balancer 를 생성하여 패킷 검사를 \n위해 어플라이언스로 트래픽을 라우팅합니다. \nB. 애플리케이션 VPC 의 퍼블릭 서브넷에 Application Load Balancer 를 생성하여 패킷 \n검사를 위해 어플라이언스로 트래픽을 라우팅합니다. \nC. 전송 게이트웨이를 통해 들어오는 패킷을 라우팅하도록 라우팅 테이블을 구성하는 검사 \nVPC 에 전송 게이트웨이를 배포합니다. \nD. 검사 VPC\n에 게이트웨이 로드 밸런서를 배포합니다. 게이트웨이 로드 밸런서 \n엔드포인트를 생성하여 수신 패킷을 수신하고 패킷을 어플라이언스로 전달합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/84727-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n해설:・ \nGateway Load Balancer 를 사용하면 방화벽, 침입 탐지 및 방지 시스템, 심층 패킷 검사 \n시스템과 같은 가상 어플라이언스를 배포, 확장 및 관리할 수 있습니다. Gateway Load \nBalancer 는 Gateway Load Balancer 엔드포인트를 사용하여 VPC 경계 전체에서 트래픽을 \n안전하게 교환합니다. \nhttps://docs.aws.amazon.com/ko_kr/elasticloadbalancing/latest/gateway/introduction.htm\nl \n오늘 AWS Gateway Load Balancer(GWLB)가 정식 출시되었다는 소식을 알려드리고자 \n합니다. 이를 통해 타사 가상 어플라이언스의 가용성을 쉽고 비용 효율적으로 배포, 확장 \n및 관리 할 수있는 서비스 방화벽 , 침입 감지 및 방지 시스템과 클라우드의 심층 패킷 \n검사 시스템. AWS 파트너 네트워크 및 AWS Marketplace 파트너는 규모, 가용성 및 서비스 \n제공이라는 복잡한 문제를 해결하지 않고도 AWS 고객에게 가상 어플라이언스를 서비스로 \n제공 할 수도 있습니다. \nhttps://aws.amazon.com/ko/blogs/korea/introducing-aws-gateway-load-balancer-easy-\ndeployment-scalability-and-high-availability-for-partner-appliances/", "answer_choice": "D"}, "20": {"q_num": 20, "question": "회사에서 동일한 AWS 리전의 테스트 환경에 대량의 프로덕션 데이터를 복제하는 기능을 \n개선하려고 합니다. 데이터는 Amazon Elastic Block Store(Amazon EBS) 볼륨의 Amazon \nEC2 인스턴스에 저장됩니다. 복제된 데이터를 수정해도 프로덕션 환경에 영향을 주지 \n않아야 합니다. 이 데이터에 액세스하는 소프트웨어는 일관되게 높은 I/O 성능을 \n요구합니다. \n솔루션 설계자는 프로덕션 데이터를 테스트 환경에 복제하는 데 필요한 시간을 최소화해야 \n\n합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 프로덕션 EBS 볼륨의 EBS 스냅샷을 만듭니다. 테스트 환경의 EC2 인스턴스 스토어 \n볼륨에 스냅샷을 복원합니다. \nB. EBS 다중 연결 기능을 사용하도록 프로덕션 EBS 볼륨을 구성합니다. 프로덕션 EBS \n볼륨의 EBS 스냅샷을 만듭니다. 테스트 환경의 EC2 인스턴스에 프로덕션 EBS 볼륨을 \n연결합니다. \nC. 프로덕션 EBS 볼륨의 EBS 스냅샷을 만듭니다. 새 EBS 볼륨을 생성하고 초기화합니다. \n프로덕션 EBS 스냅샷에서 볼륨을 복원하기 전에 테스트 환경의 EC2 인스턴스에 새 EBS \n볼륨을 연결합니다. \nD. 프로덕션 EBS 볼륨의 EBS 스냅샷을 만듭니다. EBS 스냅샷에서 EBS 빠른 스냅샷 복원 \n기능을 켭니다. 스냅샷을 새 EBS 볼륨으로 복원합니다. 테스트 환경의 EC2 인스턴스에 새 \nEBS 볼륨을 연결합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/85226-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n해설:・ \nA(X) : 인스턴스 스토어 볼륨은 휘발성이라 꺼지면 데이터 날라감. \nB(X) : EBS 다중 연결을 사용하게 되면 복제된 데이터를 수정할 때 프로덕션 환경에 영향을 \n주게 됨. 이는 지문에서 요구한 사항과 위배됨. \nC(X) : 스냅샷으로 새로운 볼륨을 만드는 것이지 만들어진 볼륨에 스냅샷을 복원하는 게 \n아님. \nD(O) : 정답.", "answer_choice": "D"}, "21": {"q_num": 21, "question": "전자 상거래 회사는 AWS 에서 하루 1 회 웹 사이트를 시작하려고 합니다. 매일 24 시간 \n동안 정확히 하나의 제품을 판매합니다. 회사는 피크 시간 동안 밀리초 지연 시간으로 \n시간당 수백만 개의 요청을 처리할 수 있기를 원합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Amazon S3 를 사용하여 다른 S3 버킷에 전체 웹 사이트를 호스팅합니다. Amazon \nCloudFront 배포를 추가합니다. S3 버킷을 배포의 오리진으로 설정합니다. Amazon S3 에 \n주문 데이터를 저장합니다. \nB. 여러 가용 영역의 Auto Scaling 그룹에서 실행되는 Amazon EC2 인스턴스에 전체 웹 \n사이트를 배포합니다. ALB(Application Load Balancer)를 추가하여 웹 사이트 트래픽을 \n\n분산합니다. 백엔드 API 에 대해 다른 ALB 를 추가하십시오. MySQL 용 Amazon RDS 에 \n데이터를 저장합니다. \nC. 컨테이너에서 실행되도록 전체 애플리케이션을 마이그레이션합니다. Amazon Elastic \nKubernetes Service(Amazon EKS)에서 컨테이너를 호스팅합니다. Kubernetes 클러스터 자동 \n확장 처리를 사용하여 트래픽 버스트를 처리할 포드 수를 늘리거나 줄입니다. MySQL 용 \nAmazon RDS 에 데이터를 저장합니다. \nD. Amazon S3 버킷을 사용하여 웹 사이트의 정적 콘텐츠를 호스팅합니다. Amazon \nCloudFront 배포를 배포합니다. S3 버킷을 오리진으로 설정합니다. 백엔드 API 에 Amazon \nAPI Gateway 및 AWS Lambda 함수를 사용합니다. Amazon DynamoDB 에 데이터를 \n저장합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/85195-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \nA(X) : 전체 웹사이트를 호스팅하기에는 동적인 요소들이 들어가 있을 수 있는데 \nS3+CloudFront 조합은 정적 웹사이트 호스팅을 위한 것임. \nB(X) : RDS 는 기본적으로 Auto Scaling 을 사용하지 않음. 따로 켜야하는데 해당 선택지엔 \nAuto Scaling 을 사용한단 언급이 없음. \n워크로드를 \n예측할 \n수 \n없는 \n경우 \nAmazon \nRDS \nDB \n인스턴스에 \n대해 \n스토리지 \nAutoscaling 을 활성화할 수 있습니다. \nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PIOPS.StorageTypes.\nhtml#USER_PIOPS.Autoscaling \nC(X) : B 와 동일한 이유로 오답. \nD(O) : 정적인 웹사이트 요소들은 S3 + CloudFront 로 빠르게 제공하고, API Gateway 에서 \nLambda 함수를 호출해 DynamoDB 에 데이터 저장 가능. DynamoDB 는 확장성이 뛰어나고 \n밀리초 단위 액세스를 지원하는 데이터베이스 유형. \n・S3 + CloudFront 조합의 정적 웹사이트 호스팅 :  \nhttps://aws.amazon.com/ko/premiumsupport/knowledge-center/cloudfront-serve-static-\nwebsite/ \n・즉, HTTPS 엔드포인트를 통해 API\n를 호출하면 API Gateway\n가 Lambda 함수를 \n호출합니다. \nhttps://docs.aws.amazon.com/ko_kr/lambda/latest/dg/services-apigateway-tutorial.html \n・개발자는 DynamoDB\n를 사용해 최신 서버리스 애플리케이션을 구축하여 우선 작은 \n규모에서 시작했다가 전역적으로 확장하여 초당 페타바이트 단위의 데이터와 수천만 건의 \n읽기 및 쓰기 요청을 지원하도록 할 수 있습니다.....DynamoDB 는 용량에 맞게 테이블을 \n\n자동으로 조정하므로 별도로 관리하지 않아도 성능을 유지합니다. \nhttps://aws.amazon.com/ko/dynamodb/features/#Enterprise_ready \n \n설명2: \n사용량이 많은 시간 동안 지연 시간이 밀리초이고 운영 오버헤드가 최소인 AWS 에서 하루 \n1 회 거래 웹 사이트를 시작하려면 가장 좋은 옵션은 Amazon S3 버킷을 사용하여 웹 \n사이트의 정적 콘텐츠를 호스팅하고 Amazon CloudFront 배포를 배포하는 것입니다. \nS3 버킷을 오리진으로 설정하고 백엔드 API 에 Amazon API Gateway 및 AWS Lambda \n함수를 사용하고 데이터를 Amazon DynamoDB 에 저장합니다. \n이 옵션은 최소한의 운영 오버헤드가 필요하며 사용량이 많은 시간 동안 밀리초 대기 \n시간으로 시간당 수백만 건의 요청을 처리할 수 있습니다. 따라서 보기 D 가 정답입니다.", "answer_choice": "D"}, "22": {"q_num": 22, "question": "솔루션 설계자는 Amazon S3 를 사용하여 새로운 디지털 미디어 애플리케이션의 스토리지 \n아키텍처를 설계하고 있습니다. 미디어 파일은 가용 영역 손실에 대한 복원력이 있어야 \n합니다. 일부 파일은 자주 액세스되는 반면 다른 파일은 예측할 수 없는 패턴으로 거의 \n액세스되지 \n않습니다. \n솔루션 \n설계자는 \n미디어 \n파일을 \n저장하고 \n검색하는 \n비용을 \n최소화해야 합니다. \n이러한 요구 사항을 충족하는 스토리지 옵션은 무엇입니까? \nA. S3 Standard (S3 표준) \nB. S3 Intelligent-Tiering (S3 지능형 계층화) \nC. S3 Standard-Infrequent Access(S3 Standard-IA) \nD. S3 One Zone-Infrequent Access(S3 One Zone-IA)", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/84943-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명:・ \nS3 Intelligent-Tiering - 액세스 빈도 또는 불규칙한 사용 패턴을 모를 때 완벽한 사용 \n사례입니다. \nAmazon S3 는 다양한 사용 사례를 위해 설계된 다양한 스토리지 클래스를 제공합니다. \n여기에는 자주 액세스하는 데이터의 범용 스토리지를 위한 S3 Standard 가 포함됩니다. \n액세스 패턴을 알 수 없거나 변경하는 데이터를 위한 S3 Intelligent-Tiering; S3 \nStandard-Infrequent Access(S3 Standard-IA) 및 S3 One Zone-Infrequent Access(S3 One \nZone-IA)는 수명이 길지만 액세스 빈도가 낮은 데이터를 위한 것입니다. 장기 아카이브 및 \n\n디지털 보존을 위한 Amazon S3 Glacier(S3 Glacier) 및 Amazon S3 Glacier Deep Archive(S3 \nGlacier Deep Archive). 기존 AWS 리전에서 충족할 수 없는 데이터 레지던시 요구 사항이 \n있는 경우 S3 Outposts 스토리지 클래스를 사용하여 S3 데이터를 온프레미스에 저장할 수 \n있습니다. \nAmazon S3 는 수명 주기 동안 데이터를 관리하는 기능도 제공합니다. S3 수명 주기 정책이 \n설정되면 애플리케이션을 변경하지 않고도 데이터가 자동으로 다른 스토리지 클래스로 \n전송됩니다. \nhttps://aws.amazon.com/getting-started/hands-on/getting-started-using-amazon-s3-in\ntelligent-tiering/?nc1=h_ls \n \n예측할 수 없는 패턴 = S3 Intelligent Tiering.", "answer_choice": "B"}, "23": {"q_num": 23, "question": "회사에서 Amazon S3 Standard 스토리지를 사용하여 백업 파일을 저장하고 있습니다. 1 개월 \n동안 파일에 자주 액세스합니다. 단, 1 개월 이후에는 파일에 접근하지 않습니다. 회사는 \n파일을 무기한 보관해야 합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 스토리지 솔루션은 무엇입니까? \nA. 객체를 자동으로 마이그레이션하도록 S3 Intelligent-Tiering 을 구성합니다. \nB. S3 수명 주기 구성을 생성하여 1 개월 후에 S3 Standard 에서 S3 Glacier Deep Archive 로 \n객체를 전환합니다. \nC. S3 수명 주기 구성을 생성하여 1\n개월 후에 객체를 S3 Standard\n에서 S3 \nStandard-Infrequent Access(S3 Standard-IA)로 전환합니다. \nD. S3 수명 주기 구성을 생성하여 1 개월 후에 객체를 S3 Standard\n에서 S3 One \nZone-Infrequent Access(S3 One Zone-IA)로 전환합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/85092-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명:・ \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 스토리지 솔루션은 B 입니다. \n1 개월 후에 객체를 S3 Standard 에서 S3 Glacier Deep Archive 로 전환하는 S3 수명 주기 \n구성을 생성합니다. Amazon S3 Glacier Deep Archive 는 거의 액세스하지 않고 몇 시간의 \n검색 시간이 허용되는 데이터의 장기 보존을 위한 안전하고 내구성이 있으며 매우 저렴한 \nAmazon S3 스토리지 클래스입니다. Amazon S3 에서 가장 저렴한 스토리지 옵션이므로 \n1 개월 후에 액세스하지 않는 백업 파일을 저장하는 데 비용 효율적인 선택입니다. S3 수명 \n\n주기 구성을 사용하여 1 개월 후에 객체를 S3 Standard 에서 S3 Glacier Deep Archive 로 \n자동 전환할 수 있습니다. 이렇게 하면 자주 액세스하지 않는 백업 파일의 저장 비용이 \n최소화됩니다. \n \n1 개월 이후 파일에 접근하지 않음 = S3 Glacier Deep Archive. 답은 B.", "answer_choice": "B"}, "24": {"q_num": 24, "question": "회사는 가장 최근 청구서에서 Amazon EC2 비용 증가를 관찰했습니다. 청구 팀은 몇 개의 \nEC2 인스턴스에 대한 인스턴스 유형의 원치 않는 수직적 확장을 발견했습니다. 솔루션 \n설계자는 지난 2 개월간의 EC2 비용을 비교하는 그래프를 생성하고 심층 분석을 수행하여 \n수직적 확장의 근본 원인을 식별해야 합니다. \n솔루션 설계자는 운영 오버헤드가 가장 적은 정보를 어떻게 생성해야 합니까? \nA. AWS 예산을 사용하여 예산 보고서를 생성하고 인스턴스 유형에 따라 EC2 비용을 \n비교합니다. \nB. Cost Explorer 의 세분화된 필터링 기능을 사용하여 인스턴스 유형을 기반으로 EC2 \n비용에 대한 심층 분석을 수행합니다. \nC. AWS Billing and Cost Management 대시보드의 그래프를 사용하여 지난 2 개월 동안의 \n인스턴스 유형을 기준으로 EC2 비용을 비교합니다. \nD. AWS 비용 및 사용 보고서를 사용하여 보고서를 생성하고 Amazon S3 버킷으로 \n보냅니다. Amazon S3 와 함께 Amazon QuickSight 를 소스로 사용하여 인스턴스 유형을 \n기반으로 대화형 그래프를 생성합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/85038-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명 \nAWS Cost Explorer 는 비용과 사용량을 보고 분석할 수 있는 도구입니다. 기본 그래프, Cost \nExplorer 비용 및 사용량 보고서 또는 Cost Explorer RI 보고서를 사용하여 사용량 및 \n비용을 탐색할 수 있습니다. 최대 지난 12 개월 동안의 데이터를 보고 향후 12 개월 동안 \n지출할 가능성이 있는 금액을 예측하고 구매할 예약 인스턴스에 대한 추천을 받을 수 \n있습니다. 비용 탐색기를 사용하여 추가 조사가 필요한 영역을 식별하고 비용을 이해하는 \n데 사용할 수 있는 추세를 볼 수 있습니다. \nhttps://docs.aws.amazon.com/cost-management/latest/userguide/ce-what-is.html", "answer_choice": "B"}, "25": {"q_num": 25, "question": "회사에서 응용 프로그램을 설계하고 있습니다. 애플리케이션은 AWS Lambda 함수를 \n사용하여 Amazon API Gateway 를 통해 정보를 수신하고 Amazon Aurora PostgreSQL \n데이터베이스에 정보를 저장합니다. \n개념 증명 단계에서 회사는 데이터베이스에 로드해야 하는 대용량 데이터를 처리하기 위해 \nLambda 할당량을 크게 늘려야 합니다. 솔루션 설계자는 확장성을 개선하고 구성 노력을 \n최소화하기 위해 새로운 설계를 권장해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. Lambda 함수 코드를 Amazon EC2 인스턴스에서 실행되는 Apache Tomcat 코드로 \n리팩터링합니다. 네이티브 JDBC(Java Database Connectivity) 드라이버를 사용하여 \n데이터베이스를 연결합니다. \nB. 플랫폼을 Aurora 에서 Amazon DynamoDProvision a DynamoDB Accelerator(DAX) \n클러스터로 변경합니다. DAX 클라이언트 SDK\n를 사용하여 DAX 클러스터에서 기존 \nDynamoDB API 호출을 가리킵니다. \nC. 두 개의 Lambda 함수를 설정합니다. 정보를 수신할 하나의 기능을 구성하십시오. \n정보를 데이터베이스에 로드하도록 다른 기능을 구성하십시오. Amazon Simple Notification \nService(Amazon SNS)를 사용하여 Lambda 함수를 통합합니다. \nD. 두 개의 Lambda 함수를 설정합니다. 정보를 수신할 하나의 기능을 구성하십시오. \n정보를 데이터베이스에 로드하도록 다른 기능을 구성하십시오. Amazon Simple Queue \nService(Amazon SQS) 대기열을 사용하여 Lambda 함수를 통합합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/85197-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명:・ \n대기열(SQS)로 병목 현상을 방지할 수 있습니다. \n대량의 데이터 처리 + 확장성 개선 = SQS queue + Lambda 조합.", "answer_choice": "D"}, "26": {"q_num": 26, "question": "회사는 AWS 클라우드 배포를 검토하여 Amazon S3 버킷에 무단 구성 변경이 없는지 \n확인해야 합니다. \n솔루션 설계자는 이 목표를 달성하기 위해 무엇을 해야 합니까? \nA. 적절한 규칙으로 AWS Config 를 켭니다. \nB. 적절한 검사를 통해 AWS Trusted Advisor 를 켭니다. \nC. 적절한 평가 템플릿으로 Amazon Inspector 를 켭니다. \n\nD. Amazon S3 서버 액세스 로깅을 켭니다. Amazon EventBridge(Amazon Cloud Watch \nEvents)를 구성합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/84940-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \nAWS Config 는 AWS 리소스 구성을 측정, 감사 및 평가할 수 있는 서비스입니다. Config 는 \nAWS 리소스 구성을 지속적으로 모니터링 및 기록하고, 원하는 구성을 기준으로 기록된 \n구성을 자동으로 평가해 줍니다.  \nhttps://aws.amazon.com/ko/config/ \n \n설명2: \nAmazon S3 버킷에 무단 구성 변경이 없도록 하려면 솔루션 설계자가 적절한 규칙으로 \nAWS Config 를 켜야 합니다. AWS Config 는 사용자가 업계 표준 및 내부 정책을 준수하는지 \nAWS 리소스 구성을 감사하고 평가할 수 있는 서비스입니다. 리소스가 서로 어떻게 \n관련되어 있는지에 대한 정보를 포함하여 리소스 및 해당 구성에 대한 자세한 보기를 \n제공합니다. 적절한 규칙으로 AWS Config 를 켜면 사용자는 Amazon S3 버킷에 대한 무단 \n구성 변경을 식별하고 수정할 수 있습니다.", "answer_choice": "A"}, "27": {"q_num": 27, "question": "회사에서 새 애플리케이션을 시작하고 Amazon CloudWatch 대시보드에 애플리케이션 \n지표를 표시합니다. 회사의 제품 관리자는 이 대시보드에 주기적으로 액세스해야 합니다. \n제품 관리자에게 AWS 계정이 없습니다. 솔루션 설계자는 최소 권한 원칙에 따라 제품 \n관리자에 대한 액세스를 제공해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. CloudWatch 콘솔에서 대시보드를 공유합니다. 제품 관리자의 이메일 주소를 입력하고 \n공유 \n단계를 \n완료합니다. \n대시보드에 \n대한 \n공유 \n가능한 \n링크를 \n제품 \n관리자에게 \n제공하십시오. \nB. 특히 제품 관리자를 위한 IAM 사용자를 생성합니다. CloudWatchReadOnlyAccess AWS \n관리형 정책을 사용자에게 연결합니다. 새 로그인 자격 증명을 제품 관리자와 공유하십시오. \n올바른 대시보드의 브라우저 URL 을 제품 관리자와 공유하십시오. \nC. 회사 직원을 위한 IAM 사용자를 생성합니다. ViewOnlyAccess AWS 관리형 정책을 IAM \n사용자에게 연결합니다. 새 로그인 자격 증명을 제품 관리자와 공유하십시오. 제품 \n관리자에게 CloudWatch \n콘솔로 이동하여 대시보드 섹션에서 이름으로 대시보드를 \n\n찾으라고 요청합니다. \nD. 퍼블릭 서브넷에 배스천 서버를 배포합니다. 제품 관리자가 대시보드에 액세스해야 하는 \n경우 서버를 시작하고 RDP 자격 증명을 공유합니다. 배스천 서버에서 대시보드를 볼 수 \n있는 적절한 권한이 있는 캐시된 AWS 자격 증명으로 대시보드 URL 을 열도록 브라우저가 \n구성되어 있는지 확인합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/85227-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n해설:・ \nAWS 계정에 직접 액세스할 수 없는 사람들과 CloudWatch 대시보드를 공유할 수 있습니다. \n대시보드를 공유할 때 다음 세 가지 방법으로 대시보드를 볼 수 있는 사람을 지정할 수 \n있습니다. \n◎하나의 대시보드를 공유하고 대시보드를 볼 수 있는 사람들의 특정 이메일 주소를 \n지정합니다. 이러한 각 사용자는 대시보드를 보기 위해 입력해야 하는 고유한 암호를 \n만듭니다. \n◎링크가 있는 모든 사용자가 대시보드를 볼 수 있도록 단일 대시보드를 공개적으로 \n공유합니다. \n◎계정의 모든 CloudWatch 대시보드를 공유하고 대시보드 액세스를 위한 타사 SSO(Single \nSign-On) 공급자를 지정합니다. 이 SSO 공급자 목록의 구성원인 모든 사용자는 계정의 \n모든 대시보드에 액세스할 수 있습니다. 이를 활성화하려면 SSO 공급자를 Amazon \nCognito 와 통합합니다. SSO 공급자는 SAML(Security Assertion Markup Language)을 \n지원해야 합니다. \nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch-dashbo\nard-sharing.html", "answer_choice": "A"}, "28": {"q_num": 28, "question": "회사에서 애플리케이션을 AWS\n로 마이그레이션하고 있습니다. 응용 프로그램은 다른 \n계정에 배포됩니다. 회사는 AWS Organizations 를 사용하여 중앙에서 계정을 관리합니다. \n회사의 보안 팀은 회사의 모든 계정에 SSO(Single Sign-On) 솔루션이 필요합니다. 회사는 \n사내 자체 관리 Microsoft Active Directory 에서 사용자 및 그룹을 계속 관리해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. AWS SSO 콘솔에서 AWS Single Sign-On(AWS SSO)을 활성화합니다. 단방향 포리스트 \n트러스트 또는 단방향 도메인 트러스트를 생성하여 Microsoft Active Directory 용 AWS \nDirectory Service 를 사용하여 회사의 자체 관리형 Microsoft Active Directory 를 AWS \n\nSSO 와 연결합니다. \nB. AWS SSO 콘솔에서 AWS Single Sign-On(AWS SSO)을 활성화합니다. Microsoft Active \nDirectory 용 AWS Directory Service 를 사용하여 회사의 자체 관리형 Microsoft Active \nDirectory 를 AWS SSO 와 연결하는 양방향 포리스트 트러스트를 생성합니다. \nC. AWS 디렉터리 서비스를 사용합니다. 회사의 자체 관리 Microsoft Active Directory 와 \n양방향 신뢰 관계를 만드십시오. \nD. 온프레미스에 ID 공급자(IdP)를 배포합니다. AWS SSO 콘솔에서 AWS Single \nSign-On(AWS SSO)을 활성화합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/85231-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n해설:・ \n・AWS Organizations 로 SSO 설정하여 Active Directory 사용 가능. \nAWS IAM Identity Center(AWS SSO 의 후속 서비스)를 설정하여 Active Directory 를 통해 \nAWS 계정 및 리소스에 대한 액세스를 제공하며, 별도의 작업 역할에 따라 권한을 사용자 \n지정합니다. https://aws.amazon.com/ko/organizations/features/ \n・AWS Directory Service 를 사용하여 AWS Managed Microsoft AD 디렉터리에 연결 가능. \nIAM Identity Center 는 AWS Identity and Access Management(IAM)를 기반으로 구축된 \n서비스로, \n여러 \nAWS \n계정, \nAWS \n애플리케이션 \n및 \n다른 \nSAML \n사용 \n클라우드 \n애플리케이션에 대한 액세스 관리를 간소화합니다. AWS Directory Service 를 사용하여 IAM \nIdentity Center 를 온프레미스 Active Directory(AD) 또는 AWS Managed Microsoft AD \n디렉터리에 연결할 수 있습니다. https://aws.amazon.com/ko/iam/identity-center/faqs/ \nA(X) : SSO, AWS 관리 콘솔에는 양방향 트러스트가 필요. \nAWS Managed Microsoft AD 는 수신, 발신 및 양방향(양방향)의 세 가지 신뢰 관계 방향을 \n모두 지원합니다. AWS Managed Microsoft AD 는 외부 및 포리스트 트러스트를 모두 \n지원합니다. Amazon Chime, Amazon Connect, Amazon QuickSight, AWS IAM Identity \nCenter(AWS Single Sign-On 의 후속 제품), Amazon WorkDocs, Amazon WorkMail, Amazon \nWorkSpaces 및 AWS Management Console 과 같은 AWS 엔터프라이즈 앱에는 양방향 \n신뢰가 필요합니다. Amazon EC2, Amazon RDS 및 Amazon FSx 는 단방향 또는 양방향 \n신뢰로 작동합니다. \nhttps://docs.aws.amazon.com/directoryservice/latest/admin-guide/ms_ad_setup_trust.ht\nml \nB(O) : A 와 같은 이유로 정답. \nC(X) : SSO 는 온프레미스 Active Directory 나 AWS 관리형 Microsoft AD Directory 에 연결할 \n수 있지, 온프레미스 Microsoft AD Direcotry 에 연결할 수는 없음. ▲위의 설명 참고 \n\nD(X) : IdP 는 외부 자격 증명 서비스. \n자격 증명 공급자(IdP)를 사용하면 AWS 외부의 사용자 자격 증명을 관리할 수 있고 이 \n외부 사용자 자격 증명에 계정의 AWS 리소스에 대한 사용 권한을 부여할 수 있습니다. \nhttps://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/id_roles_providers.html", "answer_choice": "B"}, "29": {"q_num": 29, "question": "회사는 UDP 연결을 사용하는 VoIP(Voice over Internet Protocol) 서비스를 제공합니다. 이 \n서비스는 Auto Scaling 그룹에서 실행되는 Amazon EC2 인스턴스로 구성됩니다. 회사는 \n여러 AWS 리전에 배포하고 있습니다. \n회사는 지연 시간이 가장 짧은 리전으로 사용자를 라우팅해야 합니다. 이 회사는 또한 지역 \n간 자동 장애 조치가 필요합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. NLB(Network Load Balancer) 및 연결된 대상 그룹을 배포합니다. 대상 그룹을 Auto \nScaling 그룹과 연결합니다. 각 리전에서 NLB 를 AWS Global Accelerator 엔드포인트로 \n사용합니다. \nB. ALB(Application Load Balancer) 및 연결된 대상 그룹을 배포합니다. 대상 그룹을 Auto \nScaling 그룹과 연결합니다. 각 리전에서 ALB 를 AWS Global Accelerator 엔드포인트로 \n사용합니다. \nC. NLB(Network Load Balancer) 및 연결된 대상 그룹을 배포합니다. 대상 그룹을 Auto \nScaling 그룹과 연결합니다. 각 NLB 의 별칭을 가리키는 Amazon Route 53 지연 시간 \n레코드를 생성합니다. 지연 시간 레코드를 오리진으로 사용하는 Amazon CloudFront 배포를 \n생성합니다. \nD. ALB(Application Load Balancer) 및 연결된 대상 그룹을 배포합니다. 대상 그룹을 Auto \nScaling 그룹과 연결합니다. 각 ALB 의 별칭을 가리키는 Amazon Route 53 가중치 레코드를 \n생성합니다. 가중 레코드를 오리진으로 사용하는 Amazon CloudFront 배포를 배포합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/85029-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n해설:・ \nUDP 연결을 사용한다고 했으므로 NLB. 대기 시간이 가장 짧은 리전으로 라우팅 + UDP \n사용 = AWS Global Accelerator. \nAWS Global Accelerator 에서 제공하는 고정 IP 주소와 AWS 엣지 로케이션의 애니캐스트를 \n리전별 AWS 리소스 또는 엔드포인트(예: Network Load Balancer, Application Load Balancer \nEC2 인스턴스 및 탄력적 IP 주소)에 연결할 수 있습니다. IP 주소는 AWS 엣지 \n\n로케이션에서 애니캐스트 되므로 사용자와 가까운 AWS 글로벌 네트워크에 온보딩 기능을 \n제공합니다. \nhttps://aws.amazon.com/ko/global-accelerator/faqs/ \n \nhttps://aws.amazon.com/global-accelerator/faqs/ \nHTTP /HTTPS - ALB ; TCP and UDP - NLB; Lowest latency routing and more throughput. \nAlso supports failover, uses Anycast Ip addressing - Global Accelerator Caching at Egde \nLocations - CloudFront WS Global Accelerator automatically checks the health of your \napplications and routes user traffic only to healthy application endpoints. If the health status \nchanges or you make configuration updates, AWS Global Accelerator reacts instantaneously \nto route your users to the next available endpoint.", "answer_choice": "A"}, "30": {"q_num": 30, "question": "개발 팀은 성능 개선 도우미가 활성화된 MySQL DB 인스턴스용 범용 Amazon RDS 에서 \n매월 리소스 집약적 테스트를 실행합니다. 테스트는 한 달에 한 번 48 시간 동안 지속되며 \n데이터베이스를 사용하는 유일한 프로세스입니다. 팀은 DB 인스턴스의 컴퓨팅 및 메모리 \n속성을 줄이지 않고 테스트 실행 비용을 줄이려고 합니다. \n어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족합니까? \nA. 테스트가 완료되면 DB 인스턴스를 중지합니다. 필요한 경우 DB 인스턴스를 다시 \n시작합니다. \nB. DB 인스턴스와 함께 Auto Scaling 정책을 사용하여 테스트가 완료되면 자동으로 \n확장합니다. \nC. 테스트가 완료되면 스냅샷을 만듭니다. DB 인스턴스를 종료하고 필요한 경우 스냅샷을 \n복원합니다. \nD. 테스트가 완료되면 DB 인스턴스를 저용량 인스턴스로 수정합니다. 필요한 경우 DB \n인스턴스를 다시 수정합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/85030-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n해설:・ \n한 달에 한 번 48 시간 동안만 사용하고, 가장 비용 효율적인 방법을 사용해야하므로 \n스냅샷이 제일 저렴. \nA(X) : DB 인스턴스를 중지해도 DB 인스턴스가 돌아가는 EBS 볼륨이나 이런 건 사용하지 \n않아도 보유 중인 용량에 따라 요금이 부과됨. \nB(X) : Auto Scaling 을 사용하게 되면 사용하지 않을 때에도 인스턴스가 실행 상태가 되므로 \n\n스냅샷 보관보다 비용이 더 부과됨 \nC(O) : 스냅샷으로 보관해서 저장하면 스냅샷 용량만큼만 비용이 부과됨. \nD(X) : 사용 중이 아닐 때도 인스턴스가 실행 상태이므로 스냅샷 보관보다 비용이 더 \n부과됨", "answer_choice": "C"}, "31": {"q_num": 31, "question": "AWS 에서 웹 애플리케이션을 호스팅하는 회사는 모든 Amazon EC2 인스턴스를 보장하기를 \n원합니다. Amazon RDS DB 인스턴스. Amazon Redshift 클러스터는 태그로 구성됩니다. \n회사는 이 검사를 구성하고 운영하는 노력을 최소화하기를 원합니다. \n솔루션 설계자는 이를 달성하기 위해 무엇을 해야 합니까? \nA. AWS Config 규칙을 사용하여 적절하게 태그가 지정되지 않은 리소스를 정의하고 \n감지합니다. \nB. 비용 탐색기를 사용하여 제대로 태그가 지정되지 않은 리소스를 표시합니다. 해당 \n리소스에 수동으로 태그를 지정합니다. \nC. 적절한 태그 할당을 위해 모든 리소스를 확인하는 API 호출을 작성합니다. EC2 \n인스턴스에서 주기적으로 코드를 실행합니다. \nD. 적절한 태그 할당을 위해 모든 리소스를 확인하는 API 호출을 작성합니다. Amazon \nCloudWatch 를 통해 AWS Lambda 함수를 예약하여 코드를 주기적으로 실행합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/85198-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \n사후 대응적 거버넌스는 Resource Groups Tagging API, AWS Config Rules, 사용자 지정 \n스크립트 등의 도구를 사용하여 제대로 태그가 지정되지 않은 리소스를 찾습니다. \nhttps://docs.aws.amazon.com/ko_kr/general/latest/gr/aws_tagging.html \n \n설명2: \n모든 Amazon EC2 인스턴스, Amazon RDS DB 인스턴스 및 Amazon Redshift 클러스터가 \n태그로 구성되도록 하려면 솔루션 설계자가 AWS Config 규칙을 사용하여 적절하게 태그가 \n지정되지 않은 리소스를 정의하고 감지해야 합니다. AWS Config 규칙은 AWS Config 가 \n모범 사례 및 회사 정책을 준수하는지 AWS 리소스 구성을 평가하는 데 사용하는 사용자 \n지정 가능한 규칙 세트입니다. AWS Config 규칙을 사용하면 비준수 리소스를 식별하고 \n담당 팀에 알리는 프로세스를 자동화하므로 이 검사를 구성하고 운영하는 노력을 최소화할 \n수 있습니다. \n\n참조: AWS Config 규칙: \n(https://docs.aws.amazon.com/ko_kr/config/latest/developerguide/evaluate-config_use-\nmanaged-rules.html)", "answer_choice": "A"}, "32": {"q_num": 32, "question": "개발 팀은 다른 팀이 액세스할 웹사이트를 호스팅해야 합니다. 웹사이트 콘텐츠는 HTML, \nCSS, 클라이언트 측 JavaScript 및 이미지로 구성됩니다. \n웹 사이트 호스팅에 가장 비용 효율적인 방법은 무엇입니까? \nA. 웹 사이트를 컨테이너화하고 AWS Fargate 에서 호스팅합니다. \nB. Amazon S3 버킷을 생성하고 거기에서 웹 사이트를 호스팅합니다. \nC. Amazon EC2 인스턴스에 웹 서버를 배포하여 웹 사이트를 호스팅합니다. \nD. Express.js 프레임워크를 사용하는 AWS Lambda 대상으로 Application Load Balancer 를 \n구성합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/85199-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \n정적 웹 사이트에서 웹 페이지는 사전 구축된 서버에 의해 반환됩니다. HTML, CSS 또는 \nJavaScript 와 같은 간단한 언어를 사용합니다. 정적 웹 사이트에서는 서버에서(사용자에 \n따라) 콘텐츠를 처리하지 않습니다. 웹 페이지는 변경 없이 서버에 의해 반환되므로 정적 \n웹 사이트는 빠릅니다. 데이터베이스와의 상호 작용이 없습니다. \n또한 호스트가 다른 언어로 서버 측 처리를 지원할 필요가 없기 때문에 비용이 적게 듭니다. \n동적 웹 사이트에서 웹 페이지는 런타임 중에 처리되는 서버에 의해 반환됩니다. 즉, 사전 \n구축된 웹 페이지가 아니라 사용자의 요구에 따라 런타임 중에 구축됩니다. 이들은 PHP, \nNode.js, ASP.NET 및 서버에서 지원하는 더 많은 것과 같은 서버 측 스크립팅 언어를 \n사용합니다. 따라서 정적 웹 사이트보다 느리지만 업데이트 및 데이터베이스와의 상호 \n작용이 가능합니다. \n \n설명2: \n모두 정적 웹사이트 콘텐츠 유형에 해당. \nAmazon S3\n를 사용하여 웹 서버를 구성하거나 관리할 필요 없이 정적 웹 사이트를 \n호스팅할 수 있습니다. 다음 단계를 완료하여 웹사이트에 모든 고정 자산을 호스팅할 새 \nAmazon S3 버킷을 생성합니다. 이 자산에는 HTML, CSS, JavaScript, 이미지 파일이 \n포함됩니다. \n\nhttps://aws.amazon.com/ko/getting-started/hands-on/app-onboarding/module-5/", "answer_choice": "B"}, "33": {"q_num": 33, "question": "회사는 AWS 에서 온라인 마켓플레이스 웹 애플리케이션을 실행합니다. 이 애플리케이션은 \n피크 시간에 수십만 명의 사용자에게 서비스를 제공합니다. 이 회사는 수백만 건의 금융 \n거래 세부 정보를 다른 여러 내부 애플리케이션과 공유할 수 있는 확장 가능한 거의 실시간 \n솔루션이 필요합니다. 또한 지연 시간이 짧은 검색을 위해 문서 데이터베이스에 저장하기 \n전에 민감한 데이터를 제거하기 위해 트랜잭션을 처리해야 합니다. \n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까? \nA. 트랜잭션 데이터를 Amazon DynamoDB 에 저장합니다. 쓰기 시 모든 트랜잭션에서 \n민감한 데이터를 제거하도록 DynamoDB 에서 규칙을 설정합니다. DynamoDB 스트림을 \n사용하여 다른 애플리케이션과 트랜잭션 데이터를 공유합니다. \nB. 트랜잭션 데이터를 Amazon Kinesis Data Firehose 로 스트리밍하여 Amazon DynamoDB \n및 Amazon S3 에 데이터를 저장합니다. Kinesis Data Firehose 와 AWS Lambda 통합을 \n사용하여 민감한 데이터를 제거하십시오. 다른 애플리케이션은 Amazon S3\n에 저장된 \n데이터를 사용할 수 있습니다. \nC. 트랜잭션 데이터를 Amazon Kinesis Data Streams 로 스트리밍합니다. AWS Lambda \n통합을 사용하여 모든 트랜잭션에서 민감한 데이터를 제거한 다음 Amazon DynamoDB 에 \n트랜잭션 데이터를 저장합니다. 다른 애플리케이션은 Kinesis 데이터 스트림의 트랜잭션 \n데이터를 사용할 수 있습니다. \nD. 일괄 처리된 트랜잭션 데이터를 Amazon S3 에 파일로 저장합니다. Amazon S3 에서 \n파일을 업데이트하기 전에 AWS Lambda\n를 사용하여 모든 파일을 처리하고 민감한 \n데이터를 제거하십시오. 그러면 Lambda 함수가 Amazon DynamoDB\n에 데이터를 \n저장합니다. 다른 애플리케이션은 Amazon S3\n에 저장된 트랜잭션 파일을 사용할 수 \n있습니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/85201-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \n피크 시간에 수십만 명의 사용자에게 서비스 제공 = Kinesis 사용. B,C 둘 중 하나가 답. \nB(X) : Kinesis Data Firehose 는 데이터 변환 및 전송 서비스. 데이터 수집을 하려면 Kinesis \nData Streams 가 필요. \nKinesis Data Firehose 로 데이터를 보내도록 데이터 생산자를 구성하면 지정한 대상으로 \n데이터가 자동으로 전달됩니다. 데이터를 전송하기 전에 변환하도록 Kinesis Data \n\nFirehose 를 구성할 수도 있습니다. \nhttps://docs.aws.amazon.com/firehose/latest/dev/what-is-this-service.html \nC(O) : Amazon Kinesis Data Streams 를 사용하면 특수 요구에 맞춰 스트리밍 데이터를 처리 \n또는 분석하는 사용자 지정 애플리케이션을 구축할 수 있습니다. 수십 만개의 소스에서 \n클릭 스트림, 애플리케이션 로그, 소셜 미디어와 같은 다양한 유형의 데이터를 Kinesis \n데이터 스트림에 추가할 수 있습니다. 그러면 몇 초 안에 애플리케이션에서 스트림의 해당 \n데이터를 읽고 처리할 수 있습니다. \nhttps://aws.amazon.com/ko/kinesis/data-streams/faqs/?nc=sn&loc=6 \n \n설명2: \nKinesis Data Firehose 전송 스트림의 대상입니다. Kinesis Data Firehose 는 Amazon Simple \nStorage Service(Amazon S3), Amazon 을 비롯한 다양한 대상으로 데이터 레코드를 보낼 수 \n있습니다. \nRedshift, Amazon OpenSearch Service 및 귀하 또는 귀하의 제3 자 서비스 공급자가 \n소유한 모든 HTTP 엔드포인트. \n다음은 지원되는 대상입니다. \n* Amazon 오픈서치 서비스(Amazon OpenSearch Service) \n* Amazon S3 \n* 데이터독(Datadog) \n* 다이나트레이스(Dynatrace) \n* 벌집(Honeycomb) \n* HTTP 끝점(Endpoint) \n* 로직 모니터(Logic Monitor) \n* 몽고디비 클라우드(MongoDB Cloud) \n* 새로운 유물(New Relic) \n* 스플렁크(Splunk) \n* 스모 로직(Sumo Logic) \nhttps://docs.aws.amazon.com/firehose/latest/dev/create-name.html \nhttps://aws.amazon.com/kinesis/data-streams/ \nAmazon Kinesis Data Streams(KDS)는 확장성과 내구성이 뛰어난 실시간 데이터 스트리밍 \n서비스입니다. \nKDS 는 웹사이트 클릭 스트림, 데이터베이스 이벤트 스트림, 금융 거래, 소셜 미디어 피드, \nIT 로그 및 위치 추적 이벤트와 같은 수십만 개의 소스에서 초당 기가바이트의 데이터를 \n지속적으로 캡처할 수 있습니다.", "answer_choice": "C"}, "34": {"q_num": 34, "question": "회사는 AWS 에서 다중 계층 애플리케이션을 호스팅합니다. 규정 준수, 거버넌스, 감사 및 \n보안을 위해 회사는 AWS 리소스의 구성 변경 사항을 추적하고 이러한 리소스에 대한 API \n호출 기록을 기록해야 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. AWS CloudTrail 을 사용하여 구성 변경을 추적하고 AWS Config 를 사용하여 API 호출을 \n기록하십시오. \nB. AWS Config 를 사용하여 구성 변경을 추적하고 AWS CloudTrail 을 사용하여 API 호출을 \n기록합니다. \nC. AWS Config 를 사용하여 구성 변경을 추적하고 Amazon CloudWatch 를 사용하여 API \n호출을 기록합니다. \nD. AWS CloudTrail 을 사용하여 구성 변경을 추적하고 Amazon CloudWatch 를 사용하여 API \n호출을 기록합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/85202-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \n리소스 구성 사항 변경 추적 = AWS Config / 리소스 내역 기록 = CloudTrail \nAWS Config 는 AWS 리소스 인벤토리, 구성 기록, 구성 변경 알림을 제공하여 보안 및 \n거버넌스를 실현하는 완벽한 관리형 서비스입니다. \nhttps://aws.amazon.com/ko/config/faq/ \nAWS Cloudtrail 은 사용자 활동 및 API 사용을 추적하여 감사, 보안 모니터링 및 운영 문제 \n해결을 지원합니다. CloudTrail\n은 AWS 인프라 전체에서 작업과 관련된 계정 활동을 \n로그하고 지속적으로 모니터링하고 보존하여 스토리지, 분석 및 해결 작업을 제어할 수 \n있도록 합니다. \nhttps://aws.amazon.com/ko/cloudtrail/faqs/ \n \n설명2: \nAWS Config 는 회사가 AWS 리소스의 구성을 평가, 감사 및 평가할 수 있는 완전관리형 \n서비스입니다. 사용 중인 리소스에 대한 자세한 인벤토리를 제공하고 리소스 구성에 대한 \n변경 사항을 추적합니다. AWS Config 는 구성 변경을 감지하고 변경이 발생하면 회사에 \n알릴 수 있습니다. 또한 규정 준수 및 거버넌스 목적에 필수적인 변경 기록 보기를 \n제공합니다. AWS CloudTrail 은 회사의 AWS 리소스에 대한 자세한 API 호출 기록을 \n제공하는 완전 관리형 서비스입니다. API 호출을 한 사람, 호출한 시간, 호출의 영향을 받은 \n리소스를 포함하여 AWS 계정의 모든 API 활동을 기록합니다. 이 정보를 통해 회사는 AWS \n\n리소스에서 발생할 수 있는 의심스러운 활동을 조사할 수 있으므로 보안 및 감사 목적에 \n매우 중요합니다.", "answer_choice": "B"}, "35": {"q_num": 35, "question": "한 회사가 AWS 클라우드에서 공개 웹 애플리케이션 출시를 준비하고 있습니다. 아키텍처는 \nElastic Load Balancer(ELB) 뒤의 VPC 내 Amazon EC2 인스턴스로 구성됩니다. DNS 에는 \n타사 서비스가 사용됩니다. 회사의 솔루션 설계자는 대규모 DDoS 공격을 감지하고 \n보호하기 위한 솔루션을 권장해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 계정에서 Amazon GuardDuty 를 활성화합니다. \nB. EC2 인스턴스에서 Amazon Inspector 를 활성화합니다. \nC. AWS Shield 를 활성화하고 여기에 Amazon Route 53 을 할당합니다. \nD. AWS Shield Advanced 를 활성화하고 ELB 를 할당합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/85203-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n해설:・ \nA(X) : GuardDuty 는 계정 보호 서비스. \nAmazon GuardDuty 는 AWS 계정 및 워크로드에서 악의적 활동을 모니터링하고 상세한 \n보안 결과를 제공하여 가시성 및 해결을 촉진하는 위협 탐지 서비스입니다. \nhttps://aws.amazon.com/ko/guardduty/ \nB(X) : Amazon Inspector 는 취약점 스캔 서비스. \nAmazon Inspector 는 지속적으로 스캔하는 취약성 관리 서비스입니다. \nhttps://docs.aws.amazon.com/ko_kr/inspector/latest/user/what-is-inspector.html \nC(X) : 대규모 DDoS 방어는 AWS Shield Advanced 가 더 적합. \nD(O) : AWS Shield Advanced 는 정교한 대규모 DDoS 공격에 대한 추가 보호 및 완화, \n실시간에 가까운 공격에 대한 가시성, 웹 애플리케이션 방화벽 AWS WAF 와의 통합을 \n제공합니다. DDoS 관련 급증 시 Amazon Elastic Compute Cloud(EC2), Elastic Load \nBalancing(ELB), Amazon CloudFront, AWS Global Accelerator 및 Amazon Route 53 요금 \n보호를 제공합니다. \nhttps://aws.amazon.com/ko/shield/?whats-new-cards.sort-by=item.additionalFields.post\nDateTime&whats-new-cards.sort-order=desc", "answer_choice": "D"}, "36": {"q_num": 36, "question": "회사는 AWS 클라우드에서 애플리케이션을 구축하고 있습니다. 애플리케이션은 두 AWS \n리전의 Amazon S3 버킷에 데이터를 저장합니다. 회사는 AWS Key Management \nService(AWS KMS) 고객 관리형 키를 사용하여 S3 버킷에 저장된 모든 데이터를 \n암호화해야 합니다. 두 S3 버킷의 데이터는 동일한 KMS 키로 암호화 및 복호화해야 \n합니다. 데이터와 키는 두 지역 각각에 저장되어야 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 각 리전에서 S3 버킷을 생성합니다. Amazon S3 관리형 암호화 키(SSE-S3)와 함께 서버 \n측 암호화를 사용하도록 S3 버킷을 구성합니다. S3 버킷 간의 복제를 구성합니다. \nB. 고객 관리형 다중 지역 KMS 키를 생성합니다. 각 리전에서 S3 버킷을 생성합니다. S3 \n버킷 간의 복제를 구성합니다. 클라이언트 측 암호화와 함께 KMS 키를 사용하도록 \n애플리케이션을 구성합니다. \nC. 각 리전에서 고객 관리형 KMS 키와 S3 버킷을 생성합니다. Amazon S3 관리형 암호화 \n키(SSE-S3)와 함께 서버 측 암호화를 사용하도록 S3 버킷을 구성합니다. S3 버킷 간의 \n복제를 구성합니다. \nD. 각 리전에서 고객 관리형 KMS 키와 S3 버킷을 생성합니다. AWS KMS 키(SSE-KMS)로 \n서버 측 암호화를 사용하도록 S3 버킷을 구성합니다. S3 버킷 간의 복제를 구성합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/84747-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nhttps://docs.aws.amazon.com/kms/latest/developerguide/custom-key-store-overview.ht\nml \n대부분의 사용자는 FIPS 140-2 인증 암호화 모듈로 보호되는 기본 AWS KMS 키 스토어가 \n보안 요구 사항을 충족합니다. 추가 유지 관리 책임 계층이나 추가 서비스에 대한 종속성을 \n추가할 필요가 없습니다. 그러나 조직에 다음과 같은 요구 사항이 있는 경우 사용자 지정 \n키 스토어 생성을 고려할 수 있습니다. 키 자료는 공유 환경에 저장할 수 없습니다. 키 \n자료는 독립적인 보조 감사 경로를 따라야 합니다. 키 자료를 생성하고 저장하는 HSM 은 \nFIPS 140-2 레벨 3 에서 인증을 받아야 합니다. \nhttps://docs.aws.amazon.com/kms/latest/developerguide/custom-key-store-overview.ht\nml \nhttps://docs.aws.amazon.com/kms/latest/developerguide/multi-region-keys-overview.ht\nml \n \n설명2: \n\nA(X) : SSE-S3은 AWS에서 데이터 키와 마스터 키 모두 관리하기 때문에 고객 관리형 키가 \n사용되지 않음. \n참고: AWS KMS 키로 암호화된 개체를 업로드하려면 키와 S3 버킷이 동일한 AWS 리전에 \n있어야 합니다. \nNote: To upload an object encrypted by an AWS KMS key, the key and the S3 bucket must be \nin the same AWS Region. \nhttps://aws.amazon.com/ko/premiumsupport/knowledge-center/s3-bucket-store-kms-e\nncrypted-objects/ \nB(O) : 고객 관리형 다중 리전 KMS 키 생성. 각 리전에 S3 버킷 생성. S3 버킷 간 복제 \n설정. 클라이언트 측 암호화로 KMS 키 사용하도록 애플리케이션 설정 \nC(X) : A 와 같은 이유로 오답. \nD(X) : 각 리전에 고객 관리형 KMS 키 및 S3 버킷 생성. AWS KMS keys(SSE-KMS)로 KMS \n키(SSE-KMS)로 서버 측 암호화 사용하도록 S3 버킷 설정. S3 버킷 간 복제 설정.", "answer_choice": "B"}, "37": {"q_num": 37, "question": "한 회사는 최근 AWS 계정의 Amazon EC2 인스턴스에서 다양한 새로운 워크로드를 \n출시했습니다. 회사는 인스턴스에 원격으로 안전하게 액세스하고 관리하는 전략을 수립해야 \n합니다. 회사는 기본 AWS 서비스와 함께 작동하고 AWS Well-Architected 프레임워크를 \n따르는 반복 가능한 프로세스를 구현해야 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. EC2 직렬 콘솔을 사용하여 관리를 위해 각 인스턴스의 터미널 인터페이스에 직접 \n액세스합니다. \nB. 각 기존 인스턴스와 새 인스턴스에 적절한 IAM 역할을 연결합니다. AWS Systems \nManager Session Manager 를 사용하여 원격 SSH 세션을 설정합니다. \nC. 관리 SSH 키 쌍을 만듭니다. 공개 키를 각 EC2 인스턴스에 로드합니다. 퍼블릭 \n서브넷에 배스천 호스트를 배포하여 각 인스턴스의 관리를 위한 터널을 제공합니다. \nD. AWS Site-to-Site VPN 연결을 설정합니다. 관리자에게 로컬 온프레미스 머신을 사용하여 \nVPN 터널에서 SSH 키를 사용하여 인스턴스에 직접 연결하도록 지시합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/85037-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명:・ \nA(X) : 물리적으로 케이블 갖다 꽂는 것이기 때문에 원격 접속이 아님. \nB(O) : 세션 관리자는 사용자 인스턴스에 SSH 키 또는 인증서를 유지하거나 인바운드 \n\n포트를 열도록 요구하지 않고 보안 태세를 강화합니다. 또한, AWS IAM\n을 사용하여 \n인스턴스 액세스를 중앙에서 관리합니다. 세션 관리자를 사용하면 Linux 또는 Windows \nEC2 인스턴스와 연결하여 각 인스턴스에서 세션을 시작한 각 사용자를 추적할 수 있습니다. \n인스턴스에 액세스한 사용자와 AWS CloudTrail\n을 사용한 시점을 감사할 수 있으며, \n인스턴스에서 실행된 각 명령을 Amazon S3 또는 Amazon CloudWatch Logs 에 기록할 수 \n있습니다. 끝으로 Session Manager 를 사용하면 배스쳔 호스트를 운영하고 관리하기 위한 \n초기 투자 비용이 들지 않습니다.  https://aws.amazon.com/ko/systems-manager/faq/ \nC(X) : SSH 키 쌍이 필요하므로 B 보다 운영 오버헤드가 많이 발생함. \nD(X) : C 와 동일한 이유로 오답. \n \n참고 \nhttps://docs.aws.amazon.com/ko_kr/systems-manager/latest/userguide/setup-instance-\npermissions.html", "answer_choice": "B"}, "38": {"q_num": 38, "question": "회사는 Amazon S3 에서 정적 웹 사이트를 호스팅하고 DNS 에 Amazon Route 53 을 \n사용하고 있습니다. 웹 사이트는 전 세계적으로 수요가 증가하고 있습니다. 회사는 웹 \n사이트에 액세스하는 사용자의 대기 시간을 줄여야 합니다. \n어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족합니까? \nA. 웹 사이트가 포함된 S3 버킷을 모든 AWS 리전에 복제합니다. Route 53 지리적 위치 \n라우팅 항목을 추가합니다. \nB. AWS Global Accelerator 에서 액셀러레이터를 프로비저닝합니다. 제공된 IP 주소를 S3 \n버킷과 연결합니다. 액셀러레이터의 IP 주소를 가리키도록 Route 53 항목을 편집합니다. \nC. S3 버킷 앞에 Amazon CloudFront 배포를 추가합니다. CloudFront 배포를 가리키도록 \nRoute 53 항목을 편집합니다. \nD. 버킷에서 S3 Transfer Acceleration 을 활성화합니다. 새 엔드포인트를 가리키도록 Route \n53 항목을 편집합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/85238-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \nA(X) : S3 버킷을 각 리전마다 복제하면 콘텐츠가 업로드될 때마다 각 리전의 버킷에 \n복제해야하므로 낭비임. CloudFront 를 사용하는 것이 훨씬 더 효율적이고 경제적. \nB(X) : AWS Global Accelerator 는 TCP/UDP 를 사용하는 네트워크 계층에서 동작하는데, \n\n지문에서 사용된 Route 53 은 DNS 서비스로서, 애플리케이션 계층에서 동작. \nC(O) : Route 53 으로 CloudFront 배포를 가리킬 수 있음. \nS3 를 사용해 정적 콘텐츠를 저장하면 다양한 이점이 있습니다. 하지만 비용을 효과적으로 \n관리하는 동시에 애플리케이션의 성능과 보안까지 최적화하려면 Amazon CloudFront 를 \n설정해 S3 버킷과 함께 사용하면서 콘텐츠를 제공하고 보호하는 것이 좋습니다. \nCloudFront 는 전 세계의 정적/동적 웹 콘텐츠, 비디오 스트림 및 API 를 안전하게 대규모로 \n전송할 수 있는 콘텐츠 전송 네트워크(CDN) 서비스입니다. CloudFront\n에서 데이터를 \n전송하면 설계상 S3 에서 직접 사용자에게 전송하는 것보다 더욱 비용 효율적입니다.  \nhttps://aws.amazon.com/ko/blogs/korea/amazon-s3-amazon-cloudfront-a-match-mad\ne-in-the-cloud/ \n자체 도메인 이름을 사용하려는 경우 Amazon Route 53 을 사용하여 CloudFront 배포를 \n가리키는 별칭 레코드(alias record)를 생성합니다 \nhttps://docs.aws.amazon.com/ko_kr/Route53/latest/DeveloperGuide/routing-to-cloudfro\nnt-distribution.html \nD(X) : S3 Transfer Acceleration 은 각지에서 중앙 S3 버킷으로 업로드하는 서비스. \nS3 Transfer Acceleration 은 전 세계에서 S3 버킷으로 전송되는 속도를 최적화하도록 \n설계되었습니다. 지리적으로 분산된 위치에서 중앙 집중식 버킷으로 데이터를 업로드하거나, \n대륙 간에 GB 또는 TB 규모의 데이터를 정기적으로 전송하는 경우, S3 Transfer \nAcceleration 을 사용하면 몇 시간 또는 며칠의 데이터 전송 시간을 절약할 수 있습니다.  \nhttps://aws.amazon.com/ko/s3/faqs/#s3ta \n \n설명2: \nAmazon CloudFront 는 전 세계 엣지 로케이션에서 콘텐츠를 캐싱하여 콘텐츠에 액세스하는 \n사용자에게 \n짧은 \n지연 \n시간과 \n빠른 \n전송 \n속도를 \n제공하는 \n콘텐츠 \n전송 \n네트워크(CDN)입니다. S3 버킷 앞에 CloudFront 배포를 추가하면 전 세계 엣지 위치에서 \n정적 웹 사이트의 콘텐츠를 캐싱하여 웹 사이트에 액세스하는 사용자의 지연 시간을 \n줄입니다. 또한 이 솔루션은 CloudFront 엣지 로케이션에서 콘텐츠에 액세스하는 사용자의 \n데이터 전송 및 요청에 대해서만 비용을 청구하므로 비용 효율적입니다. 또한 이 솔루션은 \nCloudFront 가 자동으로 확장하여 수요 증가를 처리하고 웹 사이트에 고가용성을 제공할 수 \n있으므로 확장성과 안정성 이점을 제공합니다.", "answer_choice": "C"}, "39": {"q_num": 39, "question": "회사는 웹 사이트에서 검색 가능한 항목 저장소를 유지 관리합니다. 데이터는 천만 개 \n이상의 행이 포함된 Amazon RDS for MySQL 데이터베이스 테이블에 저장됩니다. \n데이터베이스에는 2TB 의 범용 SSD 스토리지가 있습니다. 회사 웹 사이트를 통해 이 \n\n데이터에 대한 수백만 건의 업데이트가 매일 있습니다. \n이 회사는 일부 삽입 작업이 10 초 이상 걸리는 것을 확인했습니다. 회사는 데이터베이스 \n스토리지 성능이 문제라고 판단했습니다. \n이 성능 문제를 해결하는 솔루션은 무엇입니까? \nA. 스토리지 유형을 프로비저닝된 IOPS SSD 로 변경합니다. \nB. DB 인스턴스를 메모리 최적화 인스턴스 클래스로 변경합니다. \nC. DB 인스턴스를 버스트 가능한 성능 인스턴스 클래스로 변경합니다. \nD. MySQL 기본 비동기 복제로 다중 AZ RDS 읽기 전용 복제본을 활성화합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/84748-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \nhttps://aws.amazon.com/ebs/features/ \n프로비저닝된 IOPS 볼륨은 솔리드 스테이트 드라이브(SSD)로 지원되며 중요한 I/O \n집약적인 데이터베이스 애플리케이션을 위해 설계된 최고 성능의 EBS 볼륨입니다. \n이러한 볼륨은 극히 짧은 대기 시간이 필요한 IOPS 집약적 워크로드와 처리량 집약적 \n워크로드 모두에 이상적입니다. \nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html \n \n설명2: \n'삽입' 작업이라고 했으므로 I/O 성능과 관련되어있음을 유추할 수 있음. 그리고 '저장소 \n성능'이 문제라고 판단했고, 범용 'SSD' 스토리지가 있다고 했으므로 A 가 정답. \nD(X) : 버스트 가능한 성능 인스턴스는 잠시 I/O 성능을 끌어올리는 것일 뿐 근본적인 I/O \n성능 개선은 하지 못함. \n획득한 크레딧이 남아 있지 않으면 인스턴스가 기준 CPU 사용률로 점진적으로 저하되고 \n크레딧이 더 많이 적립될 때까지 기준 이상으로 버스트할 수 없습니다. \nhttps://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/burstable-credits-baselin\ne-concepts.html", "answer_choice": "A"}, "40": {"q_num": 40, "question": "회사에는 매일 1TB 의 상태 알림을 집합적으로 생성하는 수천 개의 에지 장치가 있습니다. \n각 경고의 크기는 약 2KB 입니다. 솔루션 설계자는 향후 분석을 위해 경고를 수집하고 \n저장하는 솔루션을 구현해야 합니다. \n회사는 고가용성 솔루션을 원합니다. 그러나 회사는 비용을 최소화해야 하며 추가 인프라 \n\n관리를 원하지 않습니다. 또한 회사는 즉각적인 분석을 위해 14\n일 동안의 데이터를 \n유지하고 14 일이 지난 데이터를 보관하기를 원합니다. \n이러한 요구 사항을 충족하는 가장 운영 효율성이 높은 솔루션은 무엇입니까? \nA. Amazon Kinesis Data Firehose 전송 스트림을 생성하여 알림을 수집합니다. Amazon S3 \n버킷에 알림을 전달하도록 Kinesis Data Firehose 스트림을 구성합니다. 14 일 후에 데이터를 \nAmazon S3 Glacier 로 전환하도록 S3 수명 주기 구성을 설정합니다. \nB. 두 가용 영역에서 Amazon EC2 인스턴스를 시작하고 Elastic Load Balancer 뒤에 \n배치하여 알림을 수집합니다. Amazon S3 버킷에 경고를 저장할 EC2 인스턴스에 대한 \n스크립트를 생성합니다. 14 일 후에 데이터를 Amazon S3 Glacier 로 전환하도록 S3 수명 \n주기 구성을 설정합니다. \nC. Amazon Kinesis Data Firehose 전송 스트림을 생성하여 알림을 수집합니다. Amazon \nOpenSearch Service(Amazon Elasticsearch Service) 클러스터에 알림을 전달하도록 Kinesis \nData Firehose 스트림을 구성합니다. Amazon OpenSearch Service(Amazon Elasticsearch \nService) 클러스터를 설정하여 매일 수동 스냅샷을 만들고 클러스터에서 14 일이 지난 \n데이터를 삭제합니다. \nD. Amazon Simple Queue Service(Amazon SQS) 표준 대기열을 생성하여 알림을 수집하고 \n메시지 보존 기간을 14\n일로 설정합니다. SQS 대기열을 폴링하고, 메시지의 수명을 \n확인하고, 필요에 따라 메시지 데이터를 분석하도록 소비자를 구성합니다. 메시지가 14 일이 \n지난 경우 소비자는 메시지를 Amazon S3 버킷에 복사하고 SQS 대기열에서 메시지를 \n삭제해야 합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/85204-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명:・ \n수 천 개의 Edge 장치로부터 경고 수집 및 저장 = Kinesis. A,C 둘 중 하나가 답. \nA(O) : 정답. \n・Kinesis Firehose Delivery Stream 에서 데이터 수집 \n다양한 유형의 소스를 사용하여 Kinesis Data Firehose 전송 스트림으로 데이터를 보낼 수 \n있습니다. https://docs.aws.amazon.com/firehose/latest/dev/basic-write.html \n・Kinesis Firehose 에서 S3 로 데이터 전송 \nKinesis Data Firehose 전송 스트림을 설정할 때 데이터의 최종 대상을 선택합니다. 대상 \n옵션은 Amazon Simple Storage Service(Amazon S3), Amazon OpenSearch Service 및 \nAmazon Redshift 입니다.  \nhttps://docs.aws.amazon.com/ko_kr/ses/latest/dg/event-publishing-kinesis-analytics-fir\nehose-stream.html \n\n・S3 에서 Life Cycle Policy 를 사용해 S3 Glacier 로 객체 이전 \n수명 주기 규칙을 사용하여 객체 수명 주기 동안 Amazon S3 에서 수행하려는 작업을 \n정의할 수 있습니다(예: 객체를 다른 스토리지 클래스로 이전, 객체 보관, 지정된 기간이 \n경과한 후 객체 삭제). \nhttps://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/how-to-set-lifecycle-c\nonfiguration-intro.html) \nC(X) : 14 일이 지난 데이터를 보관하길 원한다고 했는데 삭제해버리므로 오답. \n \n참고: \nhttps://aws.amazon.com/ko/kinesis/data-firehose/features/?nc=sn&loc=2#:~:text=into%\n20Amazon%20S3%2C%20", "answer_choice": "A"}, "41": {"q_num": 41, "question": "회사의 애플리케이션은 데이터 수집을 위해 여러 SaaS(Software-as-a-Service) 소스와 \n통합됩니다. 이 회사는 Amazon EC2 인스턴스를 실행하여 데이터를 수신하고 분석을 위해 \n데이터를 Amazon S3 버킷에 업로드합니다. 데이터를 수신하고 업로드하는 동일한 EC2 \n인스턴스도 업로드가 완료되면 사용자에게 알림을 보냅니다. 회사는 느린 응용 프로그램 \n성능을 발견했으며 가능한 한 성능을 개선하려고 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. EC2 인스턴스가 확장할 수 있도록 Auto Scaling 그룹을 생성합니다. S3 버킷에 업로드가 \n완료되면 Amazon Simple Notification Service(Amazon SNS) 주제에 이벤트를 보내도록 S3 \n이벤트 알림을 구성합니다. \nB. Amazon AppFlow 흐름을 생성하여 각 SaaS 소스와 S3 버킷 간에 데이터를 전송합니다. \nS3 버킷에 업로드가 완료되면 Amazon Simple Notification Service(Amazon SNS) 주제에 \n이벤트를 보내도록 S3 이벤트 알림을 구성합니다. \nC. 각 SaaS 소스에 대해 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 \n생성하여 출력 데이터를 보냅니다. S3 버킷을 규칙의 대상으로 구성합니다. S3 버킷에 \n업로드가 완료되면 이벤트를 전송하는 두 번째 EventBridge(Cloud Watch Events) 규칙을 \n생성합니다. Amazon Simple Notification Service(Amazon SNS) 주제를 두 번째 규칙의 \n대상으로 구성합니다. \nD. EC2 인스턴스 대신 사용할 Docker 컨테이너를 생성합니다. Amazon Elastic Container \nService(Amazon ECS)에서 컨테이너화된 애플리케이션을 호스팅합니다. S3 버킷에 업로드가 \n완료되면 Amazon Simple Notification Service(Amazon SNS) 주제에 이벤트를 보내도록 \nAmazon CloudWatch Container Insights 를 구성합니다.", "answer_block": "Answer: B \n\nhttps://www.examtopics.com/discussions/amazon/view/85446-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \nAmazon AppFlow\n는 Salesforce, SAP, Zendesk, Slack 및 ServiceNow\n와 같은 \nSaaS(Software-as-a-Service) 애플리케이션과 Amazon S3 및 Amazon Redshift 와 같은 \nAWS 서비스 간에 데이터를 안전하게 전송할 수 있는 완전 관리형 통합 서비스입니다. 클릭 \n몇 번이면 됩니다. \nhttps://aws.amazon.com/appflow/ \n \n설명2: \nSaaS = Appflow. Appflow 는 완전 관리형 통합 서비스이기 때문에 운영 오버헤드가 적음. \nAmazon AppFlow 는 클릭 몇 번으로 Salesforce, Marketo, Slack 및 ServiceNow 와 같은 \nSaaS(Software-as-a-Service) 애플리케이션과 Amazon S3 및 Amazon Redshift 와 같은 \nAWS 서비스 간에 데이터를 안전하게 전송할 수 있게 해 주는 완전관리형 통합 서비스. \nhttps://aws.amazon.com/ko/appflow/faqs/", "answer_choice": "B"}, "42": {"q_num": 42, "question": "회사는 단일 VPC 의 Amazon EC2 인스턴스에서 고가용성 이미지 처리 애플리케이션을 \n실행합니다. EC2 인스턴스는 여러 가용 영역의 여러 서브넷 내에서 실행됩니다. EC2 \n인스턴스는 서로 통신하지 않습니다. 그러나 EC2 인스턴스는 Amazon S3 에서 이미지를 \n다운로드하고 단일 NAT 게이트웨이를 통해 Amazon S3 에 이미지를 업로드합니다. 회사는 \n데이터 전송 요금에 대해 우려하고 있습니다. \n회사가 지역 데이터 전송 요금을 피할 수 있는 가장 비용 효율적인 방법은 무엇입니까? \nA. 각 가용 영역에서 NAT 게이트웨이를 시작합니다. \nB. NAT 게이트웨이를 NAT 인스턴스로 교체합니다. \nC. Amazon S3 용 게이트웨이 VPC 엔드포인트를 배포합니다. \nD. EC2 인스턴스를 실행할 EC2 전용 호스트를 프로비저닝합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/85205-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n해설1:・ \n데이터 전송 요금이 걱정되니 전용 전송 통로를 뚫으면 됨. VPC-S3 간 전용 통로는 S3 \nVPC Gateway Endpoint. 답은 C. \n\n \n해설2: \nS3\n용 게이트웨이 VPC 엔드포인트를 배포함으로써 회사는 인터넷 게이트웨이나 NAT \n게이트웨이를 거치지 않고 VPC 와 S3 사이에 직접 연결을 설정할 수 있습니다. 이렇게 \n하면 EC2 와 S3 사이의 트래픽이 Amazon 네트워크 내에 머물면서 지역 데이터 전송 \n요금을 피할 수 있습니다. \n \nA 는 각 AZ 에서 NAT 게이트웨이를 시작할 것을 제안합니다. 이는 가용성과 중복성에 \n도움이 될 수 있지만 트래픽이 여전히 NAT 게이트웨이를 통과하고 데이터 전송 요금이 \n발생하므로 데이터 전송 요금 문제를 해결하지 못합니다. \n \nB 는 NAT 게이트웨이를 NAT 인스턴스로 교체할 것을 제안합니다. 그러나 이 솔루션은 \n여전히 NAT 인스턴스를 통해 인스턴스와 S3 간에 데이터를 전송하므로 데이터 전송 \n요금이 발생합니다. \n \nD 는 EC2 를 실행하기 위해 EC2 전용 호스트를 프로비저닝할 것을 제안합니다. 이는 \n인스턴스 전용 하드웨어를 제공할 수 있지만 데이터 전송 요금 문제를 직접적으로 \n해결하지는 않습니다.", "answer_choice": "C"}, "43": {"q_num": 43, "question": "회사에 Amazon S3 에 백업되는 시간에 민감한 대량의 데이터를 생성하는 온프레미스 \n애플리케이션이 있습니다. 애플리케이션이 성장했고 인터넷 대역폭 제한에 대한 사용자 \n불만이 있습니다. 솔루션 설계자는 Amazon S3\n에 대한 적시 백업을 허용하고 내부 \n사용자의 인터넷 연결에 미치는 영향을 최소화하는 장기 솔루션을 설계해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. AWS VPN 연결을 설정하고 VPC 게이트웨이 엔드포인트를 통해 모든 트래픽을 \n프록시합니다. \nB. 새 AWS Direct Connect 연결을 설정하고 이 새 연결을 통해 백업 트래픽을 직접 \n연결합니다. \nC. 매일 AWS Snowball 디바이스를 주문합니다. Snowball 디바이스에 데이터를 로드하고 \n디바이스를 매일 AWS 로 반환합니다. \nD. AWS Management 콘솔을 통해 지원 티켓을 제출합니다. 계정에서 S3 서비스 제한 \n제거를 요청합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/85206-exam-aws-certified-solut\n\nions-architect-associate-saa-c03/ \n \n설명1:・ \nA(X) : VPN 은 인터넷을 통과하는데다가, VPC Gateway Endpoint 는 VPC-S3,Dynamo 간 \n전송을 담당. \nB(O) : Direct Connect 는 전용선을 통과하기 때문에 인터넷에 전송중인 데이터가 노출되지 \n않음 \nC(X) : Snowball Device 는 배송기간까지 합하면 보통 7 일 정도 걸리는데 이를 매일 \n주문한다는 것은 무리수. \nD(X) : 한도 증가만 가능. 한도 제거 옵션은 없음. \nhttps://docs.aws.amazon.com/ko_kr/general/latest/gr/aws_service_limits.html \n \n설명2: \n회사의 온프레미스 애플리케이션에 대한 대역폭 제한 문제를 해결하고 내부 사용자 연결에 \n대한 영향을 최소화하려면 이 새로운 연결을 통해 백업 트래픽을 전달하도록 새로운 AWS \nDirect Connect 연결을 설정해야 합니다. 이 솔루션은 회사의 데이터 센터와 AWS 간에 \n안전한 고속 연결을 제공하여 회사가 인터넷 대역폭을 사용하지 않고 데이터를 빠르게 \n전송할 수 있도록 합니다. \n참조: \nAWS Direct Connect 설명서: https://aws.amazon.com/directconnect/", "answer_choice": "B"}, "44": {"q_num": 44, "question": "회사에 중요한 데이터가 포함된 Amazon S3 버킷이 있습니다. 회사는 우발적인 삭제로부터 \n데이터를 보호해야 합니다. \n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 단계 조합을 취해야 합니까? \n(2 개를 선택하세요.) \nA. S3 버킷에서 버전 관리를 활성화합니다. \nB. S3 버킷에서 MFA 삭제를 활성화합니다. \nC. S3 버킷에 버킷 정책을 생성합니다. \nD. S3 버킷에서 기본 암호화를 활성화합니다. \nE. S3 버킷의 객체에 대한 수명 주기 정책을 생성합니다.", "answer_block": "Answer: A, B \nhttps://www.examtopics.com/discussions/amazon/view/84750-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n\n설명1: \nA(O) : 버전 관리는 실수로 삭제했을 때 이전 버전의 파일을 불러올 수 있도록 해줌. \nAmazon S3 의 버전 관리는 동일 버킷 내에 여러 개의 객체 변형을 보유하는 수단입니다. \nS3 버전 관리를 사용하면 버킷에 저장된 모든 버전의 객체를 모두 보존, 검색 및 복원할 \n수 있습니다. \nhttps://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/Versioning.html \nB(O) : MFA Delete 는 함부로 삭제하지 못하도록 막음. \nMFA Delete 는 다음 작업에 대해 추가 인증을 요구합니다. ◎버킷의 버전 관리 상태 변경 \n◎객체 버전 영구 삭제 \nhttps://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/MultiFactorAuthenticatio\nnDelete.html \nC(X) : 버킷 정책은 액세스 권한에 관련된 것. 버킷 정책은 버킷과 해당 버킷의 객체에 대한 \n액세스 권한을 부여할 수 있는 리소스 기반 정책입니다. \nhttps://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/bucket-policies.html \nD(X) : 암호화는 파일 내용을 함부로 볼 수 없게하는 등의 기능은 있지만 기본적으로 \n삭제는 막지 못함. 우리가 직장에서 DRM 걸린 문서는 열람 못해도 액세스 권한이 있다면 \n삭제할 수 있는 거랑 비슷함. \nE(X) : 객체 수명 주기 정책은 객체를 언제 이동하고 삭제할 거냐의 문제. \n \n설명2: \nS3 버킷의 데이터를 실수로 삭제하지 않도록 보호하려면 S3 버킷에 있는 모든 객체의 모든 \n버전을 보존, 검색 및 복원할 수 있는 버전 관리를 활성화해야 합니다. \n또한 S3 버킷에서 MFA(다단계 인증) 삭제를 활성화하면 버킷의 객체를 삭제하기 위해 \n사용자의 액세스 키 외에 인증 토큰을 요구함으로써 추가 보호 계층이 추가됩니다. \n참조: \nAWS S3 버전 관리 설명서: \nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html \nAWS S3 MFA 문서 삭제:  \nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/UsingMFADelete.html", "answer_choice": "A"}, "45": {"q_num": 45, "question": "회사에는 다음으로 구성된 데이터 수집 워크플로가 있습니다. \n• 새로운 데이터 전송에 대한 알림을 위한 Amazon Simple Notification Service(Amazon \nSNS) 주제 \n• 데이터를 처리하고 메타데이터를 기록하는 AWS Lambda 함수 \n\n회사는 네트워크 연결 문제로 인해 수집 워크플로가 때때로 실패하는 것을 관찰했습니다. \n이러한 장애가 발생하면 회사에서 수동으로 작업을 다시 실행하지 않는 한 Lambda 함수는 \n해당 데이터를 수집하지 않습니다. \nLambda 함수가 향후 모든 데이터를 수집하도록 하려면 솔루션 설계자가 취해야 하는 작업 \n조합은 무엇입니까? (2 개를 선택하세요.) \nA. 여러 가용 영역에 Lambda 함수를 배포합니다. \nB. Amazon Simple Queue Service(Amazon SQS) 대기열을 생성하고 SNS 주제를 \n구독합니다. \nC. Lambda 함수에 할당된 CPU 와 메모리를 늘립니다. \nD. Lambda 함수에 대해 프로비저닝된 처리량을 늘립니다. \nE. Amazon Simple Queue Service(Amazon SQS) 대기열에서 읽도록 Lambda 함수를 \n수정합니다.", "answer_block": "Answer: B, E \nhttps://www.examtopics.com/discussions/amazon/view/85408-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \n네트워크 연결 문제로 데이터 수집이 잠시 실패하는 현상이 일어남. 이런 경우 데이터 \n손실이 일어날 위험성이 크므로 데이터를 보관해둘 곳이 필요하고, 대책으로는 SQS \nQueue 가 적절. 또한 SQS Queue 에 머물러 있는 작업들은 Lambda 로 처리 가능. 답은 BE. \nSQS\n를 사용하면 메시지 손실 위험을 감수하거나 다른 서비스를 가동할 필요 없이 \n소프트웨어 구성 요소 간에 모든 볼륨의 메시지를 전송, 저장 및 수신할 수 있습니다.  \nhttps://aws.amazon.com/ko/sqs/ \nLambda 함수를 사용하여 Amazon Simple Queue Service(Amazon SQS) 대기열의 메시지를 \n처리할 수 있습니다. \nhttps://docs.aws.amazon.com/ko_kr/lambda/latest/dg/with-sqs.html \n \n설명2: \n간헐적인 네트워크 연결 문제에도 불구하고 Lambda 함수가 향후 모든 데이터를 \n수집하도록 하려면 다음 조치를 취해야 합니다. \nAmazon Simple Queue Service(SQS) 대기열을 생성하고 SNS 주제를 구독합니다. 이를 \n통해 알림과 처리를 분리할 수 있으므로 처리 Lambda 함수가 실패하더라도 나중에 추가 \n처리를 위해 메시지가 대기열에 남아 있습니다. \nSNS 에서 직접 읽지 않고 SQS 대기열에서 읽도록 Lambda 함수를 수정합니다. 이 분리는 \n재시도 및 내결함성을 허용하고 모든 메시지가 Lambda 함수에 의해 처리되도록 합니다. \n참조: \n\nAWS SNS 설명서: https://aws.amazon.com/sns/ \nAWS SQS 설명서: https://aws.amazon.com/sqs/ \nAWS Lambda 설명서: https://aws.amazon.com/lambda/", "answer_choice": "B"}, "46": {"q_num": 46, "question": "회사에 매장에 마케팅 서비스를 제공하는 애플리케이션이 있습니다. 서비스는 매장 고객의 \n이전 구매를 기반으로 합니다. 상점은 SFTP 를 통해 거래 데이터를 회사에 업로드하고 \n데이터를 처리 및 분석하여 새로운 마케팅 제안을 생성합니다. 일부 파일의 크기는 \n200GB 를 초과할 수 있습니다. \n최근에 회사는 일부 상점에서 포함되어서는 안 되는 개인 식별 정보(PII)가 포함된 파일을 \n업로드했음을 발견했습니다. 회사는 PII 가 다시 공유될 경우 관리자에게 경고를 주기를 \n원합니다. 회사는 또한 문제 해결을 자동화하기를 원합니다. \n최소한의 개발 노력으로 이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 해야 \n합니까? \nA. Amazon S3 버킷을 보안 전송 지점으로 사용하십시오. Amazon Inspector 를 사용하여 \n버킷의 객체를 스캔합니다. 객체에 PII 가 포함된 경우 S3 수명 주기 정책을 트리거하여 \nPII 가 포함된 객체를 제거합니다. \nB. Amazon S3 버킷을 보안 전송 지점으로 사용합니다. Amazon Macie 를 사용하여 버킷의 \n객체를 스캔합니다. 객체에 PII 가 포함된 경우 Amazon Simple Notification Service(Amazon \nSNS)를 사용하여 관리자에게 PII 가 포함된 객체를 제거하라는 알림을 트리거합니다. \nC. AWS Lambda 함수에서 사용자 지정 스캔 알고리즘을 구현합니다. 객체가 버킷에 로드될 \n때 함수를 트리거합니다. 객체에 PII\n가 포함된 경우 Amazon Simple Notification \nService(Amazon SNS)를 사용하여 관리자에게 PII 가 포함된 객체를 제거하라는 알림을 \n트리거합니다. \nD. AWS Lambda 함수에서 사용자 지정 스캔 알고리즘을 구현합니다. 객체가 버킷에 로드될 \n때 함수를 트리거합니다. 객체에 PII 가 포함된 경우 Amazon Simple Email Service(Amazon \nSES)를 사용하여 관리자에게 알림을 트리거하고 S3 수명 주기 정책을 트리거하여 PII 가 \n포함된 고기를 제거합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/85264-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nAmazon Macie 는 AWS 에서 PII 와 같은 민감한 데이터를 자동으로 검색, 분류 및 보호하는 \n관리형 서비스입니다. S3 에서 Macie 를 활성화하면 업로드된 객체에서 PII 를 검색할 수 \n\n있습니다. \n \nA. Amazon Inspector 를 사용하여 S3 의 객체를 스캔하는 것은 PII 데이터 스캔을 위한 \n최적의 선택이 아닙니다. Amazon Inspector 는 콘텐츠 스캔이 아닌 호스트 수준 취약성 \n평가를 위해 설계되었습니다. \n \nC. AWS Lambda 함수에서 사용자 지정 검색 알고리즘을 구현하려면 대용량 파일 검색을 \n처리하기 위해 상당한 개발 노력이 필요합니다. \n \nD. 알림에 SES 를 사용하고 S3 수명 주기 정책을 트리거하면 솔루션에 불필요한 복잡성이 \n추가될 수 있습니다. \n \n따라서 최소한의 개발 노력으로 요구 사항을 충족하는 최상의 옵션은 S3 를 안전한 전송 \n지점으로 사용하고 Amazon Macie\n를 PII 스캔에 활용하고 관리자에게 SNS 알림을 \n트리거하는 것입니다(옵션 B). \n \n설명2: \n최소한의 개발 노력으로 PII 가 공유될 때 관리자에게 탐지 및 경고하고 수정을 자동화하는 \n요구 사항을 충족하려면 Amazon S3 버킷을 안전한 전송 지점으로 사용하고 Amazon \nMacie 로 버킷의 객체를 스캔하는 것이 가장 좋습니다. \nAmazon Macie 는 기계 학습 및 패턴 일치를 사용하여 Amazon S3 에 저장된 중요한 \n데이터를 검색하고 보호하는 완전 관리형 데이터 보안 및 데이터 개인 정보 보호 \n서비스입니다. 민감한 데이터를 분류하고, 민감한 데이터에 대한 액세스를 모니터링하고, \n수정 작업을 자동화하는 데 사용할 수 있습니다. \n이 시나리오에서는 파일을 Amazon S3 버킷에 업로드한 후 Amazon Macie 에서 객체를 \n스캔하여 PII 를 찾을 수 있으며, PII 가 감지되면 Amazon Simple Notification Service(SNS) \n알림을 트리거하여 관리자에게 제거하도록 알릴 수 있습니다. PII 를 포함하는 객체. Amazon \nMacie 에는 이미 다양한 형식의 PII 를 탐지할 수 있는 사전 구축된 데이터 분류 규칙이 \n있으므로 이 접근 방식은 최소한의 개발 노력이 필요합니다. \n개인정보 = Macie. 정답은 B. \n참조: \nhtml AWS Well-Architected 프레임워크 - 보안 기반: \nhttps://docs.aws.amazon.com/wellarchitected/latest/security-pillar/welcome.html", "answer_choice": "B"}, "47": {"q_num": 47, "question": "회사는 1 주일 동안 진행될 예정된 이벤트를 위해 특정 AWS 리전의 3 개의 특정 가용 \n영역에서 보장된 Amazon EC2 용량이 필요합니다. \nEC2 용량을 보장하기 위해 회사는 무엇을 해야 합니까? \nA. 필요한 리전을 지정하는 예약 인스턴스를 구매합니다. \nB. 필요한 지역을 지정하는 온디맨드 용량 예약을 생성합니다. \nC. 필요한 리전과 3 개의 가용 영역을 지정하는 예약 인스턴스를 구매합니다. \nD. 필요한 지역과 3 개의 가용 영역을 지정하는 온디맨드 용량 예약을 생성합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/85529-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n설명1: \nA(X) : 예약 인스턴스는 1 년 또는 3 년 단위 약정 방식. \n예약 인스턴스(RI)는 1 년 또는 3 년 기간으로 약정하는 경우 EC2 사용 요금을 상당히 \n할인해 주는 EC2 상품입니다. https://aws.amazon.com/ko/ec2/faqs/ \nB(X) : 용량 예약을 생성할 때 다음을 지정합니다. ◎용량을 예약할 가용 영역 \nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-capacity-reservations.html \nC(X) : 예약 인스턴스는 1 년 또는 3 년 단위 약정 방식. \nD(O) : B 번 참조. \n \n설명2: \nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-capacity-reservations.html \n예비 인스턴스: 비용 효율적이지 않은 전체 기간(1 년 또는 3 년)에 대해 비용을 지불해야 \n합니다.", "answer_choice": "D"}, "48": {"q_num": 48, "question": "회사 웹 사이트는 항목 카탈로그에 Amazon EC2 인스턴스 스토어를 사용합니다. 회사는 \n카탈로그의 가용성이 높고 카탈로그가 내구성 있는 위치에 저장되기를 원합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. 카탈로그를 Redis 용 Amazon ElastiCache 로 이동합니다. \nB. 더 큰 인스턴스 스토어로 더 큰 EC2 인스턴스를 배포합니다. \nC. 인스턴스 스토어에서 Amazon S3 Glacier Deep Archive 로 카탈로그를 이동합니다. \nD. 카탈로그를 Amazon Elastic File System(Amazon EFS) 파일 시스템으로 이동합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/85119-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n\n \n설명1: \nA(X) : ElastiCache 는 캐시 서비스. \nB(X) : 인스턴스 스토어는 휘발성 스토리지. 내구성 불충족. \nC(X) : Amazon S3 Glacier Deep Archive 는 콜드 스토리지. 가용성 불충족. \nD(O) : 정답. \n \n설명2: \n카탈로그를 Amazon Elastic File System(Amazon EFS) 파일 시스템으로 이동하면 \n고가용성과 내구성이 모두 제공됩니다. Amazon EFS 는 필요에 따라 확장할 수 있도록 \n구축된 완전 관리형, 가용성 및 내구성이 뛰어난 파일 시스템입니다. Amazon EFS 를 \n사용하면 다양한 가용 영역에 있는 여러 EC2 인스턴스에서 카탈로그 데이터를 저장하고 \n액세스할 수 있으므로 고가용성이 보장됩니다. 또한 Amazon EFS 는 여러 가용 영역 내에서 \n파일을 자동으로 중복 저장하므로 내구성 있는 스토리지 옵션이 됩니다.", "answer_choice": "D"}, "49": {"q_num": 49, "question": "회사는 매월 통화 기록 파일을 저장합니다. 사용자는 통화 후 1 년 이내에 파일에 무작위로 \n액세스하지만 1 년 이후에는 파일에 자주 액세스하지 않습니다. 이 회사는 사용자에게 1 년 \n미만의 파일을 가능한 한 빨리 쿼리하고 검색할 수 있는 기능을 제공하여 솔루션을 \n최적화하려고 합니다. 오래된 파일을 검색하는 데 있어 지연은 허용됩니다. \n어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족합니까? \nA. Amazon S3 Glacier Instant Retrieval 에 태그가 있는 개별 파일을 저장합니다. 태그를 \n쿼리하여 S3 Glacier Instant Retrieval 에서 파일을 검색합니다. \nB. Amazon S3 Intelligent-Tiering 에 개별 파일을 저장합니다. S3 수명 주기 정책을 사용하여 \n1 년 후 파일을 S3 Glacier Flexible Retrieval 로 이동합니다. Amazon Athena 를 사용하여 \nAmazon S3 에 있는 파일을 쿼리하고 검색합니다. S3 Glacier Select 를 사용하여 S3 \nGlacier 에 있는 파일을 쿼리하고 검색합니다. \nC. Amazon S3 Standard 스토리지에 태그가 있는 개별 파일을 저장합니다. Amazon S3 \nStandard 스토리지의 각 아카이브에 대한 검색 메타데이터를 저장합니다. S3 수명 주기 \n정책을 사용하여 1 년 후에 파일을 S3 Glacier Instant Retrieval 로 이동합니다. Amazon \nS3 에서 메타데이터를 검색하여 파일을 쿼리하고 검색합니다. \nD. Amazon S3 Standard 스토리지에 개별 파일을 저장합니다. S3 수명 주기 정책을 \n사용하여 1 년 후에 파일을 S3 Glacier Deep Archive 로 이동합니다. Amazon RDS 에 검색 \n메타데이터를 저장합니다. Amazon RDS\n에서 파일을 쿼리합니다. S3 Glacier Deep \nArchive 에서 파일을 검색합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/85211-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n해설: \n의료 이미지, 뉴스 미디어 자산 또는 유전체학 데이터와 같이 즉각적인 액세스가 필요한 \n아카이브 데이터의 경우 S3 Glacier Instant Retrieve 스토리지 클래스를 선택하십시오. S3 \nGlacier Instant Retrieve 스토리지 클래스는 밀리초 검색으로 최저 비용의 스토리지를 \n제공합니다.  \n즉각적인 액세스가 필요하지는 않지만 백업 또는 재해 복구 사용 사례와 같이 비용 없이 \n대용량 데이터 세트를 검색할 수 있는 유연성이 필요한 아카이브 데이터의 경우 S3 Glacier \nFlexible Retrieve(이전의 S3 Glacier)를 선택하고, 몇 분 내에 검색하거나 5-12 시간 내에 \n대량 검색을 무료로 제공합니다.", "answer_choice": "B"}, "50": {"q_num": 50, "question": "회사에 1,000\n개의 Amazon EC2 Linux 인스턴스에서 실행되는 프로덕션 워크로드가 \n있습니다. 워크로드는 타사 소프트웨어에 의해 구동됩니다. 회사는 중요한 보안 취약성을 \n수정하기 위해 가능한 한 빨리 모든 EC2 인스턴스에서 타사 소프트웨어를 패치해야 \n합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. AWS Lambda 함수를 생성하여 모든 EC2 인스턴스에 패치를 적용합니다. \nB. 모든 EC2 인스턴스에 패치를 적용하도록 AWS Systems Manager Patch Manager 를 \n구성합니다. \nC. AWS Systems Manager 유지 관리 기간을 예약하여 모든 EC2 인스턴스에 패치를 \n적용합니다. \nD. AWS Systems Manager Run Command 를 사용하여 모든 EC2 인스턴스에 패치를 \n적용하는 사용자 지정 명령을 실행합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/85026-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n해설:・ \nA(X) : 1000 개의 인스턴스에 일일이 다 Lambda 로 패치 적용한다는 것은 비효율적이고 \n번거로움 \nB(X) : 자동 업데이트에는 시간이 좀 걸림. \"\"패치 관리자는 승인 및 거부된 패치 목록과 \n\n함께 릴리스 후 며칠 이내에 패치를 자동 승인하기 위한 규칙을 포함 하는 패치 기준선 을 \n사용합니다. \nhttps://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-pat\nch.html \nC(X) : 가능한 빨리 패치해야한다고 했는데 예약을 하고 있어서 안 됨.  \nD(O) : 리소스 그룹을 통해 한 번에 여러 인스턴스를 업데이트 가능. 리소스 그룹이 명령 \n대상으로 지원됨에 따라 해당 리소스 그룹에 속한 모든 관리형 인스턴스에서 관리 및 임시 \n작업을 자동화할 수 있습니다. \nhttps://aws.amazon.com/ko/about-aws/whats-new/2019/08/now-select-resource-group\ns-as-targets-for-aws-systems-manager-run-command/ \n \n참고: \nhttps://docs.aws.amazon.com/ko_kr/systems-manager/latest/userguide/about-windows-\napp-patching.html", "answer_choice": "D"}, "51": {"q_num": 51, "question": "회사는 REST API 로 검색하기 위해 주문 배송 통계를 제공하는 애플리케이션을 개발 \n중입니다. 이 회사는 배송 통계를 추출하고 데이터를 읽기 쉬운 HTML 형식으로 구성하고 \n매일 아침 여러 이메일 주소로 보고서를 보내려고 합니다. \n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 단계 조합을 취해야 합니까? \n(2 개를 선택하세요.) \nA. 데이터를 Amazon Kinesis Data Firehose 로 보내도록 애플리케이션을 구성합니다. \nB. Amazon Simple Email Service(Amazon SES)를 사용하여 데이터 형식을 지정하고 \n보고서를 이메일로 보냅니다. \nC. AWS Glue 작업을 호출하여 데이터에 대한 애플리케이션의 API 를 쿼리하는 Amazon \nEventBridge(Amazon CloudWatch Events) 예약 이벤트를 생성합니다. \nD. AWS Lambda 함수를 호출하여 데이터에 대한 애플리케이션의 API 를 쿼리하는 Amazon \nEventBridge(Amazon CloudWatch Events) 예약 이벤트를 생성합니다. \nE. Amazon S3 에 애플리케이션 데이터를 저장합니다. 보고서를 이메일로 보낼 S3 이벤트 \n대상으로 Amazon Simple Notification Service(Amazon SNS) 주제를 생성합니다.", "answer_block": "Answer: B, D \nhttps://www.examtopics.com/discussions/amazon/view/85557-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \n\nhttps://docs.aws.amazon.com/ses/latest/dg/send-email-formatted.html \n1. 데이터에 대한 애플리케이션의 API 를 쿼리하기 위해 AWS Lambda 함수를 호출하는 \nAmazon EventBridge(Amazon CloudWatch Events) 예약 이벤트를 생성합니다. 이 단계는 \nAWS Lambda 를 사용하여 배송 통계를 추출하고 데이터를 HTML 형식으로 구성할 수 \n있습니다. \n2. Amazon Simple Email Service(Amazon SES)를 사용하여 데이터 형식을 지정하고 \n이메일로 보고서를 보냅니다. \n이 단계는 Amazon SES 를 사용하여 매일 아침 동시에 여러 이메일 주소로 보고서를 \n전송함으로써 수행할 수 있습니다. \n따라서 옵션 D 와 B 는 이 질문에 대한 올바른 선택입니다. Kinesis Data Firehose 가 이 사용 \n사례에 필요하지 않기 때문에 옵션 A\n는 올바르지 않습니다. 애플리케이션의 API\n를 \n쿼리하는 데 AWS Glue 가 필요하지 않기 때문에 옵션 C 는 올바르지 않습니다. S3 이벤트 \n알림을 사용하여 이메일로 보고서를 보낼 수 없기 때문에 옵션 E 는 올바르지 않습니다. \n \n설명2: \nB(O) : HTML 형식의 이메일 요구사항을 충족 \nD(O) : 매일 아침 일정 이벤트 요구사항 충족", "answer_choice": "B"}, "52": {"q_num": 52, "question": "회사에서 온프레미스 애플리케이션을 AWS 로 마이그레이션하려고 합니다. 애플리케이션은 \n수십 기가바이트에서 수백 테라바이트까지 다양한 크기의 출력 파일을 생성합니다. \n애플리케이션 데이터는 표준 파일 시스템 구조로 저장되어야 합니다. 회사는 자동으로 \n확장되는 솔루션을 원합니다. 고가용성이며 최소한의 운영 오버헤드가 필요합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. \nAmazon \nElastic \nContainer \nService(Amazon \nECS)에서 \n컨테이너로 \n실행되도록 \n애플리케이션을 마이그레이션합니다. 스토리지에 Amazon S3 를 사용합니다. \nB. Amazon Elastic Kubernetes Service(Amazon EKS)에서 컨테이너로 실행되도록 \n애플리케이션을 마이그레이션합니다. 스토리지에 Amazon Elastic Block Store(Amazon \nEBS)를 사용합니다. \nC. \n다중 \nAZ \nAuto \nScaling \n그룹의 \nAmazon \nEC2 \n인스턴스로 \n애플리케이션을 \n마이그레이션합니다. 스토리지에 Amazon Elastic File System(Amazon EFS)을 사용합니다. \nD. \n다중 \nAZ \nAuto \nScaling \n그룹의 \nAmazon \nEC2 \n인스턴스로 \n애플리케이션을 \n마이그레이션합니다. 스토리지에 Amazon Elastic Block Store(Amazon EBS)를 사용합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/85265-exam-aws-certified-solut\n\nions-architect-associate-saa-c03/ \n \n설명1:・ \nEFS 는 표준 파일 시스템으로 자동 확장되며 가용성이 높습니다. \n \n설명2: \n고가용성이므로 Auto Scaling 이 들어간 C,D 둘 중 하나가 정답. EFS vs EBS 를 비교해보면 \n보통은 EFS 가 정답인 경우가 많음. 일단 EBS 는 여러 EC2 인스턴스에서 동시 접속할 수 \n없다는 단점이 치명적이기 때문. \nAmazon Elastic File System 은 전체 파일 시스템 액세스 의미 체계를 지원하는 표준 파일 \n시스템 인터페이스를 제공합니다. \nhttps://docs.aws.amazon.com/efs/latest/ug/using-fs.html \nEBS 다중 연결 볼륨에서 표준 파일 시스템 작업은 지원되는 구성이 아닙니다. \nhttps://aws.amazon.com/ko/premiumsupport/knowledge-center/ebs-access-volumes-us\ning-multi-attach/", "answer_choice": "C"}, "53": {"q_num": 53, "question": "회사는 Amazon S3 에 회계 기록을 저장해야 합니다. 기록은 1 년 동안 즉시 액세스할 수 \n있어야 하며 그 후 추가로 9 년 동안 보관해야 합니다. 관리자 및 루트 사용자를 포함하여 \n회사의 그 누구도 전체 10\n년 동안 기록을 삭제할 수 없습니다. 기록은 최대한의 \n복원력으로 저장해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 전체 10 년 동안 S3 Glacier 에 기록을 저장합니다. 접근통제 정책을 사용하여 10 년 동안 \n기록 삭제를 거부합니다. \nB. S3 Intelligent-Tiering 을 사용하여 레코드를 저장합니다. IAM 정책을 사용하여 레코드 \n삭제를 거부합니다. 10 년 후 삭제를 허용하도록 IAM 정책을 변경합니다. \nC. S3 수명 주기 정책을 사용하여 1 년 후에 S3 Standard 에서 S3 Glacier Deep Archive 로 \n레코드를 전환합니다. 10 년 동안 규정 준수 모드에서 S3 Object Lock 을 사용합니다. \nD. S3 수명 주기 정책을 사용하여 1\n년 후 레코드를 S3 Standard\n에서 S3 One \nZone-Infrequent Access(S3 One Zone-IA)로 전환합니다. 10 년 동안 거버넌스 모드에서 S3 \nObject Lock 을 사용합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/85532-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n\n설명1:・ \nA(X) : 1 년 동안 즉시 액세스할 수 있어야 한다고 했으므로 액세스 시간이 1 분 이상 걸리는 \nS3 Glacier 는 오답. \nB(X) : 특정 기간동안 즉시 액세스할 수 있어야 하므로 Intelligent Tiering 이 아니라 Life \nCycle Policy 가 적합. \nC(O) : S3 Standard = 즉시 액세스 가능 / S3 Glacier Deep Archive = 콜드 스토리지. \n보관용으로 사용됨. Object Lock 으로 객체 삭제 방지. \nS3 객체 잠금을 사용하면 write-once-read-many(WORM) 모델을 사용하여 객체를 저장할 \n수 있습니다. 객체 잠금은 고정된 시간 동안 또는 무기한으로 객체의 삭제 또는 덮어쓰기를 \n방지하는 데 도움이 될 수 있습니다.  \nhttps://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/object-lock.html \nD(X) : 기록은 최대한의 복원력으로 저장해야한다고 했으므로 One Zone-IA 는 적합하지 \n않음. \n \n설명2: \n1 년 동안 즉시 액세스 가능한 레코드의 요구 사항을 충족한 다음 최대 복원력으로 추가 \n9 년 동안 보관하기 위해 S3 수명 주기 정책을 사용하여 1 년 후 S3 Standard 에서 S3 \nGlacier Deep Archive 로 레코드를 전환할 수 있습니다. 또한 관리자 및 루트 사용자를 \n포함하여 누구도 레코드를 삭제할 수 없도록 10 년 동안 규정 준수 모드에서 S3 객체 \n잠금을 사용할 수 있습니다. 따라서 정답은 옵션 C 입니다.", "answer_choice": "C"}, "54": {"q_num": 54, "question": "회사는 AWS 에서 여러 Windows 워크로드를 실행합니다. 회사 직원은 두 개의 Amazon \nEC2 인스턴스에서 호스팅되는 Windows 파일 공유를 사용합니다. 파일 공유는 서로 간에 \n데이터를 동기화하고 중복 복사본을 유지합니다. 이 회사는 사용자가 현재 파일에 \n액세스하는 방식을 보존하는 고가용성 및 내구성 스토리지 솔루션을 원합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. 모든 데이터를 Amazon S3 로 마이그레이션합니다. 사용자가 파일에 액세스할 수 있도록 \nIAM 인증을 설정합니다. \nB. Amazon S3 파일 게이트웨이를 설정합니다. 기존 EC2 인스턴스에 S3 파일 게이트웨이를 \n탑재합니다. \nC. 다중 AZ 구성을 사용하여 파일 공유 환경을 Windows 파일 서버용 Amazon FSx 로 \n확장합니다. 모든 데이터를 Windows 파일 서버용 FSx 로 마이그레이션합니다. \nD. 다중 AZ 구성을 사용하여 파일 공유 환경을 Amazon Elastic File System(Amazon \nEFS)으로 확장합니다. 모든 데이터를 Amazon EFS 로 마이그레이션합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/85574-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \nWindows File 공유가 핵심 키워드. 답은 C. \n \n설명2: \nhttps://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/AmazonEFS.html \nAmazon FSx for Windows File Server 는 완전히 네이티브로 지원되는 완전히 관리되는 \nMicrosoft Windows 파일 서버를 제공합니다. \n윈도우 파일 시스템. \nhttps://docs.aws.amazon.com/fsx/latest/WindowsGuide/what-is.html", "answer_choice": "C"}, "55": {"q_num": 55, "question": "솔루션 설계자는 여러 서브넷을 포함하는 VPC 아키텍처를 개발 중입니다. 아키텍처는 \nAmazon EC2 인스턴스 및 Amazon RDS DB 인스턴스를 사용하는 애플리케이션을 \n호스팅합니다. 아키텍처는 2 개의 가용 영역에 있는 6 개의 서브넷으로 구성됩니다. 각 가용 \n영역에는 퍼블릭 서브넷, 프라이빗 서브넷 및 데이터베이스용 전용 서브넷이 포함됩니다. \n프라이빗 서브넷에서 실행되는 EC2 인스턴스만 RDS 데이터베이스에 액세스할 수 \n있습니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 퍼블릭 서브넷의 CIDR 블록에 대한 경로를 제외하는 새 라우팅 테이블을 생성합니다. \n라우팅 테이블을 데이터베이스 서브넷과 연결합니다. \nB. 퍼블릭 서브넷의 인스턴스에 할당된 보안 그룹의 인바운드 트래픽을 거부하는 보안 \n그룹을 생성합니다. 보안 그룹을 DB 인스턴스에 연결합니다. \nC. 프라이빗 서브넷의 인스턴스에 할당된 보안 그룹의 인바운드 트래픽을 허용하는 보안 \n그룹을 생성합니다. 보안 그룹을 DB 인스턴스에 연결합니다. \nD. 퍼블릭 서브넷과 프라이빗 서브넷 사이에 새로운 피어링 연결을 생성합니다. 프라이빗 \n서브넷과 데이터베이스 서브넷 간에 다른 피어링 연결을 만듭니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/85409-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명:・ \n\n프라이빗 서브넷의 인스턴스에 할당된 보안 그룹의 인바운드 트래픽을 허용하는 보안 \n그룹을 생성하면 프라이빗 서브넷에서 실행되는 EC2 만 RDS 데이터베이스에 액세스할 수 \n있습니다. 보안 그룹을 DB 와 연결하여 지정된 보안 그룹에 속한 인스턴스로만 접근을 \n제한합니다. \n \n질문에 설명된 요구 사항을 충족하는 솔루션은 옵션 C\n입니다. 프라이빗 서브넷의 \n인스턴스에 할당된 보안 그룹에서 인바운드 트래픽을 허용하는 보안 그룹을 생성합니다. \n보안 그룹을 DB 인스턴스에 연결합니다. \n \n이 솔루션에서 DB 인스턴스에 적용된 보안 그룹은 프라이빗 서브넷의 인스턴스에 할당된 \n보안 그룹의 인바운드 트래픽을 허용합니다. 이렇게 하면 프라이빗 서브넷에서 실행되는 \nEC2 인스턴스만 RDS 데이터베이스에 액세스할 수 있습니다.", "answer_choice": "C"}, "56": {"q_num": 56, "question": "회사는 Amazon Route 53 에 도메인 이름을 등록했습니다. 이 회사는 ca-central-1 리전의 \nAmazon API Gateway 를 백엔드 마이크로서비스 API 의 공용 인터페이스로 사용합니다. 타사 \n서비스는 API 를 안전하게 사용합니다. 회사는 타사 서비스에서 HTTPS 를 사용할 수 있도록 \n회사의 도메인 이름 및 해당 인증서로 API 게이트웨이 URL 을 설계하려고 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. API Gateway 에서 Name=\"Endpoint-URL\" 및 Value=\"Company Domain Name\"으로 단계 \n변수를 생성하여 기본 URL 을 덮어씁니다. 회사의 도메인 이름과 연결된 공인 인증서를 \nAWS Certificate Manager(ACM)로 가져옵니다. \nB. 회사의 도메인 이름으로 Route 53 DNS 레코드를 생성합니다. 별칭 레코드가 리전 API \n게이트웨이 단계 엔드포인트를 가리키도록 합니다. 회사의 도메인 이름과 연결된 공인 \n인증서를 us-east-1 리전의 AWS Certificate Manager(ACM)로 가져옵니다. \nC. 리전 API 게이트웨이 엔드포인트를 생성합니다. API Gateway 엔드포인트를 회사의 \n도메인 이름과 연결합니다. 회사의 도메인 이름과 연결된 공인 인증서를 동일한 리전의 \nAWS Certificate Manager(ACM)로 가져옵니다. API Gateway 엔드포인트에 인증서를 \n연결합니다. API Gateway 엔드포인트로 트래픽을 라우팅하도록 Route 53 을 구성합니다. \nD. 리전 API 게이트웨이 엔드포인트를 생성합니다. API Gateway 엔드포인트를 회사의 \n도메인 이름과 연결합니다. 회사의 도메인 이름과 연결된 공인 인증서를 us-east-1 리전의 \nAWS Certificate Manager(ACM)로 가져옵니다. API Gateway API 에 인증서를 연결합니다. \n회사의 도메인 이름으로 Route 53 DNS 레코드를 생성합니다. A 레코드가 회사의 도메인 \n이름을 가리키도록 합니다.", "answer_block": "Answer: C \n\nhttps://www.examtopics.com/discussions/amazon/view/85266-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \n사용자 정의 도메인 이름 은 API 사용자에게 제공할 수 있는 더 간단하고 직관적인 \nURL 입니다. API 를 배포한 후 귀하(및 귀하의 고객)는 다음 형식의 기본 기본 URL 을 \n사용하여 API 를 호출할 수 있습니다. \nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-custom-domai\nns.html \n \n리전 사용자 지정 도메인 이름은 API 와 동일한 AWS 리전에 있는 SSL/TLS 인증서를 \n사용해야 합니다. \nhttps://aws.amazon.com/ko/premiumsupport/knowledge-center/custom-domain-name-\namazon-api-gateway/ \n \n・여기서 API Gateway URL 이란, Route 53 에 등록된 도메인 이름으로, 이를 통해 API 를 \n호출할 수 있음. \n・인증서는 HTTPS 에 사용됨. HTTPS=HTTL + SSL 인데, SSL 에 인증서가 필요하기 때문. \n인증서는 ACM 으로 가져올 수 있음. \n \n1. 리전 API 게이트웨이 엔드포인트 생성 및 회사 도메인 이름과 연결 \n또한 API Gateway REST API, Amazon CLI 또는 Amazon SDK 중 하나를 호출하여 사용자 \n지정 도메인 이름을 호스트 이름으로 사용하여 API\n의 기본 경로 매핑을 설정할 수 \n있습니다. \nhttps://docs.amazonaws.cn/en_us/apigateway/latest/developerguide/how-to-edge-opti\nmized-custom-domain-name.html#how-to-custom-domains-mapping-console \n2. 회사 도메인 이름과 연결된 공인 인증서를 동일 리전의 ACM 으로 가져옴 \nAPI Gateway 리전 사용자 지정 도메인 이름의 경우 API 와 동일한 리전에서 인증서를 \n요청하거나 가져와야 합니다......도메인 이름에 대한 인증서를 ACM 으로 가져오려면.... \nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-custom-domai\nns-prerequisites.html \n3. API 게이트웨이 엔드포인트에 인증서 연결 \nACM 인증서로 리전 사용자 지정 도메인 이름을 생성(또는 마이그레이션)하면 API \nGateway 는 해당 계정에 서비스 연결 역할을 생성합니다(이 역할이 아직 없는 경우). \n서비스 연결 역할은 ACM 인증서를 해당 리전 엔드포인트에 연결하는 데 필요합니다. \nhttps://docs.aws.amazon.com/ko_kr/apigateway/latest/developerguide/apigateway-regio\n\nnal-api-custom-domain-create.html \n4. API 게이트웨이 엔드포인트로 트래픽 라우팅 하도록 Route 53 설정 \n \nAPI Gateway 리전 사용자 지정 도메인 이름의 경우 API 와 동일한 리전에서 인증서를 \n요청하거나 가져와야 합니다. 그리하여 회사의 도메인 이름과 연결된 공인 인증서는 동일 \n리전의 ACM 으로 가져와야됩니다. 따라서 정답은 C 에 한표 입니다. \n도메인 이름을 사용하여 Amazon API Gateway API 로 트래픽 라우팅  \n・리전 API 엔드포인트(Regional API endpoint): 리전 API 엔드포인트로 트래픽을 라우팅하는 \nRoute 53 별칭 레코드를 생성합니다. \nhttps://docs.aws.amazon.com/ko_kr/Route53/latest/DeveloperGuide/routing-to-api-gate\nway.html \n \n설명2 \n회사의 도메인 이름과 해당 인증서로 API Gateway URL 을 설계하려면 회사에서 다음을 \n수행해야 합니다. \n1. 지역 API 게이트웨이 엔드포인트 생성: 이를 통해 회사는 지역에 특정한 엔드포인트를 \n생성할 수 있습니다. \n2. API 게이트웨이 엔드포인트를 회사의 도메인 이름과 연결: 이렇게 하면 회사에서 API \n게이트웨이 URL 에 자체 도메인 이름을 사용할 수 있습니다. \n3. 회사의 도메인 이름과 연결된 공인 인증서를 동일한 리전의 AWS Certificate \nManager(ACM)로 가져옵니다. 이렇게 하면 회사에서 API 와의 보안 통신을 위해 HTTPS 를 \n사용할 수 있습니다. \n4. API Gateway 엔드포인트에 인증서 첨부: 회사에서 API Gateway URL 보안을 위해 \n인증서를 사용할 수 있습니다. \n5. 트래픽을 API 게이트웨이 엔드포인트로 라우팅하도록 Route 53 구성: 이를 통해 회사는 \nRoute 53 을 사용하여 회사의 도메인 이름을 사용하는 API 게이트웨이 URL 로 트래픽을 \n라우팅할 수 있습니다.", "answer_choice": "C"}, "57": {"q_num": 57, "question": "한 회사에서 인기 있는 소셜 미디어 웹사이트를 운영하고 있습니다. 웹사이트는 사용자에게 \n이미지를 업로드하여 다른 사용자와 공유할 수 있는 기능을 제공합니다. 회사는 이미지에 \n부적절한 콘텐츠가 포함되지 않았는지 확인하고 싶습니다. 회사는 개발 노력을 최소화하는 \n솔루션이 필요합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. Amazon Comprehend\n를 사용하여 부적절한 콘텐츠를 감지합니다. 신뢰도가 낮은 \n\n예측에는 인적 검토를 사용합니다. \nB. Amazon Rekognition\n을 사용하여 부적절한 콘텐츠를 감지합니다. 신뢰도가 낮은 \n예측에는 인적 검토를 사용합니다. \nC. Amazon SageMaker 를 사용하여 부적절한 콘텐츠를 감지합니다. 신뢰도가 낮은 예측에 \n레이블을 지정하려면 정답을 사용합니다. \nD. AWS Fargate 를 사용하여 사용자 지정 기계 학습 모델을 배포하여 부적절한 콘텐츠를 \n감지합니다. 신뢰도가 낮은 예측에 레이블을 지정하려면 정답을 사용합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/85452-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명:・ \nAmazon Rekognition\n을 사용하여 부적절하거나 원치 않거나 불쾌감을 주는 콘텐츠를 \n감지할 수 있습니다. \nhttps://docs.aws.amazon.com/rekognition/latest/dg/moderation.html \n \n참조 \nhttps://docs.aws.amazon.com/rekognition/latest/dg/moderation.html?pg=ln&sec=ft \nhttps://docs.aws.amazon.com/rekognition/latest/dg/a2i-rekognition.html", "answer_choice": "B"}, "58": {"q_num": 58, "question": "회사는 확장성 및 가용성에 대한 요구 사항을 충족하기 위해 컨테이너에서 중요한 응용 \n프로그램을 실행하려고 합니다. 회사는 중요한 응용 프로그램의 유지 관리에 집중하는 것을 \n선호합니다. 회사는 컨테이너화된 워크로드를 실행하는 기본 인프라의 프로비저닝 및 \n관리에 대한 책임을 원하지 않습니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. Amazon EC2 인스턴스를 사용하고 인스턴스에 Docker 를 설치합니다. \nB. Amazon EC2 작업자 노드에서 Amazon Elastic Container Service(Amazon ECS)를 \n사용합니다. \nC. AWS Fargate 에서 Amazon Elastic Container Service(Amazon ECS)를 사용합니다. \nD. \nAmazon \nElastic \nContainer \nService(Amazon \nECS)에 \n최적화된 \nAmazon \n머신 \n이미지(AMI)의 Amazon EC2 인스턴스를 사용합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/85453-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n\n \n설명1: \nAWS 에서 컨테이너라고 하면 ECS, ECS 라고 하면 일단 Fargate 부터 떠올리면 됨. AWS \nFargate Fargate\n는 Amazon EC2 인스턴스의 서버나 클러스터를 관리할 필요 없이 \n컨테이너를 실행하기 위해 Amazon ECS 에 사용할 수 있는 기술입니다. \nhttps://docs.aws.amazon.com/ko_kr/AmazonECS/latest/developerguide/AWS_Fargate.ht\nml \n \n설명2: \n요구 사항은 컨테이너화된 워크로드를 실행하기 위해 기본 인프라를 프로비저닝하고 관리할 \n필요 없이 확장성과 가용성을 위한 것이므로 AWS Fargate 에서 AWS ECS 를 사용합니다. \nhttps://docs.aws.amazon.com/AmazonECS/latest/userguide/what-is-fargate.html", "answer_choice": "C"}, "59": {"q_num": 59, "question": "회사는 300 개 이상의 글로벌 웹사이트 및 애플리케이션을 호스팅합니다. 이 회사는 매일 \n30TB 이상의 클릭스트림 데이터를 분석할 플랫폼이 필요합니다. \n솔루션 설계자는 클릭스트림 데이터를 전송하고 처리하기 위해 무엇을 해야 합니까? \nA. AWS Data Pipeline 을 설계하여 데이터를 Amazon S3 버킷에 보관하고 데이터로 Amazon \nEMR 클러스터를 실행하여 분석을 생성합니다. \nB. Amazon EC2 인스턴스의 Auto Scaling 그룹을 생성하여 데이터를 처리하고 Amazon \nRedshift 가 분석에 사용할 수 있도록 Amazon S3 데이터 레이크로 보냅니다. \nC. 데이터를 Amazon CloudFront 에 캐시합니다. Amazon S3 버킷에 데이터를 저장합니다. \n객체가 S3 버킷에 추가될 때. AWS Lambda 함수를 실행하여 분석용 데이터를 처리합니다. \nD. Amazon Kinesis Data Streams\n에서 데이터를 수집합니다. Amazon Kinesis Data \nFirehose 를 사용하여 Amazon S3 데이터 레이크로 데이터를 전송합니다. 분석을 위해 \nAmazon Redshift 에 데이터를 로드합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/85793-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명:・ \n대량의 스트림 데이터 수집 = Kinesis Data Streams. 정답은 D. \n※실제 사례가 있음. \n◎전 세계 300 개 이상의 Hearst 웹사이트에서 스트리밍되는 하루 30 테라바이트 이상의 \n클릭스트림 데이터를 전송하고 처리하는 클릭스트림 분석 플랫폼을 구축했습니다. \n\n◎Amazon Kinesis Firehose 는 버퍼링된 데이터를 Amazon Kinesis Data Streams 에서 \nAmazon Simple Storage Service (Amazon S3) 의 영구 스토리지로 자동 이동합니다. 이는 \n팀이 이전에 관리해야 했던 Amazon Elastic Compute Cloud(Amazon EC2) 인스턴스를 \n대체합니다. \n◎변환된 클릭스트림 데이터는 Hearst 데이터 레이크에서 가져와 분석 쿼리 및 복잡한 \n데이터 과학 작업을 위해 Amazon Redshift 로 전송됩니다. \n◎Amazon Redshift 에서 데이터는 API 를 통해 회사의 콘텐츠 관리 시스템으로 최종 \n사용자에게 푸시됩니다. \nhttps://aws.amazon.com/ko/solutions/case-studies/hearst-data-analytics/", "answer_choice": "D"}, "60": {"q_num": 60, "question": "회사에 AWS 에서 호스팅되는 웹 사이트가 있습니다. 웹 사이트는 HTTP 와 HTTPS 를 \n별도로 처리하도록 구성된 ALB(Application Load Balancer) 뒤에 있습니다. 회사는 요청이 \nHTTPS 를 사용하도록 모든 요청을 웹사이트로 전달하려고 합니다. \n솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. HTTPS 트래픽만 허용하도록 ALB 의 네트워크 ACL 을 업데이트합니다. \nB. URL 의 HTTP 를 HTTPS 로 바꾸는 규칙을 만듭니다. \nC. ALB 에서 리스너 규칙을 생성하여 HTTP 트래픽을 HTTPS 로 리디렉션합니다. \nD. ALB 를 SNI(서버 이름 표시)를 사용하도록 구성된 Network Load Balancer 로 교체합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/85121-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n해설:・ \nApplication Load Balancer 를 위한 리스너…..쿼리 문자열 조건을 사용하여 쿼리 문자열의 \n키/값 페어 또는 값을 기반으로 요청을 라우팅하는 규칙을 구성할 수 있습니다. \nhttps://docs.aws.amazon.com/ko_kr/elasticloadbalancing/latest/application/load-balance\nr-listeners.html \nApplication Load Balancer 리스너 규칙을 사용하여 HTTP 요청을 HTTPS 로 리디렉션하려고 \n합니다. 어떻게 해야 하나요? \n①HTTP 요청을 HTTPS 로 리디렉션하는 HTTP 리스너 규칙 생성. \n②HTTPS 리스너 생성. \n③Application Load Balancer 의 보안 그룹이 443 의 트래픽을 허용하는지 확인 \nhttps://aws.amazon.com/ko/premiumsupport/knowledge-center/elb-redirect-http-to-htt\nps-using-alb/ \n\n \n참조 \nhttps://aws.amazon.com/premiumsupport/knowledge-center/elb-redirect-http-to-https-\nusing-alb/ \nhttps://repost.aws/ko/knowledge-center/elb-redirect-http-to-https-using-alb", "answer_choice": "C"}, "61": {"q_num": 61, "question": "한 회사가 AWS 에서 2 계층 웹 애플리케이션을 개발하고 있습니다. 회사 개발자는 백엔드 \nAmazon RDS 데이터베이스에 직접 연결되는 Amazon EC2 인스턴스에 애플리케이션을 \n배포했습니다. 회사는 애플리케이션에 데이터베이스 자격 증명을 하드코딩해서는 안 됩니다. \n또한 회사는 정기적으로 데이터베이스 자격 증명을 자동으로 교체하는 솔루션을 구현해야 \n합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. \n인스턴스 \n메타데이터에 \n데이터베이스 \n자격 \n증명을 \n저장합니다. \nAmazon \nEventBridge(Amazon CloudWatch Events) 규칙을 사용하여 RDS 자격 증명과 인스턴스 \n메타데이터를 동시에 업데이트하는 예약된 AWS Lambda 함수를 실행합니다. \nB. 암호화된 Amazon S3 버킷의 구성 파일에 데이터베이스 자격 증명을 저장합니다. \nAmazon EventBridge(Amazon CloudWatch Events) 규칙을 사용하여 RDS 자격 증명과 구성 \n파일의 자격 증명을 동시에 업데이트하는 예약된 AWS Lambda 함수를 실행합니다. S3 버전 \n관리를 사용하여 이전 값으로 폴백하는 기능을 보장합니다. \nC. 데이터베이스 자격 증명을 AWS Secrets Manager 에 암호로 저장합니다. 보안 비밀에 \n대한 자동 순환을 켭니다. EC2 역할에 필요한 권한을 연결하여 보안 암호에 대한 액세스 \n권한을 부여합니다. \nD. 데이터베이스 자격 증명을 AWS Systems Manager Parameter Store\n에 암호화된 \n파라미터로 저장합니다. 암호화된 매개변수에 대해 자동 회전을 켭니다. EC2 역할에 필요한 \n권한을 연결하여 암호화된 파라미터에 대한 액세스 권한을 부여합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/85580-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명:・ \n애플리케이션에 자격증명 하드코딩 안 됨 = Secrets Manager. \nSecrets Manager\n를 사용하면 애플리케이션 소스 코드에서 하드 코딩된 자격 증명을 \n제거하고 애플리케이션 자체에 자격 증명을 저장하지 않음으로써 보안 태세를 개선할 수 \n있습니다. 사용자의 개입 없이 지정한 일정에 따라 자동으로 보안 암호를 교체하도록 \n\nSecrets Manager 를 구성할 수 있습니다. 교체는 AWS Lambda 함수를 사용하여 정하고 \n실행합니다. \nhttps://docs.aws.amazon.com/ko_kr/secretsmanager/latest/userguide/intro.html \n \n참고: \nhttps://docs.aws.amazon.com/secretsmanager/latest/userguide/create_database_secret.\nhtml", "answer_choice": "C"}, "62": {"q_num": 62, "question": "회사에서 AWS 에 새로운 공개 웹 애플리케이션을 배포하고 있습니다. 애플리케이션은 \nALB(Application Load Balancer) 뒤에서 실행됩니다. 애플리케이션은 외부 CA(인증 \n기관)에서 발급한 SSL/TLS 인증서를 사용하여 에지에서 암호화해야 합니다. 인증서가 \n만료되기 전에 매년 인증서를 교체해야 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. AWS Certificate Manager(ACM)를 사용하여 SSL/TLS 인증서를 발급합니다. 인증서를 \nALB 에 적용합니다. 관리형 갱신 기능을 사용하여 인증서를 자동으로 교체합니다. \nB. AWS Certificate Manager(ACM)를 사용하여 SSL/TLS 인증서를 발급합니다. 인증서에서 \n키 자료를 가져옵니다. AL\n에 인증서 적용 관리되는 갱신 기능을 사용하여 인증서를 \n자동으로 교체합니다. \nC. AWS Certificate Manager(ACM) 사설 인증 기관을 사용하여 루트 CA 에서 SSL/TLS \n인증서를 발급합니다. 인증서를 ALB 에 적용합니다. 관리형 갱신 기능을 사용하여 인증서를 \n자동으로 교체합니다. \nD. AWS Certificate Manager(ACM)를 사용하여 SSL/TLS 인증서를 가져옵니다. 인증서를 \nALB 에 적용합니다. Amazon EventBridge(Amazon CloudWatch Events)를 사용하여 인증서가 \n만료될 때 알림을 보냅니다. 인증서를 수동으로 교체합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/85524-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명:・ \n외부 인증기관에서 발급한 SSL/TLS 인증서가 이미 있고 이를 사용해야하므로 ACM 쪽에서 \nSSL/TLS 인증서를 발급하는 A,B 는 모두 오답. \nC(X) : 인증서가 있는데 또 발급받을 필요가 없음. \nhttps://www.amazonaws.cn/en/certificate-manager/faqs/#Managed_renewal_and_deploy\nment", "answer_choice": "D"}, "63": {"q_num": 63, "question": "회사는 AWS 에서 인프라를 실행하고 문서 관리 애플리케이션에 대해 700,000 명의 등록 \n기반을 보유하고 있습니다. 회사는 큰 .pdf 파일을 .jpg 이미지 파일로 변환하는 제품을 \n만들려고 합니다. .pdf 파일의 크기는 평균 5MB 입니다. 회사는 원본 파일과 변환 파일을 \n보관해야 합니다. 솔루션 설계자는 시간이 지남에 따라 빠르게 증가할 수요를 수용할 수 \n있는 확장 가능한 솔루션을 설계해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족합니까? \nA. .pdf 파일을 Amazon S3 에 저장합니다. AWS Lambda 함수를 호출하여 파일을 .jpg \n형식으로 변환하고 Amazon S3 에 다시 저장하도록 S3 PUT 이벤트를 구성합니다. \nB. .pdf 파일을 Amazon DynamoD 에 저장 DynamoDB 스트림 기능을 사용하여 AWS \nLambda 함수를 호출하여 파일을 .jpg 형식으로 변환하고 DynamoDB 에 다시 저장합니다. \nC. Amazon EC2 인스턴스, Amazon Elastic Block Store(Amazon EBS) 스토리지 및 Auto \nScaling 그룹이 포함된 AWS Elastic Beanstalk 애플리케이션에 .pdf 파일을 업로드합니다. \nEC2 인스턴스의 프로그램을 사용하여 파일을 .jpg 형식으로 변환합니다. .pdf 파일과 .jpg \n파일을 EBS 스토어에 저장합니다. \nD. .pdf 파일을 Amazon EC2 인스턴스, Amazon Elastic File System(Amazon EFS) 스토리지 \n및 Auto Scaling 그룹이 포함된 AWS Elastic Beanstalk 애플리케이션에 업로드합니다. EC2 \n인스턴스의 프로그램을 사용하여 파일을 .jpg 형식으로 변환합니다. .pdf 파일과 .jpg \n파일을 EBS 스토어에 저장합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/85795-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \nA(O) : S3 에 넣으면 Lambda 를 통해 자동으로 처리가 되도록 하는 거라 OK. S3 는 저렴함. \nB(X) : dynamodb 는 이미지 저장용으론… \nC(X) : 저렴한 S3 가 있는데 굳이... 인스턴스 비용도 나감. \nD(x) : C 와 마찬가지. \n \n설명2: \nElastic BeanStalk 는 비싸고 DocumentDB 는 최대 400KB 의 파일을 업로드할 수 있습니다. \n따라서 Lambda 와 S3 가 하나여야 합니다.", "answer_choice": "A"}, "64": {"q_num": 64, "question": "회사는 온프레미스에서 실행되는 Windows 파일 서버에 5TB 이상의 파일 데이터를 가지고 \n있습니다. 사용자와 애플리케이션은 매일 데이터와 상호 작용합니다. \n이 회사는 Windows 워크로드를 AWS\n로 이전하고 있습니다. 회사가 이 프로세스를 \n계속함에 따라 회사는 최소 지연 시간으로 AWS 및 온프레미스 파일 스토리지에 액세스할 \n수 있어야 합니다. 회사는 운영 오버헤드를 최소화하고 기존 파일 액세스 패턴을 크게 \n변경할 필요가 없는 솔루션이 필요합니다. 회사는 AWS 연결을 위해 AWS Site-to-Site VPN \n연결을 사용합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. AWS 에서 Windows 파일 서버용 Amazon FSx 를 배포 및 구성합니다. 온-프레미스 파일 \n데이터를 Windows 파일 서버용 FSx로 이동합니다. AWS에서 Windows 파일 서버용 FSx를 \n사용하도록 워크로드를 재구성합니다. \nB. 온프레미스에 Amazon S3 파일 게이트웨이를 배포하고 구성합니다. 온프레미스 파일 \n데이터를 S3 파일 게이트웨이로 이동합니다. S3 파일 게이트웨이를 사용하도록 온프레미스 \n워크로드 및 클라우드 워크로드를 재구성합니다. \nC. 온프레미스에 Amazon S3 파일 게이트웨이를 배포하고 구성합니다. 온프레미스 파일 \n데이터를 Amazon S3 로 이동합니다. Amazon S3 를 직접 사용하거나 S3 파일 게이트웨이를 \n사용하도록 워크로드를 재구성합니다. 각 워크로드의 위치에 따라 다릅니다. \nD. AWS 에서 Windows 파일 서버용 Amazon FSx 를 배포 및 구성합니다. 온프레미스에 \nAmazon FSx 파일 게이트웨이를 배포하고 구성합니다. 온프레미스 파일 데이터를 FSx 파일 \n게이트웨이로 이동합니다. AWS 의 Windows 파일 서버용 FSx 를 사용하도록 클라우드 \n워크로드를 구성합니다. FSx 파일 게이트웨이를 사용하도록 온프레미스 워크로드를 \n구성합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/85173-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \nWindows File Server + AWS 로 이동 = Amazon FSx File Gateway. \nAmazon FSx 파일 게이트웨이는 Amazon FSx 의 Windows 파일 공유에 대한 온프레미스 \n액세스를 최적화하여 사용자가 짧은 지연 시간과 공유 대역폭을 유지하면서 Windows 파일 \n서버용 FSx 데이터에 쉽게 액세스할 수 있도록 합니다. 사용자는 액세스할 수 있는 자주 \n사용하는 데이터의 로컬 캐시를 활용하여 성능을 높이고 데이터 전송 트래픽을 줄일 수 \n있습니다. 파일 읽기 및 쓰기와 같은 파일 시스템 작업은 모두 로컬 캐시에 대해 수행되는 \n반면 Amazon FSx 파일 게이트웨이는 변경된 데이터를 백그라운드에서 Windows 파일 \n서버용 FSx 와 동기화합니다. 이러한 기능을 사용하면 Windows 파일 서버용 FSx 에서 \n\nAWS 의 모든 온프레미스 파일 공유 데이터를 통합하고 보호되고 탄력적인 완전 관리형 \n파일 시스템의 이점을 누릴 수 있습니다. \nhttps://aws.amazon.com/storagegateway/faqs/?nc1=h_ls \n \n설명2: \nhttps://docs.aws.amazon.com/filegateway/latest/filefsxw/what-is-file-fsxw.html \n대기 시간을 최소화하면서 AWS 와 온프레미스 파일 스토리지 모두에 액세스해야 하는 \n회사의 요구 사항을 충족하기 위해 하이브리드 클라우드 아키텍처를 사용할 수 있습니다. \n한 가지 솔루션은 완벽하게 관리되는 Windows 파일 서버를 제공하는 AWS 에서 Windows \n파일 서버용 Amazon FSx 를 배포 및 구성하는 것입니다. \n온프레미스 파일 데이터는 온프레미스와 AWS 파일 스토리지 간의 브리지 역할을 할 수 \n있는 FSx 파일 게이트웨이로 이동할 수 있습니다. 클라우드 워크로드는 AWS\n에서 \nWindows File Server 용 FSx 를 사용하도록 구성할 수 있으며 온프레미스 워크로드는 FSx \n파일 게이트웨이를 사용하도록 구성할 수 있습니다. \n이 솔루션은 운영 오버헤드를 최소화하고 기존 파일 액세스 패턴을 크게 변경할 필요가 \n없습니다. 온프레미스와 AWS 간의 연결은 AWS Site-to-Site VPN 연결을 사용하여 설정할 \n수 있습니다. \n참조: \nWindows 파일 서버용 AWS FSx: https://aws.amazon.com/fsx/windows/ \nAWS FSx 파일 게이트웨이: https://aws.amazon.com/fsx/file-gateway/ \nAWS 사이트 간 VPN: https://aws.amazon.com/vpn/site-to-site-vpn/", "answer_choice": "D"}, "65": {"q_num": 65, "question": "병원은 최근 Amazon API Gateway 및 AWS Lambda 와 함께 RESTful API 를 배포했습니다. \n병원은 API Gateway 및 Lambda\n를 사용하여 PDF 형식 및 JPEG 형식의 보고서를 \n업로드합니다. 병원은 보고서에서 보호되는 건강 정보(PHI)를 식별하기 위해 Lambda \n코드를 수정해야 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 기존 Python 라이브러리를 사용하여 보고서에서 텍스트를 추출하고 추출된 텍스트에서 \nPHI 를 식별합니다. \nB. Amazon Textract 를 사용하여 보고서에서 텍스트를 추출합니다. Amazon SageMaker 를 \n사용하여 추출된 텍스트에서 PHI 를 식별합니다. \nC. Amazon Textract 를 사용하여 보고서에서 텍스트를 추출합니다. Amazon Comprehend \nMedical 을 사용하여 추출된 텍스트에서 PHI 를 식별합니다. \nD. \nAmazon \nRekognition\n을 \n사용하여 \n보고서에서 \n텍스트를 \n추출합니다. \nAmazon \n\nComprehend Medical 을 사용하여 추출된 텍스트에서 PHI 를 식별합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/85367-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \n・Textract 로 텍스트 추출, Comprehend Medical 을 통해 식별 \nA(X) : Textract 와 Comprehend Medical 을 사용하는 것이 파이썬 코드를 별도로 관리할 \n필요가 없어서 운영하기 편함. \nB(X) : SageMaker 는 기계 학습 모델 서비스. \nAmazon SageMaker 는 완전관리형 인프라, 도구 및 워크플로를 사용하여 모든 사용 사례에 \n대해 기계 학습(ML) 모델을 구축, 훈련 및 배포하는 완전관리형 서비스입니다.  \nhttps://aws.amazon.com/ko/sagemaker/faqs/ \nC(O) : Textract 는 OCR 같은 서비스. Comprehend 는 의료용 텍스트 식별 서비스. \nAmazon Textract 는 스캔한 문서에서 텍스트, 필기 및 데이터를 자동으로 추출하는 기계 \n학습(ML) 서비스입니다. 단순한 광학 문자 인식(OCR) 이상으로 양식 및 표의 데이터를 \n식별하고 이해하며 추출합니다. \nhttps://aws.amazon.com/ko/textract/ \nAmazon Comprehend Medical 은 HIPAA 적격 자연어 처리(NLP) 서비스로, 미리 학습된 \n기계 학습을 사용하여 처방전, 처치, 진단과 같은 의료 텍스트에서 의료 데이터를 파악하고 \n추출합니다.  \nhttps://aws.amazon.com/ko/comprehend/medical/ \nD(X) : Rekognition 은 이미지나 비디오 분석 서비스지 텍스트 추출 서비스가 아님. \nAmazon Rekognition 은 애플리케이션에 강력한 시각 분석 기능을 쉽게 추가할 수 있게 해 \n주는 서비스입니다. Rekognition Image 를 통해 수백만 개의 이미지를 검색, 확인 및 구성할 \n수 있는 강력한 애플리케이션을 쉽게 구축할 수 있습니다. Rekognition Video 를 통해 \n저장된 동영상 또는 실시간 스트림 동영상에서 동작 기반 컨텍스트를 추출하고 이를 분석할 \n수 있습니다.  \nhttps://aws.amazon.com/ko/rekognition/faqs/?nc=sn&loc=7 \n \n설명2: \n대기 시간을 최소화하면서 AWS 와 온프레미스 파일 스토리지 모두에 액세스해야 하는 \n회사의 요구 사항을 충족하기 위해 하이브리드 클라우드 아키텍처를 사용할 수 있습니다. \n한 가지 솔루션은 완벽하게 관리되는 Windows 파일 서버를 제공하는 AWS 에서 Windows \n파일 서버용 Amazon FSx\n를 배포 및 구성하는 것입니다. 온프레미스 파일 데이터는 \n온프레미스와 AWS 파일 스토리지 간의 브리지 역할을 할 수 있는 FSx 파일 게이트웨이로 \n\n이동할 수 있습니다. 클라우드 워크로드는 AWS 에서 Windows File Server 용 FSx 를 \n사용하도록 구성할 수 있으며 온프레미스 워크로드는 FSx 파일 게이트웨이를 사용하도록 \n구성할 수 있습니다. 이 솔루션은 운영 오버헤드를 최소화하고 기존 파일 액세스 패턴을 \n크게 변경할 필요가 없습니다. 온프레미스와 AWS 간의 연결은 AWS Site-to-Site VPN \n연결을 사용하여 설정할 수 있습니다. \n참조: \nAWS FSx for Windows File Server: https://aws.amazon.com/fsx/windows/ \nAWS FSx File Gateway: https://aws.amazon.com/fsx/file-gateway/ \nAWS Site-to-Site VPN: https://aws.amazon.com/vpn/site-to-site-vpn/", "answer_choice": "C"}, "66": {"q_num": 66, "question": "회사에 각각 크기가 약 5MB 인 많은 수의 파일을 생성하는 응용 프로그램이 있습니다. \n파일은 Amazon S3 에 저장됩니다. 회사 정책에 따라 파일을 삭제하려면 4 년 동안 보관해야 \n합니다. 파일에는 재생산하기 쉽지 않은 중요한 비즈니스 데이터가 포함되어 있으므로 \n즉각적인 액세스가 항상 필요합니다. 파일은 객체 생성 후 처음 30\n일 동안 자주 \n액세스되지만 처음 30 일 후에는 거의 액세스되지 않습니다. \n가장 비용 효율적인 스토리지 솔루션은 무엇입니까? \nA. 객체 생성 후 30 일 동안 S3 Standard 에서 S3 Glacier 로 파일을 이동하는 S3 버킷 수명 \n주기 정책을 생성합니다. 객체 생성 후 4 년이 지나면 파일을 삭제합니다. \nB. 객체 생성 후 30 일 동안 S3 Standard 에서 S3 One Zone-Infrequent Access(S3 One \nZone-IA)로 파일을 이동하는 S3 버킷 수명 주기 정책을 생성합니다. 객체 생성 후 4 년이 \n지나면 파일을 삭제합니다. \nC. 객체 생성 후 30 일 동안 S3 Standard 에서 S3 Standard-Infrequent Access(S3 \nStandard-IA)로 파일을 이동하는 S3 버킷 수명 주기 정책을 생성합니다. 객체 생성 후 \n4 년이 지나면 파일을 삭제합니다. \nD. 객체 생성 후 30 일 동안 S3 Standard 에서 S3 Standard-Infrequent Access(S3 \nStandard-IA)로 파일을 이동하는 S3 버킷 수명 주기 정책을 생성합니다. 객체 생성 4 년 후 \n파일을 S3 Glacier 로 이동합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/85310-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명:・ \nA(X) : 즉각적인 액세스가 항상 필요하다고 했기 때문에 S3 Glacier 사용은 적합하지 않음. \nB(X) : 재생산하기 쉽지 않은 중요한 비즈니스 데이터라고 했기 때문에 One Zone-IA \n\n보다는 S3 Standard-IA 가 더 적합 \nC(O) : 30 일 동안은 자주 액세스하므로 S3 Standard, 30 일 이후에는 자주 액세스하진 \n않지만 즉각적인 액세스가 필요하므로 S3 Standard-IA, 4 년이 지나면 중요한 비즈니스 \n데이터므로 함부로 보관해서는 안됨. 따라서 삭제. \nD(X) : 중요한 비즈니스 데이터라고 했으므로 보관기간인 4 년이 지나고 나서는 함부로 \n보관해서는 안되며 삭제해야 함. \n \n참고: \nhttps://aws.amazon.com/ko/s3/storage-classes/?trk=66264cd8-3b73-416c-9693-ea7cf\n4fe846a&sc_channel=ps&s_kw", "answer_choice": "C"}, "67": {"q_num": 67, "question": "회사는 여러 Amazon EC2 인스턴스에서 애플리케이션을 호스팅합니다. 애플리케이션은 \nAmazon SQS 대기열의 메시지를 처리하고 Amazon RDS 테이블에 쓰고 대기열에서 \n메시지를 삭제합니다. RDS 테이블에서 가끔 중복 레코드가 발견됩니다. SQS 대기열에는 \n중복 메시지가 없습니다. \n메시지가 한 번만 처리되도록 솔루션 설계자는 무엇을 해야 합니까? \nA. CreateQueue API 호출을 사용하여 새 대기열을 만듭니다. \nB. AddPermission API 호출을 사용하여 적절한 권한을 추가합니다. \nC. ReceiveMessage API 호출을 사용하여 적절한 대기 시간을 설정합니다. \nD. ChangeMessageVisibility API 호출을 사용하여 가시성 시간 초과를 늘립니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/85583-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \n가시성 제한 시간은 Amazon SQS 가 메시지를 반환할 때 시작됩니다. 이 시간 동안 \n소비자는 메시지를 처리하고 삭제합니다. 그러나 메시지를 삭제하기 전에 소비자가 \n실패하고 \n가시성 \n제한 \n시간이 \n만료되기 \n전에 \n시스템에서 \n해당 \n메시지에 \n대한 \nDeleteMessage 작업을 호출하지 않으면 메시지가 다른 소비자에게 표시되고 메시지가 \n다시 수신됩니다. 메시지를 한 번만 수신해야 하는 경우 소비자는 가시성 제한 시간 내에 \n메시지를 삭제해야 합니다. \nhttps://docs.aws.amazon.com/ko_kr/AWSSimpleQueueService/latest/SQSDeveloperGuide\n/sqs-visibility-timeout.html \n키워드: Amazon RDS 에 대한 SQS 대기열 쓰기 여기에서 옵션 D 최상의 기타 옵션 \n\n제외[옵션 A - 기존 대기열에 하나 이상의 대기열을 도입할 수 없습니다. 옵션 B - 권한만 \n허용; 옵션 C - 메시지만 검색] FIFO 대기열은 중복 메시지를 도입하지 않도록 \n설계되었습니다. 그러나 메시지 생성자는 특정 시나리오에서 중복을 생성할 수 있습니다. \n예를 들어 생성자가 메시지를 보내고 응답을 받지 못한 다음 동일한 메시지를 다시 보내는 \n경우입니다. Amazon SQS API 는 메시지 생성자가 중복 전송을 방지하는 중복 제거 기능을 \n제공합니다. 메시지 생성자에 의해 도입된 모든 중복 항목은 5 분 중복 제거 간격 내에 \n제거됩니다. 표준 대기열의 경우 때때로 메시지의 복제본을 받을 수 있습니다(최소 1 회 \n전달). 표준 대기열을 사용하는 경우 애플리케이션을 멱등적으로 설계해야 합니다(즉, \n동일한 메시지를 두 번 이상 처리할 때 부정적인 영향을 받지 않아야 함). \n \n설명2: \n메시지를 수신한 직후에는 메시지가 대기열에 그대로 있습니다. 다른 소비자가 메시지를 \n다시 처리하지 못하게 Amazon SQS 에서는 다른 소비자가 메시지를 수신하고 처리할 수 \n없도록 막는 기간인 Visibility timeout 을 설정합니다. \nhttps://docs.aws.amazon.com/ko_kr/AWSSimpleQueueService/latest/SQSDeveloperGuide\n/sqs-visibility-timeout.html", "answer_choice": "D"}, "68": {"q_num": 68, "question": "솔루션 설계자는 회사의 온프레미스 인프라를 AWS 로 확장하기 위해 새로운 하이브리드 \n아키텍처를 설계하고 있습니다. 이 회사는 AWS 리전에 대해 일관되게 짧은 지연 시간과 \n고가용성 연결이 필요합니다. 회사는 비용을 최소화해야 하며 기본 연결이 실패할 경우 더 \n느린 트래픽을 기꺼이 받아들입니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. 리전에 대한 AWS Direct Connect 연결을 프로비저닝합니다. 기본 Direct Connect \n연결이 실패하는 경우 백업으로 VPN 연결을 프로비저닝합니다. \nB. 개인 연결을 위해 지역에 VPN 터널 연결을 프로비저닝합니다. 기본 VPN 연결이 실패할 \n경우 개인 연결 및 백업으로 두 번째 VPN 터널을 프로비저닝합니다. \nC. 리전에 대한 AWS Direct Connect 연결을 프로비저닝합니다. 기본 Direct Connect \n연결이 \n실패하는 \n경우 \n백업과 \n동일한 \n지역에 \n두 \n번째 \nDirect \nConnect \n연결을 \n프로비저닝합니다. \nD. 리전에 대한 AWS Direct Connect 연결을 프로비저닝합니다. AWS CLI 에서 Direct \nConnect 장애 조치 속성을 사용하여 기본 Direct Connect 연결이 실패할 경우 백업 연결을 \n자동으로 생성합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/85593-exam-aws-certified-solut\n\nions-architect-associate-saa-c03/ \n \n설명1:・ \n어떤 경우에는 이 연결만으로는 충분하지 않습니다. 항상 DX 의 백업으로 폴백 연결을 \n보장하는 것이 좋습니다. 여러 옵션이 있지만 AWS Site-To-Site VPN 으로 구현하는 것이 \n비용 효율적입니다. 비용을 줄이기 위해 활용하거나 그 동안 두 번째 DX 설정을 기다릴 수 \n있는 솔루션입니다. \nhttps://blog.besharp.it/hybrid-cloud-networking-backup-aws-direct-connect-network-c\nonnection-with-aws-site-to-site-vpn/ \n \n설명2: \nVPN 과 Direct Connect 는 같이 사용할 수 있음.  \nhttps://docs.aws.amazon.com/ko_kr/whitepapers/latest/aws-vpc-connectivity-options/a\nws-direct-connect-vpn.html", "answer_choice": "A"}, "69": {"q_num": 69, "question": "회사는 Application Load Balancer 뒤의 Amazon EC2 인스턴스에서 비즈니스 크리티컬 웹 \n애플리케이션을 실행하고 있습니다. EC2 인스턴스는 Auto Scaling 그룹에 있습니다. \n애플리케이션은 단일 가용 영역에 배포된 Amazon Aurora PostgreSQL 데이터베이스를 \n사용합니다. 회사는 다운타임과 데이터 손실을 최소화하면서 애플리케이션의 고가용성을 \n원합니다. \n최소한의 운영 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. EC2 인스턴스를 다른 AWS 리전에 배치합니다. Amazon Route 53 상태 확인을 사용하여 \n트래픽을 리디렉션합니다. Aurora PostgreSQL 교차 리전 복제를 사용합니다. \nB. 여러 가용 영역을 사용하도록 Auto Scaling 그룹을 구성합니다. 데이터베이스를 다중 \nAZ 로 구성합니다. 데이터베이스에 대한 Amazon RDS 프록시 인스턴스를 구성합니다. \nC. 하나의 가용 영역을 사용하도록 Auto Scaling 그룹을 구성합니다. 데이터베이스의 \n시간별 스냅샷을 생성합니다. 장애가 발생한 경우 스냅샷에서 데이터베이스를 복구합니다. \nD. 여러 AWS 리전을 사용하도록 Auto Scaling 그룹을 구성합니다. 애플리케이션의 \n데이터를 Amazon S3 에 씁니다. S3 이벤트 알림을 사용하여 AWS Lambda 함수를 시작하여 \n데이터베이스에 데이터를 씁니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/85594-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n\n설명1:・ \nA(X) : 다중 AZ 사용이 더 바람직. 게다가 뜬금없이 잘 쓰고 있던 EC2 인스턴스를 다른 \nAZ 도 아니고 다른 리전에 배치하는 건 무리수. \nB(O) : 다중 AZ + Auto Scaling 으로 고가용성 확보. \nC(X) : 하나의 가용영역을 사용하므로 고가용성 불충족. \nD(X) : 다중 AZ 가 더 바람직할 뿐더러 굳이 불필요하게 S3 를 거쳐가고 있음. \n \n설명2: \n최소한의 가동 중지 시간과 최소한의 데이터 손실로 고가용성을 달성하려면 단일 장애 \n지점이 없도록 여러 가용 영역을 사용하도록 Auto Scaling 그룹을 구성해야 합니다. 기본 \n가용 영역에서 정전이 발생한 경우 자동 장애 조치를 활성화하려면 데이터베이스를 다중 \nAZ 로 구성해야 합니다. 또한 Amazon RDS Proxy 인스턴스를 사용하여 연결 실패를 줄이고 \n장애 조치 시간을 개선하여 데이터베이스의 확장성과 가용성을 개선할 수 있습니다.", "answer_choice": "B"}, "70": {"q_num": 70, "question": "회사의 HTTP 애플리케이션은 NLB(Network Load Balancer) 뒤에 있습니다. NLB 의 대상 \n그룹은 웹 서비스를 실행하는 여러 EC2 인스턴스와 함께 Amazon EC2 Auto Scaling 그룹을 \n사용하도록 구성됩니다. \n회사는 NLB\n가 애플리케이션에 대한 HTTP 오류를 감지하지 못한다는 것을 알게 \n되었습니다. 이러한 오류는 웹 서비스를 실행하는 EC2 인스턴스를 수동으로 다시 시작해야 \n합니다. 회사는 사용자 정의 스크립트나 코드를 작성하지 않고 애플리케이션의 가용성을 \n개선해야 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. NLB 에서 HTTP 상태 확인을 활성화하고 회사 응용 프로그램의 URL 을 제공합니다. \nB. EC2 인스턴스에 cron 작업을 추가하여 1 분에 한 번씩 로컬 애플리케이션의 로그를 \n확인합니다. HTTP 오류가 감지된 경우. 응용 프로그램이 다시 시작됩니다. \nC. NLB 를 Application Load Balancer 로 교체합니다. 회사 애플리케이션의 URL 을 제공하여 \nHTTP 상태 확인을 활성화합니다. 비정상 인스턴스를 교체하도록 Auto Scaling 작업을 \n구성합니다. \nD. NLB 에 대한 UnhealthyHostCount 지표를 모니터링하는 Amazon Cloud Watch 경보를 \n생성합니다. 경보가 ALARM 상태일 때 비정상 인스턴스를 교체하도록 Auto Scaling 작업을 \n구성합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/85734-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n\n \n설명1:・ \n이 회사는 NLB\n가 응용 프로그램에 대한 HTTP 오류를 감지하지 못한다고 알고 \n있습니다'라는 대목에서 응용프로그램에 대한 HTTP 오류를 감지하려면 ALB(Applicaton \nLoad Balancer)가 필요함을 유추할 수 있음. \nA(X) : 응용프로그램에 대한 HTTP 오류를 감지해야하므로 NLB 는 부적절. \nB(X) : 자동이 아니라 정기적으로 로그를 확인하는 것이므로 오답. \nC(O) : Application Load Balancer 는 등록된 대상으로 요청을 주기적으로 전송하여 상태를 \n확인합니다. 이러한 테스트를 바로 상태 확인이라고 합니다....◎HealthCheckProtocol : \n대상에 대한 상태 확인을 수행할 때 로드 밸런서가 사용하는 프로토콜입니다. HTTP, HTTPS \n등의 \n프로토콜이 \n여기에 \n해당됩니다. \nHTTP \n프로토콜이 \n기본 \n설정값입니다. \n◎HealthCheckPath : 대상에 대한 상태 확인을 위한 대상입니다. 프로토콜 버전이 \nHTTP/1.1 또는 HTTP/2 인 경우 유효한 URI(/path?query)를 참조하세요. 기본값은 /입니다. \n프로토콜 \n버전이 \ngRPC\n인 \n경우, \n사용자 \n지정 \n상태 \n확인 \n방법의 \n경로를 \n/package.service/method 형식으로 지정합니다. 기본값은 /AWS.ALB/healthcheck 입니다. \nhttps://docs.aws.amazon.com/ko_kr/elasticloadbalancing/latest/application/target-group\n-health-checks.html \nD(X) : A 와 같은 이유로 오답. \n \n설명2: \n애플리케이션 가용성: NLB 는 애플리케이션의 가용성을 보장할 수 없습니다. 이는 네트워크 \n및 TCP 계층 변수에만 의존하여 결정을 내리며 애플리케이션을 전혀 인식하지 못하기 \n때문입니다. \n일반적으로 NLB 는 ICMP ping 에 응답하거나 3 방향 TCP 핸드셰이크를 올바르게 완료하는 \n서버의 기능을 기반으로 가용성을 결정합니다. ALB 는 훨씬 더 깊이 들어가 특정 페이지의 \n성공적인 HTTP GET 뿐만 아니라 콘텐츠가 입력 매개변수를 기반으로 예상한 대로라는 \n확인을 기반으로 가용성을 결정할 수 있습니다.", "answer_choice": "C"}, "71": {"q_num": 71, "question": "한 회사는 Amazon DynamoDB 를 사용하여 고객 정보를 저장하는 쇼핑 애플리케이션을 \n실행합니다. 데이터 손상의 경우 솔루션 설계자는 15 분의 RPO(복구 시점 목표)와 1 시간의 \nRTO(복구 시간 목표)를 충족하는 솔루션을 설계해야 합니다. \n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까? \nA. DynamoDB 전역 테이블을 구성합니다. RPO 복구의 경우 애플리케이션이 다른 AWS \n리전을 가리키도록 합니다. \n\nB. DynamoDB 지정 시간 복구를 구성합니다. RPO 복구의 경우 원하는 시점으로 \n복원합니다. \nC. DynamoDB 데이터를 매일 Amazon S3 Glacier 로 내보냅니다. RPO 복구의 경우 S3 \nGlacier 에서 DynamoDB 로 데이터를 가져옵니다. \nD. DynamoDB 테이블에 대한 Amazon Elastic Block Store(Amazon EBS) 스냅샷을 \n15 분마다 예약합니다. RPO 복구의 경우 EBS 스냅샷을 사용하여 DynamoDB 테이블을 \n복원합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/85603-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명:・ \n \nA(X) : 리전 장애 발생 시 리디렉션에는 탁월하나 데이터 손상에는 취약함. 글로벌 \n테이블에서 새로 작성된 항목은 1 초 이내에 모든 복제본 테이블에 전파되는데, 이는 \n데이터를 잘못 건드리면 1 초 이내에 모든 복제본 테이블에 해당 변경 사항이 적용되기 \n때문. \n전역 테이블에서 새로 작성된 항목은 일반적으로 1\n초 이내에 모든 복제본 테이블에 \n전파됩니다. \nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/V2globaltables_H\nowItWorks.html \nB(O) : DynamoDB 는 주문형 백업 기능을 제공합니다. 이를 통해 규정 준수 요구 사항에 \n대한 장기 보존 및 보관을 위해 테이블의 전체 백업을 생성할 수 있습니다. 주문형 백업을 \n생성하고 Amazon DynamoDB 테이블에 대한 특정 시점 복구를 활성화할 수 있습니다. \n지정 시간 복구는 우발적인 쓰기 또는 삭제 작업으로부터 테이블을 보호하는 데 도움이 \n됩니다. 특정 시점 복구를 사용하면 지난 35 일 동안의 특정 시점으로 테이블을 복원할 수 \n있습니다. \nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Introduction.html \nC(X) : S3 Glacier 는 콜드 스토리지로 액세스 시간이 더 김. 괜히 RTO 만 늘어남. \nD(X) : DynamoDB\n는 서버리스라 EBS 스냅샷을 찍을 수 있는지도 의문이고 애초에 \nPITR(특정 시점으로 복구)이 더 좋은 옵션임. \n \n참조 \nhttps://docs.aws.amazon.com/ko_kr/amazondynamodb/latest/developerguide/PointInTim\neRecovery.html", "answer_choice": "B"}, "72": {"q_num": 72, "question": "회사는 동일한 AWS 리전에 있는 Amazon S3 버킷에서 사진을 자주 업로드 및 \n다운로드해야 하는 사진 처리 애플리케이션을 실행합니다. 솔루션 설계자는 데이터 전송 \n비용이 증가한다는 사실을 알게 되었고 이러한 비용을 줄이기 위한 솔루션을 구현해야 \n합니다. \n솔루션 설계자는 이 요구 사항을 어떻게 충족할 수 있습니까? \nA. Amazon API Gateway 를 퍼블릭 서브넷에 배포하고 이를 통해 S3 호출을 라우팅하도록 \n라우팅 테이블을 조정합니다. \nB. NAT 게이트웨이를 퍼블릭 서브넷에 배포하고 S3 버킷에 대한 액세스를 허용하는 \n엔드포인트 정책을 연결합니다. \nC. 애플리케이션을 퍼블릭 서브넷에 배포하고 S3 버킷에 액세스하기 위해 인터넷 \n게이트웨이를 통해 라우팅하도록 허용합니다. \nD. S3 VPC 게이트웨이 엔드포인트를 VPC 에 배포하고 S3 버킷에 대한 액세스를 허용하는 \n엔드포인트 정책을 연결합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/85604-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \nA(X) : VPC-온프레미스 간 통신은 이루어지나 VPC 간 통신은 이루어지지 않고 있음. \nB(X) : A 와 같은 이유로 오답. \nC(X) : A 와 같은 이유로 오답. \nD(O) : Transit Gateway\n는 동일한 리전 내에 있는 여러 VPC\n들을 연결하는 전송 \n'허브'이므로 Transit Gateway 를 거쳐 VPC 끼리 통신이 가능 \nAWS Transit Gateway 는 동일한 리전의 VPC 를 상호 연결하여 Amazon VPC 라우팅 구성을 \n한 곳에 통합하는 네트워크 전송 허브입니다. \nhttps://docs.aws.amazon.com/whitepapers/latest/aws-vpc-connectivity-options/aws-dir\nect-connect-aws-transit-gateway.html \n \n설명2: \n정답은 옵션 D 입니다. S3 VPC 게이트웨이 엔드포인트를 VPC 에 배포하고 S3 버킷에 대한 \n액세스를 허용하는 엔드포인트 정책을 연결합니다. S3 VPC 게이트웨이 엔드포인트를 \n배포하면 애플리케이션이 VPC 내의 프라이빗 네트워크 연결을 통해 S3 버킷에 액세스할 \n수 있으므로 인터넷을 통한 데이터 전송이 필요하지 않습니다. 이를 통해 데이터 전송 \n비용을 줄이고 애플리케이션의 성능을 향상시킬 수 있습니다. 엔드포인트 정책을 사용하여 \n애플리케이션이 액세스할 수 있는 S3 버킷을 지정할 수 있습니다.", "answer_choice": "D"}, "73": {"q_num": 73, "question": "한 회사는 최근 프라이빗 서브넷의 Amazon EC2 에서 Linux 기반 애플리케이션 인스턴스를 \n시작하고 VPC 의 퍼블릭 서브넷에 있는 Amazon EC2 인스턴스에서 Linux 기반 배스천 \n호스트를 시작했습니다. 솔루션 설계자는 사내 네트워크에서 회사의 인터넷 연결을 통해 \n배스천 호스트 및 애플리케이션 서버에 연결해야 합니다. 솔루션 설계자는 모든 EC2 \n인스턴스의 보안 그룹이 해당 액세스를 허용하는지 확인해야 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 단계 조합을 취해야 합니까? \n(2 개를 선택하세요.) \nA. 배스천 호스트의 현재 보안 그룹을 애플리케이션 인스턴스의 인바운드 액세스만 \n허용하는 보안 그룹으로 교체합니다. \nB. 배스천 호스트의 현재 보안 그룹을 회사의 내부 IP 범위에서만 인바운드 액세스를 \n허용하는 보안 그룹으로 교체합니다. \nC. 배스천 호스트의 현재 보안 그룹을 회사의 외부 IP 범위에서만 인바운드 액세스를 \n허용하는 보안 그룹으로 교체합니다. \nD. 애플리케이션 인스턴스의 현재 보안 그룹을 배스천 호스트의 개인 IP 주소에서만 \n인바운드 SSH 액세스를 허용하는 보안 그룹으로 교체합니다. \nE. 애플리케이션 인스턴스의 현재 보안 그룹을 배스천 호스트의 공용 IP 주소에서만 \n인바운드 SSH 액세스를 허용하는 보안 그룹으로 교체합니다.", "answer_block": "Answer: C, D \nhttps://www.examtopics.com/discussions/amazon/view/85613-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명:・ \n전체적인 프로세스는 사내네트워크 -> 외부 인터넷 -> Bastion Host(퍼블릭서브넷 내에 \nNAT 게이트웨이와 함께 위치) -> Application(프라이빗서브넷 내에 위치)으로 이루어짐. \nBastion Host 는 내부네트워크(여기서는 Application 이 있는 곳)에 접속할 수 있는 유일한 \n창구로, SSH 접속도 여길 통과해야만 가능함. \n일단 Bastion Host 에 오는 트래픽(인바운드 트래픽)은 외부 인터넷을 통해서 온 회사의 \nIP(즉, 외부 IP)이므로 C 가 정답. \n그 다음으로는 Bastion Host 로부터 Application 으로 오는 트래픽(인바운드 트래픽)을 \n허용해야하는데 이미 Bastion Host 에서 안쪽의 내부 네트워크와 통신하려고 프라이빗 IP 를 \n들고 온 상태임. 따라서 D 가 정답이며 최종적으로는 C,D 가 정답. \n \n내부 아이피는 온프레미스 환경 사내 안에서 쓰는 아이피를 보통 뜻하고 인터넷으로 나오는 \n\nIP\n는 외부 IP 개념이라 사내 네트워크에서 외부인터넷으로 나온 external ip 범위의 \n대역에서 인바운드 액세스만 허용하는 C 가 B 보다 더 적절한 답으로 보임.", "answer_choice": "C"}, "74": {"q_num": 74, "question": "솔루션 설계자는 2 계층 웹 애플리케이션을 설계하고 있습니다. 애플리케이션은 퍼블릭 \n서브넷의 Amazon EC2 에서 호스팅되는 퍼블릭 웹 티어로 구성됩니다. 데이터베이스 계층은 \n프라이빗 서브넷의 Amazon EC2 에서 실행되는 Microsoft SQL Server 로 구성됩니다. 보안은 \n회사의 최우선 과제입니다. \n이 상황에서 보안 그룹을 어떻게 구성해야 합니까? (2 개를 선택하세요.) \nA. 0.0.0.0/0 에서 포트 443 의 인바운드 트래픽을 허용하도록 웹 계층에 대한 보안 그룹을 \n구성합니다. \nB. 0.0.0.0/0 에서 포트 443 의 아웃바운드 트래픽을 허용하도록 웹 계층에 대한 보안 \n그룹을 구성합니다. \nC. 웹 계층에 대한 보안 그룹에서 포트 1433\n의 인바운드 트래픽을 허용하도록 \n데이터베이스 계층에 대한 보안 그룹을 구성합니다. \nD. 데이터베이스 계층의 보안 그룹을 구성하여 포트 443 및 1433 의 아웃바운드 트래픽을 \n웹 계층의 보안 그룹으로 보냅니다. \nE. 웹 계층에 대한 보안 그룹의 포트 443 및 1433 에서 인바운드 트래픽을 허용하도록 \n데이터베이스 계층에 대한 보안 그룹을 구성합니다.", "answer_block": "Answer: A, C \nhttps://www.examtopics.com/discussions/amazon/view/85346-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \n전체적인 구조는 EC2 인스턴스에서 실행되는 웹 애플리케이션(퍼블릭 서브넷 내에 \n위치)---->EC2 인스턴스에서 실행되는 데이터베이스(프라이빗 서브넷 내에 위치)으로 \n되어있고, 인스턴스 단위의 보안은 보안 그룹이 담당. \n보안 그룹은 기본적으로 인바운드 트래픽에 관해서는 허용만 지정할 수 있고, 허용하지 \n않은 건 기본적으로 모두 차단하기 때문에 외부 인터넷->웹 애플리케이션으로의 액세스를 \n허용하려면 0.0.0.0/0 으로부터 온 포트 443(HTTPS)를 허용해야 함. \n그 다음으로 웹 애플리케이션->데이터베이스로의 액세스를 허용하려면 웹 애플리케이션이 \n있는 웹 계층에서 오는 포트 1433(MySQL) 인바운드 트래픽을 허용하도록 보안 그룹 \n설정을 해야 함. 따라서 정답은 A,C. \n \n설명2: \n\n\"보안 그룹은 모든 인바운드 규칙에 대한 아웃바운드 규칙을 생성합니다.\" 완전히 옳지 \n않습니다. Statefull 은 인바운드(또는 아웃바운드) 규칙을 생성하는 경우 아웃바운드(또는 \n인바운드) 규칙을 생성한다는 의미가 아닙니다. 이것이 의미하는 바는 다음과 같습니다. X \nIP 에 대한 포트 443 에서 인바운드 규칙을 생성한다고 가정합니다. 요청이 X ip 에서 포트 \n443 으로 들어오면 포트 443 에서 해당 요청에 대한 트래픽 아웃을 허용합니다. \n그러나 아웃바운드 규칙을 보면 명시적으로 생성하지 않는 한 포트 443 에 대한 아웃바운드 \n규칙이 없을 것입니다. 상태 비저장 ACL 에서는 들어오는 요청을 허용하는 인바운드 규칙과 \n애플리케이션이 이러한 들어오는 요청에 응답할 수 있도록 하는 아웃바운드 규칙을 \n만들어야 합니다. \nhttps://docs.aws.amazon.com/ko_kr/vpc/latest/userguide/VPC_SecurityGroups.html#Sec\nurityGroupRules", "answer_choice": "A"}, "75": {"q_num": 75, "question": "한 회사에서 애플리케이션의 성능을 개선하기 위해 다계층 애플리케이션을 온프레미스에서 \nAWS 클라우드로 이동하려고 합니다. 애플리케이션은 RESTful 서비스를 통해 서로 \n통신하는 \n애플리케이션 \n계층으로 \n구성됩니다. \n한 \n계층이 \n오버로드되면 \n트랜잭션이 \n삭제됩니다. 솔루션 설계자는 이러한 문제를 해결하고 애플리케이션을 현대화하는 솔루션을 \n설계해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족하고 운영상 가장 효율적입니까? \nA. Amazon API Gateway\n를 사용하고 애플리케이션 계층으로 AWS Lambda 함수에 \n트랜잭션을 전달합니다. Amazon Simple Queue Service(Amazon SQS)를 애플리케이션 \n서비스 간의 통신 계층으로 사용합니다. \nB. Amazon CloudWatch 지표를 사용하여 애플리케이션 성능 기록을 분석하여 성능 장애 \n동안 서버의 최대 사용률을 결정합니다. 최대 요구 사항을 충족하도록 애플리케이션 서버의 \nAmazon EC2 인스턴스 크기를 늘립니다. \nC. Amazon Simple Notification Service(Amazon SNS)를 사용하여 Auto Scaling 그룹의 \nAmazon EC2\n에서 실행되는 애플리케이션 서버 간의 메시징을 처리합니다. Amazon \nCloudWatch\n를 사용하여 SNS 대기열 길이를 모니터링하고 필요에 따라 확장 및 \n축소합니다. \nD. Amazon Simple Queue Service(Amazon SQS)를 사용하여 Auto Scaling 그룹의 Amazon \nEC2 에서 실행되는 애플리케이션 서버 간의 메시징을 처리합니다. Amazon CloudWatch 를 \n사용하여 SQS 대기열 길이를 모니터링하고 통신 오류가 감지되면 확장합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/86120-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n\n \n설명:・ \nAWS Lambda, Amazon API Gateway, AWS Amplify, Amazon DynamoDB 및 Amazon \nCognito 를 사용하여 서버리스 웹 애플리케이션을 구축하십시오. 이 예에서는 AWS Lambda, \nAmazon API Gateway, AWS Amplify, Amazon DynamoDB 및 Amazon Cognito 를 사용하여 \n서버리스 웹 애플리케이션 구축 질문과 유사한 설정을 보여줍니다. \n \nRESTful API = API Gateway 사용. \n트랜잭션 삭제되는 문제 = SQS.", "answer_choice": "A"}, "76": {"q_num": 76, "question": "회사는 단일 공장에 있는 여러 기계에서 매일 10TB 의 계측 데이터를 수신합니다. 데이터는 \n공장 내에 위치한 온프레미스 데이터 센터의 SAN(Storage Area Network)에 저장된 JSON \n파일로 구성됩니다. 회사는 이 데이터를 Amazon S3 로 전송하여 중요한 실시간에 가까운 \n분석을 제공하는 여러 추가 시스템에서 액세스할 수 있기를 원합니다. 데이터가 민감한 \n것으로 간주되기 때문에 안전한 전송이 중요합니다. \n가장 안정적인 데이터 전송을 제공하는 솔루션은 무엇입니까? \nA. 공용 인터넷을 통한 AWS DataSync \nB. AWS Direct Connect 를 통한 AWS DataSync \nC. 공용 인터넷을 통한 AWS Database Migration Service(AWS DMS) \nD. AWS Direct Connect 를 통한 AWS Database Migration Service(AWS DMS)", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/85801-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \nA(X) : 퍼블릭 인터넷으로 전송하면 노출 위험이 큼. 심지어는 VPN 도 안 했음. \nB(O) : Direct Connect 는 전용선 연결로 온프레미스-AWS 간 통신하는 것이고, DataSync 는 \n데이터 전송/마이그레이션에 사용되는 서비스. \nAWS DataSync 는 온프레미스와 AWS 스토리지 서비스 사이에서 데이터 이동을 자동화 및 \n가속화하는 안전한 온라인 서비스입니다. Amazon Simple Storage Service(S3) 버킷 간에 \n데이터를 복사할 수 있습니다. https://aws.amazon.com/ko/datasync/ \nC(X) : A 와 마찬가지 이유로 오답. \nD(X) : DMS 는 데이터베이스 마이그레이션 서비스로 S3 로 데이터를 전송해야하는 지문 \n상황과는 맞지 않음. \n\n \n설명2: \n다음은 AWS DataSync 의 주요 사용 사례 중 일부입니다. * 데이터 마이그레이션 - 활성 \n데이터 세트를 네트워크를 통해 Amazon S3, Amazon EFS 또는 FSx for Windows File \nServer\n로 빠르게 이동합니다. DataSync\n에는 자동 암호화 및 데이터 무결성 검증이 \n포함되어 데이터가 안전하고 온전하며 사용할 준비가 되었는지 확인하는 데 도움이 됩니다. \n\"DataSync 에는 암호화 및 무결성 검증이 포함되어 있어 데이터가 안전하고 온전하며 \n사용할 준비가 되었는지 확인하는 데 도움이 됩니다.\" \nhttps://aws.amazon.com/datasync/faqs/", "answer_choice": "B"}, "77": {"q_num": 77, "question": "회사는 애플리케이션에 대한 실시간 데이터 수집 아키텍처를 구성해야 합니다. 회사에는 \n데이터가 스트리밍될 때 데이터를 변환하는 프로세스인 API 와 데이터를 위한 스토리지 \n솔루션이 필요합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Amazon EC2 인스턴스를 배포하여 Amazon Kinesis 데이터 스트림으로 데이터를 \n전송하는 API 를 호스팅합니다. Kinesis 데이터 스트림을 데이터 원본으로 사용하는 Amazon \nKinesis Data Firehose 전송 스트림을 생성합니다. AWS Lambda 함수를 사용하여 데이터를 \n변환합니다. Kinesis Data Firehose 전송 스트림을 사용하여 데이터를 Amazon S3 로 \n보냅니다. \nB. Amazon EC2 인스턴스를 배포하여 AWS Glue 에 데이터를 전송하는 API 를 호스팅합니다. \nEC2 인스턴스에서 소스/대상 확인을 중지합니다. AWS Glue 를 사용하여 데이터를 변환하고 \n데이터를 Amazon S3 로 보냅니다. \nC. Amazon Kinesis 데이터 스트림으로 데이터를 보내도록 Amazon API Gateway API 를 \n구성합니다. Kinesis 데이터 스트림을 데이터 원본으로 사용하는 Amazon Kinesis Data \nFirehose 전송 스트림을 생성합니다. AWS Lambda 함수를 사용하여 데이터를 변환합니다. \nKinesis Data Firehose 전송 스트림을 사용하여 데이터를 Amazon S3 로 보냅니다. \nD. 데이터를 AWS Glue 로 보내도록 Amazon API Gateway API 를 구성합니다. AWS Lambda \n함수를 사용하여 데이터를 변환합니다. AWS Glue 를 사용하여 데이터를 Amazon S3 로 \n보냅니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/85740-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n\n실시간 데이터 수집 = Kinesis Data Streams. A,C 둘 중 하나가 답. \nA(X) : API 는 API Gateway 를 사용하여 전송. \nAmazon API Gateway 는 어떤 규모에서든 개발자가 API 를 손쉽게 생성, 게시, 유지 관리, \n모니터링 및 보안 유지할 수 있도록 하는 완전관리형 서비스입니다. API 는 애플리케이션이 \n백엔드 서비스의 데이터, 비즈니스 로직 또는 기능에 액세스할 수 있는 \"정문\" 역할을 \n합니다. https://aws.amazon.com/ko/api-gateway/ \nC(O) :  \n・API Gateway API 를 Kinesis Data Streams 와 같이 사용 가능 \nAPI Gateway API를 Kinesis 와 통합하려면 API Gateway 와 Kinesis 서비스를 모두 사용할 수 \n있는 리전을 선택해야 합니다. \nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/integrating-api-with-aw\ns-services-kinesis.html \n・Kinesis Data Streams 로 데이터 수집. \nAmazon Kinesis Data Streams 를 사용하면 특수 요구에 맞춰 스트리밍 데이터를 처리 또는 \n분석하는 사용자 지정 애플리케이션을 구축할 수 있습니다. 수십 만개의 소스에서 클릭 \n스트림, 애플리케이션 로그, 소셜 미디어와 같은 다양한 유형의 데이터를 Kinesis 데이터 \n스트림에 추가할 수 있습니다. \nhttps://aws.amazon.com/ko/kinesis/data-streams/faqs/ \n・Kinesis Data Streams -> Kinesis Data Firehose \nAmazon Kinesis Data Firehose 전송 스트림에 정보를 전송하도록 Amazon Kinesis Data \nStreams 를 구성할 수 있습니다. \nhttps://docs.aws.amazon.com/ko_kr/firehose/latest/dev/writing-with-kinesis-streams.ht\nml \n・Lambda 로 데이터 변환 \nKinesis Data Firehose Firehose 는 Lambda 함수를 호출하여 수신되는 소스 데이터를 \n변환하고 변환된 데이터를 대상으로 전송할 수 있습니다. \nhttps://docs.aws.amazon.com/ko_kr/firehose/latest/dev/data-transformation.html \n・S3 로 전송 \nAmazon Kinesis Data Firehose 는 실시간 스트리밍 데이터를 Amazon S3, Amazon RedShift, \nAmazon OpenSearch Service, Splunk 및 사용자 지정 HTTP 엔드포인트 또는 Datadog, \nDynatrace, LogicMonitor, MongoDB, New Relic, Sumo Logic 을 포함한 지원되는 서드파티 \n소유의 HTTP 엔드포인트 대상에 전달하기 위한 완전관리형 서비스입니다. \nhttps://docs.aws.amazon.com/firehose/latest/dev/what-is-this-service.html", "answer_choice": "C"}, "78": {"q_num": 78, "question": "회사는 사용자 트랜잭션 데이터를 Amazon DynamoDB 테이블에 보관해야 합니다. 회사는 \n데이터를 7 년간 보관해야 합니다. \n이러한 요구 사항을 충족하는 가장 운영 효율성이 높은 솔루션은 무엇입니까? \nA. DynamoDB 지정 시간 복구를 사용하여 테이블을 지속적으로 백업합니다. \nB. AWS Backup 을 사용하여 테이블에 대한 백업 일정 및 보존 정책을 생성합니다. \nC. DynamoDB 콘솔을 사용하여 테이블의 주문형 백업을 생성합니다. 백업을 Amazon S3 \n버킷에 저장합니다. S3 버킷에 대한 S3 수명 주기 구성을 설정합니다. \nD. AWS Lambda 함수를 호출하는 Amazon EventBridge(Amazon CloudWatch Events) \n규칙을 생성합니다. 테이블을 백업하고 Amazon S3 버킷에 백업을 저장하도록 Lambda \n함수를 구성합니다. S3 버킷에 대한 S3 수명 주기 구성을 설정합니다.", "answer_block": "Answer: B  \nhttps://www.examtopics.com/discussions/amazon/view/85742-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명:・ \nA(X) : 35 일 제한이 있습니다. \"\"특정 시점으로 복구가 설정되어 있으면 최근 35 일 중 \n원하는 시점으로 테이블을 복원할 수 있습니다. \nhttps://docs.aws.amazon.com/ko_kr/amazondynamodb/latest/developerguide/PointInTim\neRecovery.html \nB(O) : 한 곳에서 백업 현황 모니터링 및 콜드 스토리지에 저장, 예약 저장 가능합니다. \nAWS Backup 을 사용하면 백업 정책을 구성하고 AWS 리소스 및 온프레미스 워크로드에 \n대한 활동을 한 곳에서 모니터링할 수 있습니다. AWS Backup 과 함께 DynamoDB 를 \n사용하면 AWS 계정 및 리전에서 온디맨드 백업을 복사하고, 온디맨드 백업에 비용 할당 \n태그를 추가하고, 온디맨드 백업을 콜드 스토리지로 전환하여 비용을 절감할 수 있습니다. \nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/BackupRestore.h\ntml \nAWS Backup 을 사용하여 DynamoDB 온디맨드 백업을 자동으로 예약, 복사, 태그 지정 및 \n수명 주기를 수행할 수 있습니다. DynamoDB 콘솔에서 이러한 백업을 계속 보고 복원할 수 \n있습니다. \nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/backuprestore_H\nowItWorksAWS.html \nC(X) : 불가능한 건 아닌데, B 가 더 유리합니다. 운영 측면에서는 한 곳에서 모니터링하는 \n게 편하고, S3 버킷에 저장한다고 했는데 7 년 동안 보관할 거면 S3 콜드 스토리지에 \n보관하는 게 비용이 더 저렴합니다. \nD(X) : 너무 단계가 많습니다. 아마존에서는 DynamoDB 테이블 백업에 AWS Backup 또는 \nDynamoDB 콘솔을 사용할 것을 언급하고 있습니다. \"\"DynamoDB 온디맨드 백업을 \n\n생성하고 관리하는 데 사용할 수 있는 두 가지 옵션이 있습니다. AWS 백업 서비스 \n다이나모DB \nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/BackupRestore.h\ntml", "answer_choice": "B"}, "79": {"q_num": 79, "question": "회사에서 데이터 저장을 위해 Amazon DynamoDB 테이블을 사용할 계획입니다. 회사는 \n비용 최적화에 대해 우려하고 있습니다. 대부분의 아침에는 테이블을 사용하지 않습니다. \n저녁에는 읽기 및 쓰기 트래픽이 예측할 수 없는 경우가 많습니다. 트래픽 급증이 발생하면 \n매우 빠르게 발생합니다. \n솔루션 아키텍트는 무엇을 추천해야 합니까? \nA. 온디맨드 용량 모드에서 DynamoDB 테이블을 생성합니다. \nB. 글로벌 보조 인덱스가 있는 DynamoDB 테이블을 생성합니다. \nC. 프로비저닝된 용량 및 Auto Scaling 을 사용하여 DynamoDB 테이블을 생성합니다. \nD. 프로비저닝된 용량 모드에서 DynamoDB 테이블을 생성하고 전역 테이블로 구성합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/85743-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명:・ \n사용량 예측이 안 되므로 프로비저닝은 무의미. 따라서 C,D 는 제외되고 A,B 둘 중 하나가 \n정답. \nA(O) : 온디맨드 모드를 사용하는 테이블의 경우 DynamoDB 는 이전에 관찰된 트래픽 \n수준까지 상승하거나 하락할 때 고객의 워크로드를 즉시 수용할 수 있습니다. 트래픽 \n수준이 새로운 고점에 도달하면 DynamoDB 는 신속하게 대응하여 워크로드를 수용합니다. \nhttps://aws.amazon.com/ko/blogs/korea/amazon-dynamodb-on-demand-no-capacity-\nplanning-and-pay-per-request-pricing/ \nB(X) : 고가용성 언급이 없고 비용 최적화를 언급하고 있으므로 B 보다는 A 가 적합.", "answer_choice": "A"}, "80": {"q_num": 80, "question": "한 회사는 최근 애플리케이션 마이그레이션 이니셔티브에 대한 지원을 위해 AWS 관리형 \n서비스 공급자(MSP) 파트너와 계약을 체결했습니다. 솔루션 설계자는 기존 AWS 계정의 \nAmazon 머신 이미지(AMI)를 MSP 파트너의 AWS 계정과 공유해야 합니다. AMI 는 Amazon \nElastic Block Store(Amazon EBS)의 지원을 받으며 AWS Key Management Service(AWS \n\nKMS) 고객 관리형 키를 사용하여 EBS 볼륨 스냅샷을 암호화합니다. \n솔루션 설계자가 MSP 파트너의 AWS 계정과 AMI\n를 공유하는 가장 안전한 방법은 \n무엇입니까? \nA. 암호화된 AMI 및 스냅샷을 공개적으로 사용할 수 있도록 합니다. MSP 파트너의 AWS \n계정이 키를 사용할 수 있도록 키 정책을 수정합니다. \nB. AMI 의 launchPermission 속성을 수정합니다. MSP 파트너의 AWS 계정과만 AMI 를 \n공유하십시오. MSP 파트너의 AWS 계정이 키를 사용할 수 있도록 키 정책을 수정합니다. \nC. AMI 의 launchPermission 속성을 수정합니다. MSP 파트너의 AWS 계정과만 AMI 를 \n공유하십시오. 암호화를 위해 MSP 파트너가 소유한 새 KMS 키를 신뢰하도록 키 정책을 \n수정합니다. \nD. 원본 계정에서 MSP 파트너의 AWS 계정에 있는 Amazon S3 버킷으로 AMI 를 내보내고 \nMSP 파트너가 소유한 새 KMS 키로 S3 버킷을 암호화합니다. MSP 파트너의 AWS \n계정에서 AMI 를 복사하고 시작합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/85606-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \nA(X) : '공개적'이라는 키워드가 애초에 보안과는 거리가 멈. \nB(O) : 기존 KMS 키는 스냅샷을 암호화하는 데 사용되었기 때문에 MSP 파트너와 공유해도 \n괜찮음. \nC(X) : 파트너의 KMS 키를 신뢰하면 파트너가 해당 키를 가지고 악의적인 용도로 사용할 \n때 문제가 됨. \nD(X) : 파트너와 공유해야 하는데 파트너가 S3 버킷을 암호화하도록 냅둬버리면 파트너가 \n공유받는 입장이 아니라 내가 공유받는 입장이 되어버리는 역전현상이 벌어짐. \n \n설명2: \nAMI 스냅샷을 암호화하는 데 이미 사용되었기 때문에 기존 KMS 키를 MSP 외부 계정과 \n공유합니다. \nhttps://docs.aws.amazon.com/ko_kr/kms/latest/developerguide/key-policy-modifying-ex\nternal-accounts.html", "answer_choice": "B"}, "81": {"q_num": 81, "question": "솔루션 설계자는 AWS 에 배포되는 새 애플리케이션을 위한 클라우드 아키텍처를 설계하고 \n있습니다. 처리할 작업 수에 따라 필요에 따라 애플리케이션 노드를 추가 및 제거하면서 \n\n프로세스가 병렬로 실행되어야 합니다. 프로세서 응용 프로그램은 상태 비저장입니다. \n솔루션 설계자는 응용 프로그램이 느슨하게 연결되어 있고 작업 항목이 영구적으로 \n저장되어 있는지 확인해야 합니다. \n솔루션 설계자는 어떤 디자인을 사용해야 합니까? \nA. \n처리해야 \n하는 \n작업을 \n보낼 \nAmazon \nSNS \n주제를 \n생성합니다. \n프로세서 \n애플리케이션으로 구성된 Amazon 머신 이미지(AMI)를 생성합니다. AMI 를 사용하는 시작 \n구성을 생성합니다. 시작 구성을 사용하여 Auto Scaling 그룹을 생성합니다. CPU 사용량에 \n따라 노드를 추가 및 제거하도록 Auto Scaling 그룹에 대한 조정 정책을 설정합니다. \nB. \n처리해야 \n하는 \n작업을 \n보관할 \nAmazon \nSQS \n대기열을 \n생성합니다. \n프로세서 \n애플리케이션으로 구성된 Amazon 머신 이미지(AMI)를 생성합니다. AMI 를 사용하는 시작 \n구성을 생성합니다. 시작 구성을 사용하여 Auto Scaling 그룹을 생성합니다. Auto Scaling \n그룹의 조정 정책을 설정하여 네트워크 사용량에 따라 노드를 추가 및 제거합니다. \nC. \n처리해야 \n하는 \n작업을 \n보관할 \nAmazon \nSQS \n대기열을 \n생성합니다. \n프로세서 \n애플리케이션으로 구성된 Amazon 머신 이미지(AMI)를 생성합니다. AMI 를 사용하는 시작 \n템플릿을 생성합니다. 시작 템플릿을 사용하여 Auto Scaling 그룹을 생성합니다. SQS \n대기열의 항목 수에 따라 노드를 추가 및 제거하도록 Auto Scaling 그룹에 대한 조정 \n정책을 설정합니다. \nD. \n처리해야 \n하는 \n작업을 \n보낼 \nAmazon \nSNS \n주제를 \n생성합니다. \n프로세서 \n애플리케이션으로 구성된 Amazon 머신 이미지(AMI)를 생성합니다. AMI 를 사용하는 시작 \n템플릿을 생성합니다. 시작 템플릿을 사용하여 Auto Scaling 그룹을 생성합니다. SNS \n주제에 게시된 메시지 수에 따라 노드를 추가 및 제거하도록 Auto Scaling 그룹에 대한 \n조정 정책을 설정합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/86621-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명:・ \n\"처리해야 하는 작업을 보관할 Amazon SQS 대기열을 생성합니다. \n컴퓨팅 애플리케이션에 대한 Amazon EC2 Auto Scaling 그룹을 생성합니다. SQS 대기열의 \n항목 수에 따라 노드를 추가 및 제거하도록 Auto Scaling 그룹에 대한 조정 정책을 \n설정합니다. \nAmazon SQS 는 이 사용 사례에 이상적이며 대기열에서 대기 중인 작업 수에 따라 동적 \n조정을 사용하도록 구성할 수 있습니다. 이 조정을 구성하려면 유지 관리할 인스턴스당 \n허용되는 백로그인 대상 값과 함께 인스턴스당 백로그 메트릭을 사용할 수 있습니다. \n이러한 수치는 다음과 같이 계산할 수 있습니다.  \n인스턴스당 백로그: \n\n인스턴스당 \n백로그를 \n계산하려면 \nApproximateNumberOfMessages \n대기열 \n속성으로 \n시작하여 SQS 대기열의 길이를 결정합니다.", "answer_choice": "C"}, "82": {"q_num": 82, "question": "회사는 AWS 클라우드에서 웹 애플리케이션을 호스팅합니다. 회사는 AWS Certificate \nManager(ACM)로 가져온 인증서를 사용하도록 Elastic Load Balancer 를 구성합니다. 각 \n인증서가 만료되기 30 일 전에 회사 보안팀에 알려야 합니다. \n솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 권장해야 합니까? \nA. ACM 에 규칙을 추가하여 인증서가 만료되기 30 일 전부터 매일 Amazon Simple \nNotification Service(Amazon SNS) 주제에 사용자 지정 메시지를 게시합니다. \nB. 30 일 이내에 만료되는 인증서를 확인하는 AWS Config 규칙을 생성합니다. AWS \nConfig 가 비준수 리소스를 보고할 때 Amazon Simple Notification Service(Amazon SNS)를 \n통해 사용자 지정 알림을 호출하도록 Amazon EventBridge(Amazon CloudWatch Events)를 \n구성합니다. \nC. AWS Trusted Advisor 를 사용하여 30 일 이내에 만료되는 인증서를 확인합니다. 상태 \n변경 확인에 대한 Trusted Advisor 지표를 기반으로 하는 Amazon CloudWatch 경보를 \n생성합니다. Amazon Simple Notification Service(Amazon SNS)를 통해 사용자 지정 알림을 \n보내도록 경보를 구성합니다. \nD. 30\n일 이내에 만료되는 모든 인증서를 감지하는 Amazon EventBridge(Amazon \nCloudWatch Events) 규칙을 생성합니다. AWS Lambda 함수를 호출하도록 규칙을 \n구성합니다. Amazon Simple Notification Service(Amazon SNS)를 통해 사용자 지정 알림을 \n보내도록 Lambda 함수를 구성합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/85615-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nA(X) : 30 일 전에 통보하랬지 맨날 통보하란 이야기는 없었음. \nB(O) : AWS Config 를 사용하여 만료 날짜가 가까워지는 인증서를 확인할 수 있습니다. \n인증서 만료 날짜가 가까워지면 Amazon EventBridge 를 사용하여 이메일 알림을 받을 수도 \n있습니다. \nhttps://aws.amazon.com/ko/premiumsupport/knowledge-center/acm-certificate-expiratio\nn/ \nC(X) : Trusted Advisor 는 \"\"AWS 환경을 검사한 후 비용 절감, 시스템 가용성 및 성능 향상 \n또는 보안 격차를 해결할 기회가 있을 때 권장 사항을 제시 \n\nhttps://docs.aws.amazon.com/ko_kr/awssupport/latest/user/trusted-advisor.html  \n하는 서비스로 이 경우엔 해당 사항이 없음. \nD(X) : EventBridge 는 이벤트 발생을 감지해서 뭔가를 하는 서비스이지 이벤트 발생 전에 \n뭔가 감지해서 하는 게 아님 \n \n참고 \nhttps://repost.aws/ko/knowledge-center/acm-certificate-expiration \nhttps://aws.amazon.com/ko/premiumsupport/knowledge-center/acm-certificate-expiratio\nn/", "answer_choice": "B"}, "83": {"q_num": 83, "question": "회사의 동적 웹 사이트는 미국의 온프레미스 서버를 사용하여 호스팅됩니다. 이 회사는 \n유럽에서 제품을 출시하고 있으며 새로운 유럽 사용자를 위해 사이트 로딩 시간을 \n최적화하려고 합니다. 사이트의 백엔드는 미국에 있어야 합니다. 제품이 며칠 안에 \n출시되며 즉각적인 솔루션이 필요합니다. \n솔루션 설계자는 무엇을 권장해야 합니까? \nA. us-east-1 에서 Amazon EC2 인스턴스를 시작하고 사이트를 마이그레이션합니다. \nB. 웹사이트를 Amazon S3 로 이동합니다. 지역 간 교차 지역 복제를 사용합니다. \nC. 온프레미스 서버를 가리키는 사용자 지정 오리진과 함께 Amazon CloudFront\n를 \n사용합니다. \nD. 온프레미스 서버를 가리키는 Amazon Route 53 지리 근접 라우팅 정책을 사용합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/85902-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \nhttps://aws.amazon.com/pt/blogs/aws/amazon-cloudfront-support-for-custom-origins/ \n이제 사용자 지정 오리진을 사용하여 CloudFront 배포를 생성할 수 있습니다. 각 배포는 \nS3 또는 사용자 지정 오리진을 가리킬 수 있습니다. 이것은 다른 스토리지 서비스일 수도 \n있고 EC2 인스턴스 또는 Elastic Load Balancer 와 같이 더 흥미롭고 동적인 것일 수도 \n있습니다. \n \n설명2: \nA(X) : 유럽과 가까워야 하므로 us-east-1 은 오답. \nB(X) : 동적 웹 사이트라고 했으므로 S3 가 들어가지 않음. \n\nC(O) : CloudFront 는 사용자 지정 오리진으로 온프레미스 서버를 가리킬 수 있음. \n사용자 지정 출처는 웹 서버와 같은 HTTP 서버입니다. HTTP 서버는 Amazon EC2 \n인스턴스이거나 \n다른 \n곳에서 \n호스팅하는 \nHTTP \n서버일 \n수 \n있습니다. \n웹 \n사이트 \n엔드포인트로 구성된 Amazon S3 오리진도 사용자 지정 오리진으로 간주됩니다.자체 HTTP \n서버를 \n사용자 \n지정 \n오리진으로 \n사용하는 \n경우 \n오리진에서 \n객체를 \n가져올 \n때 \nCloudFront 에서 사용할 HTTP 및 HTTPS 포트 및 프로토콜과 함께 서버의 DNS 이름을 \n지정합니다. \nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/DownloadDistS\n3AndCustomOrigins.html#concept_CustomOrigin \nD(X) : 웹 사이트엔 CDN 서비스인 CloudFront 가 필요.", "answer_choice": "C"}, "84": {"q_num": 84, "question": "회사는 기존 3\n계층 웹 아키텍처의 비용을 절감하려고 합니다. 웹, 애플리케이션 및 \n데이터베이스 서버는 개발, 테스트 및 프로덕션 환경을 위한 Amazon EC2 인스턴스에서 \n실행됩니다. EC2 인스턴스의 평균 CPU 사용률은 사용량이 많은 시간에는 30%이고 \n사용량이 많지 않은 시간에는 10%입니다. \n프로덕션 EC2 인스턴스는 하루 24 시간 실행됩니다. 개발 및 테스트 EC2 인스턴스는 매일 \n최소 8 시간 동안 실행됩니다. 회사는 개발을 중지하고 사용하지 않을 때 EC2 인스턴스를 \n테스트하는 자동화를 구현할 계획입니다. \n어떤 EC2 인스턴스 구매 솔루션이 가장 비용 효율적으로 회사의 요구 사항을 충족합니까? \nA. 프로덕션 EC2 인스턴스에 스팟 인스턴스를 사용합니다. EC2 인스턴스 개발 및 테스트에 \n예약 인스턴스를 사용합니다. \nB. 프로덕션 EC2 인스턴스에 예약 인스턴스를 사용합니다. 개발 및 테스트 EC2 \n인스턴스에 온디맨드 인스턴스를 사용합니다. \nC. 프로덕션 EC2 인스턴스에 스팟 블록을 사용합니다. EC2 인스턴스 개발 및 테스트에 \n예약 인스턴스를 사용합니다. \nD. 프로덕션 EC2 인스턴스에 온디맨드 인스턴스를 사용합니다. 개발 및 테스트 EC2 \n인스턴스에 스팟 블록을 사용합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/85665-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n해설:・ \nA(X) : 하루 24 시간 실행하는 프로덕션 EC2 인스턴스에 스팟 인스턴스는 적절치 않음. \n스팟 인스턴스는 도중에 중지될 가능성이 높은 인스턴스에 더 적합. \n\nB(O) : 1 년 또는 3 년 단위로 예약 인스턴스를 계약해서 사용하면 비용이 절감됨. 개발 및 \n테스트용 EC2 인스턴스는 매일 최소 8 시간 이상 실행된다고 했으므로 그 이상 사용될 수 \n있어 Scheduled Reserved 인스턴스보다는 온디맨드 인스턴스를 사용하는 것이 더 적절함 \nC(X) : 스팟 블록은 기간이 정의된 스팟 인스턴스로 A 와 같은 이유로 오답. \n\"\"기간이 정의된 스팟 인스턴스(스팟 블록이라고도 함)는 2021 년 7 월 1 일부로 신규 고객이 \n더 이상 사용할 수 없습니다. \nhttps://aws.amazon.com/ko/blogs/aws/new-ec2-spot-blocks-for-defined-duration-wor\nkloads/ \nD(X) : 24 시간 동안 사용할 EC2 인스턴스에는 예약 인스턴스 방식을 사용해 비용을 더 \n절감할 수 있음.", "answer_choice": "B"}, "85": {"q_num": 85, "question": "회사에 사용자가 웹 인터페이스 또는 모바일 앱을 통해 문서를 업로드하는 프로덕션 웹 \n애플리케이션이 있습니다. 새로운 규제 요구 사항에 따라. 새 문서는 저장 후에 수정하거나 \n삭제할 수 없습니다. \n솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. 업로드된 문서를 S3 버전 관리 및 S3 객체 잠금이 활성화된 Amazon S3 버킷에 \n저장합니다. \nB. 업로드된 문서를 Amazon S3 버킷에 저장합니다. 문서를 주기적으로 보관하도록 S3 \n수명 주기 정책을 구성합니다. \nC. 업로드된 문서를 S3 버전 관리가 활성화된 Amazon S3 버킷에 저장합니다. 모든 \n액세스를 읽기 전용으로 제한하도록 ACL 을 구성합니다. \nD. 업로드된 문서를 Amazon Elastic File System(Amazon EFS) 볼륨에 저장합니다. 읽기 \n전용 모드에서 볼륨을 마운트하여 데이터에 액세스합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/85751-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명:・ \n수정하거나 삭제할 수 없음 = S3 Object Lock. \nS3 객체 잠금을 사용하면 write-once-read-many(WORM) 모델을 사용하여 객체를 저장할 \n수 있습니다. 객체 잠금은 고정된 시간 동안 또는 무기한으로 객체의 삭제 또는 덮어쓰기를 \n방지하는 데 도움이 될 수 있습니다. \nhttps://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/object-lock.html", "answer_choice": "A"}, "86": {"q_num": 86, "question": "회사에는 공통 Amazon RDS MySQL 다중 AZ DB 인스턴스에 자주 액세스해야 하는 여러 웹 \n서버가 있습니다. 회사는 사용자 자격 증명을 자주 교체해야 하는 보안 요구 사항을 \n충족하면서 웹 서버가 데이터베이스에 연결할 수 있는 안전한 방법을 원합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. AWS Secrets Manager 에 데이터베이스 사용자 자격 증명을 저장합니다. 웹 서버가 AWS \nSecrets Manager 에 액세스할 수 있도록 필요한 IAM 권한을 부여합니다. \nB. AWS Systems Manager OpsCenter 에 데이터베이스 사용자 자격 증명을 저장합니다. 웹 \n서버가 OpsCenter 에 액세스할 수 있도록 필요한 IAM 권한을 부여합니다. \nC. 안전한 Amazon S3 버킷에 데이터베이스 사용자 자격 증명을 저장합니다. 웹 서버가 \n자격 증명을 검색하고 데이터베이스에 액세스할 수 있도록 필요한 IAM 권한을 부여합니다. \nD. 웹 서버 파일 시스템의 AWS Key Management Service(AWS KMS)로 암호화된 파일에 \n데이터베이스 사용자 자격 증명을 저장합니다. 웹 서버는 파일을 해독하고 데이터베이스에 \n액세스할 수 있어야 합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/85753-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \nAWS Secrets Manager 는 애플리케이션, 서비스 및 IT 리소스에 액세스하는 데 필요한 \n암호를 보호하는 데 도움이 됩니다. 이 서비스를 사용하면 수명 주기 동안 데이터베이스 \n자격 증명, API 키 및 기타 암호를 쉽게 교체, 관리 및 검색할 수 있습니다. \nhttps://docs.aws.amazon.com/secretsmanager/latest/userguide/intro.html \nSecrets Manager 를 사용하면 암호를 포함하여 코드의 하드코딩된 자격 증명을 Secrets \nManager 에 대한 API 호출로 대체하여 프로그래밍 방식으로 암호를 검색할 수 있습니다. \n이렇게 하면 비밀이 코드에 더 이상 존재하지 않기 때문에 코드를 검사하는 누군가가 \n비밀을 손상시킬 수 없습니다. 또한 지정된 일정에 따라 암호를 자동으로 교체하도록 \nSecrets Manager 를 구성할 수 있습니다. 이를 통해 장기 비밀을 단기 비밀로 대체하여 \n손상 위험을 크게 줄일 수 있습니다. \n \n설명2: \n사용자 자격 증명을 자주 바꿈 + 안전한 방법 = Secrets Manager. \nSecrets Manager\n를 사용하면 애플리케이션 소스 코드에서 하드 코딩된 자격 증명을 \n제거하고 애플리케이션 자체에 자격 증명을 저장하지 않음으로써 보안 태세를 개선할 수 \n있습니다. 사용자의 개입 없이 지정한 일정에 따라 자동으로 보안 암호를 교체하도록 \n\nSecrets Manager 를 구성할 수 있습니다. 교체는 AWS Lambda 함수를 사용하여 정하고 \n실행합니다. \nhttps://docs.aws.amazon.com/ko_kr/secretsmanager/latest/userguide/intro.html \n또한 여러 리전과 여러 AZ 에 걸쳐 작동.  \nhttps://docs.aws.amazon.com/ko_kr/secretsmanager/latest/userguide/disaster-recovery-\nresiliency.html", "answer_choice": "A"}, "87": {"q_num": 87, "question": "회사는 Amazon API Gateway API 에 의해 호출되는 AWS Lambda 함수에서 애플리케이션을 \n호스팅합니다. Lambda 함수는 고객 데이터를 Amazon Aurora MySQL 데이터베이스에 \n저장합니다. 회사에서 데이터베이스를 업그레이드할 때마다 Lambda 함수는 업그레이드가 \n완료될 때까지 데이터베이스 연결을 설정하지 못합니다. 그 결과 일부 이벤트에 대한 고객 \n데이터가 기록되지 않습니다. \n솔루션 설계자는 데이터베이스 업그레이드 중에 생성되는 고객 데이터를 저장하는 솔루션을 \n설계해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. \nLambda \n함수와 \n데이터베이스 \n사이에 \n위치하도록 \nAmazon \nRDS \n프록시를 \n프로비저닝합니다. RDS 프록시에 연결하도록 Lambda 함수를 구성합니다. \nB. Lambda 함수의 실행 시간을 최대로 늘립니다. 데이터베이스에 고객 데이터를 저장하는 \n코드에서 재시도 메커니즘을 만듭니다. \nC. 고객 데이터를 Lambda 로컬 스토리지에 유지합니다. 고객 데이터를 데이터베이스에 \n저장하기 위해 로컬 스토리지를 스캔하도록 새로운 Lambda 함수를 구성합니다. \nD. Amazon Simple Queue Service(Amazon SQS) FIFO 대기열에 고객 데이터를 저장합니다. \n대기열을 \n폴링하고 \n고객 \n데이터를 \n데이터베이스에 \n저장하는 \n새 \nLambda \n함수를 \n생성합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/85319-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \n잠시 고객 데이터를 저장하는 솔루션 = SQS. 손실될 위험이 있는 처리 대상 데이터를 잠시 \n보관하는 용도로는 SQS 가 주로 쓰인다고 보면 됨. 답은 D. \n \n설명2: \nhttps://www.learnaws.org/2020/12/13/aws-rds-proxy-deep-dive/ \n\nRDS 프록시는 새 데이터베이스 인스턴스가 작동할 때까지 대기하고 이 시간 동안 \n애플리케이션에서 받은 모든 요청을 유지함으로써 이러한 상황에서 애플리케이션 가용성을 \n향상시킬 수 있습니다. 최종 결과는 응용 프로그램이 기본 데이터베이스의 문제에 대해 더 \n탄력적이라는 것입니다. 이렇게 하면 DB 가 정상으로 돌아올 때까지 솔루션이 데이터를 \n보유할 수 있습니다. RDS 프록시는 Lambda 와 DB 간의 연결을 최적으로 활용하기 위한 \n것입니다. Lambda 는 DB 컴퓨팅 리소스에 부담을 줄 수 있는 여러 연결을 동시에 열 수 \n있습니다.", "answer_choice": "D"}, "88": {"q_num": 88, "question": "설문 조사 회사는 미국 지역에서 수년 동안 데이터를 수집했습니다. 이 회사는 크기가 \n3TB 이고 계속 증가하는 Amazon S3 버킷에 데이터를 호스팅합니다. 이 회사는 S3 버킷이 \n있는 유럽 마케팅 회사와 데이터를 공유하기 시작했습니다. 회사는 데이터 전송 비용이 \n가능한 한 낮게 유지되기를 원합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 회사의 S3 버킷에서 요청자 지불 기능을 구성합니다. \nB. 회사의 S3 버킷에서 마케팅 회사의 S3 버킷 중 하나로 S3 교차 리전 복제를 \n구성합니다. \nC. 마케팅 회사가 회사의 S3 버킷에 액세스할 수 있도록 마케팅 회사에 대한 교차 계정 \n액세스를 구성합니다. \nD. S3 Intelligent-Tiering 을 사용하도록 회사의 S3 버킷을 구성합니다. S3 버킷을 마케팅 \n회사의 S3 버킷 중 하나와 동기화합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/85738-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \n요청자 지불 버킷을 사용하면 버킷 소유자 대신 요청자가 버킷에서 데이터 다운로드 및 \n요청 비용을 지불합니다. 버킷 소유자는 항상 데이터 저장 비용을 지불합니다. \nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/RequesterPaysBuckets.html \n \n설명2: \n\"일반적으로 데이터를 공유하고 싶지만 데이터에 액세스하는 다른 사람과 관련된 요금을 \n부과하지 않으려면 버킷을 요청자 지불 버킷으로 구성합니다. \n예를 들어 우편 번호 디렉터리, 참조 데이터 지리 공간 정보 또는 웹 크롤링 데이터와 같은 \n대용량 데이터 세트를 만들 때 요청자 지불 버킷을 사용할 수 있습니다.\" \n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/RequesterPaysBuckets.html", "answer_choice": "A"}, "89": {"q_num": 89, "question": "회사는 Amazon S3 를 사용하여 기밀 감사 문서를 저장합니다. S3 버킷은 버킷 정책을 \n사용하여 최소 권한 원칙에 따라 감사 팀 IAM 사용자 자격 증명에 대한 액세스를 \n제한합니다. 회사 관리자는 S3 버킷에서 실수로 문서가 삭제되는 것을 걱정하고 더 안전한 \n솔루션을 원합니다. \n솔루션 설계자는 감사 문서를 보호하기 위해 무엇을 해야 합니까? \nA. S3 버킷에서 버전 관리 및 MFA 삭제 기능을 활성화합니다. \nB. 각 감사 팀 IAM 사용자 계정의 IAM 사용자 자격 증명에 대해 다단계 인증(MFA)을 \n활성화합니다. \nC. 감사 날짜 동안 s3:DeleteObject 작업을 거부하도록 감사 팀의 IAM 사용자 계정에 S3 \n수명 주기 정책을 추가합니다. \nD. AWS Key Management Service(AWS KMS)를 사용하여 S3 버킷을 암호화하고 감사 팀 \nIAM 사용자 계정이 KMS 키에 액세스하지 못하도록 제한합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/85808-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명:・ \n・버전 관리는 실수로 삭제했을 때 이전 버전의 파일을 불러올 수 있도록 해줌. \nAmazon S3 의 버전 관리는 동일 버킷 내에 여러 개의 객체 변형을 보유하는 수단입니다. \nS3 버전 관리를 사용하면 버킷에 저장된 모든 버전의 객체를 모두 보존, 검색 및 복원할 \n수 있습니다. \nhttps://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/Versioning.html \n・MFA Delete 는 함부로 삭제하지 못하도록 막음. \nMFA Delete 는 다음 작업에 대해 추가 인증을 요구합니다. ◎버킷의 버전 관리 상태 변경 \n◎객체 버전 영구 삭제 \nhttps://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/MultiFactorAuthenticatio\nnDelete.html", "answer_choice": "A"}, "90": {"q_num": 90, "question": "회사에서 SQL 데이터베이스를 사용하여 공개적으로 액세스할 수 있는 영화 데이터를 \n저장하고 있습니다. 데이터베이스는 Amazon RDS 단일 AZ DB 인스턴스에서 실행됩니다. \n\n스크립트는 데이터베이스에 추가된 새로운 영화의 수를 기록하기 위해 매일 임의의 \n간격으로 쿼리를 실행합니다. 스크립트는 업무 시간 동안의 최종 합계를 보고해야 합니다. \n회사의 개발 팀은 스크립트가 실행 중일 때 데이터베이스 성능이 개발 작업에 부적절하다는 \n것을 알아차렸습니다. 솔루션 설계자는 이 문제를 해결하기 위한 솔루션을 권장해야 \n합니다. \n최소한의 운영 오버헤드로 이 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. DB 인스턴스를 다중 AZ 배포로 수정합니다. \nB. 데이터베이스의 읽기 전용 복제본을 생성합니다. 읽기 전용 복제본만 쿼리하도록 \n스크립트를 구성합니다. \nC. 개발 팀에게 매일 일과가 끝날 때 데이터베이스의 항목을 수동으로 내보내도록 \n지시합니다. \nD. Amazon ElastiCache 를 사용하여 스크립트가 데이터베이스에 대해 실행하는 일반적인 \n쿼리를 캐시합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/85339-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명:・ \n・스크립트는 데이터베이스에 추가된 새로운 영화의 수를 기록하기 위해 매일 임의의 \n간격으로 쿼리를 실행합니다. = 스크립트는 쿼리를 수행하고 있음 \n・'회사의 개발 팀은 스크립트가 실행 중일 때 데이터베이스 성능이 개발 작업에 \n부적절하다는 것을 알아차렸습니다.' = 스크립트 때문에 데이터베이스 성능이 떨어지고 \n있음. \n따라서 쿼리가 너무 많이 수행되어서 데이터베이스 성능에 영향이 가는 상황입니다. 이런 \n경우 read replica 를 통해 쿼리 부하를 분산할 수 있습니다. \nB(O) : 애플리케이션에서 읽기 전용 복제본으로 읽기 쿼리를 라우팅하여 기본 DB \n인스턴스의 로드를 줄일 수 있습니다. \nhttps://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/USER_ReadRepl.html \nD(X) : ElastiCache 는 웹 애플리케이션 성능 향상 용도로 주로 사용됨. \nAmazon ElastiCache 는 더 느린 디스크 기반 데이터베이스에 전적으로 의존하기보다는 \n신속한 관리형 인 메모리 시스템에서 정보를 검색할 수 있는 기능을 지원함으로써 웹 \n애플리케이션의 성능을 향상합니다. https://aws.amazon.com/ko/elasticache/faqs/", "answer_choice": "B"}, "91": {"q_num": 91, "question": "회사에 \nVPC\n의 \nAmazon \nEC2 \n인스턴스에서 \n실행되는 \n애플리케이션이 \n있습니다. \n\n애플리케이션 중 하나는 Amazon S3 API 를 호출하여 객체를 저장하고 읽어야 합니다. \n회사의 보안 규정에 따라 응용 프로그램의 트래픽은 인터넷을 통해 이동할 수 없습니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. S3 게이트웨이 엔드포인트를 구성합니다. \nB. 프라이빗 서브넷에 S3 버킷을 생성합니다. \nC. EC2 인스턴스와 동일한 AWS 리전에 S3 버킷을 생성합니다. \nD. EC2 인스턴스와 동일한 서브넷에 NAT 게이트웨이를 구성합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/85667-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n해설:・ \nB. 프라이빗 서브넷에서 S3 를 생성하면 버킷에 대한 직접적인 인터넷 액세스가 제한되지만 \nEC2 와 S3 간의 직접적이고 안전한 연결은 제공되지 않습니다. 애플리케이션은 여전히 S3 \nAPI 에 액세스하기 위해 인터넷을 통과해야 합니다. \n \nC. EC2 와 동일한 지역에 S3 를 생성한다고 해서 본질적으로 트래픽이 인터넷을 통과하는 \n것을 막지는 않습니다. \n \nD. NAT 게이트웨이를 구성하면 프라이빗 서브넷의 리소스에 대한 아웃바운드 인터넷 \n연결이 허용되지만 S3 서비스에 대한 직접적이고 안전한 연결은 제공되지 않습니다. \nEC2 에서 S3 API 로의 트래픽은 여전히 인터넷을 통과합니다. \n \n가장 적합한 솔루션은 S3 게이트웨이 엔드포인트를 구성하는 것입니다(옵션 A). 트래픽이 \n인터넷을 통과할 필요 없이 VPC 와 S3 서비스 간에 안전한 비공개 연결을 제공합니다. S3 \n게이트웨이 엔드포인트를 통해 EC2 는 VPC 내에서 직접 S3 API 에 액세스할 수 있으므로 \n트래픽이 인터넷을 통해 이동하지 못하도록 하는 보안 요구 사항을 충족합니다. \n \n참고: \nhttps://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/privatelink-interface-en\ndpoints.html#types-of-vpc-endpoints-for-s3 \nhttps://docs.aws.amazon.com/ko_kr/vpc/latest/privatelink/vpc-endpoints-s3.html", "answer_choice": "A"}, "92": {"q_num": 92, "question": "회사에서 Amazon S3 버킷에 민감한 사용자 정보를 저장하고 있습니다. 회사는 VPC 내부의 \n\nAmazon EC2 인스턴스에서 실행되는 애플리케이션 계층에서 이 버킷에 대한 보안 액세스를 \n제공하려고 합니다. \n솔루션 설계자는 이를 달성하기 위해 어떤 단계 조합을 취해야 합니까? (2\n개를 \n선택하세요.) \nA. VPC 내에서 Amazon S3 용 VPC 게이트웨이 엔드포인트를 구성합니다. \nB. S3 버킷의 객체를 퍼블릭으로 만들기 위한 버킷 정책을 생성합니다. \nC. VPC\n에서 실행되는 애플리케이션 계층으로만 액세스를 제한하는 버킷 정책을 \n생성합니다. \nD. S3 액세스 정책으로 IAM 사용자를 생성하고 IAM 자격 증명을 EC2 인스턴스에 \n복사합니다. \nE. NAT 인스턴스를 생성하고 EC2 인스턴스가 NAT 인스턴스를 사용하여 S3 버킷에 \n액세스하도록 합니다.", "answer_block": "Answer: A, C \nhttps://www.examtopics.com/discussions/amazon/view/85903-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명:・ \nA(O) : Gateway Endpoint 는 퍼블릭 인터넷망을 통과하지 않는 전용 연결. \n게이트웨이 엔드포인트는 VPC 용 인터넷 게이트웨이 또는 NAT 디바이스가 없어도 Amazon \nS3 및 DynamoDB 에 대한 안정적인 연결을 제공합니다. 게이트웨이 엔드포인트는 AWS \nPrivateLink 를 활성화하지 않습니다. \nhttps://docs.aws.amazon.com/ko_kr/vpc/latest/privatelink/vpce-gateway.html \nB(X) : 객체를 퍼블릭으로 만드는 것은 보안과는 거리가 멈. \nC(O) : 버킷 정책으로 버킷에 대한 액세스 제어. \n버킷 정책은 버킷과 해당 버킷의 객체에 대한 액세스 권한을 부여할 수 있는 리소스 기반 \n정책입니다. \nhttps://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/example-bucket-policie\ns.html \nD(X) : 차라리 IAM 사용자 정책을 사용하는 것이 더 나음. \nAmazon S3 에 대한 사용자 액세스를 제어하는 IAM 사용자 정책을 생성하고 구성할 수 \n있습니다. \nhttps://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/user-policies.html \nE(X) : Gateway Endpoint 가 더 좋은 선택임.", "answer_choice": "A"}, "93": {"q_num": 93, "question": "회사는 MySQL 데이터베이스로 구동되는 온프레미스 애플리케이션을 실행합니다. 이 \n회사는 \n애플리케이션의 \n탄력성과 \n가용성을 \n높이기 \n위해 \n애플리케이션을 \nAWS\n로 \n마이그레이션하고 있습니다. \n현재 아키텍처는 정상 작동 시간 동안 데이터베이스에서 많은 읽기 활동을 보여줍니다. \n회사의 개발 팀은 4\n시간마다 프로덕션 데이터베이스의 전체 내보내기를 가져와 준비 \n환경의 데이터베이스를 채웁니다. 이 기간 동안 사용자는 허용할 수 없는 애플리케이션 \n대기 시간을 경험합니다. 개발 팀은 절차가 완료될 때까지 스테이징 환경을 사용할 수 \n없습니다. \n솔루션 설계자는 애플리케이션 지연 문제를 완화하는 대체 아키텍처를 권장해야 합니다. \n또한 대체 아키텍처는 개발 팀이 지연 없이 스테이징 환경을 계속 사용할 수 있는 능력을 \n제공해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 프로덕션용 다중 AZ Aurora 복제본과 함께 Amazon Aurora MySQL 을 사용합니다. \nmysqldump \n유틸리티를 \n사용하는 \n백업 \n및 \n복원 \n프로세스를 \n구현하여 \n스테이징 \n데이터베이스를 채웁니다. \nB. 프로덕션용 다중 AZ Aurora 복제본과 함께 Amazon Aurora MySQL 을 사용합니다. \n데이터베이스 복제를 사용하여 요청 시 스테이징 데이터베이스를 생성합니다. \nC. 다중 AZ 배포 및 프로덕션용 읽기 전용 복제본과 함께 MySQL 용 Amazon RDS 를 \n사용합니다. 스테이징 데이터베이스에 대해 대기 인스턴스를 사용합니다. \nD. 다중 AZ 배포 및 프로덕션용 읽기 전용 복제본과 함께 MySQL 용 Amazon RDS 를 \n사용합니다. mysqldump 유틸리티를 사용하는 백업 및 복원 프로세스를 구현하여 스테이징 \n데이터베이스를 채웁니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/85729-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명:・ \nRDS 에 비해 Aurora 는 항상 3 개의 AZ 에 6 개의 복제본(Replica)를 보유하고 있으므로 \n애플리케이션 가용성에 더 유리. A,B 둘 중 하나가 답.여기서 mysqldump 가 문젠데,  \nQ: MySQL 에서 Amazon Aurora 로 또는 그 반대로 마이그레이션하려면 어떻게 해야 하나요? \n여러 가지 옵션이 있습니다. 표준 mysqldump 유틸리티를 사용하여 MySQL 에서 데이터를 \n내보내고 mysqlimport 유틸리티를 사용하여 Amazon Aurora\n로 데이터를 가져올 수 \n있습니다. 그 반대도 마찬가지입니다. 또한, AWS 관리 콘솔에서 Amazon RDS 의 DB 스냅샷 \n마이그레이션 기능을 이용하여 Amazon RDS for MySQL DB 스냅샷을 Amazon Aurora 로 \n마이그레이션할 수 있습니다. 대부분 고객은 [1 시간 이내]에 마이그레이션을 완료하지만 \nhttps://aws.amazon.com/ko/rds/aurora/faqs/ \n\n최대 1GB 정도의 소규모 데이터베이스라면 mysqldump 를 실행 \nhttps://aws.amazon.com/ko/rds/mysql/features/ \n이걸로 봤을 때 mysqldump 는 데이터백업에 많은 시간이 소요되는 방법으로 보이므로 A \n제외. 답은 B. \n \n참고 \nhttps://aws.amazon.com/blogs/aws/amazon-aurora-fast-database-cloning/", "answer_choice": "B"}, "94": {"q_num": 94, "question": "한 회사에서 사용자가 Amazon S3 에 작은 파일을 업로드하는 애플리케이션을 설계하고 \n있습니다. 사용자가 파일을 업로드한 후 데이터를 변환하고 나중에 분석할 수 있도록 \n데이터를 JSON 형식으로 저장하려면 파일에 일회성 단순 처리가 필요합니다. \n각 파일은 업로드 후 최대한 빨리 처리해야 합니다. 수요는 다양할 것입니다. 어떤 날에는 \n사용자가 많은 수의 파일을 업로드합니다. 다른 날에는 사용자가 몇 개의 파일을 \n업로드하거나 파일을 업로드하지 않습니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Amazon S3 에서 텍스트 파일을 읽도록 Amazon EMR 을 구성합니다. 처리 스크립트를 \n실행하여 데이터를 변환합니다. 결과 JSON 파일을 Amazon Aurora DB 클러스터에 \n저장합니다. \nB. Amazon SQS(Amazon Simple Queue Service) 대기열에 이벤트 알림을 보내도록 Amazon \nS3 를 구성합니다. Amazon EC2 인스턴스를 사용하여 대기열에서 읽고 데이터를 처리합니다. \n결과 JSON 파일을 Amazon DynamoDB 에 저장합니다. \nC. 이벤트 알림을 Amazon Simple Queue Service(Amazon SQS) 대기열로 보내도록 \nAmazon S3 를 구성합니다. AWS Lambda 함수를 사용하여 대기열에서 읽고 데이터를 \n처리합니다. 결과 JSON 파일을 Amazon DynamoDB 에 저장합니다. \nD. 새 파일이 업로드될 때 Amazon Kinesis Data Streams 에 이벤트를 보내도록 Amazon \nEventBridge(Amazon CloudWatch Events)를 구성합니다. AWS Lambda 함수를 사용하여 \n스트림에서 이벤트를 소비하고 데이터를 처리합니다. 결과 JSON 파일을 Amazon Aurora \nDB 클러스터에 저장합니다.", "answer_block": "Answer: C  \nhttps://www.examtopics.com/discussions/amazon/view/86676-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1:・ \nA(X) : EMR 은 빅데이터 플랫폼 서비스라 사용 분야가 좀 다르고, 파일을 업로드하지 않는 \n\n날이나 업로드가 거의 없는 날에는 과도한 지출이 발생할 우려가 있음. \nB(X) : 파일에 일회성 단순 처리가 필요하다고 했으므로 EC2 인스턴스로 처리하는 \n것보다는 Lambda 가 더 지문 요구사항에 부합. \nC(O) : 유일하게 마음에 걸리는 게 '업로드 후 최대한 빨리 처리'해야한다는 건데 가장 \n정답에 가까운 선택지로 보임. 업로드하는 파일 숫자도 변동이 심한데 이를 SQS 대기열에 \n집어넣음으로서 대처할 수 있고, Lambda 함수로 파일에 일회성 단순 처리가 가능하며 \n추가적인 SQS->Lambda->DynamoDB\n에 저장이라는 단순한 프로세스로 인해 운영 \n오버헤드도 매우 적음. DynamoDB 는 JSON 파일을 지원 \nDynamoDB\n는 JSON\n을 사용하여 문서에 대한 기본 지원을 제공합니다. 따라서 \nDynamoDB 는 Tags 같은 반정형 데이터를 저장하는 데 적합합니다. JSON 문서 안에서 \n데이터를 가져오고 조작할 수도 있습니다. \nhttps://docs.aws.amazon.com/ko_kr/amazondynamodb/latest/developerguide/SQLtoNoS\nQL.WriteData.html \nD(X) : 파일에 일회성 단순 처리가 필요하다고 했으므로 Kinesis Data Streams 로 처리하는 \n것보다는 Lambda 가 더 지문 요구사항에 부합. 또한 파일 업로드가 없거나 거의 없는 \n날에는 Kinesis 사용은 과도한 지출을 야기할 우려가 있음. \n \n설명2: \nAmazon S3 는 S3 버킷(예: 객체 생성, 객체 제거 또는 객체 복원)에 대한 이벤트 알림을 \n동일한 리전의 SNS 주제로 보냅니다. \nSNS 주제는 중앙 리전의 SQS 대기열에 이벤트를 게시합니다. \nSQS 대기열은 Lambda 함수의 이벤트 소스로 구성되며 Lambda 함수의 이벤트 메시지를 \n버퍼링합니다. \nLambda 함수는 메시지에 대한 SQS 대기열을 폴링하고 애플리케이션의 요구 사항에 따라 \nAmazon S3 이벤트 알림을 처리합니다. \nhttps://docs.aws.amazon.com/ko_kr/prescriptive-guidance/latest/patterns/subscribe-a-l\nambda-function-to-event-notifications-from-s3-buckets-in-different-aws-regions.html", "answer_choice": "C"}, "95": {"q_num": 95, "question": "응용 프로그램을 사용하면 회사 본사의 사용자가 제품 데이터에 액세스할 수 있습니다. \n제품 데이터는 Amazon RDS MySQL DB 인스턴스에 저장됩니다. 운영 팀은 애플리케이션 \n성능 저하를 격리하고 쓰기 트래픽에서 읽기 트래픽을 분리하려고 합니다. 솔루션 설계자는 \n애플리케이션의 성능을 신속하게 최적화해야 합니다. \n솔루션 설계자는 무엇을 권장해야 합니까? \nA. 기존 데이터베이스를 다중 AZ 배포로 변경합니다. 기본 가용 영역에서 읽기 요청을 \n\n제공합니다. \nB. 기존 데이터베이스를 다중 AZ 배포로 변경합니다. 보조 가용 영역에서 읽기 요청을 \n제공합니다. \nC. 데이터베이스에 대한 읽기 전용 복제본을 생성합니다. 컴퓨팅 및 스토리지 리소스의 \n절반을 원본 데이터베이스로 사용하여 읽기 전용 복제본을 구성합니다. \nD. 데이터베이스에 대한 읽기 전용 복제본을 생성합니다. 원본 데이터베이스와 동일한 \n컴퓨팅 및 스토리지 리소스로 읽기 전용 복제본을 구성합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/85906-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n해설:・ \n복제가 효과적으로 작동하려면 각 읽기 전용 복제본에 원본 DB 인스턴스와 동일한 양의 \n컴퓨팅 및 스토리지 리소스가 있어야 합니다. 원본 DB 인스턴스를 확장하는 경우 읽기 \n전용 복제본도 확장합니다. \nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_MySQL.Replication.R\neadReplicas.html \n \n참조 \nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_MySQL.Replication.R\neadReplicas.html", "answer_choice": "D"}, "96": {"q_num": 96, "question": "Amazon EC2 관리자는 여러 사용자가 포함된 IAM 그룹과 연결된 다음 정책을 \n생성했습니다. \n\n \n이 정책의 효과는 무엇입니까? \nA. 사용자는 us-east-1\n을 제외한 모든 AWS 리전에서 EC2 인스턴스를 종료할 수 \n있습니다. \nB. 사용자는 us-east-1 리전에서 IP 주소가 10.100.100.1 인 EC2 인스턴스를 종료할 수 \n있습니다. \nC. 사용자는 사용자의 소스 IP\n가 10.100.100.254\n일 때 us-east-1 리전에서 EC2 \n인스턴스를 종료할 수 있습니다. \nD. 사용자의 소스 IP 가 10.100.100.254 인 경우 사용자는 us-east-1 리전에서 EC2 \n인스턴스를 종료할 수 없습니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/86460-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nAllow 문 해석 : 소스 IP 가 10.100.100.0/24 인 모든 리소스(*)에 대해 ec2 인스턴스 종료를 \n허용. \nDeny 문 해석 : ec2 리전이 us-east-1 이 아닌 모든 리소스(*)에 대해 ec2 의 모든 작업을 \n\n불허. 따라서 정답은 C. \n \n설명2: \n정책은 us-east-1 을 제외한 모든 지역에서 EC2 작업을 수행하는 것을 금지하고 소스 IP 가 \n10.100.100.0/24 인 사용자만 인스턴스를 종료하도록 허용하기 때문입니다. 따라서 소스 \nIP 가 10.100.100.254 인 사용자는 us-east-1 지역의 인스턴스를 종료할 수 있습니다.", "answer_choice": "C"}, "97": {"q_num": 97, "question": "회사에는 Microsoft Windows 공유 파일 저장소가 필요한 온프레미스에서 실행되는 대규모 \nMicrosoft \nSharePoint \n배포가 \n있습니다. \n회사는 \n이 \n워크로드를 \nAWS \n클라우드로 \n마이그레이션하기를 원하며 다양한 스토리지 옵션을 고려하고 있습니다. 저장소 솔루션은 \n액세스 제어를 위해 고가용성 및 Active Directory 와 통합되어야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Amazon EFS 스토리지를 구성하고 인증을 위해 Active Directory 도메인을 설정합니다. \nB. 두 가용 영역의 AWS Storage Gateway 파일 게이트웨이에 SMB 파일 공유를 \n생성합니다. \nC. Amazon S3 버킷을 생성하고 볼륨으로 탑재하도록 Microsoft Windows Server\n를 \n구성합니다. \nD. AWS 에서 Windows 파일 서버용 Amazon FSx 파일 시스템을 생성하고 인증을 위해 \nActive Directory 도메인을 설정합니다.", "answer_block": "Answer: D  \nhttps://www.examtopics.com/discussions/amazon/view/86626-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nMcrosoft Active Directory 용 AWS Directory Service : \nAWS Managed Microsoft AD 에 대한 패치 및 유지 관리. 기본적으로 각 디렉터리는 서로 \n다른 가용 영역에 설치된 두 개의 DC 로 구성됩니다. \nhttps://docs.aws.amazon.com/directoryservice/latest/admin-guide/ms_ad_key_concepts_\nmaintenance.html \nWindows 파일 서버용 FSx 를 AWS Managed Microsoft AD 와 통합하면 Windows 기반 \n애플리케이션 및 클라이언트(공유 파일 스토리지 활용)를 AWS 로 쉽게 이동할 수 있는 \n완전 관리형 기본 Microsoft Windows 기반 서버 메시지 블록(SMB) 프로토콜 파일 \n시스템을 제공합니다. \nhttps://docs.aws.amazon.com/directoryservice/latest/admin-guide/usecase1.html", "answer_choice": "D"}, "98": {"q_num": 98, "question": "이미지 처리 회사에는 사용자가 이미지를 업로드하는 데 사용하는 웹 응용 프로그램이 \n있습니다. 애플리케이션은 이미지를 Amazon S3 버킷에 업로드합니다. 회사는 객체 생성 \n이벤트를 Amazon Simple Queue Service(Amazon SQS) 표준 대기열에 게시하도록 S3 \n이벤트 알림을 설정했습니다. SQS 대기열은 이미지를 처리하고 결과를 이메일을 통해 \n사용자에게 보내는 AWS Lambda 함수의 이벤트 소스 역할을 합니다. \n사용자는 업로드된 모든 이미지에 대해 여러 이메일 메시지를 수신하고 있다고 보고합니다. \n솔루션 설계자는 SQS 메시지가 Lambda 함수를 두 번 이상 호출하여 여러 이메일 \n메시지를 생성한다고 판단합니다. \n솔루션 설계자는 이 문제를 최소한의 운영 오버헤드로 해결하기 위해 무엇을 해야 합니까? \nA. ReceiveMessage 대기 시간을 30 초로 늘려 SQS 대기열에서 긴 폴링을 설정합니다. \nB. SQS 표준 대기열을 SQS FIFO 대기열로 변경합니다. 메시지 중복 제거 ID 를 사용하여 \n중복 메시지를 버리십시오. \nC. SQS 대기열의 가시성 제한 시간을 함수 제한 시간과 일괄 처리 창 제한 시간의 \n합계보다 큰 값으로 늘립니다. \nD. 처리 전에 메시지를 읽은 직후 SQS 대기열에서 각 메시지를 삭제하도록 Lambda \n함수를 수정합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/85185-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명:・ \nA(X) : 긴 폴링 대기 시간의 최대값은 20 초입니다. \nhttps://docs.aws.amazon.com/ko_kr/AWSSimpleQueueService/latest/SQSDeveloperGuide\n/working-with-messages.html \nB(X) : 솔루션 설계자는 SQS 메시지가 Lambda 함수를 두 번 이상 호출하여 여러 이메일 \n메시지를 생성하는 것이 문제의 원인이라고 보고 있음. 즉, SQS 쪽 문제이지 이미지 생성 \n및 업로드까지는 문제가 없다는 것. 중복 ID 제거는 생산자가 중복 메시지를 발생시키는 \n문제를 SQS FIFO Queue 에서 해결하는 서비스 유형이므로 지문의 상황에는 적합하지 않음. \n더군다나 모든 이미지 업로드 시마다 같은 문제가 계속 발생한다는 건 가끔 중복 메시지가 \n유입되는 정도가 아니라 SQS 대기열 쪽에서 처리가 이루어질 때 문제가 발생했을 \n가능성이 더 높음. \nFIFO 대기열은 중복 메시지가 절대 유입되지 않도록 설계되었습니다. 다만 일부 \n시나리오에서는 메시지 생산자가 중복 메시지를 유입할 수도 있습니다. \n\nhttps://aws.amazon.com/ko/sqs/faqs/ \nC(O) : 하지만 소비자가 메시지를 삭제하기 전에 실패할 경우 제한 시간 초과가 만료되기 \n전에 시스템에서 해당 메시지에 대한 DeleteMessage 작업을 호출하지 않으면 다른 \n소비자가 \n메시지를 \n볼 \n수 \n있게 \n되고 \n메시지가 \n다시 \n수신됩니다. \n일반적으로 \n애플리케이션에서 대기열의 메시지를 처리하고 삭제하는 데 소요되는 최대 시간으로 제한 \n시간 \n초과를 \n설정해야 \n합니다. \n메시지의 \n제한 \n시간을 \n단축하거나 \n늘리기 \n위해 \nChangeMessageVisibility 작업을 사용하여 새 제한 시간 값을 지정할 수 있습니다. \nhttps://docs.aws.amazon.com/ko_kr/AWSSimpleQueueService/latest/SQSDeveloperGuide\n/sqs-visibility-timeout.html#configuring-visibility-timeout \nD(X) : Lambda 함수가 메시지 처리 및 삭제까지 담당하게 되므로 Lambda 비용이 추가로 \n발생하여 다른 방법보다 더 비용이 발생. 굳이 이 방법을 사용할 이유가 없음.", "answer_choice": "C"}, "99": {"q_num": 99, "question": "회사는 온프레미스 데이터 센터에서 호스팅되는 게임 애플리케이션을 위한 공유 스토리지 \n솔루션을 구현하고 있습니다. 회사는 Lustre 클라이언트를 사용하여 데이터에 액세스할 수 \n있는 기능이 필요합니다. 솔루션은 완전히 관리되어야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. AWS Storage Gateway 파일 게이트웨이를 생성합니다. 필요한 클라이언트 프로토콜을 \n사용하는 파일 공유를 만듭니다. 응용 프로그램 서버를 파일 공유에 연결합니다. \nB. Amazon EC2 Windows 인스턴스를 생성합니다. 인스턴스에 Windows 파일 공유 역할을 \n설치하고 구성합니다. 응용 프로그램 서버를 파일 공유에 연결합니다. \nC. Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성하고 Lustre 를 지원하도록 \n구성합니다. 파일 시스템을 원본 서버에 연결합니다. 응용 프로그램 서버를 파일 시스템에 \n연결합니다. \nD. Lustre 파일 시스템용 Amazon FSx\n를 생성합니다. 파일 시스템을 원본 서버에 \n연결합니다. 응용 프로그램 서버를 파일 시스템에 연결합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/85811-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명:・ \nA. AWS Storage Gateway 파일 게이트웨이는 Lustre 클라이언트 액세스를 지원하지 \n않습니다. \nB. EC2 Windows 인스턴스에서 Windows 파일 공유를 생성하는 것은 Windows 기반 파일 \n공유에 적합하지만 필요한 Lustre 클라이언트 액세스를 제공하지 않습니다. Lustre 는 고성능 \n\n컴퓨팅(HPC) 환경에서 주로 사용되는 고성능 병렬 파일 시스템입니다. \nC. EFS 는 기본적으로 Lustre 클라이언트 액세스를 지원하지 않습니다. EFS 는 관리형 파일 \n스토리지 서비스이지만 범용 파일 스토리지용으로 설계되었으며 Lustre 워크로드에 \n최적화되어 있지 않습니다. \nD. Amazon FSx for Lustre 는 Lustre 클라이언트를 포함하여 고성능 컴퓨팅 워크로드에 \n최적화된 완전관리형 파일 시스템입니다. Lustre 클라이언트를 사용하여 관리되고 확장 \n가능한 방식으로 데이터에 액세스할 수 있는 기능을 제공합니다. 이 옵션을 선택함으로써 \n회사는 Lustre 클라이언트 액세스 요구 사항을 충족하면서 Amazon FSx for Lustre 의 성능 \n및 관리 용이성으로부터 이점을 얻을 수 있습니다.", "answer_choice": "D"}, "100": {"q_num": 100, "question": "회사의 \n컨테이너화된 \n애플리케이션은 \nAmazon \nEC2 \n인스턴스에서 \n실행됩니다. \n애플리케이션은 다른 비즈니스 애플리케이션과 통신하기 전에 보안 인증서를 다운로드해야 \n합니다. 회사는 거의 실시간으로 인증서를 암호화하고 해독할 수 있는 매우 안전한 \n솔루션을 원합니다. 또한 솔루션은 데이터가 암호화된 후 고가용성 스토리지에 데이터를 \n저장해야 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 암호화된 인증서에 대한 AWS Secrets Manager 암호를 생성합니다. 필요에 따라 \n인증서를 수동으로 업데이트합니다. 세분화된 IAM 액세스를 사용하여 데이터에 대한 \n액세스를 제어합니다. \nB. Python 암호화 라이브러리를 사용하여 암호화 작업을 수신하고 수행하는 AWS Lambda \n함수를 생성합니다. 함수를 Amazon S3 버킷에 저장합니다. \nC. AWS Key Management Service(AWS KMS) 고객 관리형 키를 생성합니다. EC2 역할이 \n암호화 작업에 KMS 키를 사용하도록 허용합니다. 암호화된 데이터를 Amazon S3\n에 \n저장합니다. \nD. AWS Key Management Service(AWS KMS) 고객 관리형 키를 생성합니다. EC2 역할이 \n암호화 작업에 KMS 키를 사용하도록 허용합니다. 암호화된 데이터를 Amazon Elastic Block \nStore(Amazon EBS) 볼륨에 저장합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/85186-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명:・ \n고가용성 저장소 = S3. B,C 둘 중 하나가 답. \nLambda 보다 KMS 가 암호화 및 해독에 적합. 정답은 C.", "answer_choice": "C"}, "101": {"q_num": 101, "question": "솔루션 설계자는 퍼블릭 및 프라이빗 서브넷이 있는 VPC 를 설계하고 있습니다. VPC 와 \n서브넷은 IPv4 CIDR 블록을 사용합니다. 고가용성을 위해 세 개의 가용 영역(AZ) 각각에 \n하나의 퍼블릭 서브넷과 하나의 프라이빗 서브넷이 있습니다. 인터넷 게이트웨이는 퍼블릭 \n서브넷에 대한 인터넷 액세스를 제공하는 데 사용됩니다. 프라이빗 서브넷은 Amazon EC2 \n인스턴스가 소프트웨어 업데이트를 다운로드할 수 있도록 인터넷에 액세스할 수 있어야 \n합니다. \n솔루션 설계자는 프라이빗 서브넷에 대한 인터넷 액세스를 활성화하기 위해 무엇을 해야 \n합니까? \nA. 각 AZ 의 각 퍼블릭 서브넷에 대해 하나씩 3 개의 NAT 게이트웨이를 생성합니다. 비 \nVPC 트래픽을 해당 AZ 의 NAT 게이트웨이로 전달하는 각 AZ 에 대한 프라이빗 라우팅 \n테이블을 생성합니다. \nB. 각 AZ 의 프라이빗 서브넷마다 하나씩 3 개의 NAT 인스턴스를 생성합니다. 비 VPC \n트래픽을 해당 AZ 의 NAT 인스턴스로 전달하는 각 AZ 에 대한 프라이빗 라우팅 테이블을 \n생성합니다. \nC. 프라이빗 서브넷 중 하나에 두 번째 인터넷 게이트웨이를 생성합니다. VPC 가 아닌 \n트래픽을 프라이빗 인터넷 게이트웨이로 전달하는 프라이빗 서브넷의 라우팅 테이블을 \n업데이트합니다. \nD. 퍼블릭 서브넷 중 하나에 송신 전용 인터넷 게이트웨이를 생성합니다. VPC 가 아닌 \n트래픽을 외부 전용 인터넷 게이트웨이로 전달하는 프라이빗 서브넷에 대한 라우팅 \n테이블을 업데이트합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/86019-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n프라이빗 서브넷에 있는 인스턴스가 외부 인터넷과 통신하기 위해선 NAT 게이트웨이가 \n필요. \nA(O) : 각 가용 영역의 퍼블릭 서브넷마다 NAT 게이트웨이를 두어야 함. 프라이빗 서브넷의 \n인스턴스는 퍼블릭 NAT 게이트웨이를 통해 인터넷에 연결. 퍼블릭 서브넷에서 퍼블릭 NAT \n게이트웨이를 생성하고 생성 시 탄력적 IP 주소를 NAT 게이트웨이와 연결해야 합니다. \n여러 가용 영역에 리소스가 있고 NAT 게이트웨이 하나를 공유하는 경우, NAT 게이트웨이의 \n가용 영역이 다운되면 다른 가용 영역의 리소스도 인터넷에 액세스할 수 없게 됩니다. 가용 \n영역과 독립적인 아키텍처를 만들려면 각 가용 영역에 NAT 게이트웨이를 만들고 리소스가 \n\n동일한 가용 영역의 NAT 게이트웨이를 사용하도록 라우팅을 구성합니다. \nhttps://docs.aws.amazon.com/ko_kr/vpc/latest/userguide/vpc-nat-gateway.html \nB(X) : NAT 인스턴스는 더 이상 권장되지 않음 \nC(X) : 인터넷 게이트웨이는 프라이빗 서브넷과 외부 인터넷을 연결할 수 없음. \nD(X) : NAT 게이트웨이가 필요한 상황임.  \n \n참고: \nhttps://docs.aws.amazon.com/ko_kr/vpc/latest/userguide/vpc-nat-comparison.html", "answer_choice": "A"}, "102": {"q_num": 102, "question": "회사에서 온프레미스 데이터 센터를 AWS 로 마이그레이션하려고 합니다. 데이터 센터는 \nNFS 기반 파일 시스템에 데이터를 저장하는 SFTP 서버를 호스팅합니다. 서버에는 \n전송해야 하는 200GB 의 데이터가 있습니다. 서버는 Amazon Elastic File System(Amazon \nEFS) 파일 시스템을 사용하는 Amazon EC2 인스턴스에서 호스팅되어야 합니다. \n솔루션 설계자는 이 작업을 자동화하기 위해 어떤 단계 조합을 취해야 합니까? (2 개를 \n선택하세요.) \nA. EFS 파일 시스템과 동일한 가용 영역에서 EC2 인스턴스를 시작합니다. \nB. 온프레미스 데이터 센터에 AWS DataSync 에이전트를 설치합니다. \nC. 데이터에 대한 EC2 인스턴스에 보조 Amazon Elastic Block Store(Amazon EBS) 볼륨을 \n생성합니다. \nD. 수동으로 운영 체제 복사 명령을 사용하여 데이터를 EC2 인스턴스로 푸시합니다. \nE. AWS DataSync 를 사용하여 온프레미스 SFTP 서버에 적합한 위치 구성을 생성합니다.", "answer_block": "Answer: A, B \nhttps://www.examtopics.com/discussions/amazon/view/85814-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nA(O) \nEFS 파일 시스템과 동일한 가용 영역으로 EC2 인스턴스 시작하는건 문제 없어보입니다.  \nB(O) : DataSync Agent 는 AWS 로 전송할 떄 필요 \n에이전트 는 AWS DataSync\n가 스토리지 시스템에서 읽거나 쓰는 데 사용하는 가상 \n머신(VM) 또는 Amazon EC2 인스턴스입니다 . 에이전트는 온프레미스 스토리지에서 \nAWS 로 데이터를 복사할 때 일반적으로 사용됩니다. \nhttps://docs.aws.amazon.com/datasync/latest/userguide/working-with-agents.html \nDataSync 는 DataSync 위치와 같이 사용됨 \n\n대부분의 워크로드의 경우 각 자체 관리 위치에 대해 하나의 AWS DataSync 에이전트를 \n사용하는 것이 좋습니다. \nhttps://docs.aws.amazon.com/datasync/latest/userguide/multiple-agents.html \nC(X) : EBS 가 아니라 EFS 가 NFS 지원. \nD(X) : 수동으로 할 필요가 없이 DataSync 같은 대안을 사용하면 됨. \nE(X) : 온프레미스 SFTP 에 좀 더 적합한 건 DataSync 보다 Transfer Family 가 더 \n적합해보입니다.", "answer_choice": "A"}, "103": {"q_num": 103, "question": "회사에 매일 같은 시간에 실행되는 AWS Glue 추출, 변환 및 로드(ETL) 작업이 있습니다. \n작업은 Amazon S3 버킷에 있는 XML 데이터를 처리합니다. 매일 새로운 데이터가 S3 \n버킷에 추가됩니다. 솔루션 설계자는 AWS Glue 가 각 실행 중에 모든 데이터를 처리하고 \n있음을 알아차렸습니다. \n솔루션 아키텍트는 AWS Glue 가 오래된 데이터를 재처리하지 못하도록 하려면 어떻게 해야 \n합니까? \nA. 작업 북마크를 사용하도록 작업을 편집합니다. \nB. 데이터가 처리된 후 데이터를 삭제하도록 작업을 편집합니다. \nC. NumberOfWorkers 필드를 1 로 설정하여 작업을 편집합니다. \nD. FindMatches 기계 학습(ML) 변환을 사용합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/85781-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \n이것이 북마크의 목적입니다. \"AWS Glue 는 작업 실행의 상태 정보를 유지하여 ETL 작업의 \n이전 실행 중에 이미 처리된 데이터를 추적합니다. 이 지속된 상태 정보를 작업 북마크라고 \n합니다. 작업 북마크는 AWS Glue 가 유지 관리하는 데 도움이 됩니다. 상태 정보를 \n제공하고 오래된 데이터의 재처리를 방지합니다.\" \nhttps://docs.aws.amazon.com/glue/latest/dg/monitorcontinuations.html \n \n설명2: \nA(O) : AWS Glue 는 작업 실행의 상태 정보를 유지하여 이전에 ETL 작업을 실행할 때 이미 \n처리된 데이터를 추적합니다. 이와 같은 지속 상태 정보를 작업 북마크라고 합니다.  \nhttps://docs.aws.amazon.com/ko_kr/glue/latest/dg/monitor-continuations.html \nB(X) : 처리한 데이터를 어디에 쓸 줄 알고 삭제하는지...? \n\nC(X) : \"\"NumberOfWorkers – 숫자(정수) : 작업이 실행될 때 할당되는 정의된 workerType 의 \n작업자 수입니다. \nhttps://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-jobs-job.html \nD(X) : 기계 변환 학습은 전혀 관계 없음.", "answer_choice": "A"}, "104": {"q_num": 104, "question": "솔루션 설계자는 웹사이트를 위한 고가용성 인프라를 설계해야 합니다. 웹 사이트는 \nAmazon EC2 인스턴스에서 실행되는 Windows 웹 서버에 의해 구동됩니다. 솔루션 \n설계자는 수천 개의 IP 주소에서 시작되는 대규모 DDoS 공격을 완화할 수 있는 솔루션을 \n구현해야 합니다. 다운타임은 웹사이트에 허용되지 않습니다. \n솔루션 설계자는 이러한 공격으로부터 웹사이트를 보호하기 위해 어떤 조치를 취해야 \n합니까? (2 개를 선택하세요.) \nA. AWS Shield Advanced 를 사용하여 DDoS 공격을 차단하십시오. \nB. 공격자를 자동으로 차단하도록 Amazon GuardDuty 를 구성합니다. \nC. 정적 및 동적 콘텐츠 모두에 Amazon CloudFront\n를 사용하도록 웹 사이트를 \n구성합니다. \nD. AWS Lambda 함수를 사용하여 VPC 네트워크 ACL 에 공격자 IP 주소를 자동으로 \n추가합니다. \nE. 80% CPU 사용률로 설정된 대상 추적 조정 정책과 함께 Auto Scaling 그룹의 EC2 스팟 \n인스턴스를 사용합니다.", "answer_block": "Answer: A, C \nhttps://www.examtopics.com/discussions/amazon/view/85342-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nA(O) : AWS Shield Advanced 보호는 네트워크 트래픽에 대한 상시 작동, 흐름 기반 \n모니터링과 적극적인 애플리케이션 모니터링을 통해 의심되는 DDoS 공격에 대한 거의 \n실시간 알림을 제공합니다. 또한 AWS Shield Advanced 는 공격을 자동으로 완화하기 위해 \n첨단 공격 완화 및 라우팅 기법을 적용합니다. https://aws.amazon.com/ko/shield/faqs/ \nB(X) : GuardDuty 는 AWS 계정 보호 서비스. \nAmazon GuardDuty 는 AWS 계정 및 워크로드에서 악의적 활동을 모니터링하고 상세한 \n보안 결과를 제공하여 가시성 및 해결을 촉진하는 위협 탐지 서비스입니다. \nhttps://aws.amazon.com/ko/guardduty/ \nC(O) : CloudFront 로도 DDoS 에 대처 가능. CloudFront 는 정적 및 동적 콘텐츠 모두에 \n작동. 또한 Amazon CloudFront, AWS Global Accelerator 및 Amazon Route 53 과 같은 엣지 \n\n로케이션에서 작동하는 AWS 서비스를 활용하여 알려진 모든 인프라 계층 공격에 대한 \n포괄적인 가용성 보호를 구축할 수 있습니다. 이러한 서비스는 AWS 글로벌 엣지 \n네트워크의 일부이며 전 세계에 분산된 엣지 로케이션에서 모든 유형의 애플리케이션 \n트래픽을 처리할 때 애플리케이션의 DDoS 복원력을 향상할 수 있습니다. \nhttps://d1.awsstatic.com/whitepapers/Security/DDoS_White_Paper.pdf \n일반적으로 이미지나 동영상 파일 같은 정적 콘텐츠 전송을 위해서 Amazon CloudFront 를 \n많이 활용하고 있지만...TTL 을 0\n으로 설정하여 매번 원본 저장소에 접속하여 동적 \n콘텐츠를 제공하더라도, CloudFront 를 프록시로 사용함으로써 전송 성능을 향상 시킬 수 \n있습니다. \nhttps://aws.amazon.com/ko/blogs/korea/how-to-improve-dynamic-contents-delievery-\nusing-amazon-cloudfront/ \nD(X) : DDoS 는 수많은 좀비 PC 를 동원하는데, 그런 PC 들의 IP 를 일일히 차단하여 막기는 \n비효율적. \nE(X) : DDoS 로 발생하는 대규모 트래픽은 Auto Scaling 으로 막을 수 있는 스케일이 아님.", "answer_choice": "A"}, "105": {"q_num": 105, "question": "회사에서 새로운 서버리스 워크로드를 배포할 준비를 하고 있습니다. 솔루션 설계자는 최소 \n권한 원칙을 사용하여 AWS Lambda 함수를 실행하는 데 사용할 권한을 구성해야 합니다. \nAmazon EventBridge(Amazon CloudWatch Events) 규칙이 함수를 호출합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. lambda:InvokeFunction 을 작업으로, *를 보안 주체로 사용하여 함수에 실행 역할을 \n추가합니다. \nB. \n작업으로 \nlambda:InvokeFunction\n을 \n사용하고 \n보안 \n주체로 \nService: \nlambda.amazonaws.com 을 사용하여 함수에 실행 역할을 추가합니다. \nC. 작업으로 lambda:*를 사용하고 보안 주체로 Service: events.amazonaws.com\n을 \n사용하여 리소스 기반 정책을 함수에 추가합니다. \nD. lambda:InvokeFunction 을 작업으로, Service: events.amazonaws.com 을 보안 주체로 \n사용하여 리소스 기반 정책을 함수에 추가합니다.", "answer_block": "Answer: D  \nhttps://www.examtopics.com/discussions/amazon/view/85816-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n・Lambda\n의 전체 기능이 아닌 lambda 함수 호출 기능(lambda:InvokeFunction)만 \n사용하도록 하고, 전체 보안 주체(*)가 아닌 아마존 이벤트 서비스만 보안 주체로 \n\n설정하여야 하므로 B,D 둘 중 하나가 답. \n・서버리스 워크로드를 '배포'한다고 했으므로 다른 계정에서도 쓸 수 있는 D 가 유리함. \n리소스 기반 정책은 해당 리소스에 액세스할 수 있는 사용자(보안 주체)를 지정합니다. \n리소스 기반 정책을 사용한 교차 계정 액세스는 역할을 사용한 교차 계정 액세스에 비해 몇 \n가지 이점이 있습니다. 리소스 기반 정책을 통해 액세스한 리소스로 인해 보안 주체는 \n여전히 신뢰할 수 있는 계정에서 작업을 할 수 있고, 역할 권한을 수신하기 위해 자신의 \n권한을 포기할 필요가 없습니다. 즉, 보안 주체는 신뢰하는 계정의 리소스에 액세스하는 \n동시에 신뢰할 수 있는 계정의 리소스에 계속 액세스할 수 있습니다. 다른 계정의 공유 \n리소스로 정보를 복사하거나 공유 리소스의 정보를 복사하는 등의 작업에서 이는 특히 \n유용합니다. \nhttps://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/id_roles_compare-resource-p\nolicies.html \nhttps://docs.aws.amazon.com/ko_kr/eventbridge/latest/userguide/eb-use-resource-base\nd.html#lambda-per", "answer_choice": "D"}, "106": {"q_num": 106, "question": "회사에서 Amazon S3 에 기밀 데이터를 저장할 준비를 하고 있습니다. 규정 준수를 위해 \n미사용 데이터를 암호화해야 합니다. 암호화 키 사용은 감사 목적으로 기록되어야 합니다. \n키는 매년 순환해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족하고 운영상 가장 효율적입니까? \nA. 고객 제공 키를 사용한 서버 측 암호화(SSE-C) \nB. Amazon S3 관리형 키를 사용한 서버 측 암호화(SSE-S3) \nC. 수동 교체가 있는 AWS KMS 키(SSE-KMS)를 사용한 서버 측 암호화 \nD. 자동 교체 기능이 있는 AWS KMS 키(SSE-KMS)를 사용한 서버 측 암호화", "answer_block": "Answer: D  \nhttps://www.examtopics.com/discussions/amazon/view/85817-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \n감사 목적으로 기록되어야 함 = AWS KMS. 따라서 C,D 둘 중 하나가 정답. \n매년 키를 교체(rotate)해야하므로 운영 상 효율적인 방식은 수동이 아닌 자동 방식. 정답은 \nD. \n \n설명2: \nhttps://docs.aws.amazon.com/kms/latest/developerguide/rotate-keys.html \n\n고객 관리형 키에 대해 자동 키 교체를 활성화하면 AWS KMS 는 매년 KMS 키에 대한 \n새로운 암호화 자료를 생성합니다. 또한 AWS KMS\n는 KMS 키가 암호화한 데이터를 \n해독하는 데 사용할 수 있도록 KMS 키의 이전 암호화 자료를 영구적으로 저장합니다. AWS \nKMS 의 키 순환은 투명하고 사용하기 쉽게 설계된 암호화 모범 사례입니다. AWS KMS 는 \n고객 관리형 CMK 에 대해서만 선택적 자동 키 교체를 지원합니다. 키 순환을 활성화 및 \n비활성화합니다. 자동 키 교체는 고객 관리형 CMK 에서 기본적으로 비활성화됩니다. 키 \n교체를 활성화(또는 재활성화)하면 AWS KMS 는 활성화 날짜로부터 365 일 후 그리고 이후 \n365 일마다 CMK 를 자동으로 교체합니다.", "answer_choice": "D"}, "107": {"q_num": 107, "question": "자전거 공유 회사는 피크 운영 시간 동안 자전거의 위치를 추적하기 위해 다층 아키텍처를 \n개발하고 있습니다. 회사는 기존 분석 플랫폼에서 이러한 데이터 포인트를 사용하려고 \n합니다. 솔루션 설계자는 이 아키텍처를 지원하기 위해 가장 실행 가능한 다중 계층 옵션을 \n결정해야 합니다. 데이터 포인트는 REST API 에서 액세스할 수 있어야 합니다. \n위치 데이터 저장 및 검색에 대한 이러한 요구 사항을 충족하는 작업은 무엇입니까? \nA. Amazon S3 와 함께 Amazon Athena 를 사용하십시오. \nB. AWS Lambda 와 함께 Amazon API Gateway 를 사용합니다. \nC. Amazon Redshift 와 함께 Amazon QuickSight 를 사용합니다. \nD. Amazon Kinesis Data Analytics 와 함께 Amazon API Gateway 를 사용합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/85212-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nA(X) : 기존 분석 플랫폼을 사용하려고 한다고 했으므로 분석 기능이 있는 Athena 제외. \nAmazon Athena 는 표준 SQL 을 사용해 Amazon S3 에 저장된 데이터를 간편하게 분석할 수 \n있는 대화식 쿼리 서비스입니다.  \nhttps://aws.amazon.com/ko/athena/faqs/ \nB(O) : Lambda 는 512MB 의 임시 스토리지를 가지고 있기도 하고, S3 에 데이터를 저장할 \n수도 있으며, 지문에서는 [이러한 데이터 포인트를 사용하려고 합니다.] 라고 언급함과 \n동시에 [다중 계층 옵션]이라고 했으므로 Lambda + API Gateway 조합인 B 가 정답에 \n가깝다고 봄. \n・ 512MB 에서 10,240MB 사이에서 1MB 단위로 자체 임시 스토리지로 각 Lambda 함수를 \n구성할 수 있습니다. 임시 스토리지는 각 함수의 /tmp 디렉터리에서 사용할 수 있습니다. \n각 함수는 추가 비용 없이 512MB 의 스토리지에 액세스할 수 있습니다.  \n\nhttps://aws.amazon.com/ko/lambda/faqs/ \n・ Lambda 는 웹 애플리케이션 개발자의 요구 사항을 충족하는 포괄적인 스토리지 옵션을 \n제공합니다. 여기에는 Amazon S3 및 Amazon EFS 와 같은 다른 AWS 서비스가 \n포함됩니다 . 임시 저장소 또는 Lambda 계층과 같은 기본 저장소 옵션도 사용할 수 \n있습니다. \nhttps://aws.amazon.com/ko/blogs/compute/choosing-between-aws-lambda-data-stora\nge-options-in-web-apps/ \n・ Lambda 계층은 Lambda 함수와 함께 사용할 수 있는 라이브러리 및 기타 종속성을 \n패키징하는 편리한 방법을 제공합니다. \nhttps://docs.aws.amazon.com/ko_kr/lambda/latest/dg/configuration-layers.html \nC(X) : RedShift 는 Athena 에 비해 가격보다 성능이 더 우선시 될 때 사용. 위치 정보 \n서비스는 Athena 대신에 RedShift 를 사용해야할 정도의 서비스가 아님. \nAmazon Athena 와 Amazon Redshift 는 모두 서버리스 서비스이지만 그 필요와 사용 사례가 \n서로 다릅니다. 어떤 규모에서든 높은 성능을 요하는 복잡한 BI 및 분석 워크로드를 위해 \n최고의 가격 대비 성능이 필요하다면 Amazon Redshift 와 같은 데이터 웨어하우스가 최선의 \n선택입니다.\"\"(https://aws.amazon.com/ko/redshift/faqs/) \nD(X) : 기존 분석 플랫폼을 사용하려고 한다고 했으므로 분석 서비스인 Amazon Kinesis \nData Analytics 는 제외. \n \n설명2: \nhttps://aws.amazon.com/solutions/implementations/aws-streaming-data-solution-for-a\nmazonkinesis/", "answer_choice": "B"}, "108": {"q_num": 108, "question": "한 회사에 Amazon RDS 의 데이터베이스에 목록을 저장하는 자동차 판매 웹사이트가 \n있습니다. 자동차가 판매되면 웹사이트에서 목록을 제거해야 하고 데이터를 여러 대상 \n시스템으로 보내야 합니다. \n솔루션 아키텍트는 어떤 디자인을 추천해야 할까요? \nA. Amazon RDS 의 데이터베이스가 업데이트되어 대상이 소비할 Amazon Simple Queue \nService(Amazon SQS) 대기열로 정보를 보내도록 업데이트될 때 트리거되는 AWS Lambda \n함수를 생성합니다. \nB. Amazon RDS 의 데이터베이스가 대상이 사용할 Amazon Simple Queue Service(Amazon \nSQS) FIFO 대기열로 정보를 보내도록 업데이트될 때 트리거되는 AWS Lambda 함수를 \n생성합니다. \nC. RDS 이벤트 알림을 구독하고 여러 Amazon Simple Notification Service(Amazon SNS) \n\n주제로 팬아웃된 Amazon Simple Queue Service(Amazon SQS) 대기열을 보냅니다. AWS \nLambda 함수를 사용하여 대상을 업데이트합니다. \nD. RDS 이벤트 알림을 구독하고 Amazon Simple Notification Service(Amazon SNS) 주제를 \n여러 Amazon Simple Queue Service(Amazon SQS) 대기열로 보냅니다. AWS Lambda \n함수를 사용하여 대상을 업데이트합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/85427-exam-aws-certified-solut\nions-architect-associate-saa-c03/", "answer_choice": "D"}, "109": {"q_num": 109, "question": "회사는 Amazon S3 에 데이터를 저장해야 하며 데이터가 변경되지 않도록 해야 합니다. \n회사는 Amazon S3 에 업로드된 새 객체가 회사가 객체를 수정하기로 결정할 때까지 \n일정하지 않은 시간 동안 변경할 수 없는 상태로 유지되기를 원합니다. 회사 AWS 계정의 \n특정 사용자만 객체를 삭제할 수 있습니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. S3 Glacier 볼트를 생성합니다. WORM(Write-Once, Read-Many) 볼트 잠금 정책을 \n개체에 적용합니다. \nB. S3 객체 잠금이 활성화된 S3 버킷을 생성합니다. 버전 관리를 활성화합니다. 보존 \n기간을 100 년으로 설정합니다. 거버넌스 모드를 새 객체에 대한 S3 버킷의 기본 보존 \n모드로 사용합니다. \nC. S3 버킷을 생성합니다. AWS CloudTrail 을 사용하여 객체를 수정하는 모든 S3 API \n이벤트를 추적합니다. 통지 시 회사가 보유한 모든 백업 버전에서 수정된 개체를 \n복원합니다. \nD. S3 객체 잠금이 활성화된 S3 버킷을 생성합니다. 버전 관리를 활성화합니다. 개체에 \n법적 \n보존을 \n추가합니다. \n객체를 \n삭제해야 \n하는 \n사용자의 \nIAM \n정책에 \ns3:PutObjectLegalHold 권한을 추가합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/85634-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nA(X) : S3 에 저장한다고 했지 S3 Glacier 같은 콜드 스토리지에 저장한다고 한 적 없음. \nB(X) : 일정하지 않은 시간 동안이라고 지문에서 언급했는데, 보존 기간을 설정해뒀으므로 \n오답. \nC(X) : 일단 일이 벌어지고 나서 수습하는 방식인데다가, 변경된 객체마다 일일히 \n\nCloudTrail 이 작동하므로 운영 오버헤드와 비용이 증가할 우려가 있음. \nD(O) : 객체 잠금 법적 보존 작업을 사용하면 객체 버전에 법적 보전을 적용할 수 있습니다. \n보관 기간 설정과 마찬가지로 법적 보존을 사용하면 객체 버전을 덮어쓰거나 삭제할 수 \n없습니다. 그러나 법적 보존에는 연결된 보관 기간이 없고, 제거될 때까지 유효합니다. S3 \n배치 작업은 매니페스트의 키를 처리하기 전에 S3 버킷에서 객체 잠금이 활성화되어 \n있는지 확인합니다. 객체 작업 및 버킷 수준 유효성 검사를 수행하려면 S3 배치 작업이 \n사용자를 대신하여 S3 객체 잠금을 호출할 수 있도록 IAM 역할의 s3:PutObjectLegalHold \n및 s3:GetBucketObjectLockConfiguration 가 필요합니다. \nhttps://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/batch-ops-legal-hold.h\ntml \n \n설명2: \nALB 를 오리진으로 사용할 수 있음 \n원본이 하나 이상의 Amazon EC2 인스턴스에서 호스트되는 하나 이상의 HTTP 서버(웹 \n서버)인 경우 Application Load Balancer 를 사용하여 인스턴스에 트래픽을 분산할 수 \n있습니다. Application Load Balancer 를 CloudFront 의 원본으로 사용하는 방법에 대한 \n자세한 내용은 \nhttps://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/batch-ops-legal-hold.h\ntml", "answer_choice": "D"}, "110": {"q_num": 110, "question": "소셜 미디어 회사는 사용자가 웹사이트에 이미지를 업로드할 수 있도록 합니다. 웹 \n사이트는 Amazon EC2 인스턴스에서 실행됩니다. 업로드 요청 중에 웹 사이트는 이미지의 \n크기를 표준 크기로 조정하고 크기가 조정된 이미지를 Amazon S3 에 저장합니다. 사용자가 \n웹 사이트에 대한 느린 업로드 요청을 경험하고 있습니다. \n회사는 애플리케이션 내 커플링을 줄이고 웹사이트 성능을 개선해야 합니다. 솔루션 \n설계자는 이미지 업로드를 위한 운영상 가장 효율적인 프로세스를 설계해야 합니다. \n이러한 요구 사항을 충족하기 위해 솔루션 설계자가 취해야 하는 조치의 조합은 무엇입니까? \n(2 개를 선택하세요.) \nA. S3 Glacier 에 이미지를 업로드하도록 애플리케이션을 구성합니다. \nB. 원본 이미지를 Amazon S3 에 업로드하도록 웹 서버를 구성합니다. \nC. 미리 서명된 URL 을 사용하여 각 사용자의 브라우저에서 Amazon S3 로 이미지를 직접 \n업로드하도록 애플리케이션 구성 \nD. 이미지가 업로드될 때 AWS Lambda 함수를 호출하도록 S3 이벤트 알림을 구성합니다. \n기능을 사용하여 이미지 크기를 조정합니다. \n\nE. 업로드된 이미지의 크기를 조정하기 위해 일정에 따라 AWS Lambda 함수를 호출하는 \nAmazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.", "answer_block": "Answer: C, D \nhttps://www.examtopics.com/discussions/amazon/view/86471-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nAmazon S3 는 웹 어디에서나 원하는 양의 데이터를 저장하고 검색할 수 있는 확장성과 \n내구성이 뛰어난 객체 스토리지 서비스입니다. 사용자는 미리 서명된 URL 을 사용하여 각 \n사용자의 브라우저에서 Amazon S3\n으로 이미지를 직접 업로드하도록 애플리케이션을 \n구성할 수 있습니다. 미리 서명된 URL 은 제한된 시간 동안 객체 업로드와 같은 특정 \n작업을 통해 S3 버킷의 객체에 대한 액세스를 제공하는 URL 입니다. 사용자는 AWS SDK \n또는 AWS CLI 를 사용하여 프로그래밍 방식으로 미리 서명된 URL 을 생성할 수 있습니다. \n미리 서명된 URL 을 사용하면 사용자는 이미지를 웹 서버에 먼저 보낼 필요가 없으므로 \n애플리케이션 내 결합을 줄이고 웹 사이트 성능을 향상시킬 수 있습니다. \nAWS Lambda 는 이벤트에 대한 응답으로 코드를 실행하고 기본 컴퓨팅 리소스를 자동으로 \n관리하는 서버리스 컴퓨팅 서비스입니다. 사용자는 이미지가 업로드될 때 AWS Lambda \n함수를 호출하도록 S3 이벤트 알림을 구성할 수 있습니다. S3 이벤트 알림은 객체 생성이나 \n삭제 등 S3 버킷에서 특정 이벤트가 발생할 때 사용자가 알림을 받을 수 있도록 하는 \n기능입니다. 사용자는 이미지 크기를 조정하고 이를 동일하거나 다른 S3 버킷에 다시 \n저장하는 Lambda 함수를 호출하도록 S3 이벤트 알림을 구성할 수 있습니다. 이러한 \n방식으로 사용자는 이미지 크기 조정 작업을 웹 서버에서 Lambda\n로 오프로드할 수 \n있습니다.", "answer_choice": "C"}, "111": {"q_num": 111, "question": "한 회사는 최근에 메시지 처리 시스템을 AWS 로 마이그레이션했습니다. 시스템은 Amazon \nEC2 인스턴스에서 실행되는 ActiveMQ 대기열로 메시지를 수신합니다. 메시지는 Amazon \nEC2\n에서 실행되는 소비자 애플리케이션에 의해 처리됩니다. 소비자 애플리케이션은 \n메시지를 처리하고 결과를 Amazon EC2 에서 실행되는 MySQL 데이터베이스에 씁니다. \n회사는 이 애플리케이션이 낮은 운영 복잡성으로 고가용성을 갖기를 원합니다. \n가장 높은 가용성을 제공하는 아키텍처는 무엇입니까? \nA. 다른 가용 영역에 두 번째 ActiveMQ 서버를 추가합니다. 다른 가용 영역에 소비자 EC2 \n인스턴스를 추가합니다. MySQL 데이터베이스를 다른 가용 영역에 복제합니다. \nB. 두 가용 영역에 구성된 활성/대기 브로커와 함께 Amazon MQ 를 사용합니다. 다른 가용 \n영역에 소비자 EC2 인스턴스를 추가합니다. MySQL 데이터베이스를 다른 가용 영역에 \n\n복제합니다. \nC. 두 가용 영역에 구성된 활성/대기 브로커와 함께 Amazon MQ 를 사용합니다. 다른 가용 \n영역에 소비자 EC2 인스턴스를 추가합니다. 다중 AZ 가 활성화된 MySQL 용 Amazon \nRDS 를 사용합니다. \nD. 두 가용 영역에 구성된 활성/대기 브로커와 함께 Amazon MQ 를 사용합니다. 두 가용 \n영역에 걸쳐 소비자 EC2 인스턴스에 대한 Auto Scaling 그룹을 추가합니다. 다중 AZ 가 \n활성화된 MySQL 용 Amazon RDS 를 사용합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/85910-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nA(X) : 데이터베이스를 복제하는 것은 시간이 매우 걸리는 일임. 고가용성을 위해서라면 \n다중 AZ 를 사용하는 것이 좋음. \nB(X) : A 와 마찬가지 이유로 오답. \nC(X) : D 가 더 좋음. \nD(O) : 평소에는 Standby 브로커 인스턴스에 낮은 트래픽 기준으로 AWS 리소스를 \n사용하여 비용을 절감하다가 Active 브로커 인스턴스가 다운되어 Standby 브로커 인스턴스 \n쪽으로 트래픽이 몰려오면 Auto Scaling 을 통해 대처. \n일반적으로 한 번에 하나의 브로커 인스턴스만 활성 상태이고, 다른 브로커 인스턴스는 \n대기 상태입니다. 브로커 인스턴스 중 하나가 제대로 작동하지 않거나 유지 관리 중이면 \nAmazon MQ 가 비활성 인스턴스를 서비스 중지하는 데 잠깐 시간이 걸립니다. 그런 다음 \n정상 대기 인스턴스가 활성화되고 들어오는 통신을 수신하기 시작할 수 있습니다. \nhttps://docs.aws.amazon.com/ko_kr/amazon-mq/latest/developer-guide/active-standby\n-broker-deployment.html \n \n설명2: \nAmazon S3 는 확장성이 뛰어나고 내구성이 뛰어난 객체 스토리지 서비스로, 웹 어디에서나 \n원하는 양의 데이터를 저장하고 검색할 수 있습니다. 사용자는 미리 서명된 URL\n을 \n사용하여 각 사용자의 브라우저에서 Amazon S3\n로 직접 이미지를 업로드하도록 \n애플리케이션을 구성할 수 있습니다. 미리 서명된 URL 은 제한된 시간 동안 특정 작업(예: \n객체 업로드)으로 S3 버킷의 객체에 대한 액세스 권한을 부여하는 URL 입니다. 사용자는 \nAWS SDK 또는 AWS CLI 를 사용하여 프로그래밍 방식으로 미리 서명된 URL 을 생성할 수 \n있습니다. 미리 서명된 URL 을 사용하면 이미지를 웹 서버에 먼저 보낼 필요가 없으므로 \n사용자는 애플리케이션 내에서 결합을 줄이고 웹 사이트 성능을 향상시킬 수 있습니다. \nAWS Lambda 는 이벤트에 대한 응답으로 코드를 실행하고 기본 컴퓨팅 리소스를 자동으로 \n\n관리하는 서버리스 컴퓨팅 서비스입니다. 사용자는 이미지가 업로드될 때 AWS Lambda \n함수를 호출하도록 S3 이벤트 알림을 구성할 수 있습니다. S3 이벤트 알림은 객체 생성 \n또는 삭제와 같은 S3 버킷에서 특정 이벤트가 발생할 때 사용자가 알림을 받을 수 있도록 \n하는 기능입니다. 사용자는 이미지 크기를 조정하고 동일한 S3 버킷 또는 다른 S3 버킷에 \n다시 저장하는 Lambda 함수를 호출하도록 S3 이벤트 알림을 구성할 수 있습니다. 이러한 \n방식으로 사용자는 웹 서버에서 Lambda\n로 이미지 크기 조정 작업을 오프로드할 수 \n있습니다.", "answer_choice": "D"}, "112": {"q_num": 112, "question": "회사는 \n들어오는 \n요청을 \n처리하는 \n온프레미스 \n서버 \n집합에서 \n컨테이너화된 \n웹 \n애플리케이션을 호스팅합니다. 요청 수가 빠르게 증가하고 있습니다. 온프레미스 서버는 \n증가된 요청 수를 처리할 수 없습니다. 회사는 최소한의 코드 변경과 최소한의 개발 \n노력으로 애플리케이션을 AWS 로 옮기기를 원합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Amazon Elastic Container Service(Amazon ECS)에서 AWS Fargate 를 사용하여 Service \nAuto Scaling\n으로 컨테이너화된 웹 애플리케이션을 실행합니다. Application Load \nBalancer 를 사용하여 수신 요청을 배포합니다. \nB. 두 개의 Amazon EC2 인스턴스를 사용하여 컨테이너화된 웹 애플리케이션을 \n호스팅합니다. Application Load Balancer 를 사용하여 수신 요청을 배포합니다. \nC. 지원되는 언어 중 하나를 사용하는 새 코드와 함께 AWS Lambda 를 사용합니다. 로드를 \n지원하기 위해 여러 Lambda 함수를 생성합니다. Amazon API Gateway 를 Lambda 함수에 \n대한 진입점으로 사용합니다. \nD. AWS ParallelCluster 와 같은 고성능 컴퓨팅(HPC) 솔루션을 사용하여 적절한 규모로 \n들어오는 요청을 처리할 수 있는 HPC 클러스터를 설정합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/85913-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nAWS Fargate는 사용자가 Amazon EC2 인스턴스의 서버 또는 클러스터를 관리할 필요 없이 \n컨테이너를 실행할 수 있게 해주는 서버리스 컴퓨팅 엔진입니다. 사용자는 Amazon Elastic \nContainer Service(Amazon ECS)에서 AWS Fargate 를 사용하여 Service Auto Scaling 으로 \n컨테이너화된 웹 애플리케이션을 실행할 수 있습니다. \nAmazon ECS\n는 Docker\n와 Kubernetes\n를 모두 지원하는 완전관리형 컨테이너 \n오케스트레이션 서비스입니다. Service Auto Scaling 은 사용자가 CPU 사용률 또는 요청 \n\n수와 같은 CloudWatch 지표를 기반으로 ECS 서비스에서 원하는 작업 수를 조정할 수 \n있는 기능입니다. 사용자는 Amazon ECS 에서 AWS Fargate 를 사용하여 애플리케이션을 \n컨테이너에 패키징하고 CPU 및 메모리 요구 사항을 지정하기만 하면 되므로 최소한의 \n코드 변경과 최소한의 개발 노력으로 애플리케이션을 AWS 로 마이그레이션할 수 있습니다. \n사용자는 Application Load Balancer 를 사용하여 수신 요청을 분산할 수도 있습니다. \nApplication Load Balancer 는 애플리케이션 계층에서 작동하고 요청 내용에 따라 대상으로 \n트래픽을 라우팅하는 로드 밸런서입니다. 사용자는 ECS 작업을 Application Load \nBalancer 의 대상으로 등록하고 경로 또는 호스트 헤더를 기반으로 요청을 다른 대상 \n그룹으로 라우팅하도록 리스너 규칙을 구성할 수 있습니다. 사용자는 Application Load \nBalancer 를 사용하여 웹 애플리케이션의 가용성과 성능을 개선할 수 있습니다. \n컨테이너화된 웹 응용 프로그램이 핵심. Fargate + ECS 조합인 A 가 정답.", "answer_choice": "A"}, "113": {"q_num": 113, "question": "회사는 보고를 위해 50TB 의 데이터를 사용합니다. 회사는 이 데이터를 온프레미스에서 \nAWS 로 이동하려고 합니다. 회사 데이터 센터의 사용자 지정 응용 프로그램은 매주 데이터 \n변환 작업을 실행합니다. 회사는 데이터 이전이 완료되고 가능한 한 빨리 이전 프로세스를 \n시작해야 할 때까지 응용 프로그램을 일시 중지할 계획입니다. \n데이터 센터에는 추가 워크로드에 사용할 수 있는 네트워크 대역폭이 없습니다. 솔루션 \n설계자는 데이터를 전송하고 AWS 클라우드에서 계속 실행되도록 변환 작업을 구성해야 \n합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. AWS DataSync 를 사용하여 데이터를 이동합니다. AWS Glue 를 사용하여 사용자 지정 \n변환 작업을 생성합니다. \nB. AWS Snowcone 디바이스에 데이터를 이동하도록 주문합니다. 장치에 변환 응용 \n프로그램을 배포합니다. \nC. AWS Snowball Edge Storage Optimized 디바이스를 주문합니다. 데이터를 장치에 \n복사합니다. AWS Glue 를 사용하여 사용자 지정 변환 작업을 생성합니다. \nD. Amazon EC2 컴퓨팅이 포함된 AWS Snowball Edge Storage Optimized 디바이스를 \n주문합니다. 데이터를 장치에 복사합니다. AWS 에서 새 EC2 인스턴스를 생성하여 변환 \n애플리케이션을 실행합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/85912-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n\n추가 워크로드에 사용할 네트워크 대역폭이 없다는 게 핵심. 따라서 Snowball 디바이스가 \n필요. \nA(X) : 추가 워크로드에 사용할 네트워크 대역폭이 없다고 했으므로 DataSync는 사용 불가. \nB(X) : Snowcone 으로 50TB 는 어림도 없음. 그리고 Snowcone 을 사용해서 업로드하는 \n방법은 DataSync 를 사용하거나 AWS 로 다시 반송(?)하는 방법 뿐인데 DataSync 는 추가 \n워크로드에 사용할 네트워크 대역폭이 없어서 불가능하다고 A 에서 이미 설명했고, AWS 로 \n다시 보내는 건 시간이 너무 걸리고 번거로움. \nSnowcone 디바이스를 사용하여 디바이스를 AWS 로 배송하여 오프라인으로 또는 AWS \nDataSync 를 사용하여 온라인으로 데이터를 수집, 처리 및 AWS 클라우드로 이동할 수 \n있습니다. Snowcone 은 디바이스를 AWS 로 다시 배송하여 최대 8TB 또는 14TB 의 \n데이터를 AWS 클라우드로 전송할 수 있는 빠르고 저렴한 방법을 제공합니다. \nhttps://docs.aws.amazon.com/snowball/latest/snowcone-guide/snowcone-what-is-sno\nwcone.html \nC(O) : Snowball Edge Storage Optimized 는 수십 테라바이트(TB)~페타바이트(PB)의 고용량 \n데이터를 안전하고 신속하게 AWS\n로 전송해야 할 때 선택할 수 있는 가장 적합한 \n옵션입니다. 이 옵션은 대규모 데이터 전송 및 사전 처리 사용 사례를 위해 최대 80TB 의 \n가용 HDD 스토리지, 40 개의 vCPU, 1TB 의 SATA SSD 스토리지 및 최대 40Gb 네트워크 \n연결을 제공합니다. \nhttps://aws.amazon.com/ko/snowball/faqs/ \nAWS Glue 를 사용하면 70 개 이상의 다양한 데이터 소스를 검색하여 연결하고 중앙 집중식 \n데이터 카탈로그에서 데이터를 관리할 수 있습니다. 추출, 변환, 로드(ETL) 파이프라인을 \n시각적으로 생성, 실행, 모니터링하여 데이터 레이크에 데이터를 로드할 수 있습니다. \nhttps://docs.aws.amazon.com/ko_kr/glue/latest/dg/what-is-glue.html \nD(X) : 따로 변환 애플리케이션을 EC2 인스턴스에서 실행하므로 운영 오버헤드가 만만치 \n않음.", "answer_choice": "C"}, "114": {"q_num": 114, "question": "한 회사는 사용자가 사진을 업로드하고 이미지에 액자를 추가할 수 있는 이미지 분석 응용 \n프로그램을 만들었습니다. 사용자는 이미지와 메타데이터를 업로드하여 이미지에 추가할 \n사진 프레임을 나타냅니다. 애플리케이션은 단일 Amazon EC2 인스턴스와 Amazon \nDynamoDB 를 사용하여 메타데이터를 저장합니다. \n응용 프로그램이 대중화되고 사용자 수가 증가하고 있습니다. 회사는 동시 접속자 수가 \n시간과 요일에 따라 크게 달라질 것으로 예상하고 있습니다. 회사는 증가하는 사용자 \n기반의 요구 사항을 충족하도록 애플리케이션을 확장할 수 있는지 확인해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \n\nA. AWS Lambda 를 사용하여 사진을 처리합니다. 사진과 메타데이터를 DynamoDB 에 \n저장합니다. \nB. Amazon Kinesis Data Firehose 를 사용하여 사진을 처리하고 사진과 메타데이터를 \n저장합니다. \nC. AWS Lambda 를 사용하여 사진을 처리합니다. Amazon S3 에 사진을 저장합니다. \nDynamoDB 를 유지하여 메타데이터를 저장합니다. \nD. EC2 인스턴스 수를 3 개로 늘립니다. 프로비저닝된 IOPS SSD(io2) Amazon Elastic Block \nStore(Amazon EBS) 볼륨을 사용하여 사진과 메타데이터를 저장합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/85189-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nA(X) : DynamoDB 는 데이터베이스 서비스이기 떄문에 이미지를 저장하기에는 적절치 않음. \nB(X) : Amazon Kinesis Data Firehose 는 저장 기능이 없고 전송 기능만 있음. \nKinesis Data Firehose 는 스트리밍 ETL 솔루션입니다. 스트리밍 데이터를 캡처하고 변환한 \n후 Amazon S3, Amazon Redshift, Amazon OpenSearch Service 및 Splunk 로 로드하여 이미 \n사용하고 있는 기존 비즈니스 인텔리전스 도구 및 대시보드를 통해 거의 실시간으로 분석할 \n수 있습니다. \nhttps://aws.amazon.com/ko/kinesis/data-firehose/faqs/ \nC(O) : 정답. \nD(X) : 사용자 수가 증가하고 있으므로 프로비저닝은 적절치 않음. \n \n설명2: \n이 솔루션은 확장성, 성능 및 가용성 요구 사항을 충족합니다. AWS Lambda 는 사진을 \n병렬로 처리하고 수요에 따라 자동으로 확장 또는 축소할 수 있습니다. \nAmazon S3 는 사진과 메타데이터를 안정적이고 내구성 있게 저장할 수 있으며 고가용성과 \n짧은 지연 시간을 제공합니다. DynamoDB 는 메타데이터를 효율적으로 저장하고 일관된 \n성능을 제공할 수 있습니다. 또한 이 솔루션은 EC2 인스턴스 및 EBS 볼륨 관리의 비용과 \n복잡성을 줄입니다. \nDynamoDB 에 사진을 저장하는 것은 스토리지 비용을 증가시키고 처리량을 제한할 수 \n있으므로 A 옵션은 올바르지 않습니다. \n옵션 B 는 Kinesis Data Firehose 가 사진 처리용이 아니라 S3 또는 Redshift 와 같은 \n대상으로 데이터 스트리밍용으로 설계되었기 때문에 올바르지 않습니다. \n옵션 D 는 EC2 인스턴스 수를 늘리고 프로비저닝된 IOPS SSD 볼륨을 사용하는 것이 로드 \n밸런서 및 애플리케이션 코드에 따라 확장성을 보장하지 않기 때문에 올바르지 않습니다. \n\n또한 인프라 관리 비용과 복잡성도 증가합니다. \nhttps://www.quora.com/How-can-I-use-DynamoDB-for-storing-metadata-for-Amazon\n-S3-objects", "answer_choice": "C"}, "115": {"q_num": 115, "question": "의료 기록 회사는 Amazon EC2 인스턴스에서 애플리케이션을 호스팅하고 있습니다. \n애플리케이션은 Amazon S3 에 저장된 고객 데이터 파일을 처리합니다. EC2 인스턴스는 \n퍼블릭 서브넷에서 호스팅됩니다. EC2 인스턴스는 인터넷을 통해 Amazon S3\n에 \n액세스하지만 다른 네트워크 액세스는 필요하지 않습니다. \n새로운 요구 사항은 파일 전송을 위한 네트워크 트래픽이 인터넷을 통해 전송되지 않고 \n개인 경로를 사용하도록 규정하고 있습니다. \n솔루션 설계자가 이 요구 사항을 충족하기 위해 권장해야 하는 네트워크 아키텍처 변경 \n사항은 무엇입니까? \nA. NAT 게이트웨이를 생성합니다. NAT 게이트웨이를 통해 Amazon S3\n로 트래픽을 \n전송하도록 퍼블릭 서브넷에 대한 라우팅 테이블을 구성합니다. \nB. S3 접두사 목록에 대한 트래픽만 허용되도록 아웃바운드 트래픽을 제한하도록 EC2 \n인스턴스에 대한 보안 그룹을 구성합니다. \nC. EC2 인스턴스를 프라이빗 서브넷으로 이동합니다. Amazon S3 용 VPC 엔드포인트를 \n생성하고 엔드포인트를 프라이빗 서브넷의 라우팅 테이블에 연결합니다. \nD. VPC 에서 인터넷 게이트웨이를 제거합니다. AWS Direct Connect 연결을 설정하고 Direct \nConnect 연결을 통해 Amazon S3 로 트래픽을 라우팅합니다.", "answer_block": "Answer: C  \nhttps://www.examtopics.com/discussions/amazon/view/86031-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nS3 에 액세스하지만 다른 네트워크 액세스는 필요하지 않음 = S3 Gateway Endpoint. \n게이트웨이 엔드포인트는 인터넷 게이트웨이나 VPC 용 NAT 디바이스 없이 Amazon S3 및 \nDynamoDB 에 안정적인 연결을 제공합니다. 게이트웨이 엔드포인트는 AWS PrivateLink 를 \n활성화하지 않습니다. \nhttps://docs.aws.amazon.com/vpc/latest/privatelink/gateway-endpoints.html \n \n설명2: \n프라이빗 경로를 통한 파일 전송의 새로운 요구 사항을 충족하려면 EC2 인스턴스를 \n인터넷에 직접 액세스할 수 없는 프라이빗 서브넷으로 이동해야 합니다. 이렇게 하면 파일 \n\n전송을 위한 트래픽이 인터넷을 통해 이동하지 않습니다. EC2 인스턴스가 Amazon S3 에 \n액세스할 수 있도록 Amazon S3\n용 VPC 엔드포인트를 생성할 수 있습니다. VPC \n엔드포인트를 사용하면 인터넷을 통해 트래픽을 전송하지 않고도 VPC 내의 리소스가 다른 \n서비스의 리소스와 통신할 수 있습니다. VPC 엔드포인트를 프라이빗 서브넷의 라우팅 \n테이블에 연결하면 EC2 인스턴스가 VPC 내의 프라이빗 연결을 통해 Amazon S3\n에 \n액세스할 수 있습니다.", "answer_choice": "C"}, "116": {"q_num": 116, "question": "회사는 회사 웹 사이트에 널리 사용되는 CMS(콘텐츠 관리 시스템)를 사용합니다. 그러나 \n필요한 패치 및 유지 관리가 부담됩니다. 회사는 웹사이트를 재설계하고 있으며 새로운 \n솔루션을 원합니다. 웹사이트는 1 년에 4 번 업데이트되며 사용 가능한 동적 콘텐츠가 \n필요하지 않습니다. 솔루션은 높은 확장성과 향상된 보안을 제공해야 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 변경 조합은 무엇입니까? (2 개를 \n선택하세요.) \nA. HTTPS 기능을 사용하도록 웹 사이트 앞에 Amazon CloudFront 를 구성합니다. \nB. 웹 사이트 앞에 AWS WAF 웹 ACL 을 배포하여 HTTPS 기능을 제공합니다. \nC. 웹 사이트 콘텐츠를 관리하고 제공하기 위해 AWS Lambda 함수를 생성 및 배포합니다. \nD. 새 웹 사이트와 Amazon S3 버킷을 생성합니다. 정적 웹 사이트 호스팅이 활성화된 S3 \n버킷에 웹 사이트를 배포합니다. \nE. 새 웹사이트를 만듭니다. Application Load Balancer 뒤에서 Amazon EC2 인스턴스의 \nAuto Scaling 그룹을 사용하여 웹 사이트를 배포합니다.", "answer_block": "Answer: A, D  \nhttps://www.examtopics.com/discussions/amazon/view/85996-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \n지문은 정적 웹 사이트 호스팅에 대해서 설명하고 있음. 정적 웹사이트 호스팅에 관한 건 \n아래의 링크를 참조할 것. \nhttps://aws.amazon.com/ko/getting-started/projects/build-serverless-web-app-lambda-\napigateway-s3-dynamodb-cognito/module-1/ \n참고로 지문에서 높은 확장성을 요구하고 있는데, 높은 확장성이란 별 거 없고 정적 웹 \n사이트 호스팅 환경을 구축하면 그게 높은 확장성을 갖춘 것. \n정적 웹 사이트 호스팅은 비용과 유지 관리 필요성이 가장 적은 옵션이고(예: 유지 \n관리해야 할 서버가 없음), 높은 수준의 신뢰성과 [[[확장성]]]을 제공하기 때문입니다.  \nhttps://aws.amazon.com/ko/getting-started/hands-on/host-static-website/faq/ \n\nA(O) : 뷰어가 HTTPS 를 사용할 것을 요청하도록 CloudFront 를 구성할 수 있습니다. \n이렇게 하면 CloudFront 가 뷰어와 통신할 때 연결이 암호화됩니다. 또한 CloudFront 가 \n오리진과 HTTPS 를 사용하도록 구성할 수 있습니다. 이렇게 하면 CloudFront 가 오리진과 \n통신할 때 연결이 암호화됩니다. \nhttps://docs.aws.amazon.com/ko_kr/AmazonCloudFront/latest/DeveloperGuide/using-htt\nps.html \nB(X) : AWS Web ACL 은 HTTP(S) 웹 요청을 세부적으로 제어할 수 있게 해주는 것. \n웹 ACL (웹 ACL) 를 사용하면 보호된 리소스가 응답하는 모든 HTTP (S) 웹 요청을 \n세부적으로 제어할 수 있게 해줍니다. \nhttps://docs.aws.amazon.com/ko_kr/waf/latest/developerguide/web-acl.html \nC(X) : 1 년에 4 번만 업데이트할 건데 그냥 Lambda 안 쓰고 수동으로 올려도 됨. \nD(O) : 동적 콘텐츠가 필요하지 않다고 했으므로 정적 웹사이트 호스팅. 따라서 S3 버킷 + \nCloudFront 조합. CloudFront 는 ▲위 선택지 A 번에서 이미 준비되었으므로 S3 버킷만 \n준비하면 됨. \nE(X) : 정적 웹사이트 호스팅은 서버리스로서 EC2 를 사용할 필요가 없음. \n정적 웹 사이트 호스팅은 비용과 유지 관리 필요성이 가장 적은 옵션이고(예: 유지 \n관리해야 할 서버가 없음) \nhttps://aws.amazon.com/ko/getting-started/hands-on/host-static-website/faq/ \n \n설명2: \nA -> 클라이언트에서 HTTPS 를 요구하도록 CloudFront 를 구성할 수 있습니다(보안 강화). \nhttps://docs.aws.amazon.com/ko_kr/AmazonCloudFront/latest/DeveloperGuide/using-htt\nps-viewers-to-cloudfront.html \nD -> S3 에 정적 웹 사이트를 저장하면 확장성이 제공되고 운영 오버헤드가 줄어듭니다. \n그런 다음 애플리케이션 LB 및 EC2 인스턴스를 구성합니다(따라서 E 는 제외됨).", "answer_choice": "A"}, "117": {"q_num": 117, "question": "회사는 Amazon CloudWatch Logs 로그 그룹에 애플리케이션 로그를 저장합니다. 새로운 \n정책에 따라 회사는 거의 실시간으로 Amazon OpenSearch Service(Amazon Elasticsearch \nService)에 모든 애플리케이션 로그를 저장해야 합니다. \n최소한의 운영 오버헤드로 이 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 로그를 Amazon OpenSearch Service(Amazon Elasticsearch Service)로 스트리밍하도록 \nCloudWatch Logs 구독을 구성합니다. \nB. AWS Lambda 함수를 생성합니다. 로그 그룹을 사용하여 함수를 호출하여 Amazon \nOpenSearch Service(Amazon Elasticsearch Service)에 로그를 기록합니다. \n\nC. Amazon Kinesis Data Firehose 전송 스트림을 생성합니다. 전송 스트림 소스로 로그 \n그룹을 구성합니다. Amazon OpenSearch Service(Amazon Elasticsearch Service)를 전송 \n스트림의 대상으로 구성합니다. \nD. 각 애플리케이션 서버에 Amazon Kinesis Agent 를 설치하고 구성하여 Amazon Kinesis \nData Streams 에 로그를 전달합니다. Amazon OpenSearch Service(Amazon Elasticsearch \nService)에 로그를 전달하도록 Kinesis Data Streams 를 구성합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/85802-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nCloudWatch Logs 구독을 통해 실시간에 가깝게 Amazon OpenSearch Service 클러스터로 \n수신한 데이터를 스트리밍하도록 CloudWatch Logs 로그 그룹을 구성할 수 있습니다. \nhttps://docs.aws.amazon.com/ko_kr/AmazonCloudWatch/latest/logs/CWL_OpenSearch_S\ntream.html \n정답은 A. \n최소한의 운영헤드, 기본으로 cloudwatch log - opensearch 간 연동을 제공함 \n \n참고: \nhttps://computingforgeeks.com/stream-logs-in-aws-from-cloudwatch-to-elasticsearch/", "answer_choice": "A"}, "118": {"q_num": 118, "question": "회사는 여러 가용 영역의 Amazon EC2 인스턴스에서 실행되는 웹 기반 애플리케이션을 \n구축하고 있습니다. 웹 애플리케이션은 약 900TB 크기의 텍스트 문서 저장소에 대한 \n액세스를 제공합니다. 회사는 웹 응용 프로그램이 수요가 많은 기간을 경험할 것으로 \n예상합니다. 솔루션 설계자는 텍스트 문서의 스토리지 구성 요소가 애플리케이션의 요구 \n사항을 항상 충족할 수 있도록 확장할 수 있는지 확인해야 합니다. 회사는 솔루션의 전체 \n비용에 대해 우려하고 있습니다. \n어떤 스토리지 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족합니까? \nA. Amazon Elastic Block Store(Amazon EBS) \nB. Amazon Elastic File System(Amazon EFS) \nC. Amazon OpenSearch Service(Amazon Elasticsearch Service) \nD. Amazon S3", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/86512-exam-aws-certified-solut\n\nions-architect-associate-saa-c03/ \n \n설명 \nAmazon S3 는 가장 저렴하고 어디서나 액세스할 수 있습니다. \n \nAmazon S3 (Simple Storage Service)는 확장성이 뛰어나고 비용 효율적인 스토리지 \n서비스입니다. 시나리오에서 언급한 900TB\n의 텍스트 문서와 같은 대용량 데이터를 \n저장하는 데 적합합니다. S3 는 높은 내구성, 가용성 및 성능을 제공합니다. \n \n옵션 A (Amazon EBS)는 개별 EC2 인스턴스용으로 설계된 블록 스토리지이며 대용량 \n데이터의 경우 S3 만큼 원활하고 비용 효율적으로 확장되지 않을 수 있습니다. \n옵션 B (Amazon EFS)는 확장 가능한 파일 스토리지 서비스이지만 특히 예상 스토리지 \n크기가 900TB 인 경우 S3 에 비해 가장 비용 효율적인 옵션이 아닐 수 있습니다. \n옵션 C( Amazon OpenSearch 서비스)는 검색 및 분석 서비스이며 텍스트 문서의 기본 \n스토리지 솔루션으로 적합하지 않을 수 있습니다. \n \n요약하면 Amazon S3 는 웹 애플리케이션에 필요한 대규모 텍스트 문서 리포지토리를 \n저장하기 위한 높은 확장성, 비용 효율성 및 내구성을 제공하므로 권장되는 선택입니다.", "answer_choice": "D"}, "119": {"q_num": 119, "question": "글로벌 회사는 Amazon API Gateway 를 사용하여 us-east-1 리전 및 ap-southeast-2 \n리전의 로열티 클럽 사용자를 위한 REST API 를 설계하고 있습니다. 솔루션 설계자는 SQL \n주입 및 교차 사이트 스크립팅 공격으로부터 여러 계정에서 이러한 API Gateway 관리 \nREST API 를 보호하는 솔루션을 설계해야 합니다. \n최소한의 관리 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 두 리전에 AWS WAF 를 설정합니다. 리전 웹 ACL 을 API 단계와 연결합니다. \nB. 두 리전에 AWS Firewall Manager 를 설정합니다. AWS WAF 규칙을 중앙에서 구성합니다. \nC. 목욕 리전에서 AWS Shield 를 설정합니다. 리전 웹 ACL 을 API 단계와 연결합니다. \nD. 한 리전에서 AWS Shield 를 설정합니다. 리전 웹 ACL 을 API 단계와 연결합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/86450-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n[여러 계정]에서 SQL 주입, XSS 공격, DDoS 등을 방어하려면 AWS Firewall Manager 가 \n\n적격. \nAWS Firewall Manager 는 AWS WAF 용 관리형 규칙과 통합되므로, 사전에 구성된 WAF \n규칙을 애플리케이션에 손쉽게 배포할 수 있습니다. 사용자는 콘솔에서 클릭 몇 번으로 \nAWS Marketplace 판매자가 제공 및 업데이트하는 관리형 규칙을 선택하고 Application \nLoad Balancer, API Gateway 및 Amazon CloudFront 인프라에서 일관되게 해당 규칙을 \n배포할 수 있습니다. https://aws.amazon.com/ko/firewall-manager/", "answer_choice": "B"}, "120": {"q_num": 120, "question": "한 회사는 us-west-2 리전의 NLB(Network Load Balancer) 뒤에 있는 3 개의 Amazon EC2 \n인스턴스에 자체 관리형 DNS 솔루션을 구현했습니다. 회사 사용자의 대부분은 미국과 \n유럽에 있습니다. 회사는 솔루션의 성능과 가용성을 개선하기를 원합니다. 회사는 \neu-west-1 리전에서 3 개의 EC2 인스턴스를 시작 및 구성하고 EC2 인스턴스를 새 NLB 의 \n대상으로 추가합니다. \n회사에서 트래픽을 모든 EC2 인스턴스로 라우팅하는 데 사용할 수 있는 솔루션은 \n무엇입니까? \nA. 두 NLB 중 하나로 요청을 라우팅하는 Amazon Route 53 지리적 위치 라우팅 정책을 \n생성합니다. Amazon CloudFront 배포를 생성합니다. Route 53 레코드를 배포의 오리진으로 \n사용합니다. \nB. AWS Global Accelerator\n에서 표준 액셀러레이터를 생성합니다. us-west-2 및 \neu-west-1 에서 엔드포인트 그룹을 생성합니다. 엔드포인트 그룹에 대한 엔드포인트로 두 \n개의 NLB 를 추가하십시오. \nC. 탄력적 IP 주소를 6 개의 EC2 인스턴스에 연결합니다. 6 개의 EC2 인스턴스 중 하나로 \n요청을 라우팅하는 Amazon Route 53 지리적 위치 라우팅 정책을 생성합니다. Amazon \nCloudFront 배포를 생성합니다. Route 53 레코드를 배포의 오리진으로 사용합니다. \nD. 2 개의 NLB 를 2 개의 ALB(Application Load Balancer)로 교체합니다. 두 ALB 중 하나로 \n요청을 라우팅하는 Amazon Route 53 지연 시간 라우팅 정책을 생성합니다. Amazon \nCloudFront 배포를 생성합니다. Route 53 레코드를 배포의 오리진으로 사용합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/85807-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nA(X) : 자체 관리형 DNS 솔루션을 사용하고 있다고 이미 지문에서 언급했음. 자체적으로 \n해결할 수 있는 걸 Route 53 을 사용해서 추가적인 지출을 할 이유가 없음. 게다가 CDN \n서비스를 사용해야한다는 단서가 없는데 굳이 CDN 서비스를 끼워넣을 이유가 없음. \n\nB(O) : AWS Global Accelerator 는 애플리케이션 상태, 사용자의 위치 및 고객이 구성하는 \n정책의 변경에 즉각적으로 대응하여 항상 성능에 기반한 최적의 엔드포인트로 사용자 \n트래픽을 라우팅합니다......온프레미스 엔드포인트를 처리하도록 각 AWS 리전에 Network \nLoad Balancer(NLB)를 구성할 수 있습니다. 그러면 이러한 NLB 가 AWS Global Accelerator \n구성에서 엔드포인트가 될 수 있습니다. \nhttps://aws.amazon.com/ko/global-accelerator/faqs/ \nC(X) : 탄력적 IP 주소를 AWS Global Accelerator 에 연결하는 게 더 효과적. 앞으로 \n인스턴스가 늘어날 때마다 EC2 인스턴스에 탄력적 IP 를 부여할 건지? \nD(X) : 가능은 한데 A 와 같은 이유로 out. 그리고 굳이 귀찮게 ALB 로 교체할 이유가 없음. \n \n설명2: \n표준 액셀러레이터의 경우 Global Accelerator\n는 AWS 글로벌 네트워크를 사용하여 \n사용자가 구성한 상태, 클라이언트 위치 및 정책을 기반으로 트래픽을 최적의 지역 \n엔드포인트로 \n라우팅하여 \n애플리케이션의 \n가용성을 \n높입니다. \n표준 \n액셀러레이터의 \n엔드포인트는 Network Load Balancer, Application Load Balancer, Amazon EC2 인스턴스 \n또는 하나의 AWS 리전 또는 여러 리전에 위치한 탄력적 IP 주소일 수 있습니다. \nhttps://docs.aws.amazon.com/global-accelerator/latest/dg/what-is-global-accelerator.h\ntml", "answer_choice": "B"}, "121": {"q_num": 121, "question": "회사는 AWS\n에서 OLTP(온라인 트랜잭션 처리) 워크로드를 실행하고 있습니다. 이 \n워크로드는 다중 AZ 배포에서 암호화되지 않은 Amazon RDS DB 인스턴스를 사용합니다. \n일일 데이터베이스 스냅샷은 이 인스턴스에서 가져옵니다. \n데이터베이스와 스냅샷이 앞으로 항상 암호화되도록 하려면 솔루션 설계자가 무엇을 해야 \n합니까? \nA. 최신 DB 스냅샷 사본을 암호화합니다. 암호화된 스냅샷을 복원하여 기존 DB \n인스턴스를 교체합니다. \nB. 새 암호화된 Amazon Elastic Block Store(Amazon EBS) 볼륨을 생성하고 여기에 \n스냅샷을 복사합니다. DB 인스턴스에서 암호화를 활성화합니다. \nC. AWS Key Management Service(AWS KMS)를 사용하여 스냅샷을 복사하고 암호화를 \n활성화합니다. 암호화된 스냅샷을 기존 DB 인스턴스로 복원합니다. \nD. AWS Key Management Service(AWS KMS) 관리형 키(SSE-KMS)로 서버 측 암호화를 \n사용하여 암호화된 Amazon S3 버킷에 스냅샷을 복사합니다.", "answer_block": "Answer: A  \nhttps://www.examtopics.com/discussions/amazon/view/85941-exam-aws-certified-solut\n\nions-architect-associate-saa-c03/ \n \n설명1: \nAmazon RDS 암호화된 DB 인스턴스의 경우 모든 로그, 백업 및 스냅샷이 암호화됩니다.  \nAmazon RDS DB 인스턴스의 암호화는 인스턴스를 생성할 때에만 가능하며 DB 인스턴스가 \n생성된 후에는 불가능합니다. 다만 암호화되지 않은 스냅샷의 사본을 암호화할 수 있기 \n때문에 암호화되지 않은 DB 인스턴스에 실질적으로 암호화를 추가할 수 있습니다. 즉, DB \n인스턴스의 스냅샷을 만든 다음 해당 스냅샷의 암호화된 사본을 만들 수 있습니다. 그런 \n다음 암호화된 스냅샷에서 DB 인스턴스를 복구할 수 있고, 원본 DB 인스턴스의 암호화된 \n사본이 생깁니다. \nhttps://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/Overview.Encryption.h\ntml#Overview.Encryption.Limitations \n \n설명2: \nhttps://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/USER_RestoreFromSn\napshot.html#USE \nhttps://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/EBSEncryption.html", "answer_choice": "A"}, "122": {"q_num": 122, "question": "회사는 응용 프로그램의 데이터를 암호화해야 하는 개발자를 지원하기 위해 확장 가능한 키 \n관리 인프라를 구축하려고 합니다. \n솔루션 설계자는 운영 부담을 줄이기 위해 무엇을 해야 합니까? \nA. MFA(다단계 인증)를 사용하여 암호화 키를 보호합니다. \nB. AWS Key Management Service(AWS KMS)를 사용하여 암호화 키를 보호합니다. \nC. AWS Certificate Manager(ACM)를 사용하여 암호화 키를 생성, 저장 및 할당합니다. \nD. IAM 정책을 사용하여 암호화 키를 보호할 수 있는 액세스 권한이 있는 사용자의 범위를 \n제한합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/85942-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nA(X) : MFA 는 다중 인증으로, 운영 부담 감소와는 아무런 상관 없음. \nB(O) : \"\"AWS KMS 는 암호화 작업에 사용되는 키를 쉽게 생성하고 제어할 수 있도록 \n지원하는 관리형 서비스입니다. https://aws.amazon.com/ko/kms/faqs/ \n\nC(X) : ACM 은 SSL/TLS 인증서 관련 서비스. \nAWS Certificate Manager 는 AWS 서비스 및 연결된 내부 리소스에 사용할 공인 및 사설 \nSSL/TLS(Secure Sockets Layer/전송 계층 보안) 인증서를 손쉽게 프로비저닝, 관리 및 \n배포할 수 있도록 지원하는 서비스입니다. \nhttps://aws.amazon.com/ko/certificate-manager/faqs/ \nD(X) : IAM 정책은 키 관리 서비스가 아니라 권한 관련 서비스. \n \n참고: \nhttps://aws.amazon.com/ko/kms/faqs/#:~:text=If%20you%20are%20a%20developer%20\nwho%20needs", "answer_choice": "B"}, "123": {"q_num": 123, "question": "회사에 두 개의 Amazon EC2 인스턴스에서 호스팅되는 동적 웹 애플리케이션이 있습니다. \n회사에는 SSL 종료를 수행하기 위해 각 인스턴스에 있는 자체 SSL 인증서가 있습니다. \n최근 트래픽이 증가하고 있으며 운영팀은 SSL 암호화 및 복호화로 인해 웹 서버의 컴퓨팅 \n용량이 최대 한도에 도달했다고 판단했습니다. \n솔루션 설계자는 애플리케이션의 성능을 향상시키기 위해 무엇을 해야 합니까? \nA. AWS Certificate Manager(ACM)를 사용하여 새 SSL 인증서를 생성합니다. 각 인스턴스에 \nACM 인증서를 설치합니다. \nB. Amazon S3 버킷 생성 SSL 인증서를 S3 버킷으로 마이그레이션합니다. SSL 종료를 위해 \n버킷을 참조하도록 EC2 인스턴스를 구성합니다. \nC. 다른 EC2 인스턴스를 프록시 서버로 생성합니다. SSL 인증서를 새 인스턴스로 \n마이그레이션하고 기존 EC2 인스턴스에 직접 연결하도록 구성합니다. \nD. SSL 인증서를 AWS Certificate Manager(ACM)로 가져옵니다. ACM 의 SSL 인증서를 \n사용하는 HTTPS 리스너로 Application Load Balancer 를 생성합니다.", "answer_block": "Answer: D  \nhttps://www.examtopics.com/discussions/amazon/view/85943-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nAWS Certificate Manager 를 사용하면 인증서를 신속하게 요청하고 Elastic Load Balancer, \nAmazon CloudFront 배포, API Gateway 의 API 와 같은 ACM 통합 AWS 리소스에 배포하고 \nAWS Certificate Manager 가 인증서 갱신을 처리하도록 할 수 있습니다. 또한 내부 리소스에 \n대한 개인 인증서를 만들고 중앙에서 인증서 수명 주기를 관리할 수 있습니다. \n \n\n설명2: \nACM(AWS Certificate Manager)이 필요한 상황. \nAWS Certificate Manager(ACM)는 AWS 서비스 및 연결된 내부 리소스에 사용할 공인 및 \n사설 SSL/TLS(Secure Sockets Layer/전송 계층 보안) 인증서를 손쉽게 프로비저닝, 관리 및 \n배포할 수 있도록 지원하는 서비스입니다.  \nhttps://aws.amazon.com/ko/certificate-manager/ \n따라서 A,D 둘 중 하나가 정답. \nA(X) : 기존에 이미 사용하던 SSL 인증서가 있는데 하나 새로 만들 필요는 없음. \nD(O) : A 와 같은 이유로 정답. \n리스너는 연결 요청을 확인하는 프로세스입니다. 로드 밸런서를 생성할 때 리스너를 \n정의하면 언제라도 로드 밸런서에 리스너를 추가할 수 있습니다. 암호화된 연결(SSL \n오프로드라고도 함)을 사용하는 HTTPS 리스너를 생성할 수 있습니다. 이 기능을 사용하면 \n로드 밸런서와 SSL 또는 TLS 세션을 시작하는 클라이언트 간에 트래픽 암호화가 \n가능합니다. \nhttps://docs.aws.amazon.com/ko_kr/elasticloadbalancing/latest/application/create-https\n-listener.html", "answer_choice": "D"}, "124": {"q_num": 124, "question": "회사에 많은 Amazon EC2 인스턴스를 사용하여 완료하는 매우 동적인 배치 처리 작업이 \n있습니다. 작업은 본질적으로 상태 비저장이며 부정적인 영향 없이 주어진 시간에 시작 및 \n중지할 수 있으며 일반적으로 완료하는 데 총 60 분 이상이 걸립니다. 회사는 솔루션 \n설계자에게 작업 요구 사항을 충족하는 확장 가능하고 비용 효율적인 솔루션을 설계하도록 \n요청했습니다. \n솔루션 설계자는 무엇을 권장해야 합니까? \nA. EC2 스팟 인스턴스를 구현합니다. \nB. EC2 예약 인스턴스 구매. \nC. EC2 온디맨드 인스턴스를 구현합니다. \nD. AWS Lambda 에서 처리를 구현합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/86038-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nEC2 스팟 인스턴스를 통해 사용자는 여분의 Amazon EC2 컴퓨팅 용량에 입찰할 수 있으며 \n언제든지 시작 및 중지할 수 있는 상태 비저장 및 중단 가능한 워크로드를 위한 비용 \n\n효율적인 솔루션이 될 수 있습니다. \n배치 처리 작업은 상태 비저장이고 언제든지 시작 및 중지할 수 있으며 일반적으로 \n완료하는 데 60 분 이상 걸리므로 EC2 스팟 인스턴스는 이 워크로드에 적합합니다. \n \n설명2: \n상태비저장, 시작 및 중지 가능이라는 단서를 볼 때 스팟 인스턴스가 적절함.", "answer_choice": "A"}, "125": {"q_num": 125, "question": "회사는 AWS 에서 2 계층 전자상거래 웹사이트를 운영합니다. 웹 계층은 트래픽을 Amazon \nEC2 인스턴스로 보내는 로드 밸런서로 구성됩니다. 데이터베이스 계층은 Amazon RDS DB \n인스턴스를 사용합니다. EC2 인스턴스 및 RDS DB 인스턴스는 공용 인터넷에 노출되어서는 \n안 됩니다. EC2 인스턴스는 타사 웹 서비스를 통한 주문 결제 처리를 완료하기 위해 인터넷 \n액세스가 필요합니다. 애플리케이션은 고가용성이어야 합니다. \n이러한 요구 사항을 충족하는 구성 옵션의 조합은 무엇입니까? (2 개를 선택하세요.) \nA. Auto Scaling 그룹을 사용하여 프라이빗 서브넷에서 EC2 인스턴스를 시작합니다. \n프라이빗 서브넷에 RDS 다중 AZ DB 인스턴스를 배포합니다. \nB. 2 개의 가용 영역에 걸쳐 2 개의 프라이빗 서브넷과 2 개의 NAT 게이트웨이가 있는 \nVPC 를 구성합니다. 프라이빗 서브넷에 Application Load Balancer 를 배포합니다. \nC. Auto Scaling 그룹을 사용하여 2 개의 가용 영역에 걸쳐 퍼블릭 서브넷에서 EC2 \n인스턴스를 시작합니다. 프라이빗 서브넷에 RDS 다중 AZ DB 인스턴스를 배포합니다. \nD. 2 개의 가용 영역에 걸쳐 1 개의 퍼블릭 서브넷, 1 개의 프라이빗 서브넷 및 2 개의 NAT \n게이트웨이로 VPC\n를 구성합니다. 퍼블릭 서브넷에 Application Load Balancer\n를 \n배포합니다. \nE. 2 개의 가용 영역에 걸쳐 2 개의 퍼블릭 서브넷, 2 개의 프라이빗 서브넷 및 2 개의 NAT \n게이트웨이로 VPC\n를 구성합니다. 퍼블릭 서브넷에 Application Load Balancer\n를 \n배포합니다.", "answer_block": "Answer: A, E \nhttps://www.examtopics.com/discussions/amazon/view/85221-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \n시작하기 전에: EC2 인스턴스에 사용할 두 개의 가용 영역을 결정합니다. 이러한 각 가용 \n영역에서 하나 이상의 퍼블릭 서브넷으로 Virtual Private Cloud(VPC)를 구성합니다. \n이러한 퍼블릭 서브넷은 로드 밸런서를 구성하는 데 사용됩니다. 대신 이러한 가용 영역의 \n다른 서브넷에서 EC2 인스턴스를 시작할 수 있습니다. \n\n \n설명2: \n・EC2 인스턴스와 RDS DB 인스턴스는 퍼블릭 인터넷에 노출되지 않아야 하므로 프라이빗 \n서브넷에 위치해야 함. \n・그러면서도 \nEC2 \n인스턴스는 \n인터넷에 \n접속해야하니 \nNAT \n서비스가 \n필요. \nNAT \n게이트웨이(기본적으로 퍼블릭 NAT 게이트웨이를 말함)는 퍼블릭 서브넷에 위치해야 함. \n퍼블릭 서브넷에서 퍼블릭 NAT 게이트웨이를 생성하고 생성 시 탄력적 IP 주소를 NAT \n게이트웨이와 연결해야 합니다. 트래픽을 NAT 게이트웨이에서 VPC 용 인터넷 게이트웨이로 \n라우팅합니다. \nhttps://docs.aws.amazon.com/ko_kr/vpc/latest/userguide/vpc-nat-gateway.html \n・가용성 = Auto Scaling, Multi AZ \nA(O) : EC2 인스턴스와 RDS 인스턴스 모두 프라이빗 서브넷에 위치해야하며 고가용성을 \n충족시켜야 하므로 다중 AZ 를 사용. \nB(X) : ALB 는 퍼블릭 서브넷에 위치해야 함. \n프라이빗 서브넷에 있는 Amazon EC2 인스턴스를 연결하려면 백엔드 인스턴스에서 \n사용하는 프라이빗 서브넷과 동일한 가용 영역에 퍼블릭 서브넷을 생성합니다. 그런 다음 \n퍼블릭 서브넷을 로드 밸런서와 연결합니다. \nhttps://aws.amazon.com/ko/premiumsupport/knowledge-center/public-load-balancer-pr\nivate-ec2/ \nC(X) : 퍼블릭 서브넷에서 EC2 인스턴스를 시작하기 때문에 오답. EC2 인스턴스는 퍼블릭 \n인터넷에 노출되지 않아야 하므로 프라이빗 서브넷에 있어야 함. \nD(X) : 하나의 서브넷으로 두 개의 가용영역에 걸쳐 사용하는 것은 불가. \n각 서브넷은 완전히 하나의 가용 영역 내에 있어야 하며 여러 영역에 걸쳐 있을 수 \n없습니다. \nhttps://docs.aws.amazon.com/vpc/latest/userguide/configure-subnets.html#subnet-basi\ncs \nE(O) : 각 AZ 에 퍼블릭 서브넷은 1 개 있어야 하고(NAT 게이트웨이가 들어가야 하므로), \n프라이빗 서브넷은 1 개 이상 있어야 함(EC2 인스턴스와 RDS 가 들어갈 곳). 각 AZ 에 있는 \n퍼블릭 서브넷에 NAT 게이트웨이가 하나씩 들어가야 각 가용영역에 있는 프라이빗 \n서브넷마다 인터넷에 액세스가 가능한 상태가 되므로 NAT 게이트웨이는 총 2 개가 됨. \n따라서 2개의 AZ에 걸쳐 퍼블릭 서브넷 2, 프라이빗 서브넷 2, NAT 게이트웨이 2개가 됨.\"", "answer_choice": "A"}, "126": {"q_num": 126, "question": "A solutions architect needs to implement a solution to reduce a company's storage costs. All \nthe company's data is in the Amazon S3 Standard storage class. The company must keep all \n\ndata for at least 25 years. Data from the most recent 2 years must be highly available and \nimmediately retrievable. \nWhich solution will meet these requirements? \nA. Set up an S3 Lifecycle policy to transition objects to S3 Glacier Deep Archive immediately. \nB. Set up an S3 Lifecycle policy to transition objects to S3 Glacier Deep Archive after 2 \nyears. \nC. Use S3 Intelligent-Tiering. Activate the archiving option to ensure that data is archived in \nS3 Glacier Deep Archive. \nD. Set up an S3 Lifecycle policy to transition objects to S3 One Zone-Infrequent Access (S3 \nOne Zone-IA) immediately and to S3 Glacier Deep Archive after 2 years.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/86731-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nA(X) : 가장 최근 2 년의 데이터는 즉시 검색할 수 있어야 하므로 콜드 스토리지는 부적절. \nB(O) : 정답 \nC(X) : 가장 최근 2 년의 데이터는 모두 가용성이 높아야 하고 즉시 검색할 수 있어야하는 \n데이터이므로 Intelligent-Tiering 이 따로 필요하진 않음. \nD(X) : One Zone-IA 는 고가용성 조건 불충족. \nhttps://aws.amazon.com/ko/about-aws/whats-new/2018/04/announcing-s3-one-zone-i\nnfrequent-access-a-new-amazon-s3-storage-class/?nc1=h_ls", "answer_choice": "B"}, "127": {"q_num": 127, "question": "한 미디어 회사가 시스템을 AWS 클라우드로 이전할 가능성을 평가하고 있습니다. 회사는 \n비디오 처리를 위한 가능한 최대 I/O 성능을 갖춘 최소 10TB 의 스토리지, 미디어 콘텐츠를 \n저장하기 위한 300TB 의 매우 내구성 있는 스토리지, 더 이상 사용하지 않는 아카이브 \n미디어에 대한 요구 사항을 충족하기 위해 900TB 의 스토리지가 필요합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 서비스 세트를 권장해야 합니까? \nA. 최고의 성능을 위한 Amazon EBS, 내구성 있는 데이터 스토리지를 위한 Amazon S3, \n아카이브 스토리지를 위한 Amazon S3 Glacier \nB. 최고의 성능을 위한 Amazon EBS, 내구성 있는 데이터 스토리지를 위한 Amazon EFS, \n아카이브 스토리지를 위한 Amazon S3 Glacier \nC. 최고의 성능을 위한 Amazon EC2 인스턴스 스토어, 내구성 있는 데이터 스토리지를 \n위한 Amazon EFS, 아카이브 스토리지를 위한 Amazon S3 \n\nD. 최고의 성능을 위한 Amazon EC2 인스턴스 스토어, 내구성 있는 데이터 스토리지를 \n위한 Amazon S3, 아카이브 스토리지를 위한 Amazon S3 Glacier", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/85432-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명 \n고가용성이므로 Auto Scaling 이 들어간 C,D 둘 중 하나가 정답. EFS vs EBS 를 비교해보면 \n보통은 EFS 가 정답인 경우가 많음. 일단 EBS 는 여러 EC2 인스턴스에서 동시 접속할 수 \n없다는 단점이 치명적이기 때문. \nAmazon Elastic File System 은 전체 파일 시스템 액세스 의미 체계를 지원하는 표준 파일 \n시스템 인터페이스를 제공합니다.  \nhttps://docs.aws.amazon.com/efs/latest/ug/using-fs.html \nEBS 다중 연결 볼륨에서 표준 파일 시스템 작업은 지원되는 구성이 아닙니다. \nhttps://aws.amazon.com/ko/premiumsupport/knowledge-center/ebs-access-volumes-us\ning-multi-attach/ \n \n참조 \nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html", "answer_choice": "D"}, "128": {"q_num": 128, "question": "회사에서 AWS 클라우드의 컨테이너에서 애플리케이션을 실행하려고 합니다. 이러한 \n애플리케이션은 상태 비저장이며 기본 인프라 내에서 중단을 허용할 수 있습니다. 회사는 \n비용과 운영 오버헤드를 최소화하는 솔루션이 필요합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. Amazon EC2 Auto Scaling 그룹의 스팟 인스턴스를 사용하여 애플리케이션 컨테이너를 \n실행합니다. \nB. Amazon Elastic Kubernetes Service(Amazon EKS) 관리형 노드 그룹에서 스팟 \n인스턴스를 사용합니다. \nC. Amazon EC2 Auto Scaling 그룹의 온디맨드 인스턴스를 사용하여 애플리케이션 \n컨테이너를 실행합니다. \nD. Amazon Elastic Kubernetes Service(Amazon EKS) 관리형 노드 그룹에서 온디맨드 \n인스턴스를 사용합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/85404-exam-aws-certified-solut\n\nions-architect-associate-saa-c03/ \n \n설명: \n중단을 허용할 수 있음 = 스팟 인스턴스. 컨테이너에서 애플리케이션 실행 = ECS, EKS \n같은 서비스. 답은 B.", "answer_choice": "B"}, "129": {"q_num": 129, "question": "회사에서 \n온프레미스에서 \n다중 \n계층 \n웹 \n애플리케이션을 \n실행하고 \n있습니다. \n웹 \n애플리케이션은 \n컨테이너화되어 \n있으며 \n사용자 \n레코드가 \n포함된 \nPostgreSQL \n데이터베이스에 연결된 여러 Linux 호스트에서 실행됩니다. 인프라 및 용량 계획을 유지 \n관리하는 \n운영 \n오버헤드가 \n회사의 \n성장을 \n제한하고 \n있습니다. \n솔루션 \n설계자는 \n애플리케이션의 인프라를 개선해야 합니다. \n솔루션 설계자는 이를 달성하기 위해 어떤 조합의 조치를 취해야 합니까? (2 개 선택) \nA. PostgreSQL 데이터베이스를 Amazon Aurora 로 마이그레이션합니다. \nB. Amazon EC2 인스턴스에서 호스팅할 웹 애플리케이션을 마이그레이션합니다. \nC. 웹 애플리케이션 콘텐츠에 대한 Amazon CloudFront 배포를 설정합니다. \nD. 웹 애플리케이션과 PostgreSQL 데이터베이스 간에 Amazon ElastiCache 를 설정합니다. \nE. Amazon Elastic Container Service(Amazon ECS)를 사용하여 AWS Fargate 에서 호스팅할 \n웹 애플리케이션을 마이그레이션합니다.", "answer_block": "Answer: A, E \nhttps://www.examtopics.com/discussions/amazon/view/86658-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \n・컨테이너화 되어있음 = ECS(또는 EKS) + Fargate. \nA(O) : Amazon Aurora 는 PostgreSQL 과 호환되고 다중 리전 및 AZ 를 기본적으로 \n지원하므로 인프라 및 용량 계획을 유지 관리 가능. \nAmazon Aurora 는 서버리스 및 기계 학습 기반 애플리케이션의 구축을 위한 규모에 따른 \n성능 및 고가용성, 완전한 오픈 소스 MySQL 및 PostgreSQL 호환 버전과 광범위한 개발자 \n도구를 제공….Amazon Aurora\n는 데이터베이스 볼륨을 10GB 세그먼트로 자동으로 \n분리하여 여러 디스크에 분산합니다. 데이터베이스 볼륨에서 각 10GB 청크가 3 개의 AZ 에 \n6 가지 방법으로 복제됩니다. https://aws.amazon.com/ko/rds/aurora/faqs/ \nB(X) : 애플리케이션이 컨테이너화 되어있다고 했으므로 Fargate 사용이 더 적절. \nC(X) : CloudFront 는 CDN 서비스로 지문의 상황엔 적합치 않음. \nD(X) : ElastiCache 는 웹 애플리케이션과 DB 간 캐시 서비스로 지문의 상황엔 적합치 않음. \n\nE(O) : ECS + Fargate 로 컨테이너화된 애플리케이션 사용 가능. \nAWS Fargate Fargate 는 Amazon EC2 인스턴스의 서버나 클러스터를 관리할 필요 없이 \n컨테이너를 실행하기 위해 Amazon ECS 에 사용할 수 있는 기술입니다. \nhttps://docs.aws.amazon.com/ko_kr/AmazonECS/latest/userguide/what-is-fargate.html \n \n설명2: \nAmazon Aurora 는 PostgreSQL 과 호환되는 완전히 관리되고 확장 가능하며 가용성이 높은 \n관계형 데이터베이스 서비스입니다. 데이터베이스를 Amazon Aurora 로 마이그레이션하면 \n데이터베이스 인프라를 유지 관리하는 운영 오버헤드가 줄어들고 회사는 애플리케이션 구축 \n및 확장에 집중할 수 있습니다. AWS Fargate 는 사용자가 기본 EC2 인스턴스를 관리할 \n필요 없이 컨테이너를 실행할 수 있도록 하는 완전 관리형 컨테이너 오케스트레이션 \n서비스입니다. 솔루션 설계자는 Amazon Elastic Container Service(Amazon ECS)와 함께 \nAWS Fargate 를 사용하여 웹 애플리케이션의 확장성과 효율성을 개선하고 기본 인프라를 \n유지 관리하는 운영 오버헤드를 줄일 수 있습니다.", "answer_choice": "A"}, "130": {"q_num": 130, "question": "애플리케이션은 여러 가용 영역의 Amazon EC2 인스턴스에서 실행됩니다. 인스턴스는 \nApplication Load Balancer 뒤의 Amazon EC2 Auto Scaling 그룹에서 실행됩니다. \n애플리케이션은 EC2 인스턴스의 CPU 사용률이 40% 또는 거의 40%일 때 가장 잘 \n수행됩니다. \n솔루션 설계자는 그룹의 모든 인스턴스에서 원하는 성능을 유지하기 위해 무엇을 해야 \n합니까? \nA. Auto Scaling 그룹을 동적으로 확장하려면 간단한 확장 정책을 사용합니다. \nB. 대상 추적 정책을 사용하여 Auto Scaling 그룹을 동적으로 확장합니다. \nC. AWS Lambda 함수를 사용하여 원하는 Auto Scaling 그룹 용량을 업데이트합니다. \nD. 예약된 조정 작업을 사용하여 Auto Scaling 그룹을 확장 및 축소합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/86659-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명 \nCPU 사용률에 따라 Auto Scaling = Target Tracking Policy. 정답은 B. \nhttps://docs.aws.amazon.com/autoscaling/application/userguide/application-auto-scalin\ng-targettracking.html", "answer_choice": "B"}, "131": {"q_num": 131, "question": "한 회사에서 Amazon S3 버킷을 스토리지로 사용할 파일 공유 애플리케이션을 개발 \n중입니다. 회사는 Amazon CloudFront 배포를 통해 모든 파일을 제공하려고 합니다. 회사는 \nS3 URL 에 대한 직접 탐색을 통해 파일에 액세스하는 것을 원하지 않습니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \n \nA. 각 S3 버킷에 대한 개별 정책을 작성하여 CloudFront 액세스에 대해서만 읽기 권한을 \n부여합니다. \nB. IAM 사용자를 생성합니다. 사용자에게 S3 버킷의 객체에 대한 읽기 권한을 부여합니다. \n사용자를 CloudFront 에 할당합니다. \nC. CloudFront 배포 ID\n를 보안 주체로 할당하고 대상 S3 버킷을 Amazon 리소스 \n이름(ARN)으로 할당하는 S3 버킷 정책을 작성합니다. \nD. 원본 액세스 ID(OAI)를 생성합니다. CloudFront 배포에 OAI 를 할당합니다. OAI 만 읽기 \n권한을 갖도록 S3 버킷 권한을 구성합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/85992-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명 \nhttps://aws.amazon.com/premiumsupport/knowledge-center/cloudfront-access-to-amaz\non-s3/ \nhttps://docs.aws.amazon.com/ko_kr/AmazonCloudFront/latest/DeveloperGuide/private-c\nontent-restricting-access-to-s3.html#private-content-restricting-access-to-s3-overvie\nw \n \nS3 + CloudFront 를 사용하는 상황에서 S3 에 직접 액세스하는 것을 막으려면 OAC 또는 \nOAI 를 사용하면 됨. \nAmazon S3 버킷을 오리진으로 설정하여 CloudFront 를 사용하는 경우 다음과 같은 이점을 \n제공하는 방식으로 CloudFront 및 Amazon S3\n를 구성할 수 있습니다. ◎공개적으로 \n액세스할 수 없도록 Amazon S3 버킷에 대한 액세스를 제한합니다. ◎뷰어(사용자)가 \n지정된 CloudFront 배포를 통해서만 버킷의 콘텐츠에 액세스할 수 있도록 합니다. 즉, \n뷰어가 버킷에서 직접 또는 의도하지 않은 CloudFront 배포를 통해 콘텐츠에 액세스하는 \n것을 방지합니다. 이렇게 하려면 인증된 요청을 Amazon S3 로 보내도록 CloudFront 를 \n구성하고 CloudFront\n의 인증된 요청에 대한 액세스만 허용하도록 Amazon S3\n를 \n구성합니다. CloudFront 는 Amazon S3 오리진에 인증된 요청을 전송하는 두 가지 방법으로 \n\n오리진 액세스 제어(OAC)와 오리진 액세스 ID(OAI)를 제공합니다. OAC\n는 다음을 \n지원하므로 OAC 를 사용하는 것이 좋습니다. \nhttps://docs.aws.amazon.com/ko_kr/AmazonCloudFront/latest/DeveloperGuide/private-c\nontent-restricting-access-to-s3.html", "answer_choice": "D"}, "132": {"q_num": 132, "question": "회사 웹사이트는 사용자에게 다운로드 가능한 과거 실적 보고서를 제공합니다. 웹 \n사이트에는 전 세계적으로 회사의 웹 사이트 요구 사항을 충족하도록 확장할 수 있는 \n솔루션이 필요합니다. 솔루션은 비용 효율적이어야 하고 인프라 리소스 프로비저닝을 \n제한하며 가능한 가장 빠른 응답 시간을 제공해야 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 조합을 권장해야 합니까? \nA. Amazon CloudFront 및 Amazon S3 \nB. AWS Lambda 및 Amazon DynamoDB \nC. Amazon EC2 Auto Scaling 이 있는 Application Load Balancer \nD. 내부 Application Load Balancer 가 있는 Amazon Route 53", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/86654-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n전 세계적으로 웹 사이트 요구 충족 = CloudFront.  \n빠른 응답을 위한 Cloudfront 와 인프라를 최소화하기 위한 s3", "answer_choice": "A"}, "133": {"q_num": 133, "question": "회사는 \n온프레미스에서 \nOracle \n데이터베이스를 \n실행합니다. \n회사는 \nAWS\n로 \n마이그레이션하는 과정에서 데이터베이스를 사용 가능한 최신 버전으로 업그레이드하려고 \n합니다. 회사는 또한 데이터베이스에 대한 재해 복구(DR)를 설정하려고 합니다. 회사는 \n정상 운영 및 DR 설정을 위한 운영 오버헤드를 최소화해야 합니다. 회사는 또한 \n데이터베이스의 기본 운영 체제에 대한 액세스를 유지 관리해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. Oracle 데이터베이스를 Amazon EC2 인스턴스로 마이그레이션합니다. 다른 AWS \n리전으로 데이터베이스 복제를 설정합니다. \nB. Oracle 데이터베이스를 Oracle 용 Amazon RDS 로 마이그레이션합니다. 교차 리전 자동 \n백업을 활성화하여 다른 AWS 리전에 스냅샷을 복제합니다. \n\nC. Oracle 데이터베이스를 Oracle 용 Amazon RDS Custom 으로 마이그레이션합니다. 다른 \nAWS 리전의 데이터베이스에 대한 읽기 전용 복제본을 생성합니다. \nD. Oracle 데이터베이스를 Oracle용 Amazon RDS로 마이그레이션합니다. 다른 가용 영역에 \n대기 데이터베이스를 생성합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/85423-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n기본 운영 체제에 대한 액세스 유지 = Amazon RDS Custom. \nAmazon Relational Database Service(Amazon RDS) Custom 은 기본 OS 및 DB 환경에 \n액세스할 필요가 있는 레거시, 사용자 지정, 패키지 애플리케이션을 위한 관리형 \n데이터베이스 서비스입니다. \nhttps://aws.amazon.com/ko/about-aws/whats-new/2021/10/amazon-rds-custom-oracle\n/ \n \n참고: \nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/rds-custom.html \nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/working-with-custom-oracl\ne.html", "answer_choice": "C"}, "134": {"q_num": 134, "question": "한 회사에서 애플리케이션을 서버리스 솔루션으로 이동하려고 합니다. 서버리스 솔루션은 \nSL 을 사용하여 기존 및 신규 데이터를 분석해야 합니다. 회사는 데이터를 Amazon S3 \n버킷에 저장합니다. 데이터는 암호화가 필요하며 다른 AWS 리전에 복제해야 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 새 S3 버킷을 생성합니다. 데이터를 새 S3 버킷에 로드합니다. S3 교차 리전 \n복제(CRR)를 사용하여 암호화된 객체를 다른 리전의 S3 버킷에 복제합니다. AWS KMS \n다중 리전 kay(SSE-KMS)로 서버 측 암호화를 사용합니다. Amazon Athena 를 사용하여 \n데이터를 쿼리합니다. \nB. 새 S3 버킷을 생성합니다. 데이터를 새 S3 버킷에 로드합니다. S3 교차 리전 \n복제(CRR)를 사용하여 암호화된 객체를 다른 리전의 S3 버킷에 복제합니다. AWS KMS \n다중 리전 키(SSE-KMS)로 서버 측 암호화를 사용합니다. Amazon RDS\n를 사용하여 \n데이터를 쿼리합니다. \nC. 기존 S3 버킷에 데이터를 로드합니다. S3 교차 리전 복제(CRR)를 사용하여 암호화된 \n\n객체를 다른 리전의 S3 버킷에 복제합니다. Amazon S3 관리형 암호화 키(SSE-S3)로 서버 \n측 암호화를 사용합니다. Amazon Athena 를 사용하여 데이터를 쿼리합니다. \nD. 기존 S3 버킷에 데이터를 로드합니다. S3 교차 리전 복제(CRR)를 사용하여 암호화된 \n객체를 다른 리전의 S3 버킷에 복제합니다. Amazon S3 관리형 암호화 키(SSE-S3)로 서버 \n측 암호화를 사용합니다. Amazon RDS 를 사용하여 데이터를 쿼리합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/85993-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nA(X) : 최소한의 운영 오버헤드라고 했으므로 SSE-KMS 보다는 SSE-S3 가 AWS 에서 다 \n관리하기 때문에 더 적합. 또한 회사는 데이터를 S3 버킷에 저장한다고 했으므로 기존 \n버킷이 있는 것이고, 이는 현재 리전에서 새 S3 버킷을 생성할 필요가 없음을 의미. 그리고 \n지문에서 운영 오버헤드에 대한 언급은 있어도 비용에 대한 언급은 없음. \nB(X) : S3 에 쿼리하는 건 RDS 가 아니라 Athena 가 더 적합. \nC(O) : KMS 필요없이 S3 측에서 암호화할 수 있음. 기존 버킷에 데이터를 로드하고 다른 \n리전으로 복제하는 것이기 때문에 다른 리전에서도 기존 및 신규 데이터를 모두 사용할 수 \n있음. \nD(X) : B 와 같은 이유로 오답.", "answer_choice": "C"}, "135": {"q_num": 135, "question": "회사는 AWS 에서 워크로드를 실행합니다. 회사는 외부 공급자의 서비스에 연결해야 합니다. \n서비스는 공급자의 VPC 에서 호스팅됩니다. 회사 보안 팀에 따르면 연결은 비공개여야 하며 \n대상 서비스로 제한되어야 합니다. 연결은 회사의 VPC 에서만 시작되어야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 회사의 VPC 와 공급자의 VPC 간에 VPC 피어링 연결을 생성합니다. 대상 서비스에 \n연결하도록 라우팅 테이블을 업데이트합니다. \nB. 공급자에게 VPC\n에 가상 프라이빗 게이트웨이를 생성하도록 요청합니다. AWS \nPrivateLink 를 사용하여 대상 서비스에 연결합니다. \nC. 회사의 VPUpdate 라우팅 테이블의 퍼블릭 서브넷에 NAT 게이트웨이를 생성하여 대상 \n서비스에 연결합니다. \nD. 공급자에게 대상 서비스에 대한 VPC 엔드포인트를 생성하도록 요청합니다. AWS \nPrivateLink 를 사용하여 대상 서비스에 연결합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/85994-exam-aws-certified-solut\n\nions-architect-associate-saa-c03/ \n \n설명: \nA(X) : 대상 서비스로 제한되어야 한다는 조건 불충족. VPC 내의 특정 애플리케이션이나 \n서비스에 연결하려면 PrivateLInk 가 필요. 또한 연결은 회사의 VPC 에서만 시작되어야 \n한다는 점 불충족. \n설명1: \nVPC 피어링을 사용하면 VPC 를 비공개로 연결할 수 있지만 AWS PrivateLink 를 사용하면 \nVPC 의 애플리케이션이나 서비스를 VPC 피어링 연결에서 연결할 수 있는 엔드포인트로 \n구성할 \n수 \n있습니다. \n(https://docs.aws.amazon.com/ko_kr/vpc/latest/userguide/vpc-peering.html) \nB(X) : Virtual Private Gateway 는 VPN 엔드포인트. \n가상 프라이빗 게이트웨이는 단일 VPC 에 연결할 수 있는 사이트 간 VPN 연결의 Amazon \n측 VPN 엔드포인트입니다. \nhttps://docs.aws.amazon.com/ko_kr/vpn/latest/s2svpn/VPC_VPN.html \nC(X) : 대상 서비스로 제한되어야 한다는 조건 불충족. 퍼블릭 서브넷의 NAT 게이트웨이는 \n퍼블릭 NAT 게이트웨이로서, IGW, VPC, 온프레미스 네트워크에 연결할 수 있지만 특정 \n서비스에만 접속하도록 할 수 있다는 건 없음. \n\"\"퍼블릭 서브넷에서 퍼블릭 NAT 게이트웨이를 생성하고 생성 시 탄력적 IP 주소를 NAT \n게이트웨이와 연결해야 합니다. 트래픽을 NAT 게이트웨이에서 VPC 용 인터넷 게이트웨이로 \n라우팅합니다. 또는 퍼블릭 NAT 게이트웨이를 사용하여 다른 VPC 또는 온프레미스 \n네트워크에 연결할 수 있습니다. \nhttps://docs.aws.amazon.com/ko_kr/vpc/latest/userguide/vpc-nat-gateway.html \nD(O) : A 번 참고.", "answer_choice": "D"}, "136": {"q_num": 136, "question": "회사는 \n온프레미스 \nPostgreSQL \n데이터베이스를 \nAmazon \nAurora \nPostgreSQL\n로 \n마이그레이션하고 \n있습니다. \n온-프레미스 \n데이터베이스는 \n온라인 \n상태를 \n유지하고 \n마이그레이션 중에 액세스할 수 있어야 합니다. Aurora 데이터베이스는 온프레미스 \n데이터베이스와 동기화된 상태를 유지해야 합니다. \n이러한 요구 사항을 충족하기 위해 솔루션 설계자가 취해야 하는 조치의 조합은 무엇입니까? \n(2 개를 선택하세요.) \nA. 지속적인 복제 작업을 만듭니다. \nB. 온프레미스 데이터베이스의 데이터베이스 백업을 생성합니다. \nC. AWS Database Migration Service(AWS DMS) 복제 서버를 생성합니다. \n\nD. AWS Schema Conversion Tool(AWS SCT)을 사용하여 데이터베이스 스키마를 \n변환합니다. \nE. 데이터베이스 동기화를 모니터링하는 Amazon EventBridge(Amazon CloudWatch Events) \n규칙을 생성합니다.", "answer_block": "Answer: A, C \nhttps://www.examtopics.com/discussions/amazon/view/85438-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nA(O) : ongoing replication(진행중인 복제)은 CDC(변경 데이터 캡처)라고도 하며 소스 \n데이터 \n스토어에서 \n진행 \n중인 \n변경 \n사항을 \n복제할 \n때 \n이 \n프로세스를 \n사용. \n(https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Task.CDC.html) \n이는 동기화된 상태를 만들어줌. \"AWS DMS 를 사용하면 일회성 마이그레이션을 수행하고 \n지속적인 변경 사항을 복제하여 소스와 대상을 동기화 상태로 유지할 수 있습니다. \nhttps://docs.aws.amazon.com/dms/latest/userguide/Welcome.html \nC(O) : DMS 는 대상이 소스와 동기화된 상태를 유지하도록 지속적 복제를 지원하지만, \nSCT 는 그렇지 않습니다. AWS Database Migration Service(DMS)는 다양한 동종 및 이기종 \n데이터 복제를 지원합니다. \nhttps://aws.amazon.com/ko/dms/faqs/?refid=bef7080f-573e-4a75-b22b-85f316173744 \n \n설명2: \nAWS Database Migration Service 는 Oracle 에서 Oracle 로의 동종 마이그레이션은 물론 \nOracle 또는 Microsoft SQL Server 에서 Amazon Aurora 로의 서로 다른 데이터베이스 \n플랫폼 간의 이기종 마이그레이션을 지원합니다. AWS Database Migration Service 를 \n사용하면 지원되는 소스에서 지원되는 대상으로 짧은 지연 시간으로 데이터를 지속적으로 \n복제할 수도 있습니다. 예를 들어 여러 소스에서 Amazon Simple Storage Service(Amazon \nS3)로 복제하여 가용성과 확장성이 뛰어난 데이터 레이크 솔루션을 구축할 수 있습니다. \nAmazon Redshift 로 데이터를 스트리밍하여 데이터베이스를 페타바이트 규모의 데이터 \n웨어하우스로 통합할 수도 있습니다. 지원되는 소스 및 대상 데이터베이스에 대해 자세히 \n알아보세요. \nhttps://aws.amazon.com/dms/", "answer_choice": "A"}, "137": {"q_num": 137, "question": "회사는 AWS Organizations 를 사용하여 각 사업부에 대한 전용 AWS 계정을 생성하여 요청 \n시 각 사업부의 계정을 독립적으로 관리합니다. 루트 이메일 수신자가 한 계정의 루트 \n\n사용자 이메일 주소로 전송된 알림을 놓쳤습니다. 회사는 향후 모든 알림을 놓치지 않기를 \n원합니다. 향후 알림은 계정 관리자로 제한되어야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. AWS 계정 루트 사용자 이메일 주소로 전송되는 알림 이메일 메시지를 조직의 모든 \n사용자에게 전달하도록 회사 이메일 서버를 구성합니다. \nB. 모든 AWS 계정 루트 사용자 이메일 주소를 알림에 응답할 수 있는 소수의 관리자에게 \n전달되는 배포 목록으로 구성합니다. AWS Organizations 콘솔에서 또는 프로그래밍 \n방식으로 AWS 계정 대체 연락처를 구성합니다. \nC. 경보를 모니터링하고 해당 경보를 적절한 그룹에 전달할 책임이 있는 한 명의 \n관리자에게 모든 AWS 계정 루트 사용자 이메일 메시지를 보내도록 구성합니다. \nD. 동일한 루트 사용자 이메일 주소를 사용하도록 기존의 모든 AWS 계정과 새로 생성된 \n모든 계정을 구성합니다. AWS Organizations 콘솔에서 또는 프로그래밍 방식으로 AWS \n계정 대체 연락처를 구성합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/85997-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nA(X) : 향후 알림은 계정 관리자로 제한되어야 한다고 했으므로 오답. \nB(O) : AWS Organizations 콘솔에서 또는 AWS CLI 또는 AWS SDK 를 사용하여 프로그래밍 \n방식으로 조직 내 계정의 대체 연락처를 업데이트할 수 있습니다. 조직의 관리 계정을 \n사용하여 조직의 모든 계정에 대한 계정 설정을 보고 편집할 수 있습니다. 기본 계정 \n소유자는 루트 계정의 이메일에 대한 모든 이메일 통신을 계속 수신합니다. \nhttps://docs.aws.amazon.com/accounts/latest/reference/manage-acct-update-contact-\nalternate.html \nC(X) : 루트 이메일 수신자가 한 계정의 루트 사용자 이메일 주소로 전송된 알림을 \n놓쳤다고 했는데, 선택지 C 의 방식은 기존의 방식과 동일함. \nD(X) : 향후 알림은 계정 관리자로 제한되어야 한다고 했으므로 오답. \n \n참고 \nhttps://docs.aws.amazon.com/ko_kr/organizations/latest/userguide/orgs_best-practices_\nmgmt-acct.html#best-practices_mgmt-acct_email-address", "answer_choice": "B"}, "138": {"q_num": 138, "question": "회사는 AWS 에서 전자 상거래 애플리케이션을 실행합니다. 모든 새 주문은 단일 가용 \n\n영역의 Amazon EC2 인스턴스에서 실행되는 RabbitMQ 대기열에 마사지로 게시됩니다. \n이러한 메시지는 별도의 EC2 인스턴스에서 실행되는 다른 애플리케이션에서 처리됩니다. \n이 애플리케이션은 다른 EC2 인스턴스의 PostgreSQL 데이터베이스에 세부 정보를 \n저장합니다. 모든 EC2 인스턴스는 동일한 가용 영역에 있습니다. \n회사는 최소한의 운영 오버헤드로 최고의 가용성을 제공하도록 아키텍처를 재설계해야 \n합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. \n대기열을 \nAmazon \nMQ\n에서 \nRabbitMQ \n인스턴스의 \n중복 \n쌍(활성/대기)으로 \n마이그레이션합니다. 애플리케이션을 호스팅하는 EC2 인스턴스에 대한 다중 AZ Auto \nScaling 그룹을 생성합니다. PostgreSQL 데이터베이스를 호스팅하는 EC2 인스턴스에 대해 \n다른 다중 AZ Auto Scaling 그룹을 생성합니다. \nB. \n대기열을 \nAmazon \nMQ\n에서 \nRabbitMQ \n인스턴스의 \n중복 \n쌍(활성/대기)으로 \n마이그레이션합니다. 애플리케이션을 호스팅하는 EC2 인스턴스에 대한 다중 AZ Auto \nScaling 그룹을 생성합니다. PostgreSQL 용 Amazon RDS 의 다중 AZ 배포에서 실행하도록 \n데이터베이스를 마이그레이션합니다. \nC. RabbitMQ 대기열을 호스팅하는 EC2 인스턴스용 다중 AZ Auto Scaling 그룹을 \n생성합니다. 애플리케이션을 호스팅하는 EC2 인스턴스에 대해 다른 다중 AZ Auto Scaling \n그룹을 생성합니다. PostgreSQL\n용 Amazon RDS\n의 다중 AZ 배포에서 실행하도록 \n데이터베이스를 마이그레이션합니다. \nD. RabbitMQ 대기열을 호스팅하는 EC2 인스턴스용 다중 AZ Auto Scaling 그룹을 \n생성합니다. 애플리케이션을 호스팅하는 EC2 인스턴스에 대해 다른 다중 AZ Auto Scaling \n그룹을 생성합니다. PostgreSQL 데이터베이스를 호스팅하는 EC2 인스턴스에 대한 세 번째 \n다중 AZ Auto Scaling 그룹을 생성합니다.", "answer_block": "Answer: B  \nhttps://www.examtopics.com/discussions/amazon/view/85999-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \n선택지는 활성/대기 인스턴스 쌍을 사용하는 A,B 와 대기열 호스팅 방식을 사용하는 C,D 로 \n나눠짐. \n활성/대기 방식은 활성 인스턴스가 다운되어도 대기 인스턴스가 활성 인스턴스를 대체할 수 \n있으므로 가용성이 높은 방식. 따라서 A,B 둘 중 하나가 답. \nPostgreSQL 데이터베이스를 사용하는 A 보다는 Amazon RDS for Postgre 를 사용하는 B 가 \n운영 오버헤드 절감 효과가 큼. \nAmazon RDS 를 사용하면 클라우드에서 PostgreSQL 배포를 손쉽게 설정, 운영 및 확장할 \n수 있습니다. Amazon RDS 에서는 비용 효율적이고 크기 조정 가능한 하드웨어 용량을 갖춘 \n\n확장 가능한 PostgreSQL\n을 몇 분 만에 배포할 수 있습니다. Amazon RDS\n에서는 \nPostgreSQL 소프트웨어 설치 및 업그레이드, 스토리지 관리, 고가용성 및 읽기 처리량을 \n위한 복제, 재해 복구용 백업 등 복잡하고 시간 소모적인 관리 작업을 관리합니다. \nhttps://aws.amazon.com/ko/rds/postgresql/ \n \n설명2: \nAmazon MQ 로 마이그레이션하면 대기열 관리의 오버헤드가 줄어듭니다. C 와 D 는 \n오답됩니다. \nA 와 B 사이에서 결정한다는 것은 EC2 용 AutoScaling 그룹 또는 Postgress 용 RDS(모두 \n다중 \nAZ)로 \n이동하기로 \n결정하는 \n것을 \n의미합니다. \nRDS \n옵션은 \n필요한 \n도구와 \n소프트웨어를 서비스로 제공하므로 운영에 미치는 영향이 적습니다. 예를 들어 읽기 \n복제본과 같은 추가 노드를 DB 에 추가하려는 노력을 고려하십시오. \nhttps://docs.aws.amazon.com/amazon-mq/latest/developer-guide/activestandby-broker\n-deployment.html", "answer_choice": "B"}, "139": {"q_num": 139, "question": "보고 팀은 Amazon S3 버킷에서 매일 파일을 수신합니다. 보고 팀은 이 초기 S3 버킷의 \n파일을 수동으로 검토하고 Amazon QuickSight 와 함께 사용하기 위해 매일 같은 시간에 \n분석 S3 버킷으로 복사합니다. 추가 팀이 초기 S3 버킷에 더 큰 크기의 더 많은 파일을 \n보내기 시작했습니다. \n보고 팀은 파일이 초기 S3 버킷에 들어갈 때 자동으로 분석 S3 버킷을 이동하려고 합니다. \n또한 보고 팀은 AWS Lambda 함수를 사용하여 복사된 데이터에서 패턴 일치 코드를 \n실행하려고 합니다. 또한 보고 팀은 데이터 파일을 Amazon SageMaker Pipelines\n의 \n파이프라인으로 보내려고 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 해야 \n합니까? \nA. 분석 S3 버킷에 파일을 복사하는 Lambda 함수를 생성합니다. 분석 S3 버킷에 대한 S3 \n이벤트 알림을 생성합니다. 이벤트 알림의 대상으로 Lambda 및 SageMaker 파이프라인을 \n구성합니다. s3:ObjectCreated:Put 을 이벤트 유형으로 구성합니다. \nB. \n분석 \nS3 \n버킷에 \n파일을 \n복사하는 \nLambda \n함수를 \n생성합니다. \nAmazon \nEventBridge(Amazon CloudWatch Events)에 이벤트 알림을 보내도록 분석 S3 버킷을 \n구성합니다. EventBridge(CloudWatch 이벤트)에서 ObjectCreated 규칙을 구성합니다. \n규칙의 대상으로 Lambda 및 SageMaker 파이프라인을 구성합니다. \nC. S3 버킷 간에 S3 복제를 구성합니다. 분석 S3 버킷에 대한 S3 이벤트 알림을 \n생성합니다. 이벤트 알림의 대상으로 Lambda 및 SageMaker 파이프라인을 구성합니다. \n\ns3:ObjectCreated:Put 을 이벤트 유형으로 구성합니다. \nD. S3 버킷 간에 S3 복제를 구성합니다. Amazon EventBridge(Amazon CloudWatch \nEvents)에 이벤트 알림을 보내도록 분석 S3 버킷을 구성합니다. EventBridge(CloudWatch \n이벤트)에서 ObjectCreated 규칙을 구성합니다. 규칙의 대상으로 Lambda 및 SageMaker \n파이프라인을 구성합니다.", "answer_block": "Answer: D  \nhttps://www.examtopics.com/discussions/amazon/view/85872-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nS3 복제를 사용하면 S3 버킷 간에 자동으로 복제됩니다. S3 이벤트를 CloudWatch \nEvents 에서 감지하여 특정 동작을 수행할 수 있습니다. Amazon S3 복제를 사용하면 S3 \nCRR(교차 리전 복제)을 사용하여 서로 다른 AWS 리전에서, 또는 S3 SRR(동일 리전 \n복제)을 사용하여 같은 AWS 리전 내의 버킷 간에 S3 객체를 자동으로 복제하도록 Amazon \nS3 를 구성할 수 있습니다.  https://aws.amazon.com/ko/s3/features/replication/ \nAmazon S3 는 버킷에서 특정 이벤트가 발생할 때마다 Amazon EventBridge 에 이벤트를 \n보낼 수 있습니다. 이벤트 유형 : Object Created \nhttps://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/EventBridge.html) \nAmazon EventBridge 는 Amazon SageMaker 의 상태 변경 이벤트를 모니터링합니다. \nEventBridge 를 사용하면 SageMaker 를 자동화하고 교육 작업 상태 변경 또는 끝점 상태 \n변경과 같은 이벤트에 자동으로 응답할 수 있습니다. 자동으로 트리거될 수 있는 작업의 몇 \n가지 예는 다음과 같습니다. AWS Lambda 함수 호출 \nhttps://docs.aws.amazon.com/sagemaker/latest/dg/automating-sagemaker-with-eventbr\nidge.html \n \n설명2: \n이 솔루션은 파일을 자동으로 이동하고, 복사된 데이터에서 Lambda 함수를 실행하고, \n최소한의 운영 오버헤드로 데이터 파일을 SageMaker Pipelines 로 보내는 요구 사항을 \n충족합니다. S3 복제는 파일이 도착하면 초기 S3 버킷에서 분석 S3 버킷으로 파일을 \n복사할 수 있습니다. 분석 S3 버킷은 객체가 생성될 때 Amazon EventBridge(Amazon \nCloudWatch Events)에 이벤트 알림을 보낼 수 있습니다. EventBridge 는 Lambda 및 \nSageMaker \n파이프라인을 \nObjectCreated \n규칙의 \n대상으로 \n트리거할 \n수 \n있습니다. \nLambda 는 복사된 데이터에서 패턴 일치 코드를 실행할 수 있으며 SageMaker Pipelines 는 \n데이터 파일로 파이프라인을 실행할 수 있습니다. \n \nS3 복제가 자동으로 수행할 수 있는 경우 분석 S3 버킷에 파일을 복사하는 Lambda \n\n함수를 생성할 필요가 없기 때문에 옵션 A 는 올바르지 않습니다. 또한 Lambda 함수를 \n관리하기 위해 운영 오버헤드를 추가합니다. \n \nS3 복제가 자동으로 수행할 수 있는 경우 분석 S3 버킷에 파일을 복사하는 Lambda \n함수를 생성할 필요가 없기 때문에 옵션 B 는 올바르지 않습니다. 또한 Lambda 함수를 \n관리하기 위해 운영 오버헤드를 추가합니다. \n \n여러 대상과 함께 S3 이벤트 알림을 사용하면 이벤트가 너무 많은 경우 제한 또는 전달 \n실패가 발생할 수 있으므로 옵션 C 는 올바르지 않습니다. \n \n참조: \nhttps://aws.amazon.com/ko/blogs/machine-learning/automate-feature-engineering-pipe\nlines-with-amazon-sagemaker/ \nhttps://docs.aws.amazon.com/sagemaker/latest/dg/automating-sagemaker-with-eventbr\nidge.html \nhttps://aws.amazon.com/ko/about-aws/whats-new/2021/04/new-options-trigger-amazo\nn-sagemaker-pipeline-executions/", "answer_choice": "D"}, "140": {"q_num": 140, "question": "솔루션 설계자는 회사가 AWS 에서 애플리케이션을 실행하는 비용을 최적화할 수 있도록 \n도와야 합니다. 애플리케이션은 아키텍처 내 컴퓨팅을 위해 Amazon EC2 인스턴스, AWS \nFargate 및 AWS Lambda 를 사용합니다. \nEC2 인스턴스는 애플리케이션의 데이터 수집 계층을 실행합니다. EC2 사용은 산발적이고 \n예측할 수 없습니다. EC2 인스턴스에서 실행되는 워크로드는 언제든지 중단될 수 있습니다. \n애플리케이션 프런트 엔드는 Fargate 에서 실행되고 Lambda 는 API 계층을 제공합니다. \n프론트엔드 활용도와 API 계층 활용도는 내년에 예측할 수 있습니다. \n이 애플리케이션을 호스팅하는 데 가장 비용 효율적인 솔루션을 제공하는 구매 옵션 조합은 \n무엇입니까? (2 개 선택) \nA. 데이터 수집 계층에 스팟 인스턴스 사용 \nB. 데이터 수집 계층에 온디맨드 인스턴스 사용 \nC. 프런트 엔드 및 API 계층에 대한 1 년 Compute Savings Plan 을 구매합니다. \nD. 데이터 수집 계층에 대한 1 년 전체 선결제 예약 인스턴스를 구매합니다. \nE. 프런트 엔드 및 API 계층을 위한 1 년 EC2 인스턴스 Savings Plan 을 구매합니다.", "answer_block": "Answer: A, C \nhttps://www.examtopics.com/discussions/amazon/view/86083-exam-aws-certified-solut\n\nions-architect-associate-saa-c03/ \n \n설명1: \n・EC2 인스턴스에서 실행되는 워크로드는 언제든지 중단될 수 있습니다 = 스팟 인스턴스 \n・프론트엔드 활용도와 API 계층 활용도는 내년에 예측할 수 있습니다 = Savings Plans \nSavings Plans 는 1 년 또는 3 년 기간의 일정 사용량 약정(시간당 USD 요금으로 측정)을 \n조건으로 Amazon EC2, AWS Lambda 및 AWS Fargate 사용량에 대해 저렴한 요금을 \n제공하는 유연한 요금 모델입니다. Savings Plans 에 가입하면 약정 사용량까지 할인된 \nSavings Plans 요금을 적용받습니다. \nhttps://aws.amazon.com/ko/savingsplans/compute-pricing/ \n・그 중에서도 Compute Savings Plans 가 정답. \nCompute Savings Plans 는 최대 66%까지 비용을 절감할 수 있는 가장 유연한 요금 \n모델입니다. 이 플랜은 인스턴스 패밀리, 크기, AZ, 리전, OS 또는 테넌시와 관계없이 EC2 \n인스턴스 사용량에 적용되며, Fargate 또는 Lambda 사용량에도 적용됩니다. \nhttps://aws.amazon.com/ko/savingsplans/compute-pricing/ \n정답은 A,C. \n \n설명2: \nEC2 instance Savings Plan 은 72%, Compute Savings Plans 는 66%를 절약합니다. 그러나 \n링크에 따르면 \"Compute Savings Plans 는 최고의 유연성을 제공하고 비용을 최대 66%까지 \n줄이는 데 도움이 됩니다. \n이러한 요금제는 인스턴스 패밀리, 크기, AZ, 리전, OS 또는 테넌시에 관계없이 EC2 \n인스턴스 사용에 자동으로 적용되며 Fargate 및 Lambda 사용에도 적용됩니다.\" EC2 \n인스턴스 절약 계획은 Fargate 또는 Lambda 에 적용되지 않습니다.", "answer_choice": "A"}, "141": {"q_num": 141, "question": "한 회사는 사용자에게 글로벌 속보, 지역 경보 및 날씨 업데이트를 제공하는 웹 기반 \n포털을 운영합니다. 포털은 정적 콘텐츠와 동적 콘텐츠를 혼합하여 각 사용자에게 개인화된 \n보기를 제공합니다. 콘텐츠는 ALB(Application Load Balancer) 뒤의 Amazon EC2 \n인스턴스에서 실행되는 API 서버를 통해 HTTPS 를 통해 제공됩니다. 회사는 포털이 이 \n콘텐츠를 가능한 한 빨리 전 세계 사용자에게 제공하기를 원합니다. \n솔루션 설계자는 모든 사용자의 대기 시간을 최소화하도록 애플리케이션을 어떻게 설계해야 \n합니까? \nA. 단일 AWS 리전에 애플리케이션 스택을 배포합니다. Amazon CloudFront 를 사용하여 \nALB 를 오리진으로 지정하여 모든 정적 및 동적 콘텐츠를 제공합니다. \n\nB. 두 AWS 리전에 애플리케이션 스택을 배포합니다. Amazon Route 53 지연 시간 라우팅 \n정책을 사용하여 가장 가까운 리전의 ALB 에서 모든 콘텐츠를 제공합니다. \nC. 단일 AWS 리전에 애플리케이션 스택을 배포합니다. Amazon CloudFront 를 사용하여 \n정적 콘텐츠를 제공합니다. ALB 에서 직접 동적 콘텐츠를 제공합니다. \nD. 두 AWS 리전에 애플리케이션 스택을 배포합니다. Amazon Route 53 지리적 위치 라우팅 \n정책을 사용하여 가장 가까운 리전에서 ALB 의 모든 콘텐츠를 제공합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/85439-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nALB 를 오리진으로 사용할 수 있음 \n원본이 하나 이상의 Amazon EC2 인스턴스에서 호스트되는 하나 이상의 HTTP 서버(웹 \n서버)인 경우 Application Load Balancer 를 사용하여 인스턴스에 트래픽을 분산할 수 \n있습니다. Application Load Balancer 를 CloudFront 의 원본으로 사용하는 방법에 대한 \n자세한 내용은 \nhttps://docs.aws.amazon.com/ko_kr/AmazonCloudFront/latest/DeveloperGuide/Download\nDistS3AndCustomOrigins.html#concept_elb_origin", "answer_choice": "A"}, "142": {"q_num": 142, "question": "게임 회사는 고가용성 아키텍처를 설계하고 있습니다. 애플리케이션은 수정된 Linux \n커널에서 실행되며 UDP 기반 트래픽만 지원합니다. 회사는 최상의 사용자 경험을 제공하기 \n위해 프런트 엔드 계층이 필요합니다. 해당 계층은 대기 시간이 짧고 가장 가까운 엣지 \n로케이션으로 트래픽을 라우팅하고 애플리케이션 엔드포인트에 진입하기 위한 고정 IP \n주소를 제공해야 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. 요청을 Application Load Balancer 로 전달하도록 Amazon Route 53 을 구성합니다. AWS \nApplication Auto Scaling 의 애플리케이션에 AWS Lambda 를 사용합니다. \nB. 요청을 Network Load Balancer 로 전달하도록 Amazon CloudFront 를 구성합니다. AWS \nApplication Auto Scaling 그룹의 애플리케이션에 AWS Lambda 를 사용합니다. \nC. 요청을 Network Load Balancer 로 전달하도록 AWS Global Accelerator 를 구성합니다. \nEC2 Auto Scaling 그룹의 애플리케이션에 Amazon EC2 인스턴스를 사용합니다. \nD. 요청을 Application Load Balancer 로 전달하도록 Amazon API Gateway 를 구성합니다. \nEC2 Auto Scaling 그룹의 애플리케이션에 Amazon EC2 인스턴스를 사용합니다.", "answer_block": "Answer: C \n\nhttps://www.examtopics.com/discussions/amazon/view/86667-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nTCP/UDP+엔드포인트에 입력할 수 있는 고정 IP 주소를 가져야 한다는 대목에서 Global \nAccelerator 임을 유추할 수 있음.  \n \n설명2: \nAWS Global Accelerator 와 Amazon CloudFront 는 AWS 글로벌 네트워크와 전 세계 엣지 \n로케이션을 사용하는 별도의 서비스입니다. CloudFront 는 캐시 가능한 콘텐츠(예: 이미지 \n및 비디오)와 동적 콘텐츠(예: API 가속 및 동적 사이트 제공) 모두의 성능을 향상시킵니다. \nGlobal Accelerator 는 하나 이상의 AWS 리전에서 실행되는 애플리케이션에 대해 에지의 \n패킷을 프록시하여 TCP 또는 UDP 를 통해 광범위한 애플리케이션의 성능을 개선합니다. \nGlobal Accelerator 는 게임(UDP), IoT(MQTT) 또는 VoIP 와 같은 비HTTP 사용 사례와 특히 \n고정 IP 주소 또는 결정론적이고 빠른 지역 장애 조치가 필요한 HTTP 사용 사례에 \n적합합니다. 두 서비스 모두 DDoS 보호를 위해 AWS Shield 와 통합됩니다.", "answer_choice": "C"}, "143": {"q_num": 143, "question": "회사에서 기존 온프레미스 모놀리식 애플리케이션을 AWS 로 마이그레이션하려고 합니다. \n회사는 프론트엔드 코드와 백엔드 코드를 최대한 많이 유지하려고 합니다. 그러나 회사는 \n응용 프로그램을 더 작은 응용 프로그램으로 나누기를 원합니다. 다른 팀에서 각 \n애플리케이션을 관리합니다. 회사는 운영 오버헤드를 최소화하는 확장성이 뛰어난 솔루션이 \n필요합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. AWS Lambda\n에서 애플리케이션을 호스팅합니다. 애플리케이션을 Amazon API \nGateway 와 통합합니다. \nB. AWS Amplify 를 사용하여 애플리케이션을 호스팅합니다. AWS Lambda 와 통합된 Amazon \nAPI Gateway API 에 애플리케이션을 연결합니다. \nC. Amazon EC2 인스턴스에서 애플리케이션을 호스팅합니다. Auto Scaling 그룹의 EC2 \n인스턴스를 대상으로 하여 Application Load Balancer 를 설정합니다. \nD. Amazon Elastic Container Service(Amazon ECS)에서 애플리케이션을 호스팅합니다. \nAmazon ECS 를 대상으로 하여 Application Load Balancer 를 설정합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/86473-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n\n \n설명: \nECS\n는 컨테이너화된 애플리케이션을 실행하기 위해 확장성이 뛰어난 관리형 환경을 \n제공하여 운영 오버헤드를 줄입니다. ECS 를 대상으로 ALB 를 설정하면 확장성과 가용성을 \n위해 애플리케이션의 여러 인스턴스에 트래픽을 분산할 수 있습니다. 이 솔루션을 사용하면 \n여러 팀이 각 애플리케이션을 독립적으로 관리하여 팀 자율성과 효율적인 개발을 촉진할 수 \n있습니다. \nA\n는 이벤트 기반 및 서버리스 워크로드에 더 적합합니다. 모놀리식 애플리케이션을 \n마이그레이션하고 기존 코드베이스를 유지 관리하는 데 이상적인 선택이 아닐 수 있습니다. \nB 는 Lambda 및 API Gateway 와 통합되므로 애플리케이션을 더 작은 애플리케이션으로 \n분할하고 독립적으로 관리하는 데 필요한 유연성을 제공하지 못할 수 있습니다. \nC 는 인프라 관리 및 수동 확장을 포함합니다. ECS 와 같은 컨테이너 서비스를 사용할 \n때보다 운영 오버헤드가 높아질 수 있습니다.", "answer_choice": "D"}, "144": {"q_num": 144, "question": "한 회사는 최근 글로벌 전자 상거래 애플리케이션의 데이터 저장소로 Amazon Aurora 를 \n사용하기 시작했습니다. 대규모 보고서가 실행되면 개발자는 전자상거래 애플리케이션의 \n성능이 좋지 않다고 보고합니다. Amazon CloudWatch 의 지표를 검토한 후 솔루션 설계자는 \n월별 \n보고서가 \n실행될 \n때 \nReadIOPS \n및 \nCPUUtilizalion \n지표가 \n급증하고 \n있음을 \n발견했습니다. \n가장 비용 효율적인 솔루션은 무엇입니까? \nA. 월별 보고를 Amazon Redshift 로 마이그레이션합니다. \nB. 월별 보고를 Aurora 복제본으로 마이그레이션합니다. \nC. Aurora 데이터베이스를 더 큰 인스턴스 클래스로 마이그레이션합니다. \nD. Aurora 인스턴스에서 프로비저닝된 IOPS 를 늘립니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/86781-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Replication.ht\nml \n#Aurora.Replication.Replicas \nAurora \n복제본에는 \n두 \n가지 \n주요 \n목적이 \n있습니다. \n애플리케이션에 대한 읽기 작업을 확장하기 위해 쿼리를 실행할 수 있습니다. 일반적으로 \n클러스터의 리더 엔드포인트에 연결하여 이를 수행합니다. 이렇게 하면 Aurora\n는 \n\n클러스터에 있는 만큼 많은 Aurora 복제본에 읽기 전용 연결에 대한 로드를 분산시킬 수 \n있습니다. Aurora 복제본은 가용성을 높이는 데도 도움이 됩니다. 클러스터의 라이터 \n인스턴스를 사용할 수 없게 되면 Aurora 는 리더 인스턴스 중 하나를 자동으로 승격시켜 새 \n라이터로 대신합니다. \nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Overview.html \n \n설명2: \nReadIOPS 가 증가하고 있다고 했으므로 Aurora replica 를 통한 읽기 부하 분산 가능 \n\"Aurora 는 클러스터에 있는 만큼의 Aurora 복제본에 읽기 전용 연결에 대한 로드를 분산할 \n수 있습니다.  \nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Replication.ht\nml#Aurora.Replication.Replicas", "answer_choice": "B"}, "145": {"q_num": 145, "question": "회사는 단일 Amazon EC2 온디맨드 인스턴스에서 웹 사이트 분석 애플리케이션을 \n호스팅합니다. 분석 소프트웨어는 PHP 로 작성되었으며 MySQL 데이터베이스를 사용합니다. \n분석 소프트웨어, PHP\n를 제공하는 웹 서버 및 데이터베이스 서버는 모두 EC2 \n인스턴스에서 호스팅됩니다. 응용 프로그램은 바쁜 시간 동안 성능 저하 징후를 보이고 5xx \n오류를 표시합니다. 회사는 애플리케이션을 원활하게 확장해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족합니까? \nA. 데이터베이스를 Amazon RDS for MySQL DB 인스턴스로 마이그레이션합니다. 웹 \n애플리케이션의 AMI 를 생성합니다. AMI 를 사용하여 두 번째 EC2 온디맨드 인스턴스를 \n시작합니다. Application Load Balancer 를 사용하여 각 EC2 인스턴스에 로드를 분산합니다. \nB. 데이터베이스를 Amazon RDS for MySQL DB 인스턴스로 마이그레이션합니다. 웹 \n애플리케이션의 AMI 를 생성합니다. AMI 를 사용하여 두 번째 EC2 온디맨드 인스턴스를 \n시작합니다. Amazon Route 53 가중 라우팅을 사용하여 두 EC2 인스턴스에 로드를 \n분산합니다. \nC. 데이터베이스를 Amazon Aurora MySQL DB 인스턴스로 마이그레이션합니다. AWS \nLambda 함수를 생성하여 EC2 인스턴스를 중지하고 인스턴스 유형을 변경합니다. CPU \n사용률이 75%를 초과할 때 Lambda 함수를 호출하는 Amazon CloudWatch 경보를 \n생성합니다. \nD. 데이터베이스를 Amazon Aurora MySQL DB 인스턴스로 마이그레이션합니다. 웹 \n애플리케이션의 AMI 를 생성합니다. 시작 템플릿에 AMI 를 적용합니다. 시작 템플릿으로 \nAuto Scaling 그룹 생성 스팟 집합을 사용하도록 시작 템플릿을 구성합니다. Auto Scaling \n그룹에 Application Load Balancer 를 연결합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/86474-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nA(X) : 두 번째 온디맨드 인스턴스를 생성하기만 하고 Auto Scaling 설정을 안 하므로 \n확장성이 D 에 비해 떨어짐. \nB(X) : Route 53 Weighted Routing 은 각 리소스로 라우팅되는 트래픽 양을 조절하는 기능 \n가중 라우팅을 사용하면 여러 리소스를 단일 도메인 이름(example.com) 또는 하위 도메인 \n이름(acme.example.com)과 연결하고 각 리소스로 라우팅되는 트래픽 양을 선택할 수 \n있습니다. \nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-weighted.h\ntml \nC(X) : CloudWatch 경보는 임계값에 도달하면 자동으로 알림을 보내는 서비스. \n\"\"인스턴스 중 하나에 대한 CloudWatch 지표를 모니터링하는 CloudWatch 경보를 생성할 \n수 있습니다. 지표가 지정된 임계값에 도달하면 CloudWatch\n에서 자동으로 알림을 \n보냅니다. \nhttps://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/using-cloudwatch-create\nalarm.html \nD(O) : 스팟인스턴스라는 점이 걸리긴 하지만 어차피 인스턴스를 중지해서는 안 된다는 \n말이 나온 것도 아니고, Auto Scaling 이 명시되어있으므로 정답에 가장 가까움. \n \n설명2: \n데이터베이스를 Amazon Aurora MySQL\n로 마이그레이션합니다. 이렇게 하면 DB\n가 \n자체적으로 확장됩니다. 조정할 필요 없이 자동으로 크기가 조정됩니다. 시작 템플릿을 \n사용하여 웹 앱의 AMI 를 생성합니다. 이렇게 하면 앱의 향후 인스턴스를 원활하게 생성할 \n수 있습니다. 그런 다음 Auto Scaling 그룹에 추가하면 수요에 따라 확장 및 축소되므로 \n비용을 절약할 수 있습니다. \n스팟 집합을 사용하여 인스턴스를 시작합니다. 이것은 아마존이 적합하다고 판단하는 \n시점에 종료되는 비용으로 스팟 인스턴스가 크게 할인되기 때문에 질문의 \"가장 비용 \n효율적인\" 부분을 해결합니다. 이 부분에 대해서는 약간의 이견이 있기 때문이라고 \n생각합니다. 가장 비용 효율적이지만 아마존이 사용량이 많은 기간에 해당 스팟 인스턴스를 \n종료한다면 끔찍한 선택이 될 것입니다.", "answer_choice": "D"}, "146": {"q_num": 146, "question": "회사는 Application Load Balancer 뒤의 Amazon EC2 온디맨드 인스턴스 그룹에서 \n프로덕션 환경에서 상태 비저장 웹 애플리케이션을 실행합니다. 매일 8\n시간 동안 \n애플리케이션 사용량이 많습니다. 응용 프로그램 사용량은 보통이고 밤새 안정적입니다. \n주말에는 애플리케이션 사용량이 적습니다. \n이 회사는 애플리케이션의 가용성에 영향을 주지 않으면서 EC2 비용을 최소화하려고 \n합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 전체 워크로드에 대해 스팟 인스턴스를 사용합니다. \nB. 기본 사용량 수준에 대해 예약 인스턴스를 사용합니다. 애플리케이션에 필요한 추가 \n용량에 대해 스팟 인스턴스를 사용합니다. \nC. 기준 사용 수준에 대해 온디맨드 인스턴스를 사용합니다. 애플리케이션에 필요한 추가 \n용량에 대해 스팟 인스턴스를 사용합니다. \nD. 기본 사용량 수준에 대해 전용 인스턴스를 사용합니다. 애플리케이션에 필요한 추가 \n용량에 대해 온디맨드 인스턴스를 사용합니다.", "answer_block": "Answer: B  \nhttps://www.examtopics.com/discussions/amazon/view/86750-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nA(X) : 계속 사용량이 있고, 사용량이 적은 주말에도 꾸준히 사용량은 나오고 있는데 계속 \n작동 중인 걸 스팟인스턴스로 둘 이유가 없음. 스팟 인스턴스는 중지해도 되는 인스턴스에 \n사용되는 인스턴스 유형. 사용량이 많은 시간을 예상할 수 있는 상황에선 예약 인스턴스가 \n적절. \nB(O) : 상태 비저장 애플리케이션이라는 단서가 있으므로 추가 용량에 대해서는 스팟 \n인스턴스를 사용하여 비용 절감 가능. \nC(X) : 기본 사용량 수준은 예상할 수 있으므로 예약 인스턴스가 적절. \nD(X) : Dedicated Instance 는 온디맨드에 비해서도 비용이 많이 들어가는 인스턴스 유형임. \n해당 부분에 대해서는 아래의 링크를 참고할 것. \nhttps://aws.amazon.com/ko/ec2/pricing/on-demand/ \nhttps://aws.amazon.com/ko/ec2/pricing/dedicated-instances/", "answer_choice": "B"}, "147": {"q_num": 147, "question": "회사는 중요한 애플리케이션에 대한 애플리케이션 로그 파일을 10 년 동안 보관해야 합니다. \n애플리케이션 팀은 문제 해결을 위해 지난 달의 로그에 정기적으로 액세스하지만 1 개월 \n이상 된 로그는 거의 액세스하지 않습니다. 애플리케이션은 매월 10TB 이상의 로그를 \n\n생성합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 스토리지 옵션은 무엇입니까? \nA. Amazon S3 에 로그를 저장합니다. AWS Backup 을 사용하여 1 개월 이상 된 로그를 S3 \nGlacier Deep Archive 로 이동합니다. \nB. Amazon S3 에 로그를 저장합니다. S3 수명 주기 정책을 사용하여 1 개월 이상 된 로그를 \nS3 Glacier Deep Archive 로 이동합니다. \nC. Amazon CloudWatch Logs 에 로그를 저장합니다. AWS Backup 을 사용하여 1 개월 이상 \n된 로그를 S3 Glacier Deep Archive 로 이동합니다. \nD. Amazon CloudWatch Logs 에 로그를 저장합니다. Amazon S3 수명 주기 정책을 사용하여 \n1 개월 이상 된 로그를 S3 Glacier Deep Archive 로 이동합니다.", "answer_block": "Answer: B  \nhttps://www.examtopics.com/discussions/amazon/view/86864-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nA(X) : Life Cycle Policy 를 사용하면 되는데 굳이 AWS Backup 까지 동원할 필요가 없음. \nB(O) : 정답. 한 달 후에 로그를 보관하려면 S3 가 필요합니다. CloudWatch Logs 로는 \n그렇게 할 수 없습니다. \nC(X) : CloudWatch Logs 는 스토리지 서비스가 아님. \nD(X) : C 와 같은 이유로 오답.", "answer_choice": "B"}, "148": {"q_num": 148, "question": "회사에는 다음 구성 요소를 포함하는 데이터 수집 워크플로가 있습니다. \n* 새로운 데이터 전송에 대한 알림을 받는 Amazon Simple Notation Service(Amazon SNS) \n주제입니다. \n* 데이터를 처리하고 저장하는 AWS Lambda 함수입니다. \n네트워크 연결 문제로 인해 수집 워크플로가 때때로 실패합니다. 임기가 발생하면 회사에서 \n수동으로 작업을 다시 실행하지 않는 한 해당 데이터가 수집되지 않습니다. \n모든 알림이 최종적으로 처리되도록 하려면 솔루션 설계자가 무엇을 해야 합니까? \nA. 여러 가용 영역에 걸쳐 배포할 Lambda 함수를 구성합니다. \nB. Lambda 함수의 구성을 수정하여 함수에 대한 CPU 및 메모리 할당을 늘립니다. \nC. 재시도 횟수와 재시도 간 대기 시간을 모두 늘리도록 SNS 주제의 재시도 전략을 \n구성합니다. \nD. Amazon Simple Queue Service(Amazon SQS) 대기열을 장애 시 대상으로 구성합니다. \n대기열의 메시지를 처리하도록 Lambda 함수를 수정합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/85424-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n실패한 메시지를 보관할 SQS 대기열이 필요. 정답은 D.  \nhttps://docs.aws.amazon.com/ko_kr/AWSSimpleQueueService/latest/SQSDeveloperGuide\n/sqs-dead-letter-queues.html \nC 같은 경우엔 재시도 전략인데, 'When tenure occurs the corresponding data is not \ningested unless company manually reruns the job' (Tenure 가 발생하면 회사에서 수동으로 \n작업을 다시 실행하지 않는 한 해당 데이터가 수집되지 않습니다.) 라는 대목이 있므로 \nC 는 오답. Amazon SNS 가 메시지 전송을 재시도하는 방식이 전송 정책에 따라 결정됩니다. \n전송 정책이 소진되면 Amazon SNS 는 전송 재시도를 중지하고 배달 못한 편지 대기열이 \n구독에 연결되어 있지 않는 한 메시지를 삭제합니다. \nhttps://docs.aws.amazon.com/ko_kr/sns/latest/dg/sns-message-delivery-retries.html \n \n참고: \nhttps://docs.aws.amazon.com/ko_kr/sns/latest/dg/sns-dead-letter-queues.html", "answer_choice": "D"}, "149": {"q_num": 149, "question": "회사에 이벤트 데이터를 생성하는 서비스가 있습니다. 회사는 AWS 를 사용하여 이벤트 \n데이터를 수신하는 대로 처리하려고 합니다. 데이터는 처리 전반에 걸쳐 유지되어야 하는 \n특정 순서로 작성됩니다. 회사는 운영 오버헤드를 최소화하는 솔루션을 구현하려고 합니다. \n솔루션 설계자는 이를 어떻게 달성해야 합니까? \nA. 메시지를 보관할 Amazon Simple Queue Service(Amazon SQS) FIFO 대기열을 \n생성합니다. 대기열의 메시지를 처리하도록 AWS Lambda 함수를 설정합니다. \nB. 처리할 페이로드가 포함된 알림을 전달하기 위해 Amazon Simple Notification \nService(Amazon SNS) 주제를 생성합니다. AWS Lambda 함수를 구독자로 구성합니다. \nC. 메시지를 보관할 Amazon Simple Queue Service(Amazon SQS) 표준 대기열을 \n생성합니다. 대기열의 메시지를 독립적으로 처리하도록 AWS Lambda 함수를 설정합니다. \nD. 처리할 페이로드가 포함된 알림을 전달하기 위해 Amazon Simple Notification \nService(Amazon SNS) 주제를 생성합니다. Amazon Simple Queue Service(Amazon SQS) \n대기열을 구독자로 구성합니다.", "answer_block": "Answer: A  \nhttps://www.examtopics.com/discussions/amazon/view/86784-exam-aws-certified-solut\n\nions-architect-associate-saa-c03/ \n \n설명 \n자세한 내용은 아래 URL. \nhttps://docs.aws.amazon.com/ko_kr/AWSSimpleQueueService/latest/SQSDeveloperGuide\n/FIFO-queues.html \nFIFO(First-In-First-Out) 대기열은 작업 및 이벤트 순서가 중요하거나 중복을 허용할 수 \n없는 경우 애플리케이션 간의 메시징을 향상하도록 설계되었습니다. FIFO 대기열을 사용할 \n수 있는 상황의 예는 다음과 같습니다. 사용자가 입력한 명령이 올바른 순서로 실행되도록 \n합니다. 올바른 순서로 가격 수정을 전송하여 올바른 제품 가격을 표시합니다. 학생이 \n계정을 등록하기 전에 코스에 등록하지 못하도록 합니다.", "answer_choice": "A"}, "150": {"q_num": 150, "question": "회사는 온프레미스 서버에서 Amazon EC2 인스턴스로 애플리케이션을 마이그레이션하고 \n있습니다. 마이그레이션 설계 요구 사항의 일부로 솔루션 설계자는 인프라 메트릭 경보를 \n구현해야 합니다. CPU 사용률이 단기간에 50% 이상으로 증가하는 경우 회사는 조치를 \n취할 필요가 없습니다. 하지만 CPU 사용률이 50% 이상으로 증가하고 디스크의 읽기 \nIOPS 가 동시에 높다면 회사에서 최대한 빨리 조치를 취해야 합니다. 솔루션 설계자는 또한 \n오경보를 줄여야 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. 가능한 경우 Amazon CloudWatch 복합 경보를 생성합니다. \nB. Amazon CloudWatch 대시보드를 생성하여 지표를 시각화하고 문제에 신속하게 \n대응합니다. \nC. Amazon CloudWatch Synthetics 카나리아를 생성하여 애플리케이션을 모니터링하고 \n경보를 발생시킵니다. \nD. 가능한 경우 여러 지표 임계값으로 단일 Amazon CloudWatch 지표 경보를 생성합니다.", "answer_block": "Answer: A  \nhttps://www.examtopics.com/discussions/amazon/view/86034-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명 \n자세한 내용은 아래 URL. \nhttps://docs.aws.amazon.com/ko_kr/AWSSimpleQueueService/latest/SQSDeveloperGuide\n/FIFO-queues.html \nFIFO(First-In-First-Out) 대기열은 작업 및 이벤트 순서가 중요하거나 중복을 허용할 수 \n\n없는 경우 애플리케이션 간의 메시징을 향상하도록 설계되었습니다. FIFO 대기열을 사용할 \n수 있는 상황의 예는 다음과 같습니다. 사용자가 입력한 명령이 올바른 순서로 실행되도록 \n합니다. 올바른 순서로 가격 수정을 전송하여 올바른 제품 가격을 표시합니다. 학생이 \n계정을 등록하기 전에 코스에 등록하지 못하도록 합니다.", "answer_choice": "A"}, "151": {"q_num": 151, "question": "회사에서 온프레미스 데이터 센터를 AWS 로 마이그레이션하려고 합니다. 회사의 규정 준수 \n요구 사항에 따라 회사는 ap-northeast-3 지역만 사용할 수 있습니다. 회사 관리자는 \nVPC 를 인터넷에 연결할 수 없습니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? (2 개를 선택하세요.) \nA. AWS Control Tower 를 사용하여 데이터 상주 가드레일을 구현하여 인터넷 액세스를 \n거부하고 ap-northeast-3 을 제외한 모든 AWS 리전에 대한 액세스를 거부합니다. \nB. AWS WAF 의 규칙을 사용하여 인터넷 액세스를 방지합니다. AWS 계정 설정에서 \nap-northeast-3 을 제외한 모든 AWS 리전에 대한 액세스를 거부합니다. \nC. AWS Organizations 를 사용하여 VPC 가 인터넷에 액세스하지 못하도록 하는 서비스 제어 \n정책(SCPS)을 구성합니다. ap-northeast-3 을 제외한 모든 AWS 리전에 대한 액세스를 \n거부합니다. \nD. 각 VPC 의 네트워크 ACL 에 대한 아웃바운드 규칙을 생성하여 0.0.0.0/0 의 모든 \n트래픽을 거부합니다. ap-northeast-3 이외의 AWS 리전을 사용하지 못하도록 각 사용자에 \n대한 IAM 정책을 생성합니다. \nE. AWS Config 를 사용하여 관리형 규칙을 활성화하여 인터넷 게이트웨이를 감지 및 \n경고하고 ap-northeast-3 외부에 배포된 새 리소스를 감지 및 경고합니다.", "answer_block": "Answer: A, C  \nhttps://www.examtopics.com/discussions/amazon/view/86475-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nA(O) : AWS Control Tower Guardrail 을 사용해 SCP 를 통한 AWS API 액세스를 제한하여 \n특정 AWS 리전에서의 특정 리소스 방지 가능. \n오늘부터 AWS Control Tower 를 사용하여 가드레일 이라고 하는 데이터 상주 예방 및 탐지 \n제어를 배포할 수 있습니다 . 이러한 가드레일은 서비스 제어 정책(SCP) 을 통해 AWS \nAPI 에 대한 액세스를 제한하여 원치 않는 AWS 리전에서 리소스 프로비저닝을 방지합니다. \n예를 들어 독일의 AWS 고객은 AWS Identity and Access Management(IAM) 및 AWS \nOrganizations 와 같은 글로벌 서비스를 제외하고 프랑크푸르트 이외의 지역에서 AWS \n서비스에 대한 액세스를 거부할 수 있습니다. 또한 AWS Control Tower 는 Amazon Simple \n\nStorage Service(Amazon S3) 교차 리전 복제 차단 또는 인터넷 게이트웨이 생성 차단과 \n같은 기본 AWS 서비스 옵션의 데이터 상주를 추가로 제어하기 위한 가드레일을 \n제공합니다. \nhttps://aws.amazon.com/blogs/aws/new-for-aws-control-tower-region-deny-and-guar\ndrails-to-help-you-meet-data-residency-requirements/ \nB(X) : AWS WAF 는 Web ACL 을 통해 특정 국가나 지리적 위치, IP 의 요청을 차단할 수 \n있으나 리전을 차단하는 옵션은 없음. \nhttps://aws.amazon.com/ko/premiumsupport/knowledge-center/waf-allow-block-countr\ny-geolocation/)(https://aws.amazon.com/ko/premiumsupport/knowledge-center/waf-allo\nw-my-ip-block-other-ip/ \nC(O) : AWS Organizations 를 사용해 특정 리전에 대한 액세스 차단 가능. \n이 SCP 는 지정된 리전 외부의 모든 작업에 대한 액세스를 거부합니다. 이 정책은 Deny \n효과를 사용하여 승인된 두 리전(eu-central-1 및 eu-west-1) 중 하나를 대상으로 하지 \n않는 작업에 대한 모든 요청에 대한 액세스를 거부합니다. \nhttps://docs.aws.amazon.com/ko_kr/organizations/latest/userguide/orgs_manage_policie\ns_scps_examples_general.html \nD(X) : NACL 0.0.0.0/0 의 아웃바운드 트래픽을 막아버리면 트래픽이 외부로 나갈 수 없어 \n아예 통신 자체가 안 됨. IAM 정책으로 다른 AWS 리전의 다른 리소스에 대한 액세스를 \n막는 것은 가능. \nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_examples_aws_d\neny-requested-region.html \nE(X) : AWS Config 는 리소스 구성 변경 사항을 감지하고 해당 구성 변경 기록 파일을 \n전송할 수 있는 서비스로 지문의 요구사항에는 부합하지 않음.", "answer_choice": "A"}, "152": {"q_num": 152, "question": "회사에서 3\n계층 웹 응용 프로그램을 사용하여 신입 직원에게 교육을 제공합니다. \n애플리케이션은 매일 12 시간 동안만 액세스됩니다. 회사는 Amazon RDS for MySQL DB \n인스턴스를 사용하여 정보를 저장하고 비용을 최소화하려고 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. AWS Systems Manager Session Manager 에 대한 IAM 정책을 구성합니다. 정책에 대한 \nIAM 역할을 생성합니다. 역할의 신뢰 관계를 업데이트하십시오. DB 인스턴스에 대한 자동 \n시작 및 중지를 설정합니다. \nB. DB 인스턴스가 중지될 때 사용자가 캐시의 데이터에 액세스할 수 있는 기능을 제공하는 \nRedis 용 Amazon ElastiCache 캐시 클러스터를 생성합니다. DB 인스턴스가 시작된 후 \n캐시를 무효화합니다. \n\nC. Amazon EC2 인스턴스를 시작합니다. Amazon RDS 에 대한 액세스 권한을 부여하는 IAM \n역할을 생성합니다. 역할을 EC2 인스턴스에 연결합니다. 원하는 일정에 따라 EC2 \n인스턴스를 시작 및 중지하도록 크론 작업을 구성합니다. \nD. AWS Lambda 함수를 생성하여 DB 인스턴스를 시작 및 중지합니다. Amazon \nEventBridge(Amazon CloudWatch Events) \n예약 규칙을 생성하여 Lambda \n함수를 \n호출합니다. 규칙에 대한 이벤트 대상으로 Lambda 함수를 구성합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/86046-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nA(X) : 권한에 대한 언급이 없는데 굳이 IAM 을 사용할 이유가 없음. \nB(X) : ElastiCache 는 웹 애플리케이션과 DB 간의 캐시 서비스. \nC(X) : A 와 같은 이유로 오답. \nD(O) : EC2 인스턴스를 자동으로 중지 및 시작하여 Amazon Elastic Compute \nCloud(Amazon EC2) 사용량을 줄이려고 합니다. 이를 위해 AWS Lambda 및 Amazon \nEventBridge 를 사용하려면 어떻게 해야 하나요? \n이하의 항목 참고 \nhttps://aws.amazon.com/ko/premiumsupport/knowledge-center/start-stop-lambda-even\ntbridge/ \n \n설명2: \n일반적인 개발 환경에서 개발 및 테스트 데이터베이스는 대부분 하루 8 시간 동안 사용되며 \n사용하지 않을 때는 유휴 상태입니다. 그러나 데이터베이스에는 이 유휴 시간 동안 컴퓨팅 \n및 스토리지 비용이 청구됩니다. 전체 비용을 줄이기 위해 Amazon RDS 에서는 인스턴스를 \n일시적으로 중지할 수 있습니다. 인스턴스가 중지된 동안에는 스토리지 및 백업에 대한 \n요금이 부과되지만 DB 인스턴스 시간에 대한 요금은 부과되지 않습니다. 중지된 \n인스턴스는 7 일 후에 자동으로 시작됩니다. 이 게시물은 컴퓨팅 비용을 절감하기 위해 \n특정 태그로 유휴 데이터베이스를 중지 및 시작하도록 Lambda 함수를 예약할 수 있는 \nAWS Lambda 및 Amazon EventBridge 를 사용하는 솔루션을 제시합니다. 두 번째 게시물은 \nAWS Systems Manager 를 사용하여 유휴 Amazon RDS 데이터베이스의 중지 및 시작을 \n수행하는 솔루션을 제시합니다.", "answer_choice": "D"}, "153": {"q_num": 153, "question": "회사에서 인기 있는 노래 클립으로 만든 벨소리를 판매합니다. 벨소리가 포함된 파일은 \n\nAmazon S3 Standard 에 저장되며 크기는 최소 128KB 입니다. 이 회사에는 수백만 개의 \n파일이 있지만 90 일보다 오래된 벨소리의 경우 다운로드가 드뭅니다. 회사는 가장 많이 \n액세스하는 파일을 사용자가 쉽게 사용할 수 있도록 유지하면서 스토리지 비용을 절약해야 \n합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하기 위해 회사는 어떤 조치를 취해야 \n합니까? \nA. 객체의 초기 스토리지 계층에 대해 S3 Standard-Infrequent Access(S3 Standard-IA) \n스토리지를 구성합니다. \nB. 파일을 S3 Intelligent-Tiering 으로 이동하고 90 일 후에 객체를 더 저렴한 스토리지 \n계층으로 이동하도록 구성합니다. \nC. 객체를 관리하도록 S3 인벤토리를 구성하고 90 일 후에 객체를 S3 Standard-Infrequent \nAccess(S3 Standard-1A)로 이동합니다. \nD. 90 일 후에 객체를 S3 Standard 에서 S3 Standard-Infrequent Access(S3 Standard-1A)로 \n이동하는 S3 수명 주기 정책을 구현합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/86933-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nA(X) : 초기에는 사용량이 많으므로 S3 Standard 가 적절. \nB(X) : 90 일 이상된 벨소리는 다운로드가 드물다고 했으므로 부적절. \nC(X) : Amazon S3 Inventory 는 Amazon S3 에서 스토리지 관리를 지원하기 위해 제공하는 \n도구 중 하나로, 이 인벤토리를 사용하여 비즈니스, 규정 준수 및 규제 요건에 대한 객체의 \n복제 및 암호화 상태를 감사하고 보고할 수 있습니다. 또한 Amazon S3 동기식 List API \n작업의 대안으로 Amazon S3 인벤토리를 사용하면 비즈니스 워크플로 및 빅 데이터 업무를 \n단순화하고 속도를 높일 수 있습니다. \nhttps://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/storage-inventory.html \nD(O) : 90 일 이전에는 S3 Standard 로 빈번한 액세스 처리, 90 일 이후에는 다운로드가 \n드물지만 가장 많이 액세스하는 일부 파일은 쉽게 사용, 즉 빠르게 액세스할 수 있어야 \n하므로 액세스 소요 시간이 적은 S3 Standard-IA 사용이 적절. \n \n설명2: \n이 솔루션은 사용자가 가장 많이 액세스하는 파일을 쉽게 사용할 수 있도록 유지하면서 \n스토리지 비용을 절약해야 하는 요구 사항을 충족합니다. S3 수명 주기 정책은 사전 정의된 \n규칙에 따라 한 스토리지 클래스에서 다른 스토리지 클래스로 객체를 자동으로 이동할 수 \n있습니다. S3 Standard-IA 는 자주 액세스하지 않지만 필요할 때 신속하게 액세스해야 하는 \n\n데이터를 위한 저비용 스토리지 클래스입니다. 드물게 다운로드되는 90 일 이상의 벨소리에 \n적합합니다. \n \n객체의 초기 스토리지 계층에 대해 S3 Standard-IA 를 구성하면 빈번한 액세스 및 검색 \n요금으로 더 많은 비용이 발생할 수 있으므로 옵션 A 는 올바르지 않습니다. \n \n파일을 S3 Intelligent-Tiering 으로 이동하면 90 일보다 오래된 벨소리에는 필요하지 않을 수 \n있는 추가 모니터링 및 자동화 요금이 발생할 수 있으므로 옵션 B 는 올바르지 않습니다. \n \n옵션 C\n는 올바르지 않습니다. S3 인벤토리를 사용하여 객체를 관리하고 객체를 S3 \nStandard-IA 로 이동하는 것은 복잡하고 시간이 많이 소요될 수 있으며 자동 비용 절감을 \n제공하지 않기 때문입니다. \n참조: \nhttps://aws.amazon.com/s3/storage-classes/ \nhttps://aws.amazon.com/s3/cloud-storage-cost-optimization-ebook/", "answer_choice": "D"}, "154": {"q_num": 154, "question": "회사는 의료 시험의 결과를 Amazon S3 리포지토리에 저장해야 합니다. 리포지토리는 일부 \n과학자가 새 파일을 추가할 수 있도록 허용해야 하고 다른 모든 사용자는 읽기 전용 \n액세스로 제한해야 합니다. 어떤 사용자도 저장소의 파일을 수정하거나 삭제할 수 없습니다. \n회사는 모든 파일을 생성일로부터 최소 1 년 동안 저장소에 보관해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 거버넌스 모드에서 1 년의 법적 보유 기간으로 S3 Object Lock 을 사용하십시오. \nB. 보존 기간이 365 일인 규정 준수 모드에서 S3 Object Lock 을 사용합니다. \nC. IAM 역할을 사용하여 모든 사용자가 S3 버킷의 객체를 삭제하거나 변경하지 못하도록 \n제한합니다. S3 버킷 정책을 사용하여 IAM 역할만 허용합니다. \nD. 객체가 추가될 때마다 AWS Lambda 함수를 호출하도록 S3 버킷을 구성합니다. 수정된 \n개체가 그에 따라 표시될 수 있도록 저장된 개체의 해시를 추적하는 기능을 구성합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/86359-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nS3 객체 수정 및 삭제 방지 = S3 Object Lock. \nS3 객체 잠금을 사용하면 write once, read many(WORM) 모델을 사용하여 객체를 저장할 \n\n수 있습니다. 객체 잠금은 고정된 시간 동안 또는 무기한으로 객체의 삭제 또는 덮어쓰기를 \n방지하는 데 도움이 될 수 있습니다. 보관 기간은 정해진 시간 동안 객체 버전을 \n보호합니다. 객체 버전에 보관 기간을 설정하면 Amazon S3 는 객체 버전의 메타데이터에 \n타임스탬프를 저장하여 보관 기간이 만료되는 시점을 표시합니다. 보관 기간이 만료된 후 \n객체 버전에 법적 보존을 설정하지 않는 한 객체 버전을 덮어쓰거나 삭제할 수 있습니다. \nhttps://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/object-lock-overview.ht\nml#object-lock-retention-periods \n \n설명2: \n규정 준수 모드에서는 AWS 계정의 루트 사용자를 포함하여 어떤 사용자도 보호 객체 \n버전을 덮어쓰거나 삭제할 수 없습니다. 객체가 규정 준수 모드에서 잠겨 있으면 보관 \n모드를 변경할 수 없으며 보관 기간을 단축할 수 없습니다. 규정 준수 모드는 보존 기간 \n동안 개체 버전을 덮어쓰거나 삭제할 수 없도록 합니다. 거버넌스 모드에서 사용자는 \n특별한 권한이 없는 한 개체 버전을 덮어쓰거나 삭제할 수 없으며 잠금 설정을 변경할 수 \n없습니다. 거버넌스 모드를 사용하면 대부분의 사용자가 개체를 삭제하지 못하도록 \n보호하지만 필요한 경우 일부 사용자에게 보존 설정을 변경하거나 개체를 삭제할 수 있는 \n권한을 계속 부여할 수 있습니다. 거버넌스 모드에서는 특수 권한이 있는 일부 사용자가 \n개체를 삭제할 수 있으며 이는 요구 사항에 위배됩니다. \n규정 준수: \n- 객체 버전은 루트 사용자를 포함한 모든 사용자가 덮어쓰거나 삭제할 수 없습니다. \n- 개체 보존 모드를 변경할 수 없으며 보존 기간을 단축할 수 없습니다. 거버넌스: \n- 대부분의 사용자는 개체 버전을 덮어쓰거나 삭제할 수 없으며 잠금 설정을 변경할 수 \n없습니다. \n- 일부 사용자는 보존을 변경하거나 개체를 삭제할 수 있는 특별한 권한이 있습니다.", "answer_choice": "B"}, "155": {"q_num": 155, "question": "대규모 미디어 회사는 AWS 에서 웹 애플리케이션을 호스팅합니다. 이 회사는 전 세계 \n사용자가 파일에 안정적으로 액세스할 수 있도록 기밀 미디어 파일 캐싱을 시작하려고 \n합니다. 콘텐츠는 Amazon S3 버킷에 저장됩니다. 회사는 요청의 지리적 위치에 관계없이 \n콘텐츠를 신속하게 제공해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. AWS DataSync 를 사용하여 S3 버킷을 웹 애플리케이션에 연결합니다. \nB. AWS Global Accelerator 를 배포하여 S3 버킷을 웹 애플리케이션에 연결합니다. \nC. Amazon CloudFront 를 배포하여 S3 버킷을 CloudFront 엣지 서버에 연결합니다. \nD. Amazon Simple Queue Service(Amazon SQS)를 사용하여 S3 버킷을 웹 애플리케이션에 \n\n연결합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/86795-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nS3 버킷에 저장 + 요청이 지리적으로 어디에서 발생했는지에 관계없이 콘텐츠를 신속하게 \n제공 = S3 + CloudFront. 답은 C. \n \n설명2: \nCloudFront 는 로컬 캐시를 사용하여 응답을 제공하고, AWS Global Accelerator 는 요청을 \n프록시하고 응답을 위해 항상 애플리케이션에 연결합니다.", "answer_choice": "C"}, "156": {"q_num": 156, "question": "회사는 다른 데이터베이스에서 가져온 배치 데이터를 생성합니다. 이 회사는 또한 네트워크 \n센서 및 애플리케이션 API 에서 라이브 스트림 데이터를 생성합니다. 회사는 비즈니스 \n분석을 위해 모든 데이터를 한 곳으로 통합해야 합니다. 회사는 수신 데이터를 처리한 다음 \n다른 Amazon S3 버킷에 데이터를 준비해야 합니다. 팀은 나중에 일회성 쿼리를 실행하고 \n데이터를 비즈니스 인텔리전스 도구로 가져와 핵심 성과 지표(KPI)를 표시합니다. \n가장 적은 운영 오버헤드로 이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (2 개를 \n선택하세요.) \nA. 일회성 쿼리에는 Amazon Athena 를 사용하십시오. Amazon QuickSight 를 사용하여 \nKPI 용 대시보드를 생성합니다. \nB. 일회성 쿼리에 Amazon Kinesis Data Analytics 를 사용합니다. Amazon QuickSight 를 \n사용하여 KPI 용 대시보드를 생성합니다. \nC. 개별 레코드를 데이터베이스에서 Amazon Redshift 클러스터로 이동하는 사용자 지정 \nAWS Lambda 함수를 생성합니다. \nD. AWS Glue 추출, 변환 및 로드(ETL) 작업을 사용하여 데이터를 JSON 형식으로 \n변환합니다. 여러 Amazon OpenSearch Service(Amazon Elasticsearch Service) 클러스터에 \n데이터를 로드합니다. \nE. AWS Lake Formation 의 청사진을 사용하여 데이터 레이크에 수집할 수 있는 데이터를 \n식별합니다. AWS Glue\n를 사용하여 소스를 크롤링하고, 데이터를 추출하고, 데이터를 \nApache Parquet 형식으로 Amazon S3 에 로드합니다.", "answer_block": "Answer: A, E \nhttps://www.examtopics.com/discussions/amazon/view/85770-exam-aws-certified-solut\n\nions-architect-associate-saa-c03/ \n \n설명1: \nKPI 로 표시하기 위해선 Athena 가 필요하고, Athena 는 S3 에 쿼리함. 따라서 KPI 만 \n기억해도 A,E 가 정답임을 쉽게 유추할 수 있음. \n・데이터베이스에서 가져온 배치 데이터와 네트워크 센서 및 애플리케이션 API 에서 생성한 \n라이브 스트림 데이터를 한 곳에 모은다고 했으므로 형식이 다른 데이터를 한 곳에 모을 때 \n적절한 AWS LakeFormation 이 필요. \n・그리고 AWS Glue 는 Amazon S3 데이터 레이크의 필수 구성 요소이며 최신 데이터 \n분석을 위한 데이터 카탈로그 및 변환 서비스 제공 \nhttps://aws.amazon.com/ko/blogs/korea/build-a-data-lake-foundation-with-aws-glue-\nand-amazon/ \n・AWS Glue 는 Athena 에서 쿼리 가능한 Parquet 파일을 쓸 수 있음. \nAWS Glue 를 사용하여 Amazon S3 와 스트리밍 소스에서 Parquet 파일을 읽을 수 있을 \n뿐만 아니라 Amazon S3 에 Parquet 파일을 쓸 수 있습니다. \nhttps://docs.aws.amazon.com/ko_kr/glue/latest/dg/aws-glue-programming-etl-format-p\narquet-home.html \nAmazon Athena 에서 사용할 수 있는 Apache Parquet \nhttps://aws.amazon.com/ko/blogs/korea/build-a-data-lake-foundation-with-aws-glue-\nand-amazon/ \n・S3 버킷에 있는 데이터를 Athena 로 쿼리 가능 \nAmazon Athena 는 표준 SQL 을 사용하여 Amazon S3(Amazon Simple Storage Service)에 \n있는 데이터를 직접 간편하게 분석할 수 있는 대화형 쿼리 서비스입니다. \nhttps://docs.aws.amazon.com/ko_kr/athena/latest/ug/what-is.html \n・QuickSight 로 KPI 표시 가능 \nhttps://docs.aws.amazon.com/ko_kr/quicksight/latest/user/kpi.html \n \n설명2: \nAmazon Athena\n는 스트리밍 데이터에 대한 일회성 쿼리를 실행하기 위한 최상의 \n선택입니다. \nAmazon Kinesis Data Analytics 는 스트리밍 데이터를 실시간으로 분석할 수 있는 쉽고 \n친숙한 표준 SQL 언어를 제공하지만 일회성 쿼리가 아닌 지속적인 쿼리를 위해 \n설계되었습니다. 반면 Amazon Athena 는 SQL 을 사용하여 Amazon S3 의 데이터를 쿼리할 \n수 있는 서버리스 대화형 쿼리 서비스입니다. 임시 쿼리에 최적화되어 있으며 스트리밍 \n데이터에 대한 일회성 쿼리를 실행하는 데 이상적입니다. \nAWS Lake Formation 은 분석 목적으로 모든 데이터를 보관하는 중앙 위치로 사용합니다. \n\nAthena 는 S3 와 완벽하게 통합되며 쿼리를 만들 수 있습니다.", "answer_choice": "A"}, "157": {"q_num": 157, "question": "회사는 Amazon Aurora PostgreSQL DB 클러스터에 데이터를 저장합니다. 회사는 모든 \n데이터를 5 년간 보관하고 5 년이 지나면 모든 데이터를 삭제해야 합니다. 회사는 또한 \n데이터베이스 내에서 수행되는 작업의 감사 로그를 무기한으로 유지해야 합니다. 현재 이 \n회사는 Aurora 용으로 자동 백업을 구성했습니다. \n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 단계 조합을 수행해야 합니까? \n(두 가지를 선택하세요.) \nA. DB 클러스터의 수동 스냅샷을 생성합니다. \nB. 자동 백업에 대한 수명 주기 정책을 만듭니다. \nC. 5 년 동안 자동 백업 보존을 구성합니다. \nD. DB 클러스터에 대한 Amazon CloudWatch Logs 내보내기를 구성합니다. \nE. AWS Backup 을 사용하여 백업을 수행하고 5 년 동안 백업을 보관합니다.", "answer_block": "Answer: D, E \nhttps://www.examtopics.com/discussions/amazon/view/87629-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n이전에는 특히 AWS 서비스 전체에서 백업을 조정할 때 수동 Aurora 클러스터 스냅샷에 \n대한 백업 일정을 자동화하거나 보존 정책을 적용하거나 백업 활동을 통합하기 위해 사용자 \n지정 스크립트를 생성해야 했습니다. AWS Backup 을 사용하면 스냅샷 예약 및 스냅샷 보존 \n관리 기능이 있는 완전 관리형 정책 기반 백업 솔루션을 얻을 수 있습니다. 이제 \nPostgreSQL 호환 및 MySQL 호환 Aurora 버전 모두에 대해 AWS Backup 콘솔에서 직접 \nAurora 백업을 생성, 관리 및 복원할 수 있습니다. \n시작하려면 AWS Backup 콘솔에서 Amazon Aurora 클러스터를 선택하고 온디맨드 백업을 \n수행하거나 클러스터를 백업 계획에 할당하기만 하면 됩니다.", "answer_choice": "D"}, "158": {"q_num": 158, "question": "솔루션 아키텍트가 다가올 음악 행사를 위해 웹사이트를 최적화하고 있습니다. 공연 영상은 \n실시간으로 스트리밍되며 주문형으로 제공된다. 이 행사는 전 세계 온라인 청중을 끌어들일 \n것으로 예상됩니다. \n실시간 및 온디맨드 스트리밍의 성능을 모두 향상시키는 서비스는 무엇입니까? \nA. Amazon CloudFront \n\nB. AWS Global Accelerator \nC. Amazon Route 53 \nD. Amazon S3 Transfer Acceleration", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/87514-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명 \nCloudFront 를 사용하여 모든 HTTP 오리진을 사용하여 주문형 비디오(VOD) 또는 라이브 \n스트리밍 비디오를 제공할 수 있습니다. \n클라우드에서 비디오 워크플로를 설정할 수 있는 한 가지 방법은 CloudFront 를 AWS Media \nServices 와 함께 사용하는 것입니다. \nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/on-demand-str\neamingvideo.html", "answer_choice": "A"}, "159": {"q_num": 159, "question": "회사에서 Amazon API Gateway 및 AWS Lambda 를 사용하는 공개적으로 액세스 가능한 \n서버리스 \n애플리케이션을 \n실행하고 \n있습니다. \n최근 \n봇넷의 \n사기성 \n요청으로 \n인해 \n애플리케이션의 트래픽이 급증했습니다. \n승인되지 않은 사용자의 요청을 차단하기 위해 솔루션 설계자는 어떤 단계를 수행해야 \n합니까? (두 가지를 선택하세요.) \nA. 정품 사용자에게만 공유되는 API 키로 사용량 계획을 생성합니다. \nB. 사기성 IP 주소의 요청을 무시하도록 Lambda 함수 내에 논리를 통합합니다. \nC. 악성 요청을 대상으로 하는 AWS WAF 규칙을 구현하고 이를 필터링하는 작업을 \n트리거합니다. \nD. 기존 공개 API 를 비공개 API 로 전환합니다. DNS 레코드를 업데이트하여 사용자를 새 \nAPI 엔드포인트로 리디렉션합니다. \nE. API 에 액세스를 시도하는 각 사용자에 대해 IAM 역할을 생성합니다. 사용자는 API 호출 \n시 역할을 맡게 됩니다.", "answer_block": "Answer: A, C \nhttps://www.examtopics.com/discussions/amazon/view/87516-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nAPI 사용 계획을 WAF 로 보완 가능. \"\"비용을 제어하거나 API 에 대한 액세스를 차단하기 \n\n위해 사용량 계획 할당량 또는 조절에 의존하지 마십시오. AWS Budget 을 사용하여 비용을 \n모니터링하고 AWS WAF  를 사용하여 API 요청을 관리하는 것을 고려하십시오. \nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-api-usage\n-plans.html \nA(O) : 애플리케이션 요청, 즉 API 요청을 함부로 하지 못하도록 하는 것이므로 A 는 정답. \nC(O) : 애플리케이션 계층 방어이고 봇넷 방어이므로 WAF 가 있는 C 는 정답 \n(https://aws.amazon.com/ko/waf/getting-started/) \nE(X) : 공개적으로 사용가능한 서버리스 애플리케이션이라는 단서 때문에 제외됨.", "answer_choice": "A"}, "160": {"q_num": 160, "question": "전자상거래 \n회사는 \nAWS \n클라우드에서 \n분석 \n애플리케이션을 \n호스팅합니다. \n이 \n애플리케이션은 매월 약 300MB\n의 데이터를 생성합니다. 데이터는 JSON 형식으로 \n저장됩니다. 회사는 데이터 백업을 위한 재해 복구 솔루션을 평가하고 있습니다. 데이터는 \n필요한 경우 밀리초 단위로 액세스할 수 있어야 하며 데이터는 30 일 동안 보관되어야 \n합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. Amazon OpenSearch Service (Amazon Elasticsearch Service) \nB. Amazon S3 Glacier \nC. Amazon S3 Standard \nD. Amazon RDS for PostgreSQL", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/87632-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nA(X) : Amazon OpenSerach Service 는 분석 및 모니터링 서비스인데 이미 회사에서 분석 \n애플리케이션을 따로 사용 중이므로 데이터를 저장하는 서비스만 필요한 상황이라 필요가 \n없음. Amazon OpenSearch Service 는 AWS 클라우드에서 OpenSearch 클러스터를 손쉽게 \n배포, 운영 및 확장할 수 있도록 해주는 관리형 서비스입니다. OpenSearch 는 로그 분석, \n실시간 애플리케이션 모니터링, 클릭 스트림 분석 같은 사용 사례를 위한 완전한 오픈 소스 \n검색 및 분석 엔진입니다. \nhttps://docs.aws.amazon.com/ko_kr/opensearch-service/latest/developerguide/what-is.h\ntml \nB(X) : 아무리 빨라봤자 액세스 타임이 1 분 정도 걸림. \nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/restoring-objects-retrieval-op\n\ntions.html \nC(O) : S3 + Life Cycle Policy 조합으로 밀리초 단위 액세스와 30 일간 보관 조건 충족 가능 \nhttps://aws.amazon.com/ko/s3/storage-classes/)(https://docs.aws.amazon.com/ko_kr/A\nmazonS3/latest/userguide/object-lifecycle-mgmt.html \nD(X) : 데이터베이스는 데이터를 수집하여 다른 서비스에 이용할 목적으로 사용하는 것이지, \n특정 기간만 보관해두고자 하는 용도가 아님. 지문에서는 회사가 이미 분석 애플리케이션을 \n가지고 있는데다가 원하는 건 분석 애플리케이션으로 생성한 데이터를 보관할 곳을 찾는 \n것임. 따라서 C 가 더 적합. \n \n설명2: \n이 솔루션은 분석 애플리케이션에서 생성되고 JSON 형식으로 저장되는 데이터를 백업하기 \n위한 재해 복구 솔루션의 요구 사항을 충족하며 필요한 경우 밀리초 내에 액세스할 수 \n있어야 합니다. Amazon S3 Standard 는 자주 액세스하는 데이터를 위한 내구성 있고 확장 \n가능한 스토리지 클래스입니다. 모든 양의 데이터를 저장할 수 있고 고가용성과 성능을 \n제공할 수 있습니다. 또한 데이터 검색을 위한 밀리초 액세스 시간을 지원할 수 있습니다. \nAmazon OpenSearch Service(Amazon Elasticsearch Service)는 데이터를 인덱싱하고 \n쿼리할 수 있는 검색 및 분석 서비스이지만 JSON 형식으로 저장된 데이터에 대한 백업 \n솔루션이 아니기 때문에 옵션 A 는 올바르지 않습니다. \n옵션 B 는 Amazon S3 Glacier 가 데이터 보관 및 장기 백업을 위한 저비용 스토리지 \n클래스이지만 데이터 검색을 위한 밀리초 액세스 시간을 지원하지 않기 때문에 정답이 \n아닙니다. \nPostgreSQL 용 Amazon RDS 는 구조화된 데이터를 저장하고 쿼리할 수 있는 관계형 \n데이터베이스 서비스이지만 JSON 형식으로 저장된 데이터에 대한 백업 솔루션이 아니기 \n때문에 옵션 D 는 올바르지 않습니다. \n \n참조: \nhttps://aws.amazon.com/s3/storage-classes/ \nhttps://aws.amazon.com/s3/faqs/#Durability_and_data_protection", "answer_choice": "C"}, "161": {"q_num": 161, "question": "회사에는 JSON 문서를 처리하고 그 결과를 온프레미스 SQL 데이터베이스에 출력하는 \n작은 Python 애플리케이션이 있습니다. 이 애플리케이션은 매일 수천 번 실행됩니다. \n회사는 애플리케이션을 \nAWS \n클라우드로 이동하려고 합니다. 이 회사는 확장성을 \n최대화하고 운영 오버헤드를 최소화하는 고가용성 솔루션이 필요합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \n\nA. JSON 문서를 Amazon S3 버킷에 넣습니다. 여러 Amazon EC2 인스턴스에서 Python \n코드를 실행하여 문서를 처리합니다. 결과를 Amazon Aurora DB 클러스터에 저장합니다. \nB. JSON 문서를 Amazon S3 버킷에 넣습니다. 문서가 S3 버킷에 도착하면 이를 처리하기 \n위해 Python 코드를 실행하는 AWS Lambda 함수를 생성합니다. 결과를 Amazon Aurora DB \n클러스터에 저장합니다. \nC. JSON 문서를 Amazon Elastic Block Store(Amazon EBS) 볼륨에 넣습니다. EBS 다중 \n연결 기능을 사용하여 볼륨을 여러 Amazon EC2 인스턴스에 연결합니다. EC2 인스턴스에서 \nPython 코드를 실행하여 문서를 처리합니다. Amazon RDS DB 인스턴스에 결과를 \n저장합니다. \nD. JSON 문서를 Amazon Simple Queue Service(Amazon SQS) 대기열에 메시지로 \n배치합니다. Amazon EC2 시작 유형으로 구성된 Amazon Elastic Container Service(Amazon \nECS) 클러스터에 Python 코드를 컨테이너로 배포합니다. 컨테이너를 사용하여 SQS \n메시지를 처리합니다. Amazon RDS DB 인스턴스에 결과를 저장합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/87633-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nLambda 를 사용하면 서버를 관리하고 프로비저닝할 필요가 없으므로 확장성이 보장되고 \n운영 오버헤드가 최소화됩니다. S3 는 JSON 문서를 위한 내구성 있고 가용성이 높은 \n스토리지를 제공합니다. Lambda\n는 새 문서가 S3 버킷에 추가될 때마다 자동으로 \n트리거되어 실시간 처리가 가능합니다. 결과를 Aurora DB 클러스터에 저장하면 처리된 \n데이터의 고가용성과 확장성이 보장됩니다. 이 솔루션은 서버리스 아키텍처를 활용하여 \n인프라를 관리할 필요 없이 자동 확장 및 고가용성을 허용하므로 가장 적합한 선택입니다. \nA. 이 옵션을 사용하려면 EC2 인스턴스를 수동으로 관리하고 확장해야 하므로 운영 \n오버헤드와 복잡성이 높아집니다. \nC. 이 접근 방식에는 여전히 EC2 인스턴스의 수동 관리 및 확장이 포함되어 운영 복잡성과 \n오버헤드가 증가합니다. \nD. 이 솔루션은 ECS 클러스터를 관리하고 확장해야 하므로 운영 오버헤드와 복잡성이 \n추가됩니다. SQS 를 활용하면 시스템에 복잡성이 추가되어 Python 코드에서 메시지 소비 및 \n처리를 사용자 지정 처리해야 합니다. \n \n설명2: \nJSON 문서를 S3 버킷에 넣으면 문서가 내구성과 확장성이 뛰어난 객체 스토리지 서비스에 \n저장됩니다. AWS Lambda 를 사용하면 회사는 Python 코드를 실행하여 기본 인프라에 대해 \n걱정할 필요 없이 S3 버킷에 도착하는 문서를 처리할 수 있습니다. 또한 AWS Lambda 가 \n\n들어오는 요청 비율에 따라 함수의 인스턴스 수를 자동으로 조정하므로 수평적 확장성이 \n가능합니다. 결과는 MySQL 및 PostgreSQL 과 호환되는 완전 관리형 고성능 데이터베이스 \n서비스인 Amazon Aurora DB 클러스터에 저장할 수 있습니다. 이는 처리 결과에 필요한 \n내구성과 확장성을 제공합니다. \nhttps://aws.amazon.com/rds/aurora/", "answer_choice": "B"}, "162": {"q_num": 162, "question": "회사에서 재무 위험 모델링을 위해 AWS 에서 고성능 컴퓨팅(HPC) 인프라를 사용하려고 \n합니다. 회사의 HPC 워크로드는 Linux 에서 실행됩니다. 각 HPC 워크플로는 수백 개의 \nAmazon EC2 스팟 인스턴스에서 실행되고 수명이 짧으며 궁극적으로 분석 및 향후 장기적 \n사용을 위해 영구 스토리지에 저장되는 수천 개의 출력 파일을 생성합니다. \n이 회사는 모든 EC2 인스턴스에서 데이터를 처리할 수 있도록 온프레미스 데이터를 장기 \n영구 스토리지로 복사할 수 있는 클라우드 스토리지 솔루션을 찾고 있습니다. 솔루션은 \n또한 데이터 세트와 출력 파일을 읽고 쓰기 위해 영구 스토리지와 통합된 고성능 파일 \n시스템이어야 합니다. \n이러한 요구 사항을 충족하는 AWS 서비스 조합은 무엇입니까? \nA. Amazon S3 와 통합된 Amazon FSx for Lustre \nB. Amazon S3 와 통합된 Windows 파일 서버용 Amazon FSx \nC. Amazon Elastic Block Store(Amazon EBS)와 통합된 Amazon S3 Glacier \nD. Amazon Elastic Block Store(Amazon EBS) 범용 SSD(gp2) 볼륨과 통합된 VPC \n엔드포인트가 있는 Amazon S3 버킷", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/87634-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명 \nhttps://aws.amazon.com/fsx/lustre/ \nAmazon FSx for Lustre 는 컴퓨팅 워크로드를 위한 비용 효율적이고 확장 가능한 고성능 \n스토리지를 제공하는 완전관리형 서비스입니다. 기계 학습, 고성능 컴퓨팅(HPC), 비디오 \n렌더링, 재무 시뮬레이션과 같은 많은 워크로드는 고성능 공유 스토리지를 통해 동일한 \n데이터 세트에 액세스하는 컴퓨팅 인스턴스에 의존합니다. \n \nHPC = Amazon FSx for Lustre. 정답은 A.", "answer_choice": "A"}, "163": {"q_num": 163, "question": "한 회사가 온프레미스에서 컨테이너화된 애플리케이션을 구축하고 애플리케이션을 AWS 로 \n이전하기로 결정했습니다. 응용 프로그램은 배포된 직후 수천 명의 사용자를 보유하게 \n됩니다. 회사는 규모에 맞게 컨테이너 배포를 관리하는 방법을 확신하지 못합니다. 회사는 \n운영 오버헤드를 최소화하는 고가용성 아키텍처에 컨테이너화된 애플리케이션을 배포해야 \n합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Amazon Elastic Container Registry(Amazon ECR) 리포지토리에 컨테이너 이미지를 \n저장합니다. AWS Fargate 시작 유형과 함께 Amazon Elastic Container Service(Amazon ECS) \n클러스터를 사용하여 컨테이너를 실행합니다. 대상 추적을 사용하여 수요에 따라 자동으로 \n확장합니다. \nB. 컨테이너 이미지를 Amazon Elastic Container Registry(Amazon ECR) 리포지토리에 \n저장합니다. Amazon EC2 시작 유형과 함께 Amazon Elastic Container Service(Amazon ECS) \n클러스터를 사용하여 컨테이너를 실행합니다. 대상 추적을 사용하여 수요에 따라 자동으로 \n확장합니다. \nC. Amazon EC2 인스턴스에서 실행되는 리포지토리에 컨테이너 이미지를 저장합니다. 여러 \n가용 영역에 분산된 EC2 인스턴스에서 컨테이너를 실행합니다. Amazon CloudWatch 에서 \n평균 CPU 사용률을 모니터링합니다. 필요에 따라 새 EC2 인스턴스를 시작합니다. \nD. 컨테이너 이미지가 포함된 Amazon EC2 Amazon 머신 이미지(AMI)를 생성합니다. 여러 \n가용 영역의 Auto Scaling 그룹에서 EC2 인스턴스를 시작합니다. 평균 CPU 사용률 \n임계값을 초과하면 Amazon CloudWatch 경보를 사용하여 EC2 인스턴스를 확장합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/87509-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nAWS Fargate 는 사용자 애플리케이션을 위한 서버리스 환경으로, 사용자는 서버 구성 및 \n관리 대신 애플리케이션 구축에 집중할 수 있습니다. 또한 Fargate 는 리소스 관리를 \n자동화하여 사용자가 수요에 따라 애플리케이션을 쉽게 확장할 수 있도록 합니다. \n \n컨테이너화된 애플리케이션 배포 = Fargate + ECS. 정답은 A.", "answer_choice": "A"}, "164": {"q_num": 164, "question": "회사에는 처리할 페이로드가 포함된 메시지를 보내는 발신자 애플리케이션과 페이로드가 \n포함된 메시지를 수신하기 위한 처리 애플리케이션의 두 가지 애플리케이션이 있습니다. \n\n회사는 두 애플리케이션 간의 메시지를 처리하기 위해 AWS 서비스를 구현하려고 합니다. \n발신자 애플리케이션은 매시간 약 1,000\n개의 메시지를 보낼 수 있습니다. 메시지를 \n처리하는 데 최대 2 일이 걸릴 수 있습니다. 메시지를 처리하지 못한 경우 나머지 메시지 \n처리에 영향을 주지 않도록 보관해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족하고 운영상 가장 효율적입니까? \nA. Redis 데이터베이스를 실행하는 Amazon EC2 인스턴스를 설정합니다. 인스턴스를 \n사용하도록 두 애플리케이션을 모두 구성합니다. 메시지를 각각 저장, 처리 및 삭제합니다. \nB. Amazon Kinesis 데이터 스트림을 사용하여 발신자 애플리케이션에서 메시지를 \n수신합니다. 처리 애플리케이션을 Kinesis Client Library(KCL)와 통합합니다. \nC. 발신자 및 프로세서 애플리케이션을 Amazon Simple Queue Service(Amazon SQS) \n대기열과 통합합니다. 처리에 실패한 메시지를 수집하도록 배달 못한 편지 대기열을 \n구성합니다. \nD. \n처리할 \n알림을 \n수신하려면 \n처리 \n애플리케이션을 \nAmazon \nSimple \nNotification \nService(Amazon SNS) 주제에 구독합니다. 발신자 애플리케이션을 통합하여 SNS 주제에 \n씁니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/87523-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \n메시지 처리에 실패하면 = SQS Dead Letter Queue. 정답은 C. \n \n설명2: \n발신자 및 프로세서 애플리케이션을 모두 SQS\n와 통합하면 처리를 위해 발신자에서 \n프로세서 애플리케이션으로 메시지를 안정적으로 보낼 수 있습니다. SQS 는 최소 1 회 \n전달을 제공하여 메시지가 전송 중에 손실되지 않도록 합니다. 메시지 처리에 실패하면 \n다른 메시지 처리에 영향을 주지 않고 대기열에 보관하고 다시 시도할 수 있습니다. DLQ 를 \n구성하면 반복적으로 처리에 실패하는 메시지를 수집할 수 있으므로 문제 해결 및 분석을 \n위해 실패한 메시지를 볼 수 있습니다. \nA 는 운영 오버헤드 및 유지 관리 요구 사항을 추가하는 Redis 를 실행하는 EC2 인스턴스의 \n관리 및 구성과 관련되므로 최적의 선택이 아닙니다. \nB\n는 Amazon Kinesis 데이터 스트림을 사용하고 메시지 처리를 위해 Kinesis Client \nLibrary 와 통합함으로써 추가적인 복잡성을 도입하므로 운영상 가장 효율적인 솔루션은 \n아닙니다. \nSNS 를 사용하는 D는 두 애플리케이션 간의 메시지 처리라는 특정 요구 사항보다 Pub/Sub \n메시징 및 방송 알림에 더 적합하므로 시나리오에 가장 적합하지 않습니다. \n\n \n참고: \nhttps://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-\ndead-letterqueues.html", "answer_choice": "C"}, "165": {"q_num": 165, "question": "솔루션 설계자는 정적 웹 사이트를 저장하기 위해 Amazon S3 오리진과 함께 Amazon \nCloudFront 를 사용하는 솔루션을 설계해야 합니다. 회사의 보안 정책에 따라 모든 웹 \n사이트 트래픽은 AWS WAF 에서 검사해야 합니다. \n솔루션 설계자는 이러한 요구 사항을 어떻게 준수해야 합니까? \nA. AWS WAF Amazon 리소스 이름(ARN)에서만 오는 요청을 수락하도록 S3 버킷 정책을 \n구성합니다. \nB. S3 오리진에서 콘텐츠를 요청하기 전에 모든 수신 요청을 AWS WAF 로 전달하도록 \nAmazon CloudFront 를 구성합니다. \nC. Amazon CloudFront IP 주소가 Amazon S3 에만 액세스하도록 허용하는 보안 그룹을 \n구성합니다. AWS WAF 를 CloudFront 에 연결합니다. \nD. 원본 액세스 ID(OAI)를 사용하여 S3 버킷에 대한 액세스를 제한하도록 Amazon \nCloudFront 및 Amazon S3 를 구성합니다. 배포에서 AWS WAF 를 활성화합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/87524-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nCloudFront 로만 접속할 수 있도록 한 뒤에 WAF 로 검사해야 함. \nAmazon S3 버킷을 오리진으로 설정하여 CloudFront 를 사용하는 경우 다음과 같은 이점을 \n제공하는 방식으로 CloudFront 및 Amazon S3 를 구성할 수 있습니다.  \n◎공개적으로 액세스할 수 없도록 Amazon S3 버킷에 대한 액세스를 제한합니다.  \n◎뷰어(사용자)가 지정된 CloudFront 배포를 통해서만 버킷의 콘텐츠에 액세스할 수 있도록 \n합니다. 즉, 뷰어가 버킷에서 직접 또는 의도하지 않은 CloudFront 배포를 통해 콘텐츠에 \n액세스하는 것을 방지합니다. 이렇게 하려면 인증된 요청을 Amazon S3\n로 보내도록 \nCloudFront 를 구성하고 CloudFront 의 인증된 요청에 대한 액세스만 허용하도록 Amazon \nS3 를 구성합니다. CloudFront 는 Amazon S3 오리진에 인증된 요청을 전송하는 두 가지 \n방법으로 오리진 액세스 제어(OAC)와 오리진 액세스 ID(OAI)를 제공합니다. \nhttps://docs.aws.amazon.com/ko_kr/AmazonCloudFront/latest/DeveloperGuide/private-c\nontent-restricting-access-to-s3.html \n\n \nAWS WAF 는 CloudFront 에 전달되는 HTTP 및 HTTPS 요청을 모니터링할 수 있게 해주고 \n콘텐츠에 대한 액세스를 제어할 수 있게 해주는 웹 애플리케이션 방화벽입니다. \nhttps://docs.aws.amazon.com/ko_kr/AmazonCloudFront/latest/DeveloperGuide/distributio\nn-web-awswaf.html \n \n참조 \nhttps://docs.aws.amazon.com/ko_kr/AmazonCloudFront/latest/DeveloperGuide/private-c\nontent-restricting-access-to-s3.html \nhttps://docs.aws.amazon.com/ko_kr/AmazonCloudFront/latest/DeveloperGuide/distributio\nn-web-awswaf.html", "answer_choice": "D"}, "166": {"q_num": 166, "question": "글로벌 이벤트의 주최자는 일일 보고서를 정적 HTML 페이지로 온라인에 게시하려고 \n합니다. 이 페이지는 전 세계 사용자로부터 수백만 건의 조회수를 생성할 것으로 \n예상됩니다. 파일은 Amazon S3 버킷에 저장됩니다. 솔루션 설계자는 효율적이고 효과적인 \n솔루션을 설계하라는 요청을 받았습니다. \n이를 달성하기 위해 솔루션 설계자는 어떤 조치를 취해야 합니까? \nA. 파일에 대해 미리 서명된 URL 을 생성합니다. \nB. 모든 리전에 교차 리전 복제를 사용합니다. \nC. Amazon Route 53 의 지리적 근접성 기능을 사용합니다. \nD. S3 버킷과 함께 Amazon CloudFront 를 원본으로 사용합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/87522-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \n정적 HTML 페이지 + 전 세계 사용자의 조회 + S3 버킷에 저장된 데이터 = S3 + \nCloudFront 조합. 답은 D. \n \n설명2: \nAmazon CloudFront 는 HTML 페이지, 이미지 및 비디오와 같은 정적 및 동적 웹 콘텐츠의 \n전송 속도를 높이는 콘텐츠 전송 네트워크(CDN)입니다. CloudFront 를 사용하면 HTML \n페이지가 가장 가까운 엣지 로케이션에서 사용자에게 제공되므로 더 빠르게 전달되고 더 \n\n나은 사용자 경험을 얻을 수 있습니다. 또한 CloudFront 는 글로벌 이벤트에 예상되는 높은 \n트래픽과 많은 수의 요청을 처리하여 전 세계 사용자가 HTML 페이지를 사용할 수 있고 \n액세스할 수 있도록 합니다.", "answer_choice": "D"}, "167": {"q_num": 167, "question": "회사는 \nAmazon \nEC2 \n인스턴스 \n플릿에서 \n프로덕션 \n애플리케이션을 \n실행합니다. \n애플리케이션은 Amazon SQS 대기열에서 데이터를 읽고 병렬로 메시지를 처리합니다. \n메시지 볼륨은 예측할 수 없으며 종종 트래픽이 간헐적으로 발생합니다. 이 애플리케이션은 \n다운타임 없이 지속적으로 메시지를 처리해야 합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. 스팟 인스턴스를 독점적으로 사용하여 필요한 최대 용량을 처리하십시오. \nB. 예약 인스턴스를 독점적으로 사용하여 필요한 최대 용량을 처리합니다. \nC. 기본 용량으로 예약 인스턴스를 사용하고 추가 용량을 처리하려면 스팟 인스턴스를 \n사용합니다. \nD. 기본 용량에는 예약 인스턴스를 사용하고 추가 용량을 처리하려면 온디맨드 인스턴스를 \n사용합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/87510-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nA(X) : 가동 중지 시간이 없어야 한다고 했으므로 중지될 위험이 잇는 스팟 인스턴스는 \n적절치 않음. \nB(X) : 메시지 볼륨을 예측할 수 없고 간헐적인 트래픽이 발생하는 상황에서 예측할 수 \n있는 트래픽이 발생하는 데에 적합한 예약 인스턴스는 맞지 않음. \nC(X) : A 와 같은 이유로 오답. \nD(O) : 최소 사용량을 기준 용량으로 삼아 예약 인스턴스를 사용함으로서 비용을 절감하고, \n추가적이고 유동적인 트래픽은 온디맨드 인스턴스로 유연하게 처리 가능. \n \n설명2: \n중단할 수 없는 단기적이고 불규칙한 워크로드가 있는 애플리케이션에는 온디맨드 \n인스턴스를 사용하는 것이 좋습니다. \nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-on-demand-instances.ht\nml", "answer_choice": "D"}, "168": {"q_num": 168, "question": "보안 팀은 팀의 모든 AWS 계정에서 특정 서비스 또는 작업에 대한 액세스를 제한하려고 \n합니다. 모든 계정은 AWS Organizations\n의 대규모 조직에 속합니다. 솔루션은 확장 \n가능해야 하며 권한을 유지할 수 있는 단일 지점이 있어야 합니다. \n이를 달성하기 위해 솔루션 설계자는 무엇을 해야 합니까? \nA. ACL 을 생성하여 서비스 또는 작업에 대한 액세스를 제공합니다. \nB. 계정을 허용할 보안 그룹을 생성하고 사용자 그룹에 연결합니다. \nC. 각 계정에서 교차 계정 역할을 생성하여 서비스 또는 작업에 대한 액세스를 거부합니다. \nD. 루트 조직 단위에 서비스 제어 정책을 만들어 서비스 또는 작업에 대한 액세스를 \n거부합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/87512-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \n권한을 유지할 수 있는 단일 지점이 핵심 키워드. 답은 D. \n서비스 제어 정책(SCP)은 조직에서 권한을 관리하는 데 사용할 수 있는 조직 정책 \n유형입니다. SCP\n는 조직의 모든 계정에 대해 사용 가능한 최대 권한을 중앙에서 \n제어합니다. \nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps\n.html \n \n설명2: \n서비스 제어 정책(SCP)은 조직을 관리하는 데 사용할 수 있는 정책 유형 중 하나입니다. \nSCP 는 조직의 모든 계정에 대해 사용 가능한 최대 권한에 대한 중앙 제어를 제공하므로 \n계정이 조직의 액세스 제어 지침을 준수하도록 할 수 있습니다. \nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scp.\nhtml", "answer_choice": "D"}, "169": {"q_num": 169, "question": "회사는 최근 웹 공격으로 인해 공용 웹 애플리케이션의 보안에 대해 우려하고 있습니다. \n애플리케이션은 \nApplication \nLoad \nBalancer(ALB)를 \n사용합니다. \n솔루션 \n설계자는 \n애플리케이션에 대한 DDoS 공격의 위험을 줄여야 합니다. \n솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까? \n\nA. ALB 에 Amazon Inspector 에이전트를 추가합니다. \nB. 공격을 방지하도록 Amazon Macie 를 구성합니다. \nC. 공격을 방지하려면 AWS Shield Advanced 를 활성화하십시오. \nD. ALB 를 모니터링하도록 Amazon GuardDuty 를 구성합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/87526-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nAWS Shield Standard, AWS Shield Advanced 는 애플리케이션 계층에서 DDoS 공격을 방어. \nAWS Shield\n는 AWS\n에서 실행되는 애플리케이션을 보호하는 디도스(DDoS) 보호 \n서비스입니다. AWS Shield 에는 두 계층 – Standard 및 Advanced 가 있습니다. \nhttps://aws.amazon.com/ko/shield/?whats-new-cards.sort-by=item.additionalFields.post\nDateTime&whats-new-cards.sort-order=desc \n \n설명2: \nAWS Shield Advanced 는 Amazon EC2 인스턴스, Elastic Load Balancing 로드 밸런서, \nCloudFront 배포, Route 53 호스팅 영역 및 AWS Global Accelerator 표준 가속기에 대해 \n확장된 DDoS 공격 보호 기능을 제공합니다. \nhttps://docs.aws.amazon.com/waf/latest/developerguide/what-is-aws-waf.html", "answer_choice": "C"}, "170": {"q_num": 170, "question": "회사의 웹 애플리케이션이 Application Load Balancer 뒤의 Amazon EC2 인스턴스에서 \n실행되고 있습니다. 이 회사는 최근 정책을 변경하여 이제 특정 국가에서만 애플리케이션에 \n액세스하도록 요구합니다. \n이 요구 사항을 충족하는 구성은 무엇입니까? \nA. EC2 인스턴스에 대한 보안 그룹을 구성합니다. \nB. Application Load Balancer 에서 보안 그룹을 구성합니다. \nC. VPC 의 Application Load Balancer 에서 AWS WAF 를 구성합니다. \nD. EC2 인스턴스를 포함하는 서브넷에 대한 네트워크 ACL 을 구성합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/87528-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n\nAWS WAF 를 사용하여 특정 국가 또는 지리적 위치로부터의 요청을 허용하거나 차단하려면 \n어떻게 해야 합니까?  \n특정 국가의 사이트 액세스를 차단하거나 특정 국가에서만 액세스하도록 허용하려면 지리적 \n일치 규칙 문을 사용합니다. 기원 국가를 기준으로 일부 웹 요청을 허용하려면 허용하려는 \n국가에 대한 지리적 일치 규칙 문을 추가합니다. 그런 다음 차단하려는 국가에 대한 두 \n번째 지리적 일치 규칙 문을 추가합니다. \nhttps://aws.amazon.com/ko/premiumsupport/knowledge-center/waf-allow-block-countr\ny-geolocation/", "answer_choice": "C"}, "171": {"q_num": 171, "question": "회사는 사용자에게 항목 가격을 기반으로 세금 계산을 위한 조회를 자동화하는 API 를 \n제공합니다. 회사는 연휴 기간에만 더 많은 수의 문의가 발생하여 응답 시간이 느려집니다. \n솔루션 설계자는 확장 가능하고 탄력적인 솔루션을 설계해야 합니다. \n이를 달성하기 위해 솔루션 설계자는 무엇을 해야 합니까? \nA. Amazon EC2 인스턴스에서 호스팅되는 API 를 제공합니다. EC2 인스턴스는 API 요청이 \n있을 때 필요한 계산을 수행합니다. \nB. 항목 이름을 허용하는 Amazon API Gateway 를 사용하여 REST API 를 설계합니다. API \nGateway 는 세금 계산을 위해 항목 이름을 AWS Lambda 에 전달합니다. \nC. 두 개의 Amazon EC2 인스턴스가 있는 Application Load Balancer 를 생성합니다. EC2 \n인스턴스는 받은 항목 이름에 대한 세금을 계산합니다. \nD. Amazon EC2 인스턴스에서 호스팅되는 API 와 연결되는 Amazon API Gateway 를 \n사용하여 REST API 를 설계합니다. API Gateway 는 세금 계산을 위해 항목 이름을 수락하고 \nEC2 인스턴스에 전달합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/87529-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nAPI 제공 + 탄력적인 = API Gateway + Lambda. 답은 B. \n \n설명2: \nLambda 서버리스는 EC2 api 게이트웨이 솔루션보다 확장 가능하고 탄력적입니다.", "answer_choice": "B"}, "172": {"q_num": 172, "question": "솔루션 설계자가 애플리케이션을 위한 새로운 Amazon CloudFront 배포를 생성하고 \n있습니다. 사용자가 제출한 정보 중 일부는 민감한 정보입니다. 애플리케이션은 HTTPS 를 \n사용하지만 다른 보안 계층이 필요합니다. 민감한 정보는 전체 애플리케이션 스택에서 \n보호되어야 하며 정보에 대한 액세스는 특정 애플리케이션으로 제한되어야 합니다. \n솔루션 설계자는 어떤 조치를 취해야 합니까? \nA. CloudFront 서명 URL 을 구성합니다. \nB. CloudFront 서명 쿠키를 구성합니다. \nC. CloudFront 필드 수준 암호화 프로필을 구성합니다. \nD. CloudFront 를 구성하고 뷰어 프로토콜 정책에 대해 오리진 프로토콜 정책 설정을 \nHTTPS 전용으로 설정합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/87517-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nAmazon CloudFront 를 사용하면 HTTPS 를 통해 오리진 서버에 대한 종단 간 보안 연결을 \n적용할 수 있습니다. 필드 레벨 암호화는 추가 보안 레이어를 추가하여 시스템 처리 \n전체에서 특정 데이터를 보호하고 특정 애플리케이션만 이를 볼 수 있도록 합니다. \nhttps://docs.aws.amazon.com/ko_kr/AmazonCloudFront/latest/DeveloperGuide/field-level\n-encryption.html \n \n설명2: \nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/field-levelencry\nption.html \n\"Amazon CloudFront 를 사용하면 HTTPS 를 사용하여 오리진 서버에 대한 엔드 투 엔드 \n보안 연결을 적용할 수 있습니다. \n필드 수준 암호화는 특정 애플리케이션만 볼 수 있도록 시스템 처리 전반에 걸쳐 특정 \n데이터를 보호할 수 있는 추가 보안 계층을 추가합니다.\"", "answer_choice": "C"}, "173": {"q_num": 173, "question": "게임 회사는 AWS\n에서 브라우저 기반 애플리케이션을 호스팅합니다. 애플리케이션 \n사용자는 Amazon S3 에 저장된 많은 수의 비디오 및 이미지를 소비합니다. 이 내용은 모든 \n사용자에게 동일합니다. \n이 응용 프로그램은 인기가 높아졌으며 전 세계적으로 수백만 명의 사용자가 이러한 미디어 \n파일에 액세스합니다. 회사는 원본에 대한 부하를 줄이면서 사용자에게 파일을 제공하려고 \n\n합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. 웹 서버 앞에 AWS Global Accelerator 액셀러레이터를 배포합니다. \nB. S3 버킷 앞에 Amazon CloudFront 웹 배포를 배포합니다. \nC. 웹 서버 앞에 Redis 인스턴스용 Amazon ElastiCache 를 배포합니다. \nD. 웹 서버 앞에 Amazon ElastiCache for Memcached 인스턴스를 배포합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/87530-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nS3 + 많은 수의 비디오와 이미지 + 수백만명 액세스가 핵심. S3 + CloudFront 로 CDN \n서비스 사용해야 부하를 줄일 수 있음. \n \n설명2: \nElastiCache 는 완전 관리형 인 메모리 데이터 저장소에서 정보를 신속하게 검색하여 웹 \n애플리케이션의 성능을 향상시킵니다. Memcached 및 Redis 를 활용하고 애플리케이션이 \n디스크 기반 데이터베이스에서 데이터를 읽는 데 걸리는 시간을 상당히 단축합니다. \nAmazon CloudFront 는 TCP(전송 제어 프로토콜) 프로토콜을 기반으로 하는 HTTP 및 \nWebSocket 프로토콜의 동적 콘텐츠를 지원합니다. 일반적인 사용 사례에는 동적 API 호출, \n웹 페이지 및 웹 애플리케이션뿐만 아니라 오디오 및 이미지와 같은 애플리케이션의 정적 \n파일이 포함됩니다. 또한 HTTP 를 통한 주문형 미디어 스트리밍을 지원합니다. AWS Global \nAccelerator는 UDP(사용자 데이터그램 프로토콜)와 TCP 기반 프로토콜을 모두 지원합니다. \n일반적으로 게임, IoT 및 VoIP(Voice over IP)와 같은 비HTTP 사용 사례에 사용됩니다. 고정 \nIP 주소 또는 빠른 지역 장애 조치가 필요한 HTTP 사용 사례에도 적합합니다.", "answer_choice": "B"}, "174": {"q_num": 174, "question": "회사에는 ALB(Application Load Balancer) 뒤의 단일 가용 영역에 있는 Amazon EC2 Auto \nScaling 그룹에서 6 개의 프런트 엔드 웹 서버를 실행하는 다중 계층 애플리케이션이 \n있습니다. 솔루션 설계자는 애플리케이션을 수정하지 않고 인프라를 고가용성으로 수정해야 \n합니다. \n고가용성을 제공하는 솔루션 설계자는 어떤 아키텍처를 선택해야 합니까? \nA. 두 리전 각각에서 세 개의 인스턴스를 사용하는 Auto Scaling 그룹을 만듭니다. \nB. 2\n개의 가용 영역 각각에서 3\n개의 인스턴스를 사용하도록 Auto Scaling 그룹을 \n수정합니다. \n\nC. 다른 리전에서 더 많은 인스턴스를 빠르게 생성하는 데 사용할 수 있는 Auto Scaling \n템플릿을 생성합니다. \nD. 라운드 로빈 구성에서 Amazon EC2 인스턴스 앞의 ALB 를 변경하여 웹 계층에 대한 \n트래픽의 균형을 맞춥니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/87533-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \n다중 AZ 를 사용해야 하는 상황. \nA(X) : 리전 간 Auto Scaling 은 불가. \n지리적 이중화의 안전성과 안정성을 활용하려면 Auto Scaling 그룹을 리전 내의 여러 가용 \n영역에 걸쳐 확장하고 로드 밸런서를 연결하여 해당 가용 영역에 들어오는 트래픽을 \n분산하십시오. \nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/as-add-availability-zone.html \n \n설명2: \n여러 가용 영역을 사용하도록 기존 Auto Scaling 그룹을 수정하여 이 아키텍처에 대해 매우 \n간단하게 고가용성을 활성화할 수 있습니다. ASG 는 부하를 자동으로 분산하므로 실제로 \nAZ 당 인스턴스를 지정할 필요가 없습니다. \n참조: \nhttps://aws.amazon.com/ec2/autoscaling/", "answer_choice": "B"}, "175": {"q_num": 175, "question": "전자 상거래 회사에는 Amazon API Gateway 및 AWS Lambda 함수를 사용하는 주문 처리 \n애플리케이션이 있습니다. 애플리케이션은 Amazon Aurora PostgreSQL 데이터베이스에 \n데이터를 저장합니다. 최근 판매 행사 중에 고객 주문이 갑자기 급증했습니다. 일부 고객은 \n시간 초과를 경험했고 애플리케이션은 해당 고객의 주문을 처리하지 않았습니다. \n솔루션 설계자는 많은 수의 열린 연결로 인해 데이터베이스에서 CPU 사용률과 메모리 \n사용률이 높다고 판단했습니다. 솔루션 설계자는 응용 프로그램을 최소한으로 변경하면서 \n시간 초과 오류를 방지해야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Lambda 함수에 대해 프로비저닝된 동시성을 구성합니다. 여러 AWS 리전에서 글로벌 \n데이터베이스가 되도록 데이터베이스를 수정합니다. \nB. \nAmazon \nRDS \n프록시를 \n사용하여 \n데이터베이스에 \n대한 \n프록시를 \n생성합니다. \n\n데이터베이스 엔드포인트 대신 RDS 프록시 엔드포인트를 사용하도록 Lambda 함수를 \n수정합니다. \nC. 다른 AWS 리전에서 데이터베이스에 대한 읽기 전용 복제본을 생성합니다. API \nGateway\n에서 쿼리 문자열 파라미터를 사용하여 트래픽을 읽기 전용 복제본으로 \n라우팅합니다. \nD. AWS Database Migration Service(AWS DMS)를 사용하여 Aurora PostgreSQL 에서 \nAmazon DynamoDB 로 데이터를 마이그레이션합니다. DynamoDB 테이블을 사용하도록 \nLambda 함수를 수정합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/87533-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \n연결 수가 많음 = RDS Proxy. 정답은 B. \nRDS 프록시를 사용하여 예기치 않은 데이터베이스 트래픽 급증을 처리할 수 있습니다. \n급증을 처리하지 않으면 연결 초과 구독 또는 빠른 속도의 새 연결 생성으로 인한 문제가 \n발생할 수 있습니다. RDS 프록시는 데이터베이스 연결 풀을 설정하고 이 풀에서 연결을 \n재사용합니다. 이 접근 방식은 매번 새 데이터베이스 연결을 여는 데서 오는 메모리 및 \nCPU 오버헤드 를 방지합니다. 과다 구독으로부터 데이터베이스를 보호하기 위해 생성되는 \n데이터베이스 연결 수를 제어할 수 있습니다. \nhttps://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/rds-proxy.html \n \n설명2: \n최신 \n서버리스 \n아키텍처에 \n구축된 \n애플리케이션을 \n포함하여 \n많은 \n애플리케이션은 \n데이터베이스 서버에 대해 많은 수의 열린 연결을 가질 수 있으며 빠른 속도로 \n데이터베이스 연결을 열고 닫을 수 있으므로 데이터베이스 메모리와 컴퓨팅 리소스가 \n고갈될 수 있습니다. Amazon RDS Proxy 를 사용하면 애플리케이션이 데이터베이스와 \n설정된 연결을 풀링하고 공유하여 데이터베이스 효율성과 애플리케이션 확장성을 개선할 수 \n있습니다. \nhttps://aws.amazon.com/id/rds/proxy/", "answer_choice": "B"}, "176": {"q_num": 176, "question": "애플리케이션은 프라이빗 서브넷의 Amazon EC2 인스턴스에서 실행됩니다. 애플리케이션은 \nAmazon DynamoDB 테이블에 액세스해야 합니다. \n트래픽이 AWS 네트워크를 벗어나지 않도록 하면서 테이블에 액세스하는 가장 안전한 \n\n방법은 무엇입니까? \nA. DynamoDB 용 VPC 엔드포인트를 사용합니다. \nB. 퍼블릭 서브넷에서 NAT 게이트웨이를 사용합니다. \nC. 프라이빗 서브넷에서 NAT 인스턴스를 사용합니다. \nD. VPC 에 연결된 인터넷 게이트웨이를 사용합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/87532-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nVPC 내에 있는 프라이빗 서브넷의 EC2 인스턴스와 DynamoDB 간 가장 안전한 AWS \n네트워크 통신 = VPC Gateway Endpoint. \n게이트웨이 엔드포인트는 VPC 용 인터넷 게이트웨이 또는 NAT 디바이스가 없어도 Amazon \nS3 및 DynamoDB 에 대한 안정적인 연결을 제공합니다. \nhttps://docs.aws.amazon.com/ko_kr/vpc/latest/privatelink/vpce-gateway.html#vpc-endp\noints-limitations \n \n \n설명2: \nDynamoDB 용 VPC 엔드포인트를 사용하면 VPC 의 Amazon EC2 인스턴스가 프라이빗 IP \n주소를 사용하여 퍼블릭 인터넷에 노출되지 않고 DynamoDB 에 액세스할 수 있습니다. EC2 \n인스턴스에는 퍼블릭 IP 주소가 필요하지 않으며 VPC 에 인터넷 게이트웨이, NAT 디바이스 \n또는 가상 프라이빗 게이트웨이가 필요하지 않습니다. 엔드포인트 정책을 사용하여 \nDynamoDB 에 대한 액세스를 제어합니다. VPC 와 AWS 서비스 간의 트래픽은 Amazon \n네트워크를 벗어나지 않습니다.", "answer_choice": "A"}, "177": {"q_num": 177, "question": "엔터테인먼트 회사는 Amazon DynamoDB\n를 사용하여 미디어 메타데이터를 저장하고 \n있습니다. 애플리케이션이 읽기 집약적이며 지연이 발생합니다. 회사에는 추가 운영 \n오버헤드를 처리할 직원이 없으며 애플리케이션을 재구성하지 않고 DynamoDB 의 성능 \n효율성을 개선해야 합니다. \n이 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까? \nA. Redis 용 Amazon ElastiCache 를 사용합니다. \nB. Amazon DynamoDB Accelerator(DAX)를 사용합니다. \n\nC. DynamoDB 전역 테이블을 사용하여 데이터를 복제합니다. \nD. 자동 검색이 활성화된 Memcached 용 Amazon ElastiCache 를 사용합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/87572-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nDynamoDB 와 DAX 가 결합되면 성능을 한 단계 업그레이드하여 읽기 중심의 워크로드에서 \n초당 수백만 개의 요청에도 마이크로초의 응답 시간을 지원합니다. DynamoDB\n와 \n마찬가지로 DAX 는 완전관리형입니다. 따라서 하드웨어나 소프트웨어 프로비저닝, 설정 및 \n구성, 소프트웨어 패치, 분산 캐시 클러스터 운영 또는 확장 시 여러 인스턴스에 데이터 \n복제 등과 같은 관리 작업에 대해 더 이상 걱정할 필요가 없습니다. DAX 는 장애 탐지, \n장애 복구, 소프트웨어 패치와 같은 일반적인 관리 작업 상당 부분을 자동화합니다. DAX 는 \nDynamoDB API 와 호환되므로 작동하는 애플리케이션 코드를 변경할 필요가 없습니다.  \n \n참고: \nhttps://aws.amazon.com/dynamodb/dax/", "answer_choice": "B"}, "178": {"q_num": 178, "question": "회사의 인프라는 단일 AWS 리전에 있는 Amazon EC2 인스턴스와 Amazon RDS DB \n인스턴스로 구성됩니다. 회사는 별도의 리전에 데이터를 백업하려고 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. AWS Backup 을 사용하여 EC2 백업과 RDS 백업을 별도의 리전에 복사합니다. \nB. Amazon Data Lifecycle Manager(Amazon DLM)를 사용하여 EC2 백업 및 RDS 백업을 \n별도의 리전에 복사합니다. \nC. EC2 인스턴스의 Amazon 머신 이미지(AMI)를 생성합니다. AMI\n를 별도의 리전에 \n복사합니다. 별도의 리전에서 RDS DB 인스턴스에 대한 읽기 전용 복제본을 생성합니다. \nD. Amazon Elastic Block Store(Amazon EBS) 스냅샷을 생성합니다. EBS 스냅샷을 별도의 \n리전에 복사합니다. RDS 스냅샷을 생성합니다. RDS 스냅샷을 Amazon S3 로 내보냅니다. S3 \nCRR(Cross-Region Replication)을 별도의 리전에 구성합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/87639-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n\nAWS Backup 을 사용하여 EC2 및 RDS 백업을 별도의 리전에 복사하는 것은 최소한의 운영 \n오버헤드로 요구 사항을 충족하는 솔루션입니다. AWS Backup\n은 백업 프로세스를 \n간소화하고 백업을 다른 리전으로 자동 복사하여 EC2 인스턴스 및 RDS 데이터베이스에 \n대한 별도의 백업 프로세스 관리와 관련된 수동 작업 및 운영 복잡성을 줄입니다. \n \nB: Amazon Data Lifecycle Manager(Amazon DLM)가 RDS 백업을 별도의 리전에 직접 \n복사하도록 설계되지 않았기 때문에 올바르지 않습니다. \nC: Amazon 머신 이미지(AMI) 및 읽기 전용 복제본을 생성하면 전용 백업 솔루션에 비해 \n복잡성과 운영 오버헤드가 추가되기 때문에 올바르지 않습니다. \nD: Amazon EBS 스냅샷, RDS 스냅샷 및 S3 CRR(Cross-Region Replication)을 사용하려면 \n여러 수동 단계와 추가 구성이 수반되어 복잡성이 증가하기 때문에 올바르지 않습니다.", "answer_choice": "A"}, "179": {"q_num": 179, "question": "솔루션 설계자는 애플리케이션이 Amazon RDS DB 인스턴스에 액세스하는 데 사용하는 \n데이터베이스 사용자 이름과 암호를 안전하게 저장해야 합니다. 데이터베이스에 액세스하는 \n애플리케이션은 Amazon EC2 인스턴스에서 실행됩니다. 솔루션 설계자는 AWS Systems \nManager Parameter Store 에서 보안 매개변수를 생성하려고 합니다. \n솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. Parameter Store 파라미터에 대한 읽기 액세스 권한이 있는 IAM 역할을 생성합니다. \n파라미터를 암호화하는 데 사용되는 AWS Key Management Service(AWS KMS) 키에 대한 \nDecrypt 액세스를 허용합니다. 이 IAM 역할을 EC2 인스턴스에 할당합니다. \nB. Parameter Store 파라미터에 대한 읽기 액세스를 허용하는 IAM 정책을 생성합니다. \n파라미터를 암호화하는 데 사용되는 AWS Key Management Service(AWS KMS) 키에 대한 \nDecrypt 액세스를 허용합니다. 이 IAM 정책을 EC2 인스턴스에 할당합니다. \nC. Parameter Store 파라미터와 EC2 인스턴스 간에 IAM 신뢰 관계를 생성합니다. 신뢰 \n정책에서 Amazon RDS 를 보안 주체로 지정합니다. \nD. DB 인스턴스와 EC2 인스턴스 간에 IAM 신뢰 관계를 생성합니다. 신뢰 정책에서 \nSystems Manager 를 보안 주체로 지정합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/87582-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n데이터베이스 사용자 이름과 암호를 AWS 시스템 관리자 파라미터 스토어에 안전하게 \n저장하고 EC2 인스턴스에서 실행 중인 애플리케이션이 액세스할 수 있도록 하려면 \n\n솔루션스 아키텍트는 파라미터 스토어 파라미터에 대한 읽기 액세스 권한이 있는 IAM \n역할을 생성하고 파라미터를 암호화하는 데 사용되는 AWS KMS 키에 대한 암호 해독 \n액세스를 허용해야 합니다. 그런 다음 솔루션스 아키텍트는 이 IAM 역할을 EC2 인스턴스에 \n할당해야 합니다. \n이 접근 방식을 사용하면 EC2 인스턴스가 파라미터 스토어의 파라미터에 액세스하고 \n지정된 KMS 키를 사용하여 해독하는 동시에 필요한 보안 제어를 적용하여 승인된 \n당사자만 파라미터에 액세스할 수 있도록 할 수 있습니다.", "answer_choice": "A"}, "180": {"q_num": 180, "question": "회사에서 API 로 구동되는 클라우드 통신 플랫폼을 설계하고 있습니다. 애플리케이션은 \nNLB(Network Load Balancer) 뒤의 Amazon EC2 인스턴스에서 호스팅됩니다. 이 회사는 \nAmazon API Gateway 를 사용하여 외부 사용자에게 API 를 통해 애플리케이션에 대한 \n액세스 권한을 제공합니다. 이 회사는 SQL 인젝션과 같은 웹 익스플로잇으로부터 플랫폼을 \n보호하고 대규모의 정교한 DDoS 공격을 감지하고 완화하기를 원합니다. \n어떤 솔루션 조합이 MOST 보호를 제공합니까? (두 가지를 선택하세요.) \nA. AWS WAF 를 사용하여 NLB 를 보호하십시오. \nB. NLB 와 함께 AWS Shield Advanced 를 사용합니다. \nC. AWS WAF 를 사용하여 Amazon API Gateway 를 보호합니다. \nD. AWS Shield Standard 와 함께 Amazon GuardDuty 사용 \nE. Amazon API Gateway 와 함께 AWS Shield Standard 를 사용합니다.", "answer_block": "Answer: B, C \nhttps://www.examtopics.com/discussions/amazon/view/87640-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nAWS Shield Advanced 는 Amazon EC2 인스턴스, Elastic Load Balancing 로드 밸런서, \nCloudFront 배포, Route 53 호스팅 영역 및 AWS Global Accelerator 표준 가속기에 대해 \n확장된 DDoS 공격 보호 기능을 제공합니다. AWS WAF 는 보호된 웹 애플리케이션 리소스로 \n전달되는 HTTP 및 HTTPS 요청을 모니터링할 수 있는 웹 애플리케이션 방화벽입니다. \n다음 리소스 유형을 보호할 수 있습니다. \nAmazon CloudFront 배포 \n아마존 API 게이트웨이 REST API \n애플리케이션 로드 밸런서 \nAWS AppSync GraphQL API \nAmazon Cognito 사용자 풀 \n\nhttps://docs.aws.amazon.com/waf/latest/developerguide/what-is-aws-waf.html \n \n설명2: \n지문에서 등장한 수단은 AWS WAF, AWS Shield Standard, AWS Shield Advanced 로 3 개. \n◈Shield Advanced = WAF + Shield Standard. \n・Shield Advanced = Amazon Elastic Compute Cloud(EC2), Elastic Load Balancing(ELB), \nAmazon CloudFront, AWS Global Accelerator 및 Amazon Route 53 리소스에서 실행되는 \n애플리케이션을 목표로 하는 공격에 대해 더 높은 수준의 보호를 구현. 정교한 대규모 \nDDoS 공격에 대한 추가 보호 및 완화, 실시간에 가까운 공격에 대한 가시성, 웹 \n애플리케이션 방화벽 [AWS WAF 와의 통합]을 제공. \nhttps://aws.amazon.com/ko/shield/?whats-new-cards.sort-by=item.additionalFields.post\nDateTime&whats-new-cards.sort-order=desc \nAWS Shield Advanced 구독에는 다음 기능과 옵션이 포함됩니다. 이는 AWS 에서 이미 받은 \nDDoS 탐지 및 완화 기능을 보완합니다. ◎AWS WAF 통합. ◎보호 그룹. ◎AWS Firewall \nManager 를 통한 Shield Advanced 보호의 중앙 집중식 관리.◎AWS Shield 대응 팀(SRT) \nhttps://docs.aws.amazon.com/waf/latest/developerguide/ddos-advanced-summary-cap\nabilities.html \n・Shield Standard = \"\"네트워크 및 전송 계층 DDoS 공격으로부터 보호 \nhttps://aws.amazon.com/ko/shield/?whats-new-cards.sort-by=item.additionalFields.post\nDateTime&whats-new-cards.sort-order=desc \n・WAF = 일반적인 웹 공격으로부터 웹 애플리케이션이나 API 를 보호하는 데 도움이 되는 \n웹 애플리케이션 방화벽입니다. SQL 주입 또는 사이트 간 스크립팅과 같은 일반적인 공격 \n패턴을 차단하는 보안 규칙 및 사용자가 정의한 특정 트래픽 패턴을 필터링하는 규칙을 \n생성하도록 지원 https://aws.amazon.com/ko/waf/ \nAWS WAF\n로 보호할 수 있는 리소스. ◎Amazon CloudFront 배포. ◎Amazon API \n게이트웨이 REST API ◎애플리케이션 로드 밸런서 ◎AWS AppSync GraphQL API ◎Amazon \nCognito 사용자 풀 \nhttps://docs.aws.amazon.com/waf/latest/developerguide/how-aws-waf-works.html \nA(X) : WAF 는 웹 애플리케이션 방화벽으로, 네트워크 계층이 아니라 애플리케이션 계층을 \n방어. \nB(O) : AWS Shield Advanced 는 DDoS EC2, ELB, CloudFront, AGA, Route 53 리소스 \n방어하며 WAF 와 통합. \nC(O) : AWS WAF 는 웹 애플리케이션 및 API 를 공격으로부터 보호하는 데 도움이 되는 웹 \n애플리케이션 방화벽입니다. \nhttps://docs.aws.amazon.com/ko_kr/apigateway/latest/developerguide/apigateway-contr\nol-access-aws-waf.html \n\nD(X) : GuardDuty 는 AWS 계정 보호 시스템. https://aws.amazon.com/ko/guardduty/ \nE(X) : AWS Shield Standard 는 DDoS 보호만을 제공.", "answer_choice": "B"}, "181": {"q_num": 181, "question": "회사에는 Amazon EC2 인스턴스에서 실행되는 레거시 데이터 처리 애플리케이션이 \n있습니다. 데이터는 순차적으로 처리되지만 결과의 순서는 중요하지 않습니다. 응용 \n프로그램은 모놀리식 아키텍처를 사용합니다. 회사에서 수요 증가에 맞춰 애플리케이션을 \n확장할 수 있는 유일한 방법은 인스턴스 크기를 늘리는 것입니다. \n이 회사의 개발자는 Amazon Elastic Container Service(Amazon ECS)에서 마이크로서비스 \n아키텍처를 사용하도록 애플리케이션을 다시 작성하기로 결정했습니다. \n솔루션 설계자는 마이크로서비스 간의 통신을 위해 무엇을 권장해야 합니까? \nA. Amazon Simple Queue Service(Amazon SQS) 대기열을 생성합니다. 데이터 생산자에 \n코드를 추가하고 데이터를 대기열로 보냅니다. 데이터 소비자에 코드를 추가하여 대기열의 \n데이터를 처리합니다. \nB. Amazon Simple Notification Service(Amazon SNS) 주제를 생성합니다. 데이터 생산자에 \n코드를 추가하고 주제에 알림을 게시합니다. 데이터 소비자에 코드를 추가하여 주제를 \n구독합니다. \nC. 메시지를 전달할 AWS Lambda 함수를 생성합니다. 데이터 생산자에 코드를 추가하여 \n데이터 객체로 Lambda 함수를 호출합니다. 데이터 소비자에 코드를 추가하여 Lambda \n함수에서 전달되는 데이터 객체를 수신합니다. \nD. Amazon DynamoDB 테이블을 생성합니다. DynamoDB 스트림을 활성화합니다. 데이터 \n생산자에 코드를 추가하여 테이블에 데이터를 삽입합니다. 데이터 소비자에 코드를 \n추가하여 DynamoDB Streams API\n를 사용하여 새 테이블 항목을 감지하고 데이터를 \n검색합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/87647-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \n분리와 함께 처리할 응용 프로그램에 대한 메시지를 보관할 큐를 수용하도록 아키텍처를 \n변경하기만 하면 됨 A(O) – SQS \n \n설명2: \n대기열의 처리량이 제한됨(일괄 처리 없이 300msg/s, 일괄 처리 시 3000msg/s, 일괄 \n작업당 최대 10msg, 대기열에서 메시지 복제가 허용되지 않음(정확히 한 번 전달), 메시지 \n\n순서가 보존됨(FIFO), 대기열 이름 .fifo 로 끝나야 합니다.", "answer_choice": "A"}, "182": {"q_num": 182, "question": "회사에서 MySQL 데이터베이스를 온프레미스에서 AWS 로 마이그레이션하려고 합니다. 이 \n회사는 최근 비즈니스에 상당한 영향을 미치는 데이터베이스 중단을 경험했습니다. 이러한 \n일이 다시 발생하지 않도록 회사는 데이터 손실을 최소화하고 모든 트랜잭션을 최소 두 \n개의 노드에 저장하는 안정적인 AWS 데이터베이스 솔루션을 원합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 3 개의 가용 영역에 있는 3 개의 노드에 대한 동기식 복제로 Amazon RDS DB 인스턴스를 \n생성합니다. \nB. 다중 AZ 기능이 활성화된 Amazon RDS MySQL DB 인스턴스를 생성하여 데이터를 \n동기식으로 복제합니다. \nC. Amazon RDS MySQL DB 인스턴스를 생성한 다음 데이터를 동기식으로 복제하는 별도의 \nAWS 리전에서 읽기 전용 복제본을 생성합니다. \nD. Amazon RDS MySQL DB 인스턴스에 데이터를 동기식으로 복제하기 위해 AWS Lambda \n함수를 트리거하는 MySQL 엔진이 설치된 Amazon EC2 인스턴스를 생성합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/87641-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \n데이터베이스의 고가용성이 필요한 상황이므로 Multi AZ 가 필수인 상황. \nA(X) : AWS 로 MySQL 데이터베이스를 마이그레이션하려고 한다 했으므로 Amazon RDS for \nMySQL 이 맞음. \nB(O) : Amazon RDS 다중 AZ 동기 복제 기술을 사용하여 대기 데이터베이스 인스턴스의 \n데이터를 프라이머리와 함께 최신 상태로 유지합니다. 장애를 감지하면 Amazon RDS 는 \n수동 개입 없이 자동으로 대기 인스턴스로 장애 조치합니다. \nhttps://aws.amazon.com/ko/rds/features/multi-az/ \nC(X) : RDS read replica 는 동기식이 아닌 비동기식 방식임. \n기본 DB 인스턴스에 적용된 업데이트는 읽기 전용 복제본에 비동기식으로 복사됩니다. \nhttps://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/USER_ReadRepl.html \nD(X) : 다른 AZ 나 리전에 복제하는지에 대한 여부가 안 나와 있음. 그리고 굳이 Lambda 를 \n사용해야 하는지도 의문. \n \n설명2: \n\nQ: Amazon RDS 는 나를 대신하여 무엇을 관리합니까? \nAmazon RDS 는 요청한 인프라 용량 프로비저닝에서 데이터베이스 소프트웨어 설치에 \n이르기까지 관계형 데이터베이스 설정과 관련된 작업을 관리합니다. 데이터베이스가 \n가동되고 실행되면 Amazon RDS 는 백업 수행 및 데이터베이스를 강화하는 소프트웨어 \n패치와 같은 일반적인 관리 작업을 자동화합니다. 선택적 다중 AZ 배포를 통해 Amazon \nRDS 는 자동 장애 조치를 통해 가용 영역 전체에서 동기식 데이터 복제도 관리합니다. \nhttps://aws.amazon.com/rds/faqs/", "answer_choice": "B"}, "183": {"q_num": 183, "question": "회사에서 새로운 동적 주문 웹사이트를 구축하고 있습니다. 회사는 서버 유지 관리 및 \n패치를 최소화하려고 합니다. 웹 사이트는 가용성이 높아야 하며 사용자 요구의 변화를 \n충족하기 위해 가능한 한 빨리 읽기 및 쓰기 용량을 확장해야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Amazon S3 에서 정적 콘텐츠를 호스팅합니다. Amazon API Gateway 및 AWS Lambda 를 \n사용하여 동적 콘텐츠를 호스팅합니다. 데이터베이스에 대한 온디맨드 용량과 함께 \nAmazon DynamoDB 를 사용합니다. 웹 사이트 콘텐츠를 제공하도록 Amazon CloudFront 를 \n구성합니다. \nB. Amazon S3 에서 정적 콘텐츠를 호스팅합니다. Amazon API Gateway 및 AWS Lambda 를 \n사용하여 동적 콘텐츠를 호스팅합니다. 데이터베이스에는 Aurora Auto Scaling 과 함께 \nAmazon Aurora 를 사용하십시오. 웹 사이트 콘텐츠를 제공하도록 Amazon CloudFront 를 \n구성합니다. \nC. Amazon EC2 인스턴스에서 모든 웹 사이트 콘텐츠를 호스팅합니다. Auto Scaling 그룹을 \n생성하여 EC2 인스턴스를 확장합니다. Application Load Balancer 를 사용하여 트래픽을 \n분산합니다. 데이터베이스에 대해 프로비저닝된 쓰기 용량과 함께 Amazon DynamoDB 를 \n사용합니다. \nD. Amazon EC2 인스턴스에서 모든 웹 사이트 콘텐츠를 호스팅합니다. Auto Scaling 그룹을 \n생성하여 EC2 인스턴스를 확장합니다. Application Load Balancer 를 사용하여 트래픽을 \n분산합니다. 데이터베이스에는 Aurora Auto Scaling\n과 함께 Amazon Aurora\n를 \n사용하십시오.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/87570-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n질문의 핵심 문구는 읽기 및 쓰기 용량을 확장해야 한다는 것입니다. Aurora 는 읽기 \n\n전용입니다. Amazon DynamoDB 에는 테이블에 대한 읽기 및 쓰기를 처리하기 위한 두 가지 \n읽기/쓰기 용량 모드가 있습니다. 온디맨드 프로비저닝(기본, 프리 티어 가능) \nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.Rea\ndWriteCapacityMode.html \n \nDynamoDB 는 주문 데이터(키값)을 저장하는데 적합하고 온디맨드 방식으로 쓰기 및 읽기 \n용량을 확장합니다.", "answer_choice": "A"}, "184": {"q_num": 184, "question": "회사에 소프트웨어 엔지니어링에 사용되는 AWS 계정이 있습니다. AWS 계정은 한 쌍의 \nAWS Direct Connect 연결을 통해 회사의 온프레미스 데이터 센터에 액세스할 수 있습니다. \n모든 비 VPC 트래픽은 가상 프라이빗 게이트웨이로 라우팅됩니다. \n개발팀은 최근 콘솔을 통해 AWS Lambda 함수를 생성했습니다. 개발 팀은 함수가 회사 \n데이터 센터의 프라이빗 서브넷에서 실행되는 데이터베이스에 액세스할 수 있도록 허용해야 \n합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 적절한 보안 그룹을 사용하여 VPC 에서 실행되도록 Lambda 함수를 구성합니다. \nB. AWS 에서 데이터 센터로 VPN 연결을 설정합니다. VPN 을 통해 Lambda 함수의 트래픽을 \n라우팅합니다. \nC. Lambda 함수가 Direct Connect 를 통해 온프레미스 데이터 센터에 액세스할 수 있도록 \nVPC 의 라우팅 테이블을 업데이트합니다. \nD. 탄력적 IP 주소를 생성합니다. 탄력적 네트워크 인터페이스 없이 탄력적 IP 주소를 통해 \n트래픽을 보내도록 Lambda 함수를 구성합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/87534-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n해설: \nA(O) : 보안 그룹을 정의하여 VPC 에 Lambda 연결 가능. \nAWS 계정의 가상 사설 클라우드(VPC)에 있는 사설 서브넷에 연결하도록 Lambda 함수를 \n구성할 수 있습니다. Amazon Virtual Private Cloud(Amazon VPC)를 사용하여 데이터베이스, \n캐시 인스턴스 또는 내부 서비스와 같은 리소스에 대한 사설 네트워크를 생성합니다. \n함수가 실행되는 동안 프라이빗 리소스에 액세스하려면 함수를 VPC 에 연결합니다. 함수를 \nVPC 에 연결하면 Lambda 는 함수의 VPC 구성에 있는 각 서브넷의 Hyperplane ENI(탄력적 \n네트워크 인터페이스)에 함수를 할당합니다. Lambda 는 계정의 VPC 지원 기능에 대해 \n\n고유한 서브넷 및 보안 그룹 조합이 처음으로 정의될 때 Hyperplane ENI 를 생성합니다. \nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html#vpc-managing-\neni \nB(X) : ・선택지에서 말하는 VPN 연결이란 VPC-온프레미스 간 연결을 말함. \nVPN 연결 이라는 용어 는 일반적인 용어이지만 이 설명서에서 VPN 연결은 VPC 와 자체 \n온프레미스 네트워크 간의 연결을 나타냅니다. \nhttps://docs.aws.amazon.com/vpn/latest/s2svpn/VPC_VPN.html \n・먼저 Virtual Private Gateway 를 사용하여 VPC-온프레미스 간 Site to Site VPN 연결을 \n수립.  \n◎AWS Site-to-Site VPN : VPC 와 원격 네트워크 사이에 IPsec VPN 연결을 생성할 수 \n있습니다. AWS 측 Site-to-Site VPN 연결에서 가상 프라이빗 게이트웨이 또는 Transit \nGateway\n는 자동 장애 조치를 위한 2\n개의 VPN 엔드포인트(터널)를 제공합니다. \nSite-to-Site VPN 원격 연결 측에서 고객 게이트웨이 디바이스를 구성합니다. \nhttps://docs.aws.amazon.com/ko_kr/vpc/latest/userguide/vpn-connections.html \n・Virtual Private Gateway + Direct Connect + VPN 조합을 사용하는 이유는 Virtual Private \nGateway + VPN 조합은 IPv4 밖에 전송이 안 되는데, Virtual Private Gateway + Direct \nConnect 조합은 IPv6 를 지원하므로 3 가지를 조합하면 IPv4, IPv6 를 모두 사용할 수 있기 \n때문. \n가상 프라이빗 게이트웨이로 라우팅 : AWS Site-to-Site VPN 연결을 사용하여 VPC 의 \n인스턴스를 사용자의 네트워크와 통신하도록 할 수 있습니다. 이렇게 하려면 가상 프라이빗 \n게이트웨이를 생성하여 VPC 에 연결합니다.그런 다음 네트워크 대상 및 가상 프라이빗 \n게이트웨이(vgw-xxxxxxxxxxxxxxxxx)의 대상이 있는 서브넷 라우팅 테이블에 라우팅을 \n추가합니다....가상 프라이빗 게이트웨이의 Site-to-Site VPN 연결은 IPv6 트래픽을 \n지원하지 않습니다. 그러나 가상 프라이빗 게이트웨이를 통해 AWS Direct Connect 연결로 \n라우팅되는 IPv6 트래픽은 지원합니다. \nhttps://docs.aws.amazon.com/ko_kr/vpc/latest/userguide/route-table-options.html#route\n-tables-vgw \n・VPC 과 Lambda 함수 연결 \nAWS 계정에서 VPC(Virtual Private Cloud)의 프라이빗 서브넷에 연결하도록 Lambda 함수를 \n구성할 수 있습니다. \nhttps://docs.aws.amazon.com/ko_kr/lambda/latest/dg/configuration-vpc.html \nBut, 여기까지는 가능하지만 정작 Lambda 함수가 VPN 을 통해 트래픽을 라우팅할 수 \n있는지는 불명확. \n그리고 어차피 A 의 내용이 충족되어야만 가능하기 때문에 정답이 아닐 가능성이 큼. \nC(X) : A 의 내용이 충족되지 않으면 수립 불가. 즉, VPC 에 Lambda 가 연결이 되어야 \n가능하던 말던 함. \n\nLambda 함수는 항상 Lambda 서비스가 소유한 VPC 내에서 실행됩니다. 기본적으로 \nLambda 함수는 사용자 계정의 VPC 에 연결되지 않습니다. \nhttps://docs.aws.amazon.com/ko_kr/lambda/latest/dg/foundation-networking.html \nD(X) : 탄력적 IP 주소는 퍼블릭 IP 주소로, Direct Connect 가 있는 상황에서 굳이 사용할 \n필요가 없음. 게다가 온프레미스 데이터베이스가 있는 곳은 프라이빗 서브넷이라 퍼블릭 IP \n주소로는 무리임. \n \n참조 \nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html#vpc-managing-\neni", "answer_choice": "A"}, "185": {"q_num": 185, "question": "회사에서 Amazon ECS\n를 사용하여 애플리케이션을 실행합니다. 애플리케이션은 원본 \n이미지의 크기가 조정된 버전을 생성한 다음 Amazon S3 API 를 호출하여 크기가 조정된 \n이미지를 Amazon S3 에 저장합니다. \n솔루션 설계자는 애플리케이션이 Amazon S3 에 액세스할 권한이 있는지 어떻게 확인할 수 \n있습니까? \nA. Amazon ECS 에서 읽기/쓰기 액세스를 허용하도록 AWS IAM 에서 S3 역할을 업데이트한 \n다음 컨테이너를 다시 시작합니다. \nB. S3 권한이 있는 IAM 역할을 생성한 다음 작업 정의에서 해당 역할을 taskRoleArn 으로 \n지정합니다. \nC. Amazon ECS 에서 Amazon S3 로의 액세스를 허용하는 보안 그룹을 생성하고 ECS \n클러스터에서 사용하는 시작 구성을 업데이트합니다. \nD. S3 권한이 있는 IAM 사용자를 만든 다음 이 계정으로 로그인한 상태에서 ECS \n클러스터에 대한 Amazon EC2 인스턴스를 다시 시작합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/87648-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nA(X) : S3 에 관한 권한을 물어본 거지 ECS 에 대한 권한을 물어본 게 아님. \nB(O) : 태스크 정의를 등록할 때 태스크 권한의 컨테이너가 사용자 대신 연결된 정책에 \n지정된 AWS API 를 호출하도록 허용하는 IAM 역할에 태스크 역할을 제공할 수 있습니다. \nhttps://docs.aws.amazon.com/ko_kr/AmazonECS/latest/developerguide/task_definition_p\narameters.html \n\nC(X) : 보안 그룹 아웃바운드는 별 설정 안 해놔도 모두 허용이 기본값임. 굳이 설정할 \n필요가 없음. \nD(X) : 액세스 권한이 있는지 확인하겠다고 다른 걸로 로그인해서 굳이 EC2 인스턴스를 \n다시 시작하는 것은 비효율적.", "answer_choice": "B"}, "186": {"q_num": 186, "question": "회사에 AWS\n로 마이그레이션해야 하는 Windows 기반 애플리케이션이 있습니다. 이 \n애플리케이션은 여러 가용 영역에 배포된 여러 Amazon EC2 Windows 인스턴스에 연결된 \n공유 Windows 파일 시스템을 사용해야 합니다. \n솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. 볼륨 게이트웨이 모드에서 AWS Storage Gateway\n를 구성합니다. 각 Windows \n인스턴스에 볼륨을 마운트합니다. \nB. Windows 파일 서버용 Amazon FSx 를 구성합니다. Amazon FSx 파일 시스템을 각 \nWindows 인스턴스에 탑재합니다. \nC. Amazon Elastic File System(Amazon EFS)을 사용하여 파일 시스템을 구성합니다. EFS \n파일 시스템을 각 Windows 인스턴스에 마운트합니다. \nD. 필요한 크기로 Amazon Elastic Block Store(Amazon EBS) 볼륨을 구성합니다. 각 EC2 \n인스턴스를 볼륨에 연결합니다. 볼륨 내의 파일 시스템을 각 Windows 인스턴스에 \n마운트합니다.", "answer_block": "Answer: B  \nhttps://www.examtopics.com/discussions/amazon/view/87650-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n이 솔루션은 여러 가용 영역에 배포된 여러 Amazon EC2 Windows 인스턴스에 연결된 공유 \nWindows 파일 시스템을 사용해야 하는 Windows 기반 애플리케이션 마이그레이션 요구 \n사항을 충족합니다. Amazon FSx for Windows File Server 는 Windows Server 에 구축된 완전 \n관리형 공유 스토리지를 제공하며 광범위한 데이터 액세스, 데이터 관리 및 관리 기능을 \n제공합니다. SMB(서버 메시지 블록) 프로토콜을 지원하며 여러 가용 영역에서 EC2 \nWindows 인스턴스에 탑재할 수 있습니다. \nWindows 기반 애플리케이션이 핵심 키워드. 답은 B. \n \n옵션 A 의 볼륨 게이트웨이 모드의 AWS Storage Gateway 는 온프레미스 애플리케이션 \n서버에서 iSCSI 디바이스로 마운트할 수 있는 클라우드 지원 스토리지 볼륨을 제공하지만 \nSMB 프로토콜 또는 EC2 Windows 인스턴스를 지원하지 않기 때문에 올바르지 않습니다. \n\n옵션 C 는 Amazon Elastic File System(Amazon EFS)이 Linux 기반 워크로드를 위한 확장 \n가능하고 탄력적인 NFS 파일 시스템을 제공하지만 SMB 프로토콜 또는 EC2 Windows \n인스턴스를 지원하지 않기 때문에 올바르지 않습니다. \n옵션 D 는 Amazon Elastic Block Store(Amazon EBS)가 EC2 인스턴스와 함께 사용할 영구 \n블록 스토리지 볼륨을 제공하지만 SMB 프로토콜을 지원하지 않거나 동일한 볼륨에 여러 \n인스턴스를 연결하기 때문에 올바르지 않습니다. \n \n참조: \nhttps://aws.amazon.com/fsx/windows/ \nhttps://docs.aws.amazon.com/fsx/latest/WindowsGuide/using-file-shares.html", "answer_choice": "B"}, "187": {"q_num": 187, "question": "한 회사에서 로드 밸런싱된 프런트 엔드, 컨테이너 기반 애플리케이션 및 관계형 \n데이터베이스로 구성될 전자상거래 애플리케이션을 개발하고 있습니다. 솔루션 설계자는 \n가능한 한 적은 수동 개입으로 작동하는 고가용성 솔루션을 만들어야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? (2 개 선택) \nA. 다중 AZ 모드에서 Amazon RDS DB 인스턴스를 생성합니다. \nB. 다른 가용 영역에서 Amazon RDS DB 인스턴스와 하나 이상의 복제본을 생성합니다. \nC. 동적 애플리케이션 로드를 처리하기 위해 Amazon EC2 인스턴스 기반 Docker \n클러스터를 생성합니다. \nD. 동적 애플리케이션 로드를 처리하기 위해 Fargate 시작 유형으로 Amazon Elastic \nContainer Service(Amazon ECS) 클러스터를 생성합니다. \nE. 동적 애플리케이션 로드를 처리하기 위해 Amazon EC2 시작 유형으로 Amazon Elastic \nContainer Service(Amazon ECS) 클러스터를 생성합니다.", "answer_block": "Answer: A, D \nhttps://www.examtopics.com/discussions/amazon/view/87695-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nA(O) : 다중 AZ 모드로 고가용성 충족. 관계형 데이터베이스로 구성된 프로그램이어야 \n하므로 RDS 사용. \n다중 AZ 배포로 실행되도록 DB 인스턴스를 생성 또는 수정하면 Amazon RDS 가 다른 가용 \n영역에 동기식 ‘예비’ 복제본을 자동으로 프로비저닝하고 유지합니다. 특정 유형의 계획된 \n유지 관리를 수행하는 도중에, 또는 예기치 않은 DB 인스턴스 장애나 가용 영역 장애가 \n발생할 경우 Amazon RDS 가 자동으로 예비 복제본으로 장애 조치하므로 예비 복제본이 \n\n승격되자마자 데이터베이스 쓰기 및 읽기를 재개할 수 있습니다. \nhttps://aws.amazon.com/ko/rds/faqs/ \nB(X) : 장애 발생 시 복구를 위한 것이면 Multi AZ 가 더 유리하므로 고가용성 면에선 Multi \nAZ 가 추천됨. 읽기 복제본을 사용해 데이터베이스 쓰기 가용성을 개선하거나 내 소스 DB \n인스턴스의 데이터를 장애로부터 보호할 수 있습니까? 복제를 사용해 데이터베이스 쓰기 \n가용성을 높이고 최근 데이터베이스 업데이트를 다양한 장애 조건으로부터 보호하려면 DB \n인스턴스를 다중 AZ 배포로 실행하는 것이 좋습니다. Amazon RDS 읽기 전용 복제본과 \n지원되는 엔진의 기본 비동기식 복제를 사용하면 데이터베이스 쓰기가 소스 DB \n인스턴스에서 발생한 후, 읽기 전용 복제본에서 발생합니다. 이 복제 ‘지연 시간’은 상당히 \n다를 수 있습니다. https://aws.amazon.com/ko/rds/faqs/ \nC(X) : EC2 로 굳이 돌릴 거 없이 ECS 를 사용해서 서버리스로 돌릴 수 있음 \nD(O) : Fargate + ECS 조합으로 컨테이너 애플리케이션을 서버리스로 돌릴 수 있음. \nAWS Fargate Fargate 는 Amazon EC2 인스턴스의 서버나 클러스터를 관리할 필요 없이 \n컨테이너를 실행하기 위해 Amazon ECS 에 사용할 수 있는 기술입니다. \nhttps://docs.aws.amazon.com/ko_kr/AmazonECS/latest/developerguide/AWS_Fargate.ht\nml \nE(X) : C 와 같은 이유로 오답. \n \n설명2: \nhttps://docs.aws.amazon.com/AmazonECS/latest/developerguide/Welcome.html \n1. 관계형 데이터베이스: RDS \n2. 컨테이너 기반 애플리케이션: ECS \n\"Amazon ECS 를 사용하면 간단한 API 호출을 사용하여 컨테이너 기반 애플리케이션을 \n시작 및 중지할 수 있습니다. 또한 중앙 집중식 서비스에서 클러스터 상태를 검색하고 많은 \n익숙한 Amazon EC2 기능에 액세스할 수 있습니다.\" \n3. 약간의 수동 개입: Fargate AWS Fargate 에서 관리하는 서버리스 인프라에서 작업과 \n서비스를 실행할 수 있습니다. 또는 인프라를 더 잘 제어하기 위해 관리하는 Amazon EC2 \n인스턴스의 클러스터에서 작업과 서비스를 실행할 수 있습니다.", "answer_choice": "A"}, "188": {"q_num": 188, "question": "회사는 Amazon S3 를 데이터 레이크로 사용합니다. 회사에는 SFTP 를 사용하여 데이터 \n파일을 업로드해야 하는 새로운 파트너가 있습니다. 솔루션 설계자는 운영 오버헤드를 \n최소화하는 고가용성 SFTP 솔루션을 구현해야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. AWS Transfer Family 를 사용하여 공개적으로 액세스할 수 있는 엔드포인트가 있는 SFTP \n\n지원 서버를 구성합니다. S3 데이터 레이크를 대상으로 선택합니다. \nB. Amazon S3 파일 게이트웨이를 SFTP 서버로 사용합니다. S3 파일 게이트웨이 \n엔드포인트 URL\n을 새 파트너에게 노출합니다. S3 파일 게이트웨이 엔드포인트를 새 \n파트너와 공유합니다. \nC. VP 의 프라이빗 서브넷에서 Amazon EC2 인스턴스를 시작합니다. 새 파트너에게 VPN 을 \n사용하여 EC2 인스턴스에 파일을 업로드하도록 지시합니다. EC2 인스턴스에서 cron 작업 \n스크립트를 실행하여 S3 데이터 레이크에 파일을 업로드합니다. \nD. VPC 의 프라이빗 서브넷에서 Amazon EC2 인스턴스를 시작합니다. EC2 인스턴스 앞에 \nNLB(Network Load Balancer)를 배치합니다. NLB 에 대한 SFTP 수신기 포트를 만듭니다. \nNLB 호스트 이름을 새 파트너와 공유합니다. EC2 인스턴스에서 cron 작업 스크립트를 \n실행하여 S3 데이터 레이크에 파일을 업로드합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/87566-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n이 솔루션은 수동 관리 또는 운영 오버헤드 없이 고가용성 SFTP 솔루션을 제공합니다. \nAWS Transfer Family 를 사용하면 인증, 권한 부여 및 스토리지 백엔드로 S3 와의 통합을 \n통해 SFTP 서버를 쉽게 설정할 수 있습니다. \n \n옵션 B 는 SFTP 액세스가 아닌 NFS 또는 SMB 프로토콜을 통한 S3 스토리지에 대한 파일 \n기반 액세스에 주로 사용되는 Amazon S3 파일 게이트웨이 사용을 제안하므로 최선의 \n선택이 아닙니다. \n옵션 C 는 파일 업로드를 위한 EC2 인스턴스, VPN 설정 및 cron 작업 스크립트의 수동 \n관리가 필요하여 운영 오버헤드와 잠재적인 복잡성을 유발하므로 최선의 선택이 아닙니다. \n옵션 D 는 파일 업로드를 위한 EC2 인스턴스, Network Load Balancer 및 cron 작업 \n스크립트의 수동 관리도 필요하므로 최선의 선택이 아닙니다. 옵션 A 에서 AWS Transfer \nFamily 가 제공하는 더 단순하고 완벽하게 관리되는 솔루션에 비해 더 복잡하고 추가 구성 \n요소가 필요합니다.", "answer_choice": "A"}, "189": {"q_num": 189, "question": "회사는 계약 문서를 보관해야 합니다. 계약은 5 년 동안 지속됩니다. 회사는 5 년 동안 \n문서를 덮어쓰거나 삭제할 수 없도록 해야 합니다. 회사는 미사용 문서를 암호화하고 매년 \n암호화 키를 자동으로 교체해야 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하기 위해 솔루션 설계자가 수행해야 \n\n하는 단계 조합은 무엇입니까? (두 가지를 선택하세요.) \nA. Amazon S3 에 문서를 저장합니다. 거버넌스 모드에서 S3 객체 잠금을 사용합니다. \nB. Amazon S3 에 문서를 저장합니다. 규정 준수 모드에서 S3 객체 잠금을 사용합니다. \nC. Amazon S3 관리형 암호화 키(SSE-S3)로 서버 측 암호화를 사용합니다. 키 순환을 \n구성합니다. \nD. AWS Key Management Service(AWS KMS) 고객 관리형 키로 서버 측 암호화를 \n사용합니다. 키 순환을 구성합니다. \nE. AWS Key Management Service(AWS KMS) 고객 제공(가져온) 키로 서버 측 암호화를 \n사용합니다. 키 순환을 구성합니다.", "answer_block": "Answer: B, D \nhttps://www.examtopics.com/discussions/amazon/view/87535-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nB. 규정 준수 모드에서 S3 객체 잠금을 사용하면 객체에 엄격한 보존 정책을 적용하여 \n수정이나 삭제를 방지합니다. \nD. AWS KMS 고객 관리형 키와 함께 서버 측 암호화를 사용하면 문서가 고객 제어형 키로 \n암호화됩니다. 키 순환을 활성화하면 정의된 순환 간격으로 새 암호화 키가 자동으로 \n생성되어 보안이 강화됩니다. \n \n옵션 A: 거버넌스 모드의 S3 객체 잠금은 문서에 필요한 불변성을 제공하지 않으므로 \n잠재적인 수정 또는 삭제가 허용됩니다. \n옵션 C: SSE-S3 만으로는 서버 측 암호화가 명시적으로 지정된 암호화 키 순환 요구 \n사항을 충족하지 않습니다. \n옵션 E: AWS KMS 고객 관리 키(옵션 D)를 사용할 수 있는 경우 고객 제공(가져온) \n키(SSE-C)를 사용한 서버 측 암호화는 필요하지 않으며, 이는 보다 통합되고 관리 가능한 \n솔루션을 제공합니다.", "answer_choice": "B"}, "190": {"q_num": 190, "question": "회사에 Java 및 PHP 기반 웹 애플리케이션이 있습니다. 회사는 애플리케이션을 \n온프레미스에서 AWS 로 옮길 계획입니다. 회사는 새로운 사이트 기능을 자주 테스트할 수 \n있는 능력이 필요합니다. 회사는 또한 최소한의 운영 오버헤드를 필요로 하는 가용성이 \n높고 관리되는 솔루션이 필요합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Amazon S3 버킷을 생성합니다. S3 버킷에서 정적 웹 호스팅을 활성화합니다. 정적 \n\n콘텐츠를 S3 버킷에 업로드합니다. AWS Lambda\n를 사용하여 모든 동적 콘텐츠를 \n처리합니다. \nB. 웹 애플리케이션을 AWS Elastic Beanstalk 환경에 배포합니다. 기능 테스트를 위해 URL \n스와핑을 사용하여 여러 Elastic Beanstalk 환경 간에 전환합니다. \nC. Java 및 PHP 로 구성된 Amazon EC2 인스턴스에 웹 애플리케이션을 배포합니다. Auto \nScaling 그룹과 Application Load Balancer 를 사용하여 웹 사이트의 가용성을 관리하십시오. \nD. 웹 애플리케이션을 컨테이너화합니다. 웹 애플리케이션을 Amazon EC2 인스턴스에 \n배포합니다. AWS 로드 밸런서 컨트롤러를 사용하여 테스트용 새 사이트 기능이 포함된 \n컨테이너 간에 트래픽을 동적으로 라우팅합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/87536-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nElastic Beanstalk 를 사용하면 애플리케이션을 실행하는 인프라에 대해 자세히 알지 못해도 \nAWS 클라우드에서 애플리케이션을 신속하게 배포하고 관리할 수 있습니다. \nElastic Beanstalk 는 Go, Java, .NET, Node.js, PHP, Python 및 Ruby 에서 개발된 \n애플리케이션을 지원합니다....애플리케이션을 생성 및 배포한 후에는 지표, 이벤트, 환경 \n상태 등의 애플리케이션 정보를 Elastic Beanstalk 콘솔, API 또는 통합된 AWS CLI 를 \n비롯한 명령줄 인터페이스를 통해 확인할 수 있습니다. \nhttps://docs.aws.amazon.com/ko_kr/elasticbeanstalk/latest/dg/Welcome.html \n \n설명2: \n빈번한 기능 테스트 - \n- 개발, 테스트 및 프로덕션 사용 사례를 위해 여러 Elastic Beanstalk 환경을 쉽게 생성할 \n수 있습니다. \n- 간단한 URL 스와핑 기술을 사용하여 A/B 테스트 및 기능 반복을 위한 환경 간에 \n트래픽을 라우팅할 수 있습니다. 복잡한 라우팅 규칙이나 인프라 변경이 필요하지 \n않습니다.", "answer_choice": "B"}, "191": {"q_num": 191, "question": "회사에는 MySQL 용 Amazon RDS 에 고객 정보를 저장하는 주문 애플리케이션이 있습니다. \n정규 업무 시간 동안 직원은 보고 목적으로 일회성 쿼리를 실행합니다. 보고 쿼리를 \n실행하는 데 시간이 오래 걸리기 때문에 주문 처리 중에 시간 초과가 발생합니다. 회사는 \n직원이 쿼리를 수행하는 것을 막지 않으면서 시간 초과를 제거해야 합니다. \n\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. 읽기 전용 복제본을 생성합니다. 보고 쿼리를 읽기 전용 복제본으로 이동합니다. \nB. 읽기 전용 복제본을 생성합니다. 주문 애플리케이션을 기본 DB 인스턴스와 읽기 전용 \n복제본에 배포합니다. \nC. 주문형 용량이 있는 Amazon DynamoDB 로 주문 애플리케이션을 마이그레이션합니다. \nD. 사용량이 적은 시간에 보고 쿼리를 예약합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/89077-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nA. 보고 쿼리를 읽기 전용 복제본으로 이동하면 주문 처리에 사용되는 기본 DB 인스턴스가 \n장기 실행 보고 쿼리의 영향을 받지 않습니다. 이렇게 하면 주문 처리 중 시간 초과를 \n제거하는 동시에 직원이 애플리케이션 성능에 영향을 주지 않고 쿼리를 수행할 수 \n있습니다. \nB. 이것은 일정 수준의 부하 분산을 제공할 수 있지만 주문 처리 중 쿼리 보고로 인해 \n발생하는 시간 초과 문제를 구체적으로 다루지는 않습니다. \nC. DynamoDB 는 확장성과 성능상의 이점을 제공하지만 애플리케이션의 데이터 모델 및 \n쿼리 접근 방식을 크게 변경해야 할 수 있습니다. \nD. 이 접근 방식은 주문 처리에 미치는 영향을 완화하는 데 도움이 될 수 있지만 직원이 \n쿼리를 수행하는 것을 막지 않고 시간 초과를 제거해야 하는 요구 사항을 해결하지는 \n못합니다.", "answer_choice": "A"}, "192": {"q_num": 192, "question": "한 병원에서 대규모 기록 기록 수집을 위한 디지털 사본을 만들고자 합니다. 병원은 매일 \n수백 개의 새로운 문서를 계속 추가할 것입니다. 병원의 데이터 팀이 문서를 스캔하고 \n문서를 AWS 클라우드에 업로드합니다. \n솔루션 설계자는 애플리케이션이 데이터에 대해 SQL 쿼리를 실행할 수 있도록 문서를 \n분석하고, 의료 정보를 추출하고, 문서를 저장하는 솔루션을 구현해야 합니다. 솔루션은 \n확장성과 운영 효율성을 극대화해야 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 단계 조합을 수행해야 합니까? \n(2 개 선택) \nA. MySQL 데이터베이스를 실행하는 Amazon EC2 인스턴스에 문서 정보를 씁니다. \nB. 문서 정보를 Amazon S3 버킷에 씁니다. Amazon Athena\n를 사용하여 데이터를 \n쿼리합니다. \n\nC. Amazon EC2 인스턴스의 Auto Scaling 그룹을 생성하여 스캔한 파일을 처리하고 의료 \n정보를 추출하는 사용자 지정 애플리케이션을 실행합니다. \nD. 새 문서가 업로드될 때 실행되는 AWS Lambda 함수를 생성합니다. Amazon \nRekognition 을 사용하여 문서를 원시 텍스트로 변환합니다. Amazon Transcribe Medical 을 \n사용하여 텍스트에서 관련 의료 정보를 감지하고 추출합니다. \nE. 새 문서가 업로드될 때 실행되는 AWS Lambda 함수를 생성합니다. Amazon Textract 를 \n사용하여 문서를 원시 텍스트로 변환합니다. Amazon Comprehend Medical 을 사용하여 \n텍스트에서 관련 의료 정보를 감지하고 추출합니다.", "answer_block": "Answer: B, E \nhttps://www.examtopics.com/discussions/amazon/view/89133-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nA(X) : AWS 클라우드에 문서를 업로드할 거라고 했으니 적절치 않음. MySQL 이 아니라 \nAmazon RDS for MySQL 이 됐던지 했어야 함. \nB(O) : S3 는 자료를 저장하는데 많이 사용되고, Athena 는 S3 에 쿼리하는 대화형 서비스임. \nAmazon Athena 는 표준 SQL 을 사용하여 Amazon S3(Amazon Simple Storage Service)에 \n있는 데이터를 직접 간편하게 분석할 수 있는 대화형 쿼리 서비스입니다. \nhttps://docs.aws.amazon.com/ko_kr/athena/latest/ug/what-is.html \nC(?) : 프로그램을 AWS 에서 돌려야한다는 말이 없어서 불명확. \nD(X) : Amazon Rekognition 은 이미지나 비디오 분석 서비스인데, 문서라면 텍스트 위주라서 \n탈락. 그리고 Transcribe Medical 은 음성->텍스트 변환이지 텍스트->의료 정보 추출이 \n아님. \nAmazon Transcribe Medical 은 사용자가 의료 관련 음성 데이터를 텍스트로 변환하는 \n기능을 사용자의 음성 지원 애플리케이션에 쉽게 추가할 수 있도록 하는 자동 음성 \n인식(ASR) 서비스입니다. \nhttps://aws.amazon.com/ko/transcribe/medical/ \nE(O) : Lambda 로 Scalabilty 확보 가능. Amazon Textract 는 이미지 등에서 텍스트를 \n추출하는 OCR 서비스로 문서화에 적합. Amazon Comprehend Medical 은 미리 학습된 기계 \n학습을 사용하여 처방전, 처치, 진단과 같은 의료 텍스트에서 의료 데이터를 파악하고 \n추출하는 서비스로 병원에서 사용하기 적합. \n확장성 : Lambda 는 코드를 실행하는 인프라를 관리하고 수신 요청에 대한 응답으로 자동 \n확장됩니다. \nhttps://docs.aws.amazon.com/ko_kr/lambda/latest/dg/gettingstarted-features.html#getti\nngstarted-features-scaling \nAmazon Textract 는 스캔한 문서에서 텍스트, 필기 및 데이터를 자동으로 추출하는 기계 \n\n학습(ML) 서비스입니다. 단순한 광학 문자 인식(OCR) 이상으로 양식 및 표의 데이터를 \n식별하고 이해하며 추출합니다.  \nhttps://aws.amazon.com/ko/textract/ \nAmazon Comprehend Medical 은 HIPAA 적격 자연어 처리(NLP) 서비스로, 미리 학습된 \n기계 학습을 사용하여 처방전, 처치, 진단과 같은 의료 텍스트에서 의료 데이터를 파악하고 \n추출합니다. \nhttps://aws.amazon.com/ko/comprehend/medical/ \n \n설명2: \n이 솔루션은 애플리케이션이 데이터에 대해 SQL 쿼리를 실행할 수 있도록 문서를 분석하고 \n의료 정보를 추출하고 문서를 저장하는 대량의 과거 서면 기록 컬렉션을 위한 디지털 사본 \n생성 요구 사항을 충족합니다. 문서 정보를 Amazon S3 버킷에 쓰면 스캔한 파일을 위한 \n확장 가능하고 내구성 있는 스토리지를 제공할 수 있습니다. Amazon Athena 를 사용하여 \n데이터를 쿼리하면 S3 에 저장된 데이터에 대한 서버리스 및 대화형 SQL 분석을 제공할 수 \n있습니다. 새 문서가 업로드될 때 실행되는 AWS Lambda 함수를 생성하면 스캔한 파일의 \n이벤트 기반 및 서버리스 처리를 제공할 수 있습니다. Amazon Textract 를 사용하여 문서를 \n원시 텍스트로 변환하면 정확한 광학 문자 인식(OCR)을 제공하고 인공 지능(AI)을 \n사용하여 문서에서 테이블 및 양식과 같은 구조화된 데이터를 추출할 수 있습니다. Amazon \nComprehend Medical 을 사용하여 텍스트에서 관련 의료 정보를 감지하고 추출하면 의료 \n텍스트에서 건강 데이터를 이해하고 추출하도록 사전 훈련된 기계 학습을 사용하는 자연어 \n처리(NLP) 서비스를 제공할 수 있습니다. \n \n실행되는 Amazon EC2 인스턴스에 문서 정보를 쓰기 때문에 옵션 A 가 올바르지 않습니다. \nMySQL 데이터베이스는 인프라 오버헤드와 복잡성을 증가시킬 수 있으며 대량의 데이터를 \n처리하지 못할 수 있습니다. \n \n스캔한 파일을 처리하고 의료 정보를 추출하는 사용자 지정 애플리케이션을 실행하기 위해 \nAmazon EC2 인스턴스의 Auto Scaling 그룹을 생성하면 인프라 오버헤드와 복잡성이 \n증가할 수 있고 기존 AI 및 NLP 서비스를 활용하지 못할 수 있으므로 옵션 C 는 올바르지 \n않습니다. Textract 및 Comprehend Medical 과 같은 \n \nAmazon Rekognition 을 사용하여 문서를 원시 텍스트로 변환하면 이미지 및 비디오 분석을 \n제공할 수 있지만 OCR 또는 문서에서 구조화된 데이터 추출을 지원하지 않기 때문에 옵션 \nD 는 올바르지 않습니다. Amazon Transcribe Medical 을 사용하여 텍스트에서 관련 의료 \n정보를 감지하고 추출하면 의료 대화를 위한 음성-텍스트 변환 서비스를 제공할 수 있지만 \n텍스트 분석이나 의료 텍스트에서 건강 데이터 추출은 지원하지 않습니다. \n\n참조: \nhttps://aws.amazon.com/s3/ \nhttps://aws.amazon.com/athena/ \nhttps://aws.amazon.com/lambda/ \nhttps://aws.amazon.com/texttract/ \nhttps://aws.amazon.com/comprehend/medical/", "answer_choice": "B"}, "193": {"q_num": 193, "question": "회사는 \nAmazon \nEC2 \n인스턴스에서 \n배치 \n애플리케이션을 \n실행하고 \n있습니다. \n애플리케이션은 여러 Amazon RDS 데이터베이스가 있는 백엔드로 구성됩니다. 응용 \n프로그램으로 인해 데이터베이스에서 많은 수의 읽기가 발생하고 있습니다. 솔루션 \n설계자는 고가용성을 보장하면서 데이터베이스 읽기 수를 줄여야 합니다. \n솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. Amazon RDS 읽기 전용 복제본을 추가합니다. \nB. Redis 용 Amazon ElastiCache 를 사용합니다. \nC. Amazon Route 53 DNS 캐싱 사용 \nD. Memcached 용 Amazon ElastiCache 를 사용합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/89134-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \n이 \n솔루션은 \n여러 \nAmazon \nRDS \n데이터베이스가 \n있는 \n백엔드로 \n구성된 \n배치 \n애플리케이션의 고가용성을 보장하면서 데이터베이스 읽기 수를 줄이는 요구 사항을 \n충족합니다. \nAmazon RDS 읽기 전용 복제본은 읽기 전용 트래픽을 처리할 수 있는 기본 데이터베이스 \n인스턴스의 복사본입니다. 기본 데이터베이스 인스턴스에 대해 하나 이상의 읽기 전용 \n복제본을 만들고 특수 엔드포인트를 사용하여 연결할 수 있습니다. 읽기 전용 복제본은 \n기본 데이터베이스 인스턴스에서 읽기 쿼리를 오프로드하여 애플리케이션의 성능과 \n가용성을 향상시킬 수 있습니다. \n \nRedis 용 Amazon ElastiCache 를 사용하면 자주 액세스하는 데이터를 캐시할 수 있는 빠른 \n인 메모리 데이터 스토어를 제공할 수 있지만 Amazon RDS 데이터베이스에서 복제를 \n지원하지 않기 때문에 옵션 B 는 올바르지 않습니다. \n \n\nAmazon Route 53 DNS 캐싱을 사용하면 DNS 쿼리의 성능과 가용성을 개선할 수 있지만 \n데이터베이스 읽기 수는 줄어들지 않기 때문에 옵션 C 는 올바르지 않습니다. \n \nMemcached 용 Amazon ElastiCache 를 사용하면 자주 액세스하는 데이터를 캐시할 수 있는 \n빠른 메모리 데이터 스토어를 제공할 수 있지만 Amazon RDS 데이터베이스에서 복제를 \n지원하지 않기 때문에 옵션 D 는 올바르지 않습니다. \n \n설명2: \nAmazon RDS 데이터베이스에 읽기 전용 복제본을 추가하면 읽기 워크로드를 복제본으로 \n오프로드하여 데이터베이스 읽기 수를 줄이고 성능을 향상할 수 있습니다. 읽기 전용 \n복제본은 고가용성을 제공하고 읽기 트래픽을 독립적으로 처리하여 로드를 분산하고 기본 \n데이터베이스의 부담을 줄일 수 있습니다. \nB. Redis 용 Amazon ElastiCache 는 주로 캐싱에 사용되는 인 메모리 데이터 스토어로, 읽기 \n성능을 향상시킬 수 있지만 데이터베이스 읽기 수를 직접적으로 줄이지는 않습니다. \nC. Amazon Route 53 DNS 캐싱은 DNS 응답을 캐시하는 서비스로, 전체 네트워크 성능을 \n향상시킬 수 있지만 데이터베이스 읽기 감소를 구체적으로 다루지는 않습니다. \nD. Memcached 용 Amazon ElastiCache 는 Redis 와 유사한 또 다른 캐싱 서비스이지만 \n데이터베이스 읽기 감소 문제를 직접적으로 해결하지는 않습니다. \n \n참조: \nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html", "answer_choice": "A"}, "194": {"q_num": 194, "question": "회사는 AWS\n에서 중요한 애플리케이션을 실행해야 합니다. 회사는 애플리케이션의 \n데이터베이스에 Amazon EC2 를 사용해야 합니다. 데이터베이스는 가용성이 높아야 하며 \n중단 이벤트가 발생할 경우 자동으로 장애 조치되어야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 동일한 AWS 지역의 다른 가용 영역에서 각각 두 개의 EC2 인스턴스를 시작합니다. 두 \nEC2 인스턴스 모두에 데이터베이스를 설치합니다. EC2 인스턴스를 클러스터로 구성합니다. \n데이터베이스 복제를 설정합니다. \nB. 가용 영역에서 EC2 인스턴스를 시작합니다. EC2 인스턴스에 데이터베이스를 설치합니다. \nAmazon 머신 이미지(AMI)를 사용하여 데이터를 백업하십시오. 중단 이벤트가 발생할 경우 \nAWS CloudFormation 을 사용하여 EC2 인스턴스의 프로비저닝을 자동화하십시오. \nC. 각각 다른 AWS 지역에서 두 개의 EC2 인스턴스를 시작합니다. 두 EC2 인스턴스 \n모두에 데이터베이스를 설치합니다. 데이터베이스 복제를 설정합니다. 데이터베이스를 두 \n\n번째 리전으로 장애 조치합니다. \nD. 가용 영역에서 EC2 인스턴스를 시작합니다. EC2 인스턴스에 데이터베이스를 설치합니다. \nAmazon 머신 이미지(AMI)를 사용하여 데이터를 백업하십시오. 중단 이벤트가 발생하면 \nEC2 자동 복구를 사용하여 인스턴스를 복구하십시오.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/89136-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n서로 다른 가용 영역에서 두 개의 EC2 인스턴스를 시작하고 데이터베이스 복제가 있는 \n클러스터로 구성하면 데이터베이스에서 고가용성과 자동 장애 조치를 달성할 수 있습니다. \n한 인스턴스 또는 가용 영역을 사용할 수 없게 되더라도 다른 인스턴스는 중단 없이 \n애플리케이션을 계속 제공할 수 있습니다. \nB. 단일 EC2 인스턴스를 시작하고 백업 및 프로비저닝 자동화를 위해 AMI 를 사용하면 \n자동 장애 조치 또는 고가용성이 제공되지 않습니다. \nC. 다른 AWS 리전에서 EC2 인스턴스를 시작하고 데이터베이스 복제를 설정하는 것은 \n재해 복구 기능을 제공할 수 있지만 단일 리전 내에서 자동 장애 조치를 제공하지 않는 \n다중 리전 설정입니다. \nD. EC2 자동 복구를 사용하면 하드웨어 문제로 인해 인스턴스가 실패하는 경우 인스턴스를 \n복구할 수 있지만 여러 인스턴스 또는 가용 영역에서 자동 장애 조치 또는 고가용성을 \n제공하지는 않습니다.", "answer_choice": "A"}, "195": {"q_num": 195, "question": "회사의 주문 시스템은 클라이언트의 요청을 Amazon EC2 인스턴스로 보냅니다. EC2 \n인스턴스는 주문을 처리한 다음 Amazon RDS\n의 데이터베이스에 주문을 저장합니다. \n사용자는 시스템이 실패하면 주문을 다시 처리해야 한다고 보고합니다. 회사는 시스템 \n중단이 발생할 경우 주문을 자동으로 처리할 수 있는 탄력적인 솔루션을 원합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. EC2 인스턴스를 Auto Scaling 그룹으로 이동합니다. Amazon Elastic Container \nService(Amazon ECS) 작업을 대상으로 하는 Amazon EventBridge(Amazon CloudWatch \nEvents) 규칙을 생성합니다. \nB. Application Load Balancer(ALB) 뒤에 있는 Auto Scaling 그룹으로 EC2 인스턴스를 \n이동합니다. ALB 엔드포인트에 메시지를 보내도록 주문 시스템을 업데이트합니다. \nC. EC2 인스턴스를 Auto Scaling 그룹으로 이동합니다. Amazon Simple Queue \nService(Amazon SQS) 대기열로 메시지를 보내도록 주문 시스템을 구성합니다. 대기열의 \n\n메시지를 사용하도록 EC2 인스턴스를 구성합니다. \nD. Amazon Simple Notification Service(Amazon SNS) 주제를 생성합니다. AWS Lambda \n함수를 생성하고 함수를 SNS 주제에 구독합니다. SNS 주제에 메시지를 보내도록 주문 \n시스템을 구성합니다. AWS Systems Manager Run Command\n를 사용하여 메시지를 \n처리하도록 EC2 인스턴스에 명령을 보냅니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/89138-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nSQS 는 Dead Letter Queue 등 다양한 옵션으로 메시지 처리가 실패했을 경우 해당 \n메시지를 보관했다가 다시 처리할 수 있게끔 하는 기능을 제공하고 있음. \n \n설명2: \n시스템 중단 시 자동으로 주문을 처리할 수 있는 탄력적인 솔루션을 보유해야 한다는 \n회사의 요구 사항을 충족하려면 솔루션 설계자가 내결함성 아키텍처를 구현해야 합니다. \n주어진 시나리오에 따라 가능한 솔루션은 EC2 인스턴스를 Auto Scaling 그룹으로 이동하고 \n메시지를 Amazon Simple Queue Service(Amazon SQS) 대기열로 보내도록 주문 시스템을 \n구성하는 것입니다. 그런 다음 EC2 인스턴스는 대기열의 메시지를 사용할 수 있습니다.", "answer_choice": "C"}, "196": {"q_num": 196, "question": "회사는 \n대규모 \nAmazon \nEC2 \n인스턴스 \n플릿에서 \n애플리케이션을 \n실행합니다. \n애플리케이션은 항목을 읽고 Amazon DynamoDB 테이블에 씁니다. DynamoDB 테이블의 \n크기는 지속적으로 증가하지만 애플리케이션에는 지난 30 일 동안의 데이터만 필요합니다. \n회사는 비용과 개발 노력을 최소화하는 솔루션이 필요합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. AWS CloudFormation 템플릿을 사용하여 전체 솔루션을 배포합니다. 30\n일마다 \nCloudFormation 스택을 재배포하고 원래 스택을 삭제합니다. \nB. AWS Marketplace 에서 모니터링 애플리케이션을 실행하는 EC2 인스턴스를 사용합니다. \nAmazon DynamoDB Streams 를 사용하여 테이블에 새 항목이 생성될 때 타임스탬프를 \n저장하도록 모니터링 애플리케이션을 구성합니다. EC2 인스턴스에서 실행되는 스크립트를 \n사용하여 30 일보다 오래된 타임스탬프가 있는 항목을 삭제합니다. \nC. 테이블에 새 항목이 생성될 때 AWS Lambda 함수를 호출하도록 Amazon DynamoDB \nStreams 를 구성합니다. 테이블에서 30 일보다 오래된 항목을 삭제하도록 Lambda 함수를 \n구성합니다. \n\nD. 애플리케이션을 확장하여 현재 타임스탬프에 30 일을 더한 값을 테이블에 생성된 각 새 \n항목에 추가하는 속성을 추가합니다. 속성을 TTL 속성으로 사용하도록 DynamoDB\n를 \n구성합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/89140-exam-aws-certified-solut \nions-architect-associate-saa-c03/ \n \n해설1: \n30 일 동안의 데이터만 필요하다고 했으니 30 일이 지나면 자동 삭제되도록 하는 기능이 \n필요. \nA(X) : 30 일마다 재배포하는 것은 번거로움. \nB(X) : 스크립트를 사용하는 것은 스크립트를 짜야하므로 번거로움. \nC(X) : Lambda 함수를 매번 쓰는 것은 비용 효율성 면에서 좋지 않고 Lambda 코드 짜는 \n것도 번거로움. \nD(O) : TTL 속성을 사용하면 별다른 코딩이나 노력 없이 설정만 해두면 자동으로 \n삭제되므로 간편함. \nAmazon DynamoDB TTL(Time to Live)을 사용하면 항목별 타임스탬프를 정의하여 항목이 더 \n이상 필요하지 않은 시기를 결정할 수 있습니다. 지정된 타임스탬프의 날짜 및 시간 직후 \nDynamoDB 는 쓰기 처리량을 소모하지 않고 테이블에서 항목을 삭제합니다. \nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/TTL.html \n \n설명2: \nAmazon DynamoDB TTL(Time to Live)을 사용하면 항목별 타임스탬프를 정의하여 항목이 더 \n이상 필요하지 않은 시기를 결정할 수 있습니다. 지정된 타임스탬프의 날짜 및 시간 직후 \nDynamoDB\n는 쓰기 처리량을 소비하지 않고 테이블에서 항목을 삭제합니다. TTL\n은 \n워크로드 요구 사항에 따라 최신 상태로 유지되는 항목만 유지하여 저장된 데이터 볼륨을 \n줄이는 수단으로 추가 비용 없이 제공됩니다. TTL 은 특정 시간이 지나면 관련성을 잃는 \n항목을 저장할 때 유용합니다. \n다음은 TTL 사용 사례의 예입니다. \n애플리케이션에서 1 년 동안 활동이 없으면 사용자 또는 센서 데이터를 제거합니다. 만료된 \n항목을 Amazon DynamoDB Streams 및 AWS Lambda 를 통해 Amazon S3 데이터 레이크에 \n보관합니다. 계약 또는 규제 의무에 따라 일정 기간 동안 민감한 데이터를 보관합니다. \nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/TTL.html", "answer_choice": "D"}, "197": {"q_num": 197, "question": "회사에는 온프레미스 Windows Server\n에서 실행되는 Microsoft .NET 애플리케이션이 \n있습니다. 애플리케이션은 Oracle Database Standard 를 사용하여 데이터를 저장합니다. \n에디션 서버. 이 회사는 AWS\n로의 마이그레이션을 계획하고 있으며 애플리케이션을 \n이동하는 동안 개발 변경을 최소화하려고 합니다. AWS 애플리케이션 환경은 가용성이 \n높아야 합니다. \n이러한 요구 사항을 충족하기 위해 회사는 어떤 조합의 조치를 취해야 합니까? (두 가지를 \n선택하세요.) \nA. .NET Core 를 실행하는 AWS Lambda 함수를 사용하여 애플리케이션을 서버리스로 \n리팩터링합니다. \nB. 다중 AZ 배포에서 .NET 플랫폼을 사용하여 AWS Elastic Beanstalk 에서 애플리케이션을 \n다시 호스팅합니다. \nC. Amazon Linux Amazon 머신 이미지(AMI)를 사용하여 Amazon EC2 에서 실행되도록 \n애플리케이션 플랫폼을 변경합니다. \nD. 다중 AZ 배포에서 AWS DMS(AWS Database Migration Service)를 사용하여 Oracle \n데이터베이스에서 Amazon DynamoDB 로 마이그레이션합니다. \nE. 다중 AZ 배포에서 AWS Database Migration Service(AWS DMS)를 사용하여 Oracle \n데이터베이스에서 Amazon RDS 의 Oracle 로 마이그레이션합니다.", "answer_block": "Answer: B, E \nhttps://www.examtopics.com/discussions/amazon/view/89068-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nA(X) : 리팩터링은 코드 변경을 수반하므로 개발 변경 사항 최소화 조건 불충족. \nB(O) : AWS Elastic Beanstalk.NET 용 에서 Amazon Web Services 를 사용하는 ASP.NET 웹 \n애플리케이션을 보다 쉽게 배포, 관리 및 조정할 수 있습니다. \nhttps://docs.aws.amazon.com/ko_kr/elasticbeanstalk/latest/dg/create_deploy_NET.html \nC(X) : 재플랫폼화는 개발 변경 사항 최소화 조건 불충족. \nD(X) : Oracle 데이터베이스는 관계형 데이터베이스이고, DynamoDB\n는 비관계형 \n데이터베이스로 유형이 다름. 개발 변경 최소화 조건 불충족. \nE(O) : 다중 AZ 배포로 고가용성 조건 충족. DMS 서비스로 데이터베이스 마이그레이션 \n가능. RDS for Oracle 로 개발 변경 최소화 가능. \n \n설명2: \n애플리케이션을 AWS 로 이동하는 동안 개발 변경을 최소화하고 높은 수준의 가용성을 \n보장하기 위해 회사는 다중 AZ 배포에서 .NET 플랫폼을 사용하여 AWS Elastic \nBeanstalk 에서 애플리케이션을 다시 호스팅할 수 있습니다. 이렇게 하면 애플리케이션 \n\n코드를 변경할 필요 없이 고가용성 환경에서 애플리케이션을 실행할 수 있습니다. \n또한 회사는 AWS Database Migration Service(AWS DMS)를 사용하여 다중 AZ 배포에서 \nOracle 데이터베이스를 Amazon RDS 의 Oracle 로 마이그레이션할 수 있습니다. 이를 통해 \n회사는 여전히 높은 수준의 가용성을 달성하면서 기존 데이터베이스 플랫폼을 유지할 수 \n있습니다.", "answer_choice": "B"}, "198": {"q_num": 198, "question": "회사는 온프레미스 데이터 센터의 Kubernetes 클러스터에서 컨테이너화된 애플리케이션을 \n실행합니다. 회사는 데이터 저장을 위해 MongoDB 데이터베이스를 사용하고 있습니다. \n회사는 이러한 환경 중 일부를 AWS\n로 마이그레이션하려고 하지만 현재로서는 코드 \n변경이나 배포 방법 변경이 불가능합니다. 회사는 운영 오버헤드를 최소화하는 솔루션이 \n필요합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 컴퓨팅을 위해 Amazon EC2 작업자 노드와 함께 Amazon Elastic Container \nService(Amazon ECS)를 사용하고 데이터 저장을 위해 EC2 의 MongoDB 를 사용합니다. \nB. 컴퓨팅용 AWS Fargate 및 데이터 저장용 Amazon DynamoDB 와 함께 Amazon Elastic \nContainer Service(Amazon ECS)를 사용합니다. \nC. Amazon Elastic Kubernetes Service(Amazon EKS)를 Amazon EC2 작업자 노드와 함께 \n컴퓨팅용으로 사용하고 Amazon DynamoDB 를 데이터 저장용으로 사용합니다. \nD. 컴퓨팅용 AWS Fargate 및 데이터 스토리지용 Amazon DocumentDB(MongoDB 호환)와 \n함께 Amazon Elastic Kubernetes Service(Amazon EKS)를 사용합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/89078-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nKubernetes 클러스터 = EKS \nMongoDB 호환 = DocumentDB \n \n설명2: \nAmazon DocumentDB(MongoDB\n와 호환)는 빠르고 안정적이며 완벽하게 관리되는 \n데이터베이스 서비스입니다. \nAmazon DocumentDB 를 사용하면 클라우드에서 MongoDB 호환 데이터베이스를 쉽게 설정, \n운영 및 확장할 수 있습니다. Amazon DocumentDB 를 사용하면 동일한 애플리케이션 \n코드를 실행하고 MongoDB 에서 사용하는 것과 동일한 드라이버 및 도구를 사용할 수 \n\n있습니다. \nhttps://docs.aws.amazon.com/documentdb/latest/developerguide/what-is.html", "answer_choice": "D"}, "199": {"q_num": 199, "question": "텔레마케팅 회사는 AWS 에서 고객 콜 센터 기능을 설계하고 있습니다. 이 회사는 여러 \n화자 인식을 제공하고 대본 파일을 생성하는 솔루션이 필요합니다. 회사는 비즈니스 패턴을 \n분석하기 위해 트랜스크립트 파일을 쿼리하려고 합니다. 기록 파일은 감사 목적으로 7 년 \n동안 저장되어야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 여러 화자 인식을 위해 Amazon Rekognition 을 사용하십시오. 성적표 파일을 Amazon \nS3 에 저장합니다. 성적표 파일 분석을 위해 기계 학습 모델을 사용합니다. \nB. 여러 화자 인식을 위해 Amazon Transcribe 를 사용합니다. 성적표 파일 분석에 Amazon \nAthena 를 사용합니다. \nC. 여러 화자 인식을 위해 Amazon Translate 를 사용합니다. Amazon Redshift 에 기록 \n파일을 저장합니다. 성적표 파일 분석에 SQL 쿼리를 사용합니다. \nD. 여러 화자 인식을 위해 Amazon Rekognition 을 사용합니다. 성적표 파일을 Amazon \nS3 에 저장합니다. 성적표 파일 분석에 Amazon Textract 를 사용하십시오.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/89141-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nA(X) : Amazon Rekognition 은 이미지/비디오 분석 서비스. 콜센터라고 했으므로 오디오를 \n다른 걸로 변환시켜주는 서비스가 필요하므로 오답. \nAmazon Rekognition 은 애플리케이션에 강력한 시각 분석 기능을 쉽게 추가할 수 있게 해 \n주는 서비스입니다. Rekognition Image 를 통해 수백만 개의 이미지를 검색, 확인 및 구성할 \n수 있는 강력한 애플리케이션을 쉽게 구축할 수 있습니다. Rekognition Video 를 통해 \n저장된 동영상 또는 실시간 스트림 동영상에서 동작 기반 컨텍스트를 추출하고 이를 분석할 \n수 있습니다. https://aws.amazon.com/ko/rekognition/faqs/ \nB(O) : Amazon Transcribe 로 다중 Speaker 인식 가능. 7 년 동안 저장해야한다고 했으므로 \nS3 같은 스토리지 서비스가 필요한데, 해당 선택지에서는 S3 가 언급은 되지 않았으나 \nS3 에 쿼리하는 Athena 가 있으므로 S3 를 사용하고 있다고 추측할 수 있음. \nAmazon Transcribe\n는 고객이 손쉽게 음성을 텍스트로 변환할 수 있게 해주는 AWS \n서비스입니다. https://aws.amazon.com/ko/transcribe/faqs/ \nC(X) : Amazon Translate 는 기계 번역 서비스. \n\nAmazon Translate 는 합리적인 가격으로 고품질의 사용자 지정 가능한 언어 번역을 빠르게 \n제공하는 신경망 기계 번역 서비스입니다.  https://aws.amazon.com/ko/translate/ \nD(X) : A 와 동일한 이유로 오답. \n \n설명2: \nAmazon Transcribe 는 이제 스트리밍 트랜스크립션을 위한 화자 레이블 지정을 지원합니다. \nAmazon Transcribe\n는 음성을 텍스트로 쉽게 변환할 수 있는 자동 음성 인식(ASR) \n서비스입니다. \n라이브 오디오 전사에서 각 오디오 스트림에는 여러 명의 화자가 포함될 수 있습니다. 이제 \n화자에게 레이블을 지정하는 기능을 편리하게 켤 수 있으므로 출력 기록에서 누가 무엇을 \n말하는지 식별하는 데 도움이 됩니다. \nhttps://aws.amazon.com/ko/about-aws/whats-new/2020/08/amazon-transcribe-support\ns-speaker-labeling-streaming-transcription/", "answer_choice": "B"}, "200": {"q_num": 200, "question": "회사는 AWS 에서 애플리케이션을 호스팅합니다. 이 회사는 Amazon Cognito 를 사용하여 \n사용자를 관리합니다. 사용자가 애플리케이션에 로그인하면 애플리케이션은 Amazon API \nGateway 에서 호스팅되는 REST API 를 사용하여 Amazon DynamoDB 에서 필요한 데이터를 \n가져옵니다. 이 회사는 개발 노력을 줄이기 위해 REST API 에 대한 액세스를 제어하는 AWS \n관리형 솔루션을 원합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 어떤 사용자가 요청했는지 확인하기 위해 API Gateway 에서 권한 부여자가 되도록 AWS \nLambda 함수를 구성합니다. \nB. 각 사용자에 대해 각 요청과 함께 전송되어야 하는 API 키를 생성하고 할당합니다. AWS \nLambda 함수를 사용하여 키를 검증합니다. \nC. 모든 요청과 함께 헤더에 사용자의 이메일 주소를 보냅니다. 해당 이메일 주소를 가진 \n사용자에게 적절한 액세스 권한이 있는지 확인하려면 AWS Lambda 함수를 호출하십시오. \nD. Amazon Cognito 가 각 요청을 검증할 수 있도록 API Gateway 에서 Amazon Cognito \n사용자 풀 권한 부여자를 구성합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/89142-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nAmazon Cognito 콘솔, CLI/SDK 또는 API 를 사용하여 사용자 풀을 만들거나 다른 AWS \n\n계정이 소유한 풀을 사용합니다. \n \n설명2: \nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-integrate-w\nithcognito.html \nREST API 에 대한 액세스를 제어하고 개발 노력을 줄이기 위해 회사는 API Gateway 에서 \nAmazon Cognito 사용자 풀 권한 부여자를 사용할 수 있습니다. 이를 통해 Amazon \nCognito 는 각 요청을 검증하고 인증된 사용자만 API 에 액세스할 수 있도록 합니다. 이 \n솔루션은 회사가 추가 인프라나 코드를 개발하고 유지 관리할 필요가 없으므로 운영 \n오버헤드가 가장 적습니다.", "answer_choice": "D"}, "201": {"q_num": 201, "question": "회사에서 모바일 앱 사용자를 대상으로 하는 마케팅 커뮤니케이션 서비스를 개발하고 \n있습니다. 회사는 SMS(Short Message Service)를 통해 사용자에게 확인 메시지를 보내야 \n합니다. 사용자는 SMS 메시지에 회신할 수 있어야 합니다. 회사는 분석을 위해 응답을 1 년 \n동안 저장해야 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. Amazon Connect 통화 흐름을 생성하여 SMS 메시지를 보냅니다. AWS Lambda 를 \n사용하여 응답을 처리합니다. \nB. Amazon Pinpoint 여정을 구축하십시오. 분석 및 보관을 위해 이벤트를 Amazon Kinesis \n데이터 스트림으로 보내도록 Amazon Pinpoint 를 구성합니다. \nC. Amazon Simple Queue Service(Amazon SQS)를 사용하여 SMS 메시지를 배포합니다. \nAWS Lambda 를 사용하여 응답을 처리합니다. \nD. Amazon Simple Notification Service(Amazon SNS) FIFO 주제를 생성합니다. 분석 및 \n보관을 위해 Amazon Kinesis 데이터 스트림을 SNS 주제에 구독합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/89080-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명 \nhttps://aws.amazon.com/pinpoint/product-details/sms/ \n양방향 메시징: 고객으로부터 SMS 메시지를 받고 채팅과 같은 대화형 환경에서 회신합니다. \nAmazon Pinpoint 를 사용하면 고객이 특정 키워드가 포함된 메시지를 보낼 때 자동 응답을 \n생성할 수 있습니다. Amazon Lex 를 사용하여 대화형 봇을 만들 수도 있습니다. 대부분의 \n휴대폰 사용자는 들어오는 SMS 메시지를 받은 직후에 읽습니다. 고객에게 긴급하거나 \n\n중요한 정보를 제공해야 하는 경우 SMS 메시징이 적합한 솔루션일 수 있습니다. Amazon \nPinpoint\n를 사용하여 대상 고객 그룹을 생성한 다음 캠페인 기반 메시지를 보낼 수 \n있습니다. Amazon Pinpoint 를 사용하여 약속 확인, 주문 업데이트, 일회용 암호와 같은 \n다이렉트 메시지를 보낼 수도 있습니다.", "answer_choice": "B"}, "202": {"q_num": 202, "question": "회사에서 데이터를 Amazon S3 버킷으로 이동할 계획입니다. 데이터는 S3 버킷에 저장될 \n때 암호화되어야 합니다. 또한 암호화 키는 매년 자동으로 순환되어야 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 데이터를 S3 버킷으로 이동합니다. Amazon S3 관리형 암호화 키(SSE-S3)로 서버 측 \n암호화를 사용합니다. SSE-S3 암호화 키의 기본 제공 키 회전 동작을 사용합니다. \nB. AWS Key Management Service(AWS KMS) 고객 관리형 키를 생성합니다. 자동 키 순환을 \n활성화합니다. 고객 관리형 KMS 키를 사용하도록 S3 버킷의 기본 암호화 동작을 \n설정합니다. 데이터를 S3 버킷으로 이동합니다. \nC. AWS Key Management Service(AWS KMS) 고객 관리형 키를 생성합니다. 고객 관리형 \nKMS 키를 사용하도록 S3 버킷의 기본 암호화 동작을 설정합니다. 데이터를 S3 버킷으로 \n이동합니다. 매년 KMS 키를 수동으로 교체합니다. \nD. 데이터를 S3 버킷으로 이동하기 전에 고객 키 자료로 데이터를 암호화합니다. 키 자료 \n없이 AWS Key Management Service(AWS KMS) 키를 생성합니다. 고객 키 자료를 KMS \n키로 가져옵니다. 자동 키 순환을 활성화합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/89081-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \n・S3 버킷에 저장될 때 암호화되므로 SSE(서버 측 암호화). 만약 S3 버킷으로 보내기 전에 \n암호화하면 CSE(클라이언트 측 암호화)임. \n・Amazon S3 버킷에 저장되는 모든 객체를 암호화하는 기본 암호화 동작을 버킷에 설정할 \n수 있습니다. 객체는 Amazon S3 관리형 키를 사용한 서버 측 암호화(SSE-S3) 또는 AWS \nKey \nManagement \nService(AWS \nKMS) \n키를 \n사용한 \n서버 \n측 \n암호화를 \n사용하여 \n암호화됩니다. \nhttps://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/default-bucket-encrypti\non.html \nA(X) : 먼저 S3 버킷을 암호화한 게 아니라 데이터를 S3 버킷에 담아놓고 암호화를 했기 \n때문에 불필요한 배치 작업이 발생. \n\nAmazon S3 기본 암호화를 사용하면 S3 버킷에 대한 기본 암호화 동작을 설정하여 모든 새 \n객체가 버킷에 저장될 때 암호화되도록 할 수 있습니다. Amazon S3 관리형 키를 사용한 \n서버 측 암호화(SSE-S3) 또는 AWS Key Management Service(AWS KMS)에 저장된 AWS \nKMS keys 를 사용한 서버 측 암호화(SSE-KMS)로 객체를 암호화합니다. 서버 측 암호화를 \n사용하는 경우 Amazon S3\n에서는 객체를 디스크에 저장하기 전에 암호화하고 기존 \nAmazon S3 객체를 암호화하기 위해 Amazon S3 배치 작업을 사용할 수 있습니다. \nhttps://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/bucket-encryption.html \nB(O) : AWS KMS CMK(고객 관리 키)는 원래 키 자동 교체(rotate)을 하진 않지만 이를 \n활성화할 수 있음. \nhttps://docs.aws.amazon.com/ko_kr/kms/latest/developerguide/concepts.html#customer\n-cmk \nC(X) : 암호화 키는 매년 자동 순환되어야 한다고 했는데 수동 순환이라 오답. \nD(X) : S3 버킷으로 이동하기 전에 기본 암호화 동작을 설정하므로 SSE\n가 아닌 \nCSE(클라이언트 측 암호화)임. \n \n설명2: \nSSE-S3 - 무료이며 AWS 소유 CMK(CMK = 고객 마스터 키)를 사용합니다. 암호화 키는 \nAWS 에서 소유하고 관리하며 여러 계정 간에 공유됩니다. 회전은 여기 표에 표시된 대로 \n시간에 따라 자동으로 바뀝니다. 시간은 명시적으로 정의되지 않습니다. \nSSE-KMS - 두 가지 특징이 있습니다. \nAWS 관리형 CMK. 귀하의 계정에 대해서만 생성된 무료 CMK\n입니다. 정책을 보고 \n사용량을 감사할 수만 있고 관리할 수는 없습니다. 교체는 자동입니다. 1095 일(3 년)당 한 \n번, 고객이 CMK 를 관리합니다. 이것은 사용자가 생성하고 관리할 수 있는 사용자 고유의 \n키를 사용합니다. 회전은 기본적으로 활성화되어 있지 않습니다. 그러나 활성화하면 \n1\n년마다 자동으로 순환됩니다. 이 변형은 사용자가 가져온 키 자료를 사용할 수도 \n있습니다. 가져온 자료로 이러한 키를 생성하면 자동 회전이 없습니다. 수동 회전만 \n가능합니다. \nSSE-C - 고객 제공 키. 암호화 키는 AWS 외부에서 사용자가 완전히 관리합니다. AWS 는 \n이를 교체하지 않습니다. \n이 솔루션은 데이터를 Amazon S3 버킷으로 이동하고, 데이터가 S3 버킷에 저장될 때 \n데이터를 암호화하고, 최소한의 운영 오버헤드로 매년 암호화 키를 자동으로 교체하는 요구 \n사항을 충족합니다. AWS Key Management Service(AWS KMS)는 데이터의 암호화 키를 \n생성하고 관리할 수 있는 서비스입니다. 고객 관리형 키는 AWS KMS\n에서 생성하고 \n관리하는 대칭 암호화 키입니다. 고객 관리형 키에 대해 자동 키 교체를 활성화할 수 \n있습니다. 즉, AWS KMS 는 매년 키에 대한 새로운 암호화 자료를 생성합니다. 고객 관리형 \nKMS 키를 사용하도록 S3 버킷의 기본 암호화 동작을 설정할 수 있습니다. 즉, 암호화 \n\n방법을 지정하지 않고 버킷에 업로드된 모든 객체는 해당 키로 암호화됩니다. \nAmazon S3 관리형 암호화 키(SSE-S3)로 서버 측 암호화를 사용하면 암호화 키를 \n제어하거나 관리할 수 없으므로 옵션 A 는 올바르지 않습니다. SSE-S3 는 각 객체에 대해 \n고유한 키를 사용하고 S3 에서 정기적으로 순환하는 마스터 키로 해당 키를 암호화합니다. \n그러나 SSE-S3 키에 대한 키 교체를 활성화 또는 비활성화하거나 교체 간격을 지정할 수 \n없습니다. \n옵션 C\n는 올바르지 않습니다. 매년 KMS 키를 수동으로 교체하면 운영 오버헤드와 \n복잡성이 증가할 수 있고 교체 프로세스를 잊어버리거나 지연하는 경우 매년 키 교체 요구 \n사항을 충족하지 못할 수 있기 때문입니다. \n데이터를 S3 버킷으로 이동하기 전에 고객 키 자료로 데이터를 암호화하면 운영 \n오버헤드와 복잡성이 증가할 수 있고 버킷의 모든 객체에 대해 일관된 암호화를 제공하지 \n못할 수 있으므로 옵션 D 는 올바르지 않습니다. 키 자료 없이 KMS 키를 생성하고 고객 키 \n자료를 KMS 키로 가져오면 고유한 임의 비트 소스를 사용하여 KMS 키를 생성할 수 \n있지만 자동 키 순환은 지원하지 않습니다. \n참조: \nhttps://docs.aws.amazon.com/kms/latest/developerguide/concepts.html \nhttps://docs.aws.amazon.com/kms/latest/developerguide/rotate-keys.html \nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/bucket-encryption.html", "answer_choice": "B"}, "203": {"q_num": 203, "question": "금융 회사의 고객은 문자 메시지를 보내 재정 고문과의 약속을 요청합니다. Amazon EC2 \n인스턴스에서 실행되는 웹 애플리케이션은 약속 요청을 수락합니다. 텍스트 메시지는 웹 \n애플리케이션을 통해 Amazon Simple Queue Service(Amazon SQS) 대기열에 게시됩니다. \nEC2 인스턴스에서 실행되는 또 다른 애플리케이션은 회의 초대장과 회의 확인 이메일 \n메시지를 고객에게 보냅니다. 예약에 성공한 후 이 애플리케이션은 회의 정보를 Amazon \nDynamoDB 데이터베이스에 저장합니다. \n회사가 확장됨에 따라 고객은 회의 초대장이 도착하는 데 시간이 더 오래 걸린다고 \n보고합니다. \n솔루션 설계자는 이 문제를 해결하기 위해 무엇을 권장해야 합니까? \nA. DynamoDB 데이터베이스 앞에 DynamoDB Accelerator(DAX) 클러스터를 추가합니다. \nB. 약속 요청을 수락하는 웹 애플리케이션 앞에 Amazon API Gateway API 를 추가합니다. \nC. \nAmazon \nCloudFront \n배포를 \n추가합니다. \n오리진을 \n약속 \n요청을 \n수락하는 \n웹 \n애플리케이션으로 설정합니다. \nD. 회의 초대를 보내는 애플리케이션에 대한 Auto Scaling 그룹을 추가합니다. SQS \n대기열의 깊이에 따라 확장되도록 Auto Scaling 그룹을 구성합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/89082-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명 \n회의 초대 전달 시간이 길어지는 문제를 해결하기 위해 솔루션 설계자는 회의 초대를 \n보내는 애플리케이션에 대해 Auto Scaling 그룹을 추가하고 SQS 대기열의 깊이에 따라 \n확장되도록 Auto Scaling 그룹을 구성하도록 권장할 수 있습니다. 이렇게 하면 약속 요청 \n수가 증가함에 따라 애플리케이션이 확장되어 회의 초대의 성능 및 배달 시간이 \n향상됩니다.", "answer_choice": "D"}, "204": {"q_num": 204, "question": "한 온라인 소매 회사는 5 천만 명 이상의 활성 고객을 보유하고 있으며 매일 25,000 건 \n이상의 주문을 받습니다. 회사는 고객의 구매 데이터를 수집하고 이 데이터를 Amazon \nS3 에 저장합니다. 추가 고객 데이터는 Amazon RDS 에 저장됩니다. \n회사는 팀이 분석을 수행할 수 있도록 다양한 팀에서 모든 데이터를 사용할 수 있도록 \n하려고 합니다. 솔루션은 데이터에 대한 세분화된 권한을 관리하는 기능을 제공하고 운영 \n오버헤드를 최소화해야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 구매 데이터를 마이그레이션하여 Amazon RDS 에 직접 씁니다. RDS 액세스 제어를 \n사용하여 액세스를 제한하십시오. \nB. Amazon RDS 에서 Amazon S3 로 데이터를 주기적으로 복사하도록 AWS Lambda 함수를 \n예약합니다. AWS Glue 크롤러를 생성합니다. Amazon Athena\n를 사용하여 데이터를 \n쿼리합니다. S3 정책을 사용하여 액세스를 제한하십시오. \nC. AWS Lake Formation 을 사용하여 데이터 레이크를 생성합니다. Amazon RDS 에 대한 \nAWS Glue JDBC 연결을 생성합니다. Lake Formation 에 S3 버킷을 등록합니다. Lake \nFormation 액세스 제어를 사용하여 액세스를 제한하십시오. \nD. Amazon Redshift 클러스터를 생성합니다. Amazon S3 및 Amazon RDS 에서 Amazon \nRedshift 로 데이터를 주기적으로 복사하도록 AWS Lambda 함수를 예약합니다. Amazon \nRedshift 액세스 제어를 사용하여 액세스를 제한하십시오.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/89083-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \n\nA(X) : 액세스 제어하는 것까지만 나왔고 어떻게 쿼리할 것인지는 언급 안 함. \nB(X) : 처음부터 S3 에 다 저장할 것이지 결국 S3 에 저장할 거면서 왜 RDS 에 저장했다가 \n다시 S3 에 저장하는지? \nC(O) : S3 버킷을 데이터레이크로 만들고 Glue 를 통해서 ETL 함으로서 S3 에 저장된 \n데이터를 RedShift 같은 서비스에서 사용할 수 있게끔 함. RDS 에 저장된 고객 데이터는 \nGlue JDBC 를 통해 변환 \n・S3 버킷을 AWS Lake Formation 을 사용해 데이터레이크로 만들고 Glue 기능 사용해 \nETL. \nAWS Lake Formation 콘솔, Lake Formation API 또는 AWS 명령줄 인터페이스(AWS CLI)를 \n사용하여 Amazon S3 위치를 등록할 수 있습니다. \nhttps://docs.aws.amazon.com/lake-formation/latest/dg/register-location.html \nLake Formation 은 콘솔 제어, ETL 코드 생성, 작업 모니터링, 공통 데이터 카탈로그, \n서버리스 아키텍처를 포함하여 AWS Glue 에서 공유 인프라를 활용합니다. AWS Glue 는 아직 \n이러한 유형의 기능에 초점을 맞추고 있는 반면, Lake Formation 은 AWS Glue 기능을 \n포함하면서, 동시에 데이터 레이크를 구축하고 보안하고 관리하는 데 유용한 추가 기능을 \n제공합니다. \nhttps://aws.amazon.com/ko/glue/faqs/ \n・AWS RDS 에 저장된 데이터를 Glue 에서 사용 \nAWS Glue 는 기본적으로 Amazon Aurora, Amazon RDS for MySQL, Amazon RDS for Oracle, \nAmazon RDS for PostgreSQL, Amazon RDS for SQL Server, Amazon Redshift, DynamoDB \n및 Amazon S3 뿐만 아니라 Amazon EC2 에서 실행되는 Virtual Private Cloud(Amazon \nVPC)에 있는 MySQL, Oracle, Microsoft SQL Server 및 PostgreSQL 데이터베이스에 저장된 \n데이터를 지원합니다. \nhttps://aws.amazon.com/ko/glue/faqs/ \nAWS Glue 는 JDBC 연결을 통해 다음 데이터 스토어에 연결할 수 있습니다. ◎Amazon \nRedshift. ◎Amazon RDS for MariaDB \nhttps://docs.aws.amazon.com/ko_kr/glue/latest/dg/connection-properties.html#connecti\non-properties-jdbc \n \n・데이터에 대한 세분화된 권한 관리 \nAWS Lake Formation 은 간단한 권한 부여/취소 메커니즘을 기반으로 하는 권한 모델을 \n제공합니다. Lake Formation 권한은 AWS Identity and Access Management(IAM) 권한과 \n결합되어 데이터 레이크에 저장된 데이터 및 해당 데이터를 설명하는 메타데이터에 대한 \n액세스를 제어합니다. \nhttps://docs.aws.amazon.com/lake-formation/latest/dg/security-data-access.html \nD(X) : 주기적으로 처리하라는 요구 사항이 있지 않는 이상 바로바로 처리하는 게 보통인데, \n\n주기적으로 처리하고 있음. \n \n설명2: \n다양한 팀에서 모든 데이터를 사용할 수 있도록 하고 운영 오버헤드를 최소화하기 위해 \n회사는 AWS Lake Formation 을 사용하여 데이터 레이크를 생성할 수 있습니다. 이를 통해 \n회사는 모든 데이터를 한 곳에서 중앙 집중화하고 세분화된 액세스 제어를 사용하여 \n데이터에 대한 액세스를 관리할 수 있습니다. 회사의 요구 사항을 충족하기 위해 솔루션 \n설계자는 AWS Lake Formation 을 사용하여 데이터 레이크를 만들고, Amazon RDS 에 대한 \nAWS Glue JDBC 연결을 만들고, Lake Formation 에 S3 버킷을 등록할 수 있습니다. 그런 \n다음 솔루션 설계자는 Lake Formation 액세스 제어를 사용하여 데이터에 대한 액세스를 \n제한할 수 있습니다. 이 솔루션은 데이터에 대한 세분화된 권한을 관리하고 운영 \n오버헤드를 최소화하는 기능을 제공합니다.", "answer_choice": "C"}, "205": {"q_num": 205, "question": "회사는 온프레미스 데이터 센터에서 마케팅 웹 사이트를 호스팅합니다. 웹 사이트는 정적 \n문서로 \n구성되며 \n단일 \n서버에서 \n실행됩니다. \n관리자는 \n웹 \n사이트 \n콘텐츠를 \n자주 \n업데이트하지 않고 SFTP 클라이언트를 사용하여 새 문서를 업로드합니다. \n회사는 AWS 에서 웹 사이트를 호스팅하고 Amazon CloudFront 를 사용하기로 결정했습니다. \n회사의 솔루션 아키텍트가 CloudFront 배포를 생성합니다. 솔루션 설계자는 웹 사이트 \n호스팅이 CloudFront 오리진 역할을 할 수 있도록 가장 비용 효율적이고 탄력적인 \n아키텍처를 설계해야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Amazon Lightsail 을 사용하여 가상 서버를 생성합니다. Lightsail 인스턴스에서 웹 서버를 \n구성합니다. SFTP 클라이언트를 사용하여 웹 사이트 콘텐츠를 업로드합니다. \nB. Amazon EC2 인스턴스에 대한 AWS Auto Scaling 그룹을 생성합니다. Application Load \nBalancer 를 사용하십시오. SFTP 클라이언트를 사용하여 웹 사이트 콘텐츠를 업로드합니다. \nC. 프라이빗 Amazon S3 버킷을 생성합니다. S3 버킷 정책을 사용하여 CloudFront 원본 \n액세스 ID(OAI)에서 액세스를 허용합니다. AWS CLI\n를 사용하여 웹사이트 콘텐츠를 \n업로드합니다. \nD. 퍼블릭 Amazon S3 버킷을 생성합니다. SFTP 용 AWS 전송을 구성합니다. 웹 사이트 \n호스팅을 위해 S3 버킷을 구성합니다. SFTP 클라이언트를 사용하여 웹 사이트 콘텐츠를 \n업로드합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/89085-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n\n \n설명: \n프라이빗 S3 에서 웹사이트를 호스팅하면 정적 웹사이트 콘텐츠를 위한 비용 효율적이고 \n가용성이 높은 스토리지를 제공합니다. CloudFront OAI 의 액세스를 허용하도록 버킷 정책을 \n구성하면 CloudFront 를 통해서만 S3 에 안전하게 액세스할 수 있습니다. 이렇게 하면 웹 \n사이트 콘텐츠가 S3 를 비공개로 유지하면서 CloudFront 를 통해 제공됩니다. AWS CLI 를 \n사용하여 웹 사이트 콘텐츠를 업로드하면 콘텐츠를 쉽고 효율적으로 관리할 수 있습니다. \n \nA. Lightsail 가상 서버에서 웹 사이트를 호스팅하면 정적 콘텐츠 호스팅에 S3 를 직접 \n사용하는 것과 비교하여 추가 관리 오버헤드와 비용이 발생합니다. \nB. 정적 웹 사이트 콘텐츠를 제공하기 위해 EC2 인스턴스 및 ALB 와 함께 AWS ASG 를 \n사용할 필요가 없습니다. 불필요한 복잡성과 비용이 추가됩니다. \nD. AWS Transfer for SFTP 를 사용하면 SFTP 업로드가 가능하지만 AWS CLI 를 사용하여 \n콘텐츠를 S3 에 직접 업로드하는 것과 비교하여 추가 비용과 복잡성이 발생합니다. 또한 \n공용 S3 에서 웹 사이트 콘텐츠를 호스팅하는 것은 보안 관점에서 바람직하지 않을 수 \n있습니다. \n \n참고: \nhttps://docs.aws.amazon.com/cli/latest/reference/transfer/describe-server.html", "answer_choice": "C"}, "206": {"q_num": 206, "question": "회사에서 Amazon 머신 이미지(AMI)를 관리하려고 합니다. 회사는 현재 AMI 가 생성된 \n동일한 AWS 리전에 AMI 를 복사합니다. 회사는 AWS API 호출을 캡처하고 회사 계정 \n내에서 Amazon EC2 CreateImage API 작업이 호출될 때마다 알림을 보내는 애플리케이션을 \n설계해야 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. AWS CloudTrail 로그를 쿼리하고 CreateImage API 호출이 감지되면 알림을 보내는 AWS \nLambda 함수를 생성합니다. \nB. 업데이트된 로그가 Amazon S3 로 전송될 때 발생하는 Amazon Simple Notification \nService(Amazon SNS) 알림으로 AWS CloudTrail 을 구성합니다. Amazon Athena 를 사용하여 \n새 테이블을 생성하고 API 호출이 감지되면 CreateImage 에서 쿼리합니다. \nC. CreateImage API 호출에 대한 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 \n생성합니다. CreateImage API 호출이 감지되면 알림을 보내도록 대상을 Amazon Simple \nNotification Service(Amazon SNS) 주제로 구성합니다. \nD. Amazon Simple Queue Service(Amazon SQS) FIFO 대기열을 AWS CloudTrail 로그의 \n\n대상으로 구성합니다. CreateImage API 호출이 감지되면 Amazon Simple Notification \nService(Amazon SNS) 주제에 알림을 보내는 AWS Lambda 함수를 생성합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/89086-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nhttps://docs.aws.amazon.com/ko_kr/AWSEC2/latest/WindowsGuide/monitor-ami-events.\nhtml \nCreateImage API 호출에 대한 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 \n생성하고 CreateImage API 호출이 감지될 때 알림을 보내도록 대상을 Amazon Simple \nNotification Service(Amazon SNS) 주제로 구성하면 운영 오버헤드가 최소인 요구 사항을 \n충족합니다. . \nAmazon EventBridge\n는 자체 애플리케이션, 통합 SaaS(Software as a Service) \n애플리케이션 및 AWS 서비스의 데이터를 사용하여 애플리케이션을 쉽게 함께 연결할 수 \n있게 해주는 서버리스 이벤트 버스입니다. CreateImage API 호출에 대한 EventBridge \n규칙을 생성하여 회사는 계정 내에서 이 작업이 호출될 때마다 경고를 설정할 수 있습니다. \n경고는 SNS 주제로 보낼 수 있으며, 그런 다음 회사의 이메일 또는 기타 원하는 대상으로 \n알림을 보내도록 구성할 수 있습니다. \n \n참고 \nhttps://docs.aws.amazon.com/ko_kr/AWSEC2/latest/WindowsGuide/monitor-ami-events.\nhtml", "answer_choice": "C"}, "207": {"q_num": 207, "question": "회사는 사용자 요청을 수집하고 요청 유형에 따라 처리를 위해 적절한 마이크로 서비스에 \n요청을 발송하는 데 사용되는 비동기 API 를 소유하고 있습니다. 이 회사는 Amazon API \nGateway 를 사용하여 API 프런트 엔드를 배포하고 Amazon DynamoDB 를 호출하여 사용자 \n요청을 처리 마이크로서비스로 보내기 전에 저장하는 AWS Lambda 함수를 사용하고 \n있습니다. \n회사는 예산이 허용하는 한 많은 DynamoDB 처리량을 프로비저닝했지만 회사는 여전히 \n가용성 문제를 겪고 있으며 사용자 요청이 손실되고 있습니다. \n솔루션 설계자는 기존 사용자에게 영향을 주지 않고 이 문제를 해결하기 위해 무엇을 해야 \n합니까? \nA. API 게이트웨이에서 서버 측 조절 제한을 사용하여 조절을 추가합니다. \n\nB. DynamoDB Accelerator(DAX) 및 Lambda 를 사용하여 DynamoDB 에 대한 쓰기를 \n버퍼링합니다. \nC. 사용자 요청이 있는 테이블에 대해 DynamoDB 에서 보조 인덱스를 생성합니다. \nD. Amazon Simple Queue Service(Amazon SQS) 대기열과 Lambda\n를 사용하여 \nDynamoDB 에 대한 쓰기를 버퍼링합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/89087-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명 \n솔루션 설계자는 SQS 대기열과 Lambda 를 사용하여 처리 마이크로서비스에서 API 프런트 \n엔드를 분리하고 시스템의 전반적인 확장성과 가용성을 개선할 수 있습니다. SQS 대기열은 \n버퍼 역할을 하여 API 프런트 엔드가 마이크로서비스 처리에 높은 작업 부하가 발생하거나 \n일시적으로 사용할 수 없는 경우에도 사용자 요청을 계속 수락할 수 있도록 합니다. 그런 \n다음 Lambda 함수는 SQS 대기열에서 요청을 검색하고 DynamoDB 에 기록하여 모든 \n사용자 요청이 저장 및 처리되도록 할 수 있습니다. 이 접근 방식을 통해 회사는 API \n프런트 엔드와 독립적으로 처리 마이크로서비스를 확장할 수 있으므로 수요가 많은 \n기간에도 사용자가 API 를 계속 사용할 수 있습니다. \n \n즉 사용자 요청을 잃고 있음 = SQS 로 해결. 정답은 D.", "answer_choice": "D"}, "208": {"q_num": 208, "question": "회사는 Amazon EC2 인스턴스에서 Amazon S3 버킷으로 데이터를 이동해야 합니다. 회사는 \nAPI 호출 및 데이터가 공용 인터넷 경로를 통해 라우팅되지 않도록 해야 합니다. EC2 \n인스턴스만 S3 버킷에 데이터를 업로드할 수 있는 액세스 권한을 가질 수 있습니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. EC2 인스턴스가 있는 서브넷에서 Amazon S3 에 대한 인터페이스 VPC 엔드포인트를 \n생성합니다. EC2 인스턴스의 IAM 역할만 액세스할 수 있도록 리소스 정책을 S3 버킷에 \n연결합니다. \nB. EC2 인스턴스가 있는 가용 영역에서 Amazon S3 에 대한 게이트웨이 VPC 엔드포인트를 \n생성합니다. 엔드포인트에 적절한 보안 그룹을 연결합니다. EC2 인스턴스의 IAM 역할만 \n액세스할 수 있도록 리소스 정책을 S3 버킷에 연결합니다. \nC. EC2 인스턴스 내부에서 nslookup 도구를 실행하여 S3 버킷 서비스 API 엔드포인트의 \n프라이빗 IP 주소를 얻습니다. S3 버킷에 대한 액세스 권한을 EC2 인스턴스에 제공하기 \n위해 VPC 경로 테이블에 경로를 생성합니다. EC2 인스턴스의 IAM 역할만 액세스할 수 \n\n있도록 리소스 정책을 S3 버킷에 연결합니다. \nD. AWS 에서 제공하고 공개적으로 사용 가능한 ip-ranges.json 파일을 사용하여 S3 버킷 \n서비스 API 엔드포인트의 프라이빗 IP 주소를 얻습니다. S3 버킷에 대한 액세스 권한을 \nEC2 인스턴스에 제공하기 위해 VPC 경로 테이블에 경로를 생성합니다. EC2 인스턴스의 \nIAM 역할만 액세스할 수 있도록 리소스 정책을 S3 버킷에 연결합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/89088-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nEC2 인스턴스-S3 버킷 간 통신이 인터넷에 노출되지 않음 = S3 Gateway Endpoint. \n \n설명2: \nEC2 인스턴스와 동일한 서브넷에 Amazon S3 용 인터페이스 VPC 종단점을 생성하면 EC2 \n인스턴스와 S3 간의 데이터 전송이 공용 인터넷을 거치지 않고 Amazon 네트워크 내에서 \n비공개로 발생할 수 있습니다. 이렇게 하면 EC2 인스턴스와 S3 간의 안전하고 직접적인 \n통신이 보장됩니다. EC2 인스턴스와 연결된 IAM 역할의 액세스만 허용하는 리소스 정책을 \nS3 버킷에 연결하면 권한이 부여된 인스턴스에 대한 액세스만 추가로 제한됩니다. \n \nB. Amazon S3 용 게이트웨이 VPC 종단점을 생성하려면 공용 인터넷을 통한 라우팅이 \n여전히 필요하므로 이 경우에는 바람직하지 않습니다. \nC. nslookup 을 실행하거나 VPC 경로 테이블에서 특정 경로를 생성하면 트래픽이 여전히 \n공용 인터넷 경로를 통과할 수 있으므로 원하는 수준의 보안 및 개인 정보 보호를 제공하지 \n않습니다. \nD. 공개적으로 사용 가능한 ip-ranges.json 파일을 사용하여 S3 버킷의 서비스 API \n엔드포인트의 프라이빗 IP 주소를 얻는 것은 권장되는 접근 방식이 아닙니다. IP 주소는 \n시간이 지남에 따라 변경될 수 있고 동일한 수준의 보안을 제공하지 않기 때문입니다. VPC \n엔드포인트를 사용합니다. \n \n참고 \nhttps://aws.amazon.com/blogs/security/how-to-restrict-amazon-s3-bucket-access-to-\na-specific-iamrole/", "answer_choice": "A"}, "209": {"q_num": 209, "question": "솔루션 아키텍트는 AWS 클라우드에 배포되는 새 애플리케이션의 아키텍처를 설계하고 \n\n있습니다. 애플리케이션은 Amazon EC2 온디맨드 인스턴스에서 실행되며 여러 가용 \n영역에서 자동으로 확장됩니다. EC2 인스턴스는 하루 종일 자주 확장 및 축소됩니다. \nApplication Load Balancer(ALB)는 부하 분산을 처리합니다. 아키텍처는 분산 세션 데이터 \n관리를 지원해야 합니다. 회사는 필요한 경우 기꺼이 코드를 변경할 수 있습니다. \n아키텍처가 분산 세션 데이터 관리를 지원하도록 하기 위해 솔루션 설계자는 무엇을 해야 \n합니까? \nA. Amazon ElastiCache 를 사용하여 세션 데이터를 관리하고 저장합니다. \nB. ALB 의 세션 선호도(스티키 세션)를 사용하여 세션 데이터를 관리합니다. \nC. AWS Systems Manager 의 Session Manager 를 사용하여 세션을 관리합니다. \nD. AWS Security Token Service(AWS STS)에서 GetSessionToken API 작업을 사용하여 \n세션을 관리합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/89089-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nhttps://aws.amazon.com/vi/caching/session-management/ \n확장성을 해결하고 개별 웹 서버에서 액세스할 수 있는 세션에 대한 공유 데이터 저장소를 \n제공하기 위해 웹 서버 자체에서 HTTP 세션을 추상화할 수 있습니다. \n이에 대한 일반적인 솔루션은 Redis 및 Memcached 와 같은 메모리 내 키/값 저장소를 \n활용하는 것입니다. 메모리 내 키/값 저장소용 ElastiCache 제품에는 복제를 지원할 수 \n있는 Redis 용 ElastiCache 와 복제를 지원하지 않는 Memcached 용 ElastiCache 가 \n포함됩니다. \n \n설명2: \nA(O) : 분산 세션 관리 : 확장성을 해결하고 개별 웹 서버에서 액세스할 수 있는 세션에 \n대한 공유 데이터 저장소를 제공하기 위해 웹 서버 자체에서 HTTP 세션을 추상화할 수 \n있습니다. 이에 대한 일반적인 솔루션은 Redis 및 Memcached 와 같은 메모리 내 키/값 \n저장소 를 활용하는 것 입니다. \nhttps://aws.amazon.com/ko/caching/session-management/ \nRedis 용 Amazon ElastiCache 는 사용자 인증 토큰, 세션 상태 등 세션 정보를 관리하는 \n세션 스토어로 사용하기에 매우 적합합니다. Redis 용 Amazon ElastiCache 를 세션 키에 \n대한 적절한 TTL 과 함께 빠른 키-값 스토어로 사용하면 세션 정보를 관리할 수 있습니다. \nhttps://aws.amazon.com/ko/elasticache/redis/?nc=sn&loc=2&dn=1#Session_Store \nB(X) : EC2 인스턴스는 하루 종일 자주 확장 및 축소된다고 했는데 Session Affinity(=Sticky \nSession)은 이에 맞지 않음. \"\"개별 노드에 세션 저장을 사용할 때의 단점은 장애가 발생할 \n\n경우 장애가 발생한 노드에 있던 세션이 손실될 가능성이 있다는 것입니다. 또한 웹 서버 \n수가 변경되는 경우(예: 확장 시나리오) 활성 세션이 특정 서버에 존재할 수 있으므로 \n트래픽이 웹 서버 전체에 불균등하게 분산될 수 있습니다.  \nhttps://aws.amazon.com/ko/caching/session-management/ \nC(X) : Session Manager\n는 접속 서비스이지 데이터 관리 서비스가 아님. Session \nManager 는 인바운드 포트를 열거나, 배스천 호스트를 유지하거나, SSH 키를 관리할 필요 \n없이 안전하고 감사 가능한 노드 관리를 제공 \nhttps://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager.html \nD(X) : STS 는 임시 보안 자격 증명 서비스. \"\"AWS Security Token Service(AWS STS)를 \n사용하면 AWS 리소스에 대한 액세스를 제어할 수 있는 임시 보안 자격 증명을 생성하여 \n신뢰받는 사용자에게 제공할 수 있습니다. \nhttps://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/id_credentials_temp.html", "answer_choice": "A"}, "210": {"q_num": 210, "question": "빠르게 성장하고 있는 음식 배달 서비스를 제공하는 회사가 있습니다. 성장으로 인해 \n회사의 주문 처리 시스템은 피크 트래픽 시간 동안 확장 문제를 겪고 있습니다. 현재 \n아키텍처에는 다음이 포함됩니다. \n• 애플리케이션에서 주문을 수집하기 위해 Amazon EC2 Auto Scaling 그룹에서 실행되는 \nAmazon EC2 인스턴스 그룹입니다. \n• 주문을 이행하기 위해 Amazon EC2 Auto Scaling 그룹에서 실행되는 또 다른 EC2 \n인스턴스 그룹. \n주문 수집 프로세스는 빠르게 진행되지만 주문 이행 프로세스는 더 오래 걸릴 수 있습니다. \n스케일링 이벤트로 인해 데이터가 손실되어서는 안 됩니다. \n솔루션 설계자는 주문 수집 프로세스와 주문 이행 프로세스가 트래픽이 가장 많은 시간에 \n적절하게 확장될 수 있는지 확인해야 합니다. 솔루션은 회사의 AWS 리소스 활용을 \n최적화해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. Amazon CloudWatch 지표를 사용하여 Auto Scaling 그룹에 있는 각 인스턴스의 CPU 를 \n모니터링합니다. 최대 워크로드 값에 따라 각 Auto Scaling 그룹의 최소 용량을 구성합니다. \nB. Amazon CloudWatch 지표를 사용하여 Auto Scaling 그룹에 있는 각 인스턴스의 CPU 를 \n모니터링합니다. 요청 시 추가 Auto Scaling 그룹을 생성하는 Amazon Simple Notification \nService(Amazon SNS) 주제를 호출하도록 CloudWatch 경보를 구성합니다. \nC. 두 개의 Amazon Simple Queue Service(Amazon SQS) 대기열을 프로비저닝합니다. \n하나는 주문 수집용이고 다른 하나는 주문 이행용입니다. 각 대기열을 폴링하도록 EC2 \n인스턴스를 구성합니다. 대기열이 보내는 알림을 기반으로 Auto Scaling 그룹을 조정합니다. \n\nD. 2 개의 Amazon Simple Queue Service(Amazon SQS) 대기열을 프로비저닝합니다. 하나는 \n주문 수집용이고 다른 하나는 주문 이행용입니다. 각 대기열을 폴링하도록 EC2 인스턴스를 \n구성합니다. 인스턴스 계산당 백로그를 기반으로 지표를 만듭니다. 이 지표를 기반으로 \nAuto Scaling 그룹을 조정합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/94992-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nAuto Scaling 그룹의 인스턴스 수는 메시지를 처리하는 데 걸리는 시간과 허용 가능한 지연 \n시간(대기열 지연)에 따라 결정될 수 있습니다. 해결책은 유지 관리할 인스턴스당 허용 \n가능한 백로그인 대상 값과 함께 인스턴스 메트릭당 백로그를 사용하는 것입니다. \n \n설명2: \nA. 이 접근 방식은 CPU 사용률에만 초점을 맞추므로 주문 수집 및 이행 프로세스의 확장 \n요구 사항을 정확하게 반영하지 못할 수 있습니다. 분리 및 신뢰할 수 있는 메시지 처리에 \n대한 요구 사항은 다루지 않습니다. \n \nB. 이 접근 방식은 경보를 통합하여 추가 Auto Scaling 그룹을 트리거하지만 SQS 대기열을 \n사용하여 제공되는 분리 및 안정적인 메시지 처리가 부족합니다. 비효율적인 확장 및 \n잠재적인 데이터 손실이 발생할 수 있습니다. \n \nC. SQS 대기열을 사용하는 것이 올바른 방향으로 나아가는 단계이지만 대기열 알림만을 \n기준으로 확장하는 것은 최적의 리소스 활용을 제공하지 못할 수 있습니다. 인스턴스당 \n백로그를 고려하지 않으며 조정에 대한 세밀한 제어를 허용하지 않습니다. \n \n전반적으로 주문 수집 및 이행을 위해 SQS 대기열을 사용하고, 인스턴스 계산당 백로그를 \n기반으로 메트릭을 생성하고, 이에 따라 Auto Scaling 그룹을 확장하는 옵션 D 는 리소스 \n활용을 최적화하고 보장하면서 확장 문제를 해결하는 가장 적합한 솔루션입니다. 신뢰할 수 \n있는 메시지 처리", "answer_choice": "D"}, "211": {"q_num": 211, "question": "한 회사에서 여러 프로덕션 애플리케이션을 호스팅합니다. 애플리케이션 중 하나는 여러 \nAWS 리전에서 Amazon EC2, AWS Lambda, Amazon RDS, Amazon Simple Notification \nService(Amazon SNS) 및 Amazon Simple Queue Service(Amazon SQS)의 리소스로 \n\n구성됩니다. 모든 회사 리소스에는 \"응용 프로그램\"이라는 태그 이름과 각 응용 프로그램에 \n해당하는 값이 태그로 지정됩니다. 솔루션 설계자는 태그가 지정된 모든 구성 요소를 \n식별하기 위한 가장 빠른 솔루션을 제공해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. AWS CloudTrail 을 사용하여 애플리케이션 태그가 있는 리소스 목록을 생성합니다. \nB. AWS CLI 를 사용하여 모든 리전에서 각 서비스를 쿼리하여 태그가 지정된 구성 요소를 \n보고합니다. \nC. Amazon CloudWatch Logs Insights 에서 쿼리를 실행하여 애플리케이션 태그가 있는 구성 \n요소에 대해 보고합니다. \nD. AWS Resource Groups Tag Editor 로 쿼리를 실행하여 애플리케이션 태그를 사용하여 \n전역적으로 리소스에 대해 보고합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/95145-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nCloudTrail 은 주로 API 활동 캡처 및 로깅에 중점을 두기 때문에 A 는 가장 빠른 솔루션이 \n아닙니다. 리소스 변경에 대한 정보를 제공할 수 있지만 여러 서비스 및 리전에서 태그가 \n지정된 모든 구성 요소를 식별하는 포괄적이고 빠른 방법을 제공하지 않을 수 있습니다. \n \nB 에는 AWS CLI 를 사용하여 각 서비스를 수동으로 쿼리하는 작업이 포함되며, 이는 특히 \n여러 서비스 및 리전을 처리할 때 시간이 많이 걸리고 번거로울 수 있습니다. 태그가 \n지정된 구성 요소를 빠르게 식별하기 위한 가장 효율적인 솔루션은 아닙니다. \n \nC\n는 태그가 지정된 구성 요소를 직접 식별하기보다는 로그 분석에 중점을 둡니다. \nCloudWatch Logs Insights 는 로그에서 정보를 추출하는 데 도움이 될 수 있지만 여러 \n서비스 및 리전에서 태그가 지정된 모든 구성 요소의 통합 목록을 수집하는 간단하고 빠른 \n방법을 제공하지 않을 수 있습니다. \n \nD 는 태그를 기반으로 리소스를 관리하고 구성하도록 특별히 설계된 Resource Groups Tag \nEditor 를 활용하므로 가장 빠른 솔루션입니다. 여러 서비스 및 리전에서 태그가 지정된 \n구성 요소에 대한 보고서를 생성하는 중앙 집중식의 효율적인 접근 방식을 제공합니다. \n \n참고: \nhttps://docs.aws.amazon.com/tag-editor/latest/userguide/tagging.html", "answer_choice": "D"}, "212": {"q_num": 212, "question": "회사는 다른 팀이 액세스할 수 있도록 데이터베이스를 하루에 한 번 Amazon S3\n로 \n내보내야 합니다. 내보낸 개체 크기는 2GB 에서 5GB 사이입니다. 데이터에 대한 S3 \n액세스 패턴은 가변적이며 빠르게 변경됩니다. 데이터는 즉시 사용할 수 있어야 하며 최대 \n3 개월 동안 액세스할 수 있어야 합니다. 회사는 검색 시간을 늘리지 않는 가장 비용 \n효율적인 솔루션이 필요합니다. \n회사는 이러한 요구 사항을 충족하기 위해 어떤 S3 스토리지 클래스를 사용해야 합니까? \nA. S3 지능형 계층화(S3 Intelligent-Tiering) \nB. S3 Glacier 즉시 검색(S3 Glacier Instant Retrieval) \nC. S3 표준(S3 Standard) \nD. S3 Standard-Infrequent Access(S3 Standard-IA)", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/95300-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n옵션 A\n는 액세스 패턴이 변화하는 개체를 위해 설계되었지만 특히 액세스 패턴이 \n가변적이고 빠르게 변경되는 경우 데이터의 장기 저장을 위한 가장 비용 효율적인 솔루션이 \n아닐 수 있습니다. \n \n옵션 B 는 장기 아카이브 저장에 최적화되어 있으며 회사에서 요구하는 즉각적인 액세스를 \n제공하지 않을 수 있습니다. Glacier 스토리지에서 데이터를 검색하면 일반적으로 다른 \n스토리지 클래스에 비해 검색 시간이 더 오래 걸립니다. \n \n옵션 C 는 즉각적인 가용성과 데이터에 대한 빠른 액세스를 위한 적절한 선택입니다. 높은 \n내구성, 가용성 및 낮은 대기 시간 액세스를 제공하므로 회사의 요구 사항에 적합합니다. \n그러나 장기 보관을 위한 가장 비용 효율적인 옵션은 아닙니다. \n \n옵션 D 는 특히 자주 액세스하지 않는 데이터의 경우 S3 Standard 에 비해 비용 효율적인 \n스토리지 클래스입니다. 그러나 데이터에 대한 액세스 패턴이 가변적이고 빠르게 변경되기 \n때문에 S3 Standard-IA 는 빈번한 액세스에 대한 추가 검색 비용이 발생하므로 가장 비용 \n효율적인 솔루션이 아닐 수 있습니다.", "answer_choice": "A"}, "213": {"q_num": 213, "question": "회사에서 새로운 모바일 앱을 개발하고 있습니다. 회사는 교차 사이트 스크립팅 또는 SQL \n주입과 같은 일반적인 애플리케이션 수준 공격으로부터 ALB(Application Load Balancer)를 \n보호하기 위해 적절한 트래픽 필터링을 구현해야 합니다. 이 회사는 최소한의 인프라와 \n운영 인력을 보유하고 있습니다. 회사는 AWS 환경의 서버를 관리, 업데이트 및 보호하는 \n책임을 줄여야 합니다. \n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까? \nA. AWS WAF 규칙을 구성하고 이를 ALB 와 연결합니다. \nB. 퍼블릭 호스팅이 활성화된 Amazon S3 를 사용하여 애플리케이션을 배포합니다. \nC. AWS Shield Advanced 를 배포하고 ALB 를 보호된 리소스로 추가합니다. \nD. 타사 방화벽을 실행하는 Amazon EC2 인스턴스로 트래픽을 보낸 다음 트래픽을 현재 \nALB 로 전달하는 새 ALB 를 생성합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/95301-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \n솔루션 설계자는 AWS WAF 규칙을 구성하고 이를 ALB 와 연결하는 옵션 A 를 권장해야 \n합니다. 이를 통해 회사는 교차 사이트 스크립팅 또는 SQL 주입과 같은 일반적인 \n애플리케이션 수준 공격으로부터 ALB 를 보호하는 데 필요한 애플리케이션 계층에서 트래픽 \n필터링을 적용할 수 있습니다. AWS WAF 는 애플리케이션 가용성에 영향을 미치거나 보안을 \n손상시키거나 과도한 리소스를 소비할 수 있는 일반적인 웹 익스플로잇으로부터 웹 \n애플리케이션을 쉽게 보호할 수 있게 해주는 관리형 서비스입니다. 회사는 애플리케이션의 \n보안을 보장하기 위해 규칙을 쉽게 관리하고 업데이트할 수 있습니다. \n \n설명2: \nAWS \nWAF \n규칙을 \n구성하고 \n이를 \nALB\n와 \n연결함으로써 \n회사는 \n악성 \n트래픽이 \n애플리케이션에 도달하기 전에 필터링하고 차단할 수 있습니다. AWS WAF 는 사전 구성된 \n규칙 세트를 제공하고 사용자 지정 규칙 생성을 허용하여 XSS 및 SQL 주입과 같은 \n일반적인 취약성으로부터 보호합니다. \n \n옵션 B 는 애플리케이션 수준 공격으로부터 보호하는 데 필요한 보안 및 트래픽 필터링 \n기능을 제공하지 않습니다. 보안 조치를 구현하는 것보다 정적 콘텐츠를 호스팅하는 데 더 \n적합합니다. \n옵션 C 는 XSS 또는 SQL 주입과 같은 애플리케이션 수준 공격이 아닌 DDoS 보호에 \n중점을 둡니다. AWS Shield Advanced 는 시나리오에 언급된 특정 요구 사항을 다루지 \n않습니다. \n\n옵션 D 는 추가 인프라를 유지하고 보호하는 것과 관련되며, 이는 책임을 줄이고 최소한의 \n운영 직원에 의존해야 한다는 요구 사항에 위배됩니다.", "answer_choice": "A"}, "214": {"q_num": 214, "question": "회사의 보고 시스템은 매일 수백 개의 .csv 파일을 Amazon S3 버킷에 전달합니다. 회사는 \n이러한 파일을 Apache Parquet 형식으로 변환하고 변환된 데이터 버킷에 파일을 저장해야 \n합니다. \n최소한의 개발 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Apache Spark 가 설치된 Amazon EMR 클러스터를 생성합니다. 데이터를 변환하는 Spark \n애플리케이션을 작성합니다. EMRFS(EMR 파일 시스템)를 사용하여 변환된 데이터 버킷에 \n파일을 씁니다. \nB. AWS Glue 크롤러를 생성하여 데이터를 검색합니다. AWS Glue 추출, 변환 및 로드(ETL) \n작업을 생성하여 데이터를 변환합니다. 출력 단계에서 변환된 데이터 버킷을 지정합니다. \nC. AWS Batch 를 사용하여 Bash 구문으로 작업 정의를 생성하여 데이터를 변환하고 \n데이터를 변환된 데이터 버킷으로 출력합니다. 작업 정의를 사용하여 작업을 제출합니다. \n어레이 작업을 작업 유형으로 지정합니다. \nD. 데이터를 변환하고 변환된 데이터 버킷으로 데이터를 출력하는 AWS Lambda 함수를 \n생성합니다. S3 버킷에 대한 이벤트 알림을 구성합니다. 이벤트 알림의 대상으로 Lambda \n함수를 지정합니다.", "answer_block": "Answer: B  \nhttps://www.examtopics.com/discussions/amazon/view/95154-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nAWS Glue 는 분석을 위해 데이터를 준비하고 변환하는 프로세스를 간소화하는 완전 관리형 \nETL 서비스입니다. AWS Glue 를 사용하려면 다른 옵션에 비해 최소한의 개발 노력이 \n필요합니다. \n \n옵션 A 는 데이터 변환을 위한 Spark 애플리케이션 작성과 관련되므로 더 많은 개발 노력이 \n필요합니다. 또한 EMR 클러스터로 추가 인프라 관리를 소개합니다. \n \n옵션 C 는 데이터 변환을 위한 사용자 지정 Bash 스크립트를 작성하고 관리해야 합니다. \n수동 작업이 더 많이 필요하며 데이터 변환을 위한 AWS Glue 의 내장 기능을 제공하지 \n않습니다. \n \n\n옵션 D\n는 데이터 변환을 위해 사용자 지정 Lambda\n를 개발하고 관리해야 합니다. \nLambda 는 변환을 처리할 수 있지만 ETL 작업을 위해 특별히 설계된 AWS Glue 에 비해 더 \n많은 노력이 필요합니다. \n \n따라서 옵션 B 는 AWS Glue 의 데이터 검색, 변환 및 변환된 데이터 버킷으로의 출력 \n기능을 활용하여 가장 쉽고 최소한의 개발 노력을 제공합니다. \n \n참고: \nhttps://docs.aws.amazon.com/ko_kr/prescriptive-guidance/latest/patterns/three-aws-glu\ne-etl-job-types-for-converting-data-to-apache-parquet.html", "answer_choice": "B"}, "215": {"q_num": 215, "question": "회사는 데이터 센터의 NAS(Network Attached Storage)에 700TB 의 백업 데이터를 저장하고 \n있습니다. 이 백업 데이터는 드문 규제 요청을 위해 액세스할 수 있어야 하며 7 년 동안 \n보관해야 합니다. 회사는 이 백업 데이터를 데이터 센터에서 AWS 로 마이그레이션하기로 \n결정했습니다. 마이그레이션은 1 개월 이내에 완료되어야 합니다. 회사는 데이터 전송에 \n사용할 수 있는 공용 인터넷 연결에 500Mbps 의 전용 대역폭을 가지고 있습니다. \n최저 비용으로 데이터를 마이그레이션하고 저장하려면 솔루션 설계자가 무엇을 해야 \n합니까? \nA. 데이터를 전송할 AWS Snowball 디바이스를 주문합니다. 수명 주기 정책을 사용하여 \n파일을 Amazon S3 Glacier Deep Archive 로 전환합니다. \nB. 데이터 센터와 Amazon VPC 간에 VPN 연결을 배포합니다. AWS CLI 를 사용하여 \n온프레미스에서 Amazon S3 Glacier 로 데이터를 복사합니다. \nC. 500Mbps AWS Direct Connect 연결을 프로비저닝하고 데이터를 Amazon S3\n로 \n전송합니다. 수명 주기 정책을 사용하여 파일을 Amazon S3 Glacier Deep Archive 로 \n전환합니다. \nD. AWS DataSync 를 사용하여 데이터를 전송하고 온프레미스에 DataSync 에이전트를 \n배포합니다. DataSync 작업을 사용하여 온프레미스 NAS 스토리지에서 Amazon S3 \nGlacier 로 파일을 복사합니다.", "answer_block": "Answer: A  \nhttps://www.examtopics.com/discussions/amazon/view/94983-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n해설: \n700TB 나 되는 대용량을 Snowball Edge Device 를 사용하지 않고 네트워크 상으로 옮기는 \n\n것은 굉장히 많은 시간이 소요됨. \nhttps://kindloveit.tistory.com/68 \nhttps://www.omnicalculator.com/other/data-transfer", "answer_choice": "A"}, "216": {"q_num": 216, "question": "회사에는 Amazon S3 버킷에 수백만 개의 객체가 있는 서버리스 웹 사이트가 있습니다. \n회사는 S3 버킷을 Amazon CloudFront 배포의 오리진으로 사용합니다. 회사는 개체가 \n로드되기 전에 S3 버킷에 암호화를 설정하지 않았습니다. 솔루션 설계자는 모든 기존 \n객체와 향후 S3 버킷에 추가되는 모든 객체에 대해 암호화를 활성화해야 합니다. \n최소한의 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 새 S3 버킷을 생성합니다. 새 S3 버킷에 대한 기본 암호화 설정을 켭니다. 모든 기존 \n개체를 임시 로컬 저장소에 다운로드합니다. 새 S3 버킷에 객체를 업로드합니다. \nB. S3 버킷의 기본 암호화 설정을 켭니다. S3 Inventory 기능을 사용하여 암호화되지 않은 \n객체를 나열하는 .csv 파일을 생성합니다. 복사 명령을 사용하여 해당 객체를 암호화하는 \nS3 배치 작업 작업을 실행합니다. \nC. AWS Key Management Service(AWS KMS)를 사용하여 새 암호화 키를 생성합니다. AWS \nKMS 관리형 암호화 키(SSE-KMS)로 서버 측 암호화를 사용하도록 S3 버킷의 설정을 \n변경합니다. S3 버킷에 대한 버전 관리를 켭니다. \nD. AWS Management Console 에서 Amazon S3 로 이동합니다. S3 버킷의 객체를 찾습니다. \n암호화 필드를 기준으로 정렬합니다. 암호화되지 않은 각 개체를 선택합니다. 수정 버튼을 \n사용하여 S3 버킷의 모든 암호화되지 않은 객체에 기본 암호화 설정을 적용합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/95040-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nS3 에서 기본 암호화 설정을 활성화하면 새로 추가된 모든 객체가 자동으로 암호화됩니다. \n기존 객체를 암호화하기 위해 S3 Inventory 기능을 사용하여 암호화되지 않은 객체 목록을 \n생성할 수 있습니다. 그런 다음 암호화를 적용하는 동안 해당 객체를 복사하기 위해 S3 \n배치 작업 작업을 실행할 수 있습니다. \nA. 이 솔루션에는 새 S3 를 생성하고 모든 기존 개체를 수동으로 다운로드 및 업로드하는 \n작업이 포함됩니다. 수백만 개의 개체를 전송하는 데 상당한 노력과 시간이 필요하므로 \n효율성이 떨어지는 솔루션입니다. \nC. AWS KMS 로 SSE 를 활성화하는 것은 S3 에서 객체를 암호화하는 유효한 접근 \n방식이지만 기존 객체를 암호화해야 하는 요구 사항을 해결하지는 않습니다. 버킷에 추가된 \n\n새 객체에만 암호화를 적용합니다. \nD. 기본 암호화 설정을 적용하기 위해 S3 의 각 개체를 수동으로 수정하는 것은 노동 \n집약적이고 오류가 발생하기 쉬운 프로세스입니다. 암호화되지 않은 각 개체를 개별적으로 \n선택하고 수정해야 하므로 많은 수의 개체에 비실용적입니다. \n \n참고: \nhttps://spin.atomicobject.com/2020/09/15/aws-s3-encrypt-existing-objects/", "answer_choice": "B"}, "217": {"q_num": 217, "question": "회사는 \nApplication \nLoad \nBalancer \n뒤의 \nAmazon \nEC2 \n인스턴스에서 \n글로벌 \n웹 \n애플리케이션을 실행합니다. 애플리케이션은 Amazon Aurora\n에 데이터를 저장합니다. \n회사는 재해 복구 솔루션을 만들어야 하며 최대 30 분의 다운타임과 잠재적인 데이터 \n손실을 허용할 수 있습니다. 솔루션은 기본 인프라가 정상일 때 부하를 처리할 필요가 \n없습니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. 필요한 인프라 요소가 있는 애플리케이션을 배치합니다. Amazon Route 53 을 사용하여 \n활성-수동 장애 조치를 구성합니다. 두 번째 AWS 리전에서 Aurora 복제본을 생성합니다. \nB. 두 번째 AWS 리전에서 애플리케이션의 축소된 배포를 호스팅합니다. Amazon Route \n53 을 사용하여 활성-활성 장애 조치를 구성합니다. 두 번째 리전에서 Aurora 복제본을 \n생성합니다. \nC. 두 번째 AWS 리전에서 기본 인프라를 복제합니다. Amazon Route 53 을 사용하여 \n활성-활성 장애 조치를 구성합니다. 최신 스냅샷에서 복원된 Aurora 데이터베이스를 \n생성합니다. \nD. AWS Backup 으로 데이터를 백업합니다. 백업을 사용하여 두 번째 AWS 리전에 필요한 \n인프라를 생성합니다. Amazon Route 53 을 사용하여 활성-수동 장애 조치를 구성합니다. 두 \n번째 리전에서 Aurora 두 번째 기본 인스턴스를 생성합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/95015-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n솔루션은 기본 인프라가 정상일 때 부하를 처리할 필요가 없다고 했으므로 Active/Passive \nFailover 를 사용하면 됨. 따라서 A,D 둘 중 하나가 답. \nA(O) : Q: Amazon Aurora 는 교차 리전 복제를 지원하나요? 예. 물리적 또는 논리적 복제를 \n사용하여 교차 리전 Aurora 복제본을 설정할 수 있습니다. Amazon RDS 콘솔에서 교차 \n\n리전 복제본을 새로운 기본 복제본으로 승격할 수 있습니다. 논리적(binlog) 복제의 경우, \n승격 프로세스는 워크로드에 따라 다르지만 보통 몇 분 정도 걸립니다. 승격 프로세스를 \n시작하면 교차 리전 복제가 중단됩니다. https://aws.amazon.com/ko/rds/aurora/faqs/ \nD(X) : 굳이 AWS Backup 을 사용하지 않아도 오로라 교차 리전 복제본 (Aurora Cross \nRegion Replica)를 사용하면 됨. 그리고 글로벌 웹 애플리케이션을 사용한다고 했는데 이런 \n경우엔 데이터를 복제해 인스턴스를 다른 리전에 생성하는 것보단 복제본을 사용해서 각 \n지역에서 읽기 쿼리를 할 때 지연시간을 줄이는 것이 더 좋음. \n \n참고: \nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-types.html", "answer_choice": "A"}, "218": {"q_num": 218, "question": "회사에는 탄력적 IP 주소가 있는 퍼블릭 서브넷의 Amazon EC2 인스턴스에서 실행되는 웹 \n서버가 있습니다. 기본 보안 그룹은 EC2 인스턴스에 할당됩니다. 모든 트래픽을 \n차단하도록 기본 네트워크 ACL 이 수정되었습니다. 솔루션 설계자는 포트 443 을 통해 \n어디에서나 웹 서버에 액세스할 수 있도록 해야 합니다. \n이 작업을 수행할 단계 조합은 무엇입니까? (2 개 선택) \nA. 소스 0.0.0.0/0 에서 TCP 포트 443 을 허용하는 규칙으로 보안 그룹을 생성합니다. \nB. 대상 0.0.0.0/0 에 대한 TCP 포트 443 을 허용하는 규칙으로 보안 그룹을 생성합니다. \nC. 소스 0.0.0.0/0 에서 TCP 포트 443 을 허용하도록 네트워크 ACL 을 업데이트합니다. \nD. 소스 0.0.0.0/0\n에서 대상 0.0.0.0/0\n으로 인바운드/아웃바운드 TCP 포트 443\n을 \n허용하도록 네트워크 ACL 을 업데이트합니다. \nE. 소스 0.0.0.0/0\n에서 인바운드 TCP 포트 443\n을 허용하고 대상 0.0.0.0/0\n으로 \n아웃바운드 TCP 포트 32768-65535 를 허용하도록 네트워크 ACL 을 업데이트합니다.", "answer_block": "Answer: A, E \nhttps://www.examtopics.com/discussions/amazon/view/95056-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n포트 443 의 모든 위치에서 웹 서버에 액세스할 수 있도록 하는 작업을 수행하는 단계 \n조합은 소스 0.0.0.0/0(A)에서 TCP 포트 443 을 허용하고 네트워크 ACL 을 업데이트하는 \n규칙으로 보안 그룹을 생성하는 것입니다. 소스 0.0.0.0/0(C)에서 인바운드 TCP 포트 \n443 을 허용합니다. \n이렇게 하면 포트 443 에 대한 트래픽이 보안 그룹 수준과 네트워크 ACL 수준 모두에서 \n\n허용되어 포트 443 의 모든 위치에서 웹 서버에 액세스할 수 있습니다.", "answer_choice": "A"}, "219": {"q_num": 219, "question": "회사의 애플리케이션에 성능 문제가 있습니다. 애플리케이션은 상태 저장이며 Amazon EC2 \n인스턴스에서 인 메모리 작업을 완료해야 합니다. 이 회사는 AWS CloudFormation 을 \n사용하여 인프라를 배포하고 M5 EC2 인스턴스 제품군을 사용했습니다. 트래픽이 증가함에 \n따라 \n애플리케이션 \n성능이 \n저하되었습니다. \n사용자는 \n사용자가 \n애플리케이션에 \n액세스하려고 할 때 지연을 보고합니다. \n운영상 가장 효율적인 방식으로 이러한 문제를 해결하는 솔루션은 무엇입니까? \nA. Auto Scaling 그룹에서 실행되는 T3 EC2 인스턴스로 EC2 인스턴스를 교체합니다. AWS \nManagement Console 을 사용하여 변경합니다. \nB. Auto Scaling 그룹에서 EC2 인스턴스를 실행하도록 CloudFormation 템플릿을 \n수정합니다. 증가가 필요한 경우 Auto Scaling 그룹의 원하는 용량과 최대 용량을 수동으로 \n늘립니다. \nC. CloudFormation 템플릿을 수정합니다. EC2 인스턴스를 R5 EC2 인스턴스로 교체합니다. \nAmazon CloudWatch 내장 EC2 메모리 메트릭을 사용하여 향후 용량 계획을 위해 \n애플리케이션 성능을 추적합니다. \nD. CloudFormation 템플릿을 수정합니다. EC2 인스턴스를 R5 EC2 인스턴스로 교체합니다. \nEC2 인스턴스에 Amazon CloudWatch 에이전트를 배포하여 향후 용량 계획을 위한 사용자 \n지정 애플리케이션 지연 시간 메트릭을 생성합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/95162-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nM5 \n인스턴스를 \n메모리 \n집약적인 \n워크로드에 \n최적화된 \nR5 \n인스턴스로 \n교체하면 \n애플리케이션에서 메모리 용량과 성능을 높일 수 있습니다. \n또한 EC2 인스턴스에 CloudWatch 에이전트를 배포하면 애플리케이션 성능에 대한 중요한 \n통찰력을 제공할 수 있는 사용자 지정 애플리케이션 대기 시간 메트릭을 생성할 수 \n있습니다. \n이 솔루션은 적절한 인스턴스 유형을 활용하고 더 나은 모니터링 및 향후 용량 계획을 위해 \n사용자 지정 애플리케이션 메트릭을 수집하여 성능 문제를 효율적으로 해결합니다. \n \nA. T3 인스턴스로 교체하면 인 메모리 작업에 충분한 메모리 용량을 제공하지 못할 수 \n있습니다. \n\nB. ASG 의 용량을 수동으로 늘리면 성능 문제가 직접적으로 해결되지 않습니다. \nC. 내장된 EC2 메모리 메트릭에만 의존하면 메모리 내 작업을 최적화하는 데 충분한 \n세분성을 제공하지 못할 수 있습니다. \n \n가장 효율적인 솔루션은 CloudFormation 템플릿을 수정하고, R5 인스턴스로 교체하고, \n사용자 지정 메트릭을 위해 CloudWatch 에이전트를 배포하는 것입니다.", "answer_choice": "D"}, "220": {"q_num": 220, "question": "솔루션 설계자는 Amazon API Gateway 를 사용하여 사용자의 요청을 수신할 새 API 를 \n설계하고 있습니다. 요청량은 매우 다양합니다. 단일 요청을 받지 않고 몇 시간이 지날 수 \n있습니다. 데이터 처리는 비동기식으로 이루어지지만 요청이 이루어진 후 몇 초 이내에 \n완료되어야 합니다. \n최저 비용으로 요구 사항을 제공하기 위해 솔루션 설계자가 API 를 호출하도록 해야 하는 \n컴퓨팅 서비스는 무엇입니까? \nA. AWS Glue 작업 \nB. AWS Lambda 함수 \nC. Amazon Elastic Kubernetes Service(Amazon EKS)에서 호스팅되는 컨테이너화된 서비스 \nD. Amazon EC2 와 함께 Amazon ECS 에서 호스팅되는 컨테이너화된 서비스", "answer_block": "Answer: B  \nhttps://www.examtopics.com/discussions/amazon/view/95306-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nAPI Gateway + Lambda 는 서버리스 아키텍처를 사용하는 최신 애플리케이션을 위한 완벽한 \n솔루션입니다. \n \n설명2: \nLambda 는 요청을 비동기식으로 처리하기 위해 API Gateway 에서 트리거할 수 있는 \n서버리스 컴퓨팅 서비스입니다. 들어오는 요청 볼륨에 따라 자동으로 확장되며 요청을 \n처리하는 데 사용된 실제 컴퓨팅 시간에 대해서만 요금을 부과하여 비용 최적화를 \n허용합니다. \n \nA. Glue 는 완전히 관리되는 ETL 서비스입니다. API 요청을 제공하는 대신 데이터 처리 및 \n변환 작업을 위해 설계되었습니다. 가변적인 요청량을 처리하고 몇 초 내에 응답을 \n전달하는 데 적합하지 않을 수 있습니다. \n\nC. EKS\n는 확장성과 유연성을 제공하지만 가변적인 API 요청 볼륨을 처리하기 위해 \n인프라를 관리하고 확장하는 데 추가적인 복잡성과 오버헤드가 발생할 수 있습니다. \nD. 이전 옵션과 마찬가지로 EC2 와 함께 ECS 를 사용하려면 인프라 관리 및 확장을 위한 \n추가 노력이 필요하며, 이는 간헐적이고 가변적인 API 요청 볼륨을 처리하는 데 필요하지 \n않을 수 있습니다.", "answer_choice": "B"}, "221": {"q_num": 221, "question": "회사는 Amazon Linux EC2 인스턴스 그룹에서 애플리케이션을 실행합니다. 규정 준수를 \n위해 회사는 모든 애플리케이션 로그 파일을 7 년 동안 보관해야 합니다. 로그 파일은 모든 \n파일에 동시에 액세스할 수 있어야 하는 보고 도구로 분석됩니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 스토리지 솔루션은 무엇입니까? \nA. Amazon Elastic Block Store(Amazon EBS) \nB. Amazon Elastic File System(Amazon EFS) \nC. Amazon EC2 인스턴스 스토어 \nD. Amazon S3", "answer_block": "Answer: D  \nhttps://www.examtopics.com/discussions/amazon/view/95307-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nA. EBS 는 EC2 인스턴스와 함께 사용할 블록 수준 스토리지 볼륨을 제공합니다. 내구성과 \n지속성을 제공하지만 로그 파일의 장기 보존을 위한 가장 비용 효율적인 솔루션은 아닙니다. \n또한 이 시나리오의 요구 사항인 파일에 대한 동시 액세스를 제공하지 않습니다. \nB. EFS 는 여러 EC2 인스턴스에 동시에 탑재할 수 있는 확장 가능한 파일 스토리지 \n서비스입니다. 파일에 대한 동시 액세스를 제공하지만 S3 에 비해 가격이 높기 때문에 장기 \n보존을 위한 가장 비용 효율적인 옵션이 아닐 수 있습니다. \nC. 인스턴스 스토어는 EC2 인스턴스에 물리적으로 연결된 임시 스토리지 옵션입니다. 규정 \n준수 목적에 필요한 내구성 및 장기 보존을 제공하지 않습니다. 또한 인스턴스 스토어는 \n연결된 특정 EC2 인스턴스 외부에서 액세스할 수 없으므로 보고 도구를 통한 동시 \n액세스가 불가능합니다. \n \n따라서 장기보존, 동시접속, 가성비 등의 요구사항을 고려할 때 S3가 가장 적합하고 가성비 \n좋은 스토리지 솔루션입니다. \n \n참고: \n\nhttps://docs.aws.amazon.com/efs/latest/ug/transfer-data-to-efs.html", "answer_choice": "D"}, "222": {"q_num": 222, "question": "회사는 회사의 AWS 계정에서 작업을 수행하기 위해 외부 공급업체를 고용했습니다. 벤더는 \n벤더가 소유한 AWS 계정에서 호스팅되는 자동화 도구를 사용합니다. 벤더는 회사의 AWS \n계정에 대한 IAM 액세스 권한이 없습니다. \n솔루션 설계자는 공급업체에 이 액세스 권한을 어떻게 부여해야 합니까? \nA. 공급업체의 IAM 역할에 대한 액세스 권한을 위임하려면 회사 계정에서 IAM 역할을 \n생성합니다. 벤더가 요구하는 권한에 대한 역할에 적절한 IAM 정책을 연결합니다. \nB. 암호 복잡성 요구 사항을 충족하는 암호를 사용하여 회사 계정에 IAM 사용자를 \n만듭니다. 벤더가 요구하는 권한에 대해 적절한 IAM 정책을 사용자에게 연결합니다. \nC. 회사 계정에 IAM 그룹을 생성합니다. 공급업체 계정의 도구 IAM 사용자를 그룹에 \n추가합니다. 공급업체에 필요한 권한에 대해 적절한 IAM 정책을 그룹에 연결합니다. \nD. IAM 콘솔에서 공급자 유형으로 \"AWS 계정\"을 선택하여 새 자격 증명 공급자를 만듭니다. \n공급업체의 AWS 계정 ID 와 사용자 이름을 제공합니다. 벤더가 요구하는 권한에 대해 \n적절한 IAM 정책을 새 제공자에 연결하십시오.", "answer_block": "Answer: A  \nhttps://www.examtopics.com/discussions/amazon/view/95160-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명:  \nIAM 역할을 생성하고 공급업체의 IAM 역할에 대한 액세스 권한을 위임함으로써 계정 간에 \n신뢰 관계를 설정합니다. 이렇게 하면 공급업체의 자동화 도구가 회사 계정의 역할을 맡고 \n필요한 리소스에 액세스할 수 있습니다. \n \n적절한 IAM 정책을 역할에 연결하면 해당 도구가 작업을 수행하는 데 벤더가 요구하는 \n정확한 권한을 정의할 수 있습니다. 이렇게 하면 공급업체가 회사 계정에 대한 직접적인 \nIAM 액세스 권한을 부여하지 않고도 필요한 액세스 권한을 가질 수 있습니다. \n \nB 는 암호가 있는 IAM 사용자를 생성하려면 벤더와 자격 증명을 공유해야 하므로 보안상의 \n이유로 권장되지 않습니다. \n \n공급업체의 IAM 사용자를 회사 계정의 IAM 그룹에 추가하면 공급업체 도구에 대한 \n액세스를 위임하는 직접적이고 통제된 방법을 제공하지 않기 때문에 C\n는 올바르지 \n않습니다. \n\n \n공급업체의 AWS 계정에 대한 새 자격 증명 공급자를 생성하면 공급업체 도구에 대한 \n액세스 권한을 위임하는 간단한 방법이 제공되지 않기 때문에 D 는 틀렸습니다. ID 공급자는 \n일반적으로 외부 ID 시스템을 사용하는 연합 액세스에 사용됩니다. \n \n참고: \nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_common-scenarios_third-p\narty.html", "answer_choice": "A"}, "223": {"q_num": 223, "question": "한 회사에서 Java Spring Boot 애플리케이션을 프라이빗 서브넷의 Amazon Elastic \nKubernetes Service(Amazon EKS)에서 실행되는 포드로 배포했습니다. 애플리케이션은 \nAmazon DynamoDB 테이블에 데이터를 써야 합니다. 솔루션 설계자는 애플리케이션이 \n인터넷에 트래픽을 노출하지 않고 DynamoDB 테이블과 상호 작용할 수 있는지 확인해야 \n합니다. \n이 목표를 달성하기 위해 솔루션 설계자는 어떤 단계 조합을 수행해야 합니까? (2 개 선택) \nA. EKS 포드에 충분한 권한이 있는 IAM 역할을 연결합니다. \nB. EKS 포드에 충분한 권한이 있는 IAM 사용자를 연결합니다. \nC. 프라이빗 서브넷의 네트워크 ACL 을 통해 DynamoDB 테이블에 대한 아웃바운드 연결을 \n허용합니다. \nD. DynamoDB 용 VPC 엔드포인트를 생성합니다. \nE. Java Spring Boot 코드에 액세스 키를 삽입합니다.", "answer_block": "Answer: A, D  \nhttps://www.examtopics.com/discussions/amazon/view/95310-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nA. IAM 역할을 EKS 포드에 연결하면 포드가 DynamoDB 에 액세스하는 데 필요한 권한을 \n부여할 수 있습니다. IAM 역할에는 DynamoDB 테이블에 대한 액세스를 허용하는 적절한 \n정책이 있어야 합니다. \n \nD. DynamoDB 용 VPC 엔드포인트를 생성하면 EKS 포드가 인터넷 연결 없이도 VPC 내에서 \n비공개로 DynamoDB 에 액세스할 수 있습니다. VPC 엔드포인트는 DynamoDB 에 대한 \n직접적이고 안전한 연결을 제공하므로 트래픽이 인터넷을 통해 흐를 필요가 없습니다. \n \n\nB 는 IAM 사용자를 포드에 연결하는 것이 권장되는 접근 방식이 아니기 때문에 올바르지 \n않습니다. IAM 사용자는 AWS Management Console 또는 AP 를 통해 AWS 서비스에 \n액세스하기 위한 것입니다. \n \n네트워크 ACL 을 통한 아웃바운드 연결 구성은 DynamoDB 에 대한 안전하고 직접적인 \n연결을 제공하지 않기 때문에 C 는 올바르지 않습니다. \n \n코드에 액세스 키를 포함하는 것은 권장되는 보안 방법이 아니기 때문에 E 는 올바르지 \n않습니다. 잠재적인 보안 취약성이 발생할 수 있습니다. AWS 서비스에 대한 액세스를 \n제공하기 위해 IAM 역할 또는 기타 보안 메커니즘을 사용하는 것이 좋습니다. \n \n참고 \nhttps://docs.aws.amazon.com/ko_kr/amazondynamodb/latest/developerguide/vpc-endpo\nints-dynamodb.html \nhttps://aws.amazon.com/ko/about-aws/whats-new/2019/09/amazon-eks-adds-support\n-to-assign-iam-permissions-to-kubernetes-service-accounts/", "answer_choice": "A"}, "224": {"q_num": 224, "question": "한 회사가 최근 단일 AWS 리전의 Amazon EC2 인스턴스에서 애플리케이션을 다시 \n호스팅하여 웹 애플리케이션을 AWS 로 마이그레이션했습니다. 이 회사는 응용 프로그램 \n아키텍처를 고가용성 및 내결함성을 갖도록 재설계하려고 합니다. 트래픽은 실행 중인 모든 \nEC2 인스턴스에 무작위로 도달해야 합니다. \n회사는 이러한 요구 사항을 충족하기 위해 어떤 조합의 단계를 수행해야 합니까? (2 개 \n선택) \nA. Amazon Route 53 장애 조치 라우팅 정책을 만듭니다. \nB. Amazon Route 53 가중 라우팅 정책을 생성합니다. \nC. Amazon Route 53 다중값 응답 라우팅 정책을 생성합니다. \nD. 3 개의 EC2 인스턴스를 시작합니다. 하나의 가용 영역에 있는 2 개의 인스턴스와 다른 \n가용 영역에 있는 하나의 인스턴스입니다. \nE. 4 개의 EC2 인스턴스를 시작합니다. 하나의 가용 영역에 2 개의 인스턴스와 다른 가용 \n영역에 2 개의 인스턴스가 있습니다.", "answer_block": "Answer: C, E \nhttps://www.examtopics.com/discussions/amazon/view/95311-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n\n설명: \nC. Route 53 의 다중 응답 라우팅 정책을 사용하면 DNS 레코드에 대한 다중 값을 구성할 \n수 있으며 Route 53 은 다중 임의 값으로 DNS 쿼리에 응답합니다. 이를 통해 사용 가능한 \nEC2 인스턴스 간에 트래픽을 무작위로 분산할 수 있습니다. \nE. 다른 AZ 에서 EC2 인스턴스를 시작하면 고가용성과 내결함성을 얻을 수 있습니다. \n4 개의 인스턴스(각 AZ 에 2 개)를 시작하면 트래픽 로드를 처리하고 원하는 수준의 \n가용성을 유지하기에 충분한 리소스가 있습니다. \n \nA. 장애 조치 라우팅은 기본 리소스 또는 위치를 사용할 수 없는 경우에만 트래픽을 백업 \n리소스 또는 보조 위치로 보내도록 설계되었습니다. \nB. 가중 라우팅 정책을 사용하면 여러 EC2 인스턴스에 트래픽을 분산할 수 있지만 무작위 \n분산이 보장되지는 않습니다. \nD. 여러 AZ\n에서 인스턴스를 시작하는 것은 내결함성을 위해 중요하지만 세 개의 \n인스턴스만 있으면 트래픽이 고르게 분산되지 않습니다. 인스턴스가 3 개뿐이면 트래픽이 \n고르게 분산되지 않아 리소스 활용이 불균형해질 수 있습니다. \n \n참고 \nhttps://aws.amazon.com/premiumsupport/knowledge-center/multivalue-versus-simple-p\nolicies/", "answer_choice": "C"}, "225": {"q_num": 225, "question": "미디어 회사는 온프레미스에서 사용자 활동 데이터를 수집하고 분석합니다. 회사는 이 \n기능을 AWS\n로 마이그레이션하려고 합니다. 사용자 활동 데이터 저장소는 계속해서 \n성장하여 크기가 페타바이트가 될 것입니다. 회사는 SQL 을 사용하여 기존 데이터 및 새 \n데이터의 온디맨드 분석을 용이하게 하는 고가용성 데이터 수집 솔루션을 구축해야 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 활동 데이터를 Amazon Kinesis 데이터 스트림으로 보냅니다. 데이터를 Amazon S3 \n버킷으로 전달하도록 스트림을 구성합니다. \nB. 활동 데이터를 Amazon Kinesis Data Firehose 전송 스트림으로 보냅니다. 데이터를 \nAmazon Redshift 클러스터로 전달하도록 스트림을 구성합니다. \nC. 활동 데이터를 Amazon S3 버킷에 배치합니다. 데이터가 S3 버킷에 도착하면 \n데이터에서 AWS Lambda 함수를 실행하도록 Amazon S3 를 구성합니다. \nD. 여러 가용 영역에 분산된 Amazon EC2 인스턴스에서 수집 서비스를 생성합니다. \n데이터를 Amazon RDS 다중 AZ 데이터베이스로 전달하도록 서비스를 구성합니다.", "answer_block": "Answer: B \n\nhttps://www.examtopics.com/discussions/amazon/view/94985-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nAmazon Redshift 는 클라우드에서 완벽하게 관리되는 페타바이트 규모의 데이터 웨어하우스 \n서비스입니다. 수백 기가바이트의 데이터로 시작하여 페타바이트 이상으로 확장할 수 \n있습니다. 이를 통해 데이터를 사용하여 비즈니스와 고객에 대한 새로운 통찰력을 얻을 수 \n있습니다. 데이터 웨어하우스를 생성하는 첫 번째 단계는 Amazon Redshift 클러스터라는 \n노드 집합을 시작하는 것입니다. 클러스터를 프로비저닝한 후 데이터 세트를 업로드한 다음 \n데이터 분석 쿼리를 수행할 수 있습니다. 데이터 세트의 크기에 관계없이 Amazon \nRedshift\n는 오늘날 사용하는 것과 동일한 SQL 기반 도구 및 비즈니스 인텔리전스 \n애플리케이션을 사용하여 빠른 쿼리 성능을 제공합니다. \n \n설명2: \nB 는 데이터 수집 및 분석을 위한 완전히 관리되고 확장 가능한 솔루션을 제공합니다. \nKDF 는 대량의 스트리밍 데이터를 처리하도록 자동으로 확장하여 데이터 수집 프로세스를 \n간소화합니다. 강력하고 완전히 관리되는 데이터 웨어하우징 솔루션인 Redshift 클러스터에 \n데이터를 직접 로드할 수 있습니다. \n \nA. Kinesis 는 스트리밍 데이터를 처리할 수 있지만 분석 솔루션에 데이터를 로드하려면 \n추가 처리가 필요합니다. \nC. S3 및 Lambda 가 데이터 저장 및 처리를 처리할 수 있지만 KDF 및 Redshift 가 \n제공하는 완전관리형 솔루션에 비해 수동 구성 및 관리가 더 많이 필요합니다. \nD. 이 옵션은 EC2 인스턴스 및 RDS 데이터베이스 인프라를 수동으로 관리하고 확장해야 \n하므로 더 많은 운영 오버헤드가 필요합니다. \n \n따라서 Redshift 클러스터에 데이터를 제공하는 KDF\n가 포함된 옵션 B\n는 주어진 \n시나리오에서 사용자 활동 데이터를 수집하고 분석하기 위한 가장 간소화되고 운영상 \n효율적인 솔루션을 제공합니다.", "answer_choice": "B"}, "226": {"q_num": 226, "question": "회사는 Amazon EC2 인스턴스에서 실행되는 RESTful 웹 서비스 애플리케이션을 사용하여 \n수천 개의 원격 장치에서 데이터를 수집합니다. EC2 인스턴스는 원시 데이터를 수신하고 \n원시 데이터를 변환하며 모든 데이터를 Amazon S3 버킷에 저장합니다. 원격 장치의 수는 \n곧 수백만 개로 증가할 것입니다. 이 회사는 운영 오버헤드를 최소화하는 확장성이 뛰어난 \n\n솔루션이 필요합니다. \n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 단계 조합을 수행해야 합니까? \n(2 개 선택) \nA. AWS Glue 를 사용하여 Amazon S3 에서 원시 데이터를 처리합니다. \nB. Amazon Route 53 을 사용하여 트래픽을 다른 EC2 인스턴스로 라우팅합니다. \nC. 들어오는 데이터의 양을 수용하기 위해 더 많은 EC2 인스턴스를 추가합니다. \nD. 원시 데이터를 Amazon Simple Queue Service(Amazon SQS)로 보냅니다. EC2 \n인스턴스를 사용하여 데이터를 처리합니다. \nE. Amazon API Gateway 를 사용하여 원시 데이터를 Amazon Kinesis 데이터 스트림으로 \n보냅니다. 데이터 스트림을 소스로 사용하여 데이터를 Amazon S3 에 전달하도록 Amazon \nKinesis Data Firehose 를 구성합니다.", "answer_block": "Answer: A, E \nhttps://www.examtopics.com/discussions/amazon/view/95312-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \n\"RESTful 웹 서비스\" => API 게이트웨이. \n\"EC2 인스턴스는 원시 데이터를 수신하고, 원시 데이터를 변환하고, 모든 데이터를 \nAmazon S3 버킷에 저장합니다.\" \n=> (Extract - Transform - Load)가 있는 GLUE \n \n설명2: \nA. 데이터의 스키마를 자동으로 발견하고 ETL 코드를 생성하여 변환합니다. \nE. API Gateway 는 RESTful 웹 서비스를 통해 원격 장치에서 원시 데이터를 수신하는 데 \n사용할 수 있습니다. 들어오는 요청을 처리하기 위해 확장 가능하고 관리되는 인프라를 \n제공합니다. 그런 다음 데이터를 확장성과 내구성이 뛰어난 실시간 데이터 스트리밍 \n서비스인 Amazon Kinesis 데이터 스트림으로 보낼 수 있습니다. 여기에서 데이터 스트림을 \n소스로 사용하고 변환된 데이터를 Amazon S3\n에 전달하도록 Amazon Kinesis Data \nFirehose 를 구성할 수 있습니다. 이러한 서비스 조합을 통해 운영 오버헤드를 최소화하면서 \n원활한 데이터 수집 및 처리가 가능합니다. \n \nB. 확장 가능한 데이터 처리 및 저장의 필요성을 직접적으로 다루지는 않습니다. DNS 관리 \n및 트래픽을 다른 끝점으로 라우팅하는 데 중점을 둡니다. \nC. 더 많은 EC2 를 추가하면 인스턴스 관리 및 확장 측면에서 운영 오버헤드가 증가할 수 \n있습니다. \nD. 데이터 처리에 SQS 및 EC2 를 사용하면 더 복잡해지고 운영 오버헤드가 발생합니다.", "answer_choice": "A"}, "227": {"q_num": 227, "question": "회사는 AWS CloudTrail 로그를 3 년 동안 보관해야 합니다. 회사는 상위 계정의 AWS \nOrganizations 를 사용하여 AWS 계정 집합에 CloudTrail 을 적용하고 있습니다. CloudTrail \n대상 S3 버킷은 S3 버전 관리가 활성화된 상태로 구성됩니다. 3 년 후 현재 객체를 \n삭제하는 S3 수명 주기 정책이 있습니다. \nS3 버킷 사용 4 년차 이후 S3 버킷 지표는 개체 수가 계속 증가했음을 보여줍니다. 그러나 \nS3 버킷에 전달되는 새 CloudTrail 로그의 수는 일관되게 유지되었습니다. \n가장 비용 효율적인 방식으로 3 년 이상 된 개체를 삭제하는 솔루션은 무엇입니까? \nA. 3 년 후에 개체가 만료되도록 조직의 중앙 집중식 CloudTrail 추적을 구성합니다. \nB. 현재 버전뿐만 아니라 이전 버전도 삭제하도록 S3 수명 주기 정책을 구성합니다. \nC. Amazon S3 에서 3 년 이상 된 객체를 열거하고 삭제하는 AWS Lambda 함수를 \n생성합니다. \nD. 상위 계정을 S3 버킷으로 전달되는 모든 객체의 소유자로 구성합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/95314-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n이전 버전과 현재 버전을 삭제하도록 S3 수명 주기 정책을 구성하면 이전 버전의 \nCloudTrail 로그가 삭제됩니다. 이렇게 하면 3 년 이상 된 객체가 S3 버킷에서 제거되어 \n객체 수를 줄이고 스토리지 비용을 제어할 수 있습니다. \n \nA. 이 옵션은 S3 의 개체 관리와 직접적인 관련이 없습니다. S3 버킷에서 객체를 삭제해야 \n하는 필요성을 해결하지 못할 수 있는 CloudTrail 추적 만료 구성에 중점을 둡니다. \nC. Lambda 를 생성하여 3 년 이상 된 객체를 삭제하는 것은 기술적으로 가능하지만 이 접근 \n방식은 복잡성과 운영 오버헤드를 추가로 도입합니다. \nD. S3 버킷에 있는 객체의 소유권을 변경해도 3 년 이상 된 객체를 삭제해야 하는 필요성이 \n직접적으로 해결되지는 않습니다. 소유권은 개체의 삭제 동작에 영향을 주지 않습니다. \n \n참고: \nhttps://docs.aws.amazon.com/ko_kr/awscloudtrail/latest/userguide/best-practices-securi\nty.html", "answer_choice": "B"}, "228": {"q_num": 228, "question": "회사에는 여러 모니터링 장치에서 실시간 데이터를 수신하는 API 가 있습니다. API 는 나중에 \n분석할 수 있도록 이 데이터를 Amazon RDS DB 인스턴스에 저장합니다. 모니터링 장치가 \nAPI 로 보내는 데이터의 양은 변동합니다. 트래픽이 많은 기간 동안 API 는 종종 시간 초과 \n오류를 반환합니다. \n로그를 검사한 후 회사는 데이터베이스가 API 에서 오는 쓰기 트래픽 볼륨을 처리할 수 \n없음을 확인합니다. 솔루션 설계자는 데이터베이스에 대한 연결 수를 최소화하고 트래픽이 \n많은 기간 동안 데이터가 손실되지 않도록 해야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 사용 가능한 메모리가 더 많은 인스턴스 유형으로 DB 인스턴스의 크기를 늘리십시오. \nB. DB 인스턴스를 다중 AZ DB 인스턴스로 수정합니다. 모든 활성 RDS DB 인스턴스에 \n쓰도록 애플리케이션을 구성합니다. \nC. 수신 데이터를 Amazon Simple Queue Service(Amazon SQS) 대기열에 쓰도록 API 를 \n수정합니다. Amazon SQS\n가 호출하는 AWS Lambda 함수를 사용하여 대기열에서 \n데이터베이스로 데이터를 씁니다. \nD. 수신 데이터를 Amazon Simple Notification Service(Amazon SNS) 주제에 쓰도록 API 를 \n수정합니다. Amazon SNS\n가 호출하는 AWS Lambda 함수를 사용하여 주제에서 \n데이터베이스로 데이터를 씁니다.", "answer_block": "Answer: C  \nhttps://www.examtopics.com/discussions/amazon/view/95318-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nAmazon SQS 를 사용하면 API 가 데이터를 데이터베이스에 직접 쓰지 않고 대기열에 쓰기 \n때문에 데이터베이스에 대한 연결 수를 최소화하는 데 도움이 됩니다. 또한 대기열에서 \n데이터베이스로 데이터를 쓰기 위해 Amazon SQS 가 호출하는 AWS Lambda 함수를 \n사용하면 대기열이 API 와 데이터베이스 사이에서 버퍼 역할을 하므로 트래픽이 많은 기간 \n동안 데이터가 손실되지 않도록 하는 데 도움이 됩니다. \n \n설명2: \nSQS 를 버퍼로 활용하고 Lambda 를 사용하여 큐에서 데이터베이스로 데이터를 처리하고 \n기록함으로써 이 솔루션은 데이터베이스에 대한 연결 수를 최소화하면서 확장성, 분리 및 \n안정성을 제공합니다. 이 접근 방식은 트래픽 변동을 처리하고 트래픽이 많은 기간 동안 \n데이터 무결성을 보장합니다. \n\n \nA. DB 인스턴스의 크기를 늘리면 더 많은 메모리를 제공할 수 있지만 높은 쓰기 트래픽을 \n효율적으로 처리하고 데이터베이스에 대한 연결을 최소화하는 문제는 해결되지 않습니다. \nB. DB 인스턴스를 다중 AZ 인스턴스로 수정하고 모든 활성 인스턴스에 쓰면 가용성이 \n향상될 수 있지만 높은 쓰기 트래픽을 효율적으로 처리하고 데이터베이스에 대한 연결을 \n최소화하는 문제는 해결되지 않습니다. \nD. SNS 와 Lambda 를 사용하면 디커플링과 확장성을 제공할 수 있지만 많은 쓰기 트래픽을 \n효율적으로 처리하고 데이터베이스에 대한 연결을 최소화하는 데 적합하지 않습니다.", "answer_choice": "C"}, "229": {"q_num": 229, "question": "회사는 MySQL 데이터베이스를 실행하는 자체 Amazon EC2 인스턴스를 관리합니다. 회사는 \n수요가 증가하거나 감소함에 따라 복제 및 확장을 수동으로 관리하고 있습니다. 회사는 \n필요에 따라 데이터베이스 계층에서 컴퓨팅 용량을 추가하거나 제거하는 프로세스를 \n간소화하는 새로운 솔루션이 필요합니다. 또한 솔루션은 최소한의 운영 노력으로 향상된 \n성능, 확장성 및 내구성을 제공해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 데이터베이스를 Aurora MySQL 용 Amazon Aurora Serverless 로 마이그레이션합니다. \nB. 데이터베이스를 Aurora PostgreSQL용 Amazon Aurora Serverless로 마이그레이션합니다. \nC. 데이터베이스를 하나의 더 큰 MySQL 데이터베이스로 결합합니다. 더 큰 EC2 \n인스턴스에서 더 큰 데이터베이스를 실행합니다. \nD. 데이터베이스 계층에 대한 EC2 Auto Scaling 그룹을 생성합니다. 기존 데이터베이스를 \n새 환경으로 마이그레이션합니다.", "answer_block": "Answer: A  \nhttps://www.examtopics.com/discussions/amazon/view/95319-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n데이터베이스를 Aurora Serverless\n로 마이그레이션하면 자동 조정 및 복제 기능이 \n제공됩니다. Aurora Serverless 는 워크로드에 따라 자동으로 용량을 조정하므로 필요에 따라 \n컴퓨팅 용량을 원활하게 추가하거나 제거할 수 있습니다. 또한 복제 및 확장을 수동으로 \n관리할 필요 없이 향상된 성능, 내구성 및 고가용성을 제공합니다. \n \nB. 호환성 문제가 발생할 수 있고 중요한 코드 수정이 필요할 수 있는 다른 데이터베이스 \n엔진으로의 마이그레이션을 제안하기 때문에 올바르지 않습니다. \nC. 더 큰 EC2 인스턴스에서 더 큰 MySQL 데이터베이스로 통합하면 원하는 확장성과 \n\n자동화가 제공되지 않기 때문에 올바르지 않습니다. \nD. 데이터베이스 계층에 대해 EC2 Auto Scaling 그룹을 사용하려면 여전히 복제 및 조정을 \n수동으로 관리해야 하기 때문에 올바르지 않습니다. \n \n참고: \nhttps://aws.amazon.com/rds/aurora/serverless/", "answer_choice": "A"}, "230": {"q_num": 230, "question": "회사는 사용 중인 두 개의 NAT 인스턴스가 더 이상 회사 애플리케이션에 필요한 트래픽을 \n지원할 수 없을 것이라고 우려합니다. 솔루션 설계자는 가용성이 높고 내결함성이 있으며 \n자동으로 확장 가능한 솔루션을 구현하려고 합니다. \n솔루션 설계자는 무엇을 추천해야 합니까? \nA. 2 개의 NAT 인스턴스를 제거하고 동일한 가용 영역에 있는 2 개의 NAT 게이트웨이로 \n교체합니다. \nB. 다른 가용 영역의 NAT 인스턴스에 대해 Network Load Balancer 와 함께 Auto Scaling \n그룹을 사용합니다. \nC. 2 개의 NAT 인스턴스를 제거하고 서로 다른 가용 영역에 있는 2 개의 NAT 게이트웨이로 \n교체합니다. \nD. 두 개의 NAT 인스턴스를 서로 다른 가용 영역의 스팟 인스턴스로 교체하고 Network \nLoad Balancer 를 배포합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/95322-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \n여러 가용 영역에 리소스가 있고 하나의 NAT 게이트웨이를 공유하는 경우 NAT \n게이트웨이의 가용 영역이 다운되면 다른 가용 영역의 리소스가 인터넷에 액세스할 수 없게 \n됩니다. 가용 영역 독립적 아키텍처를 생성하려면 각 가용 영역에 NAT 게이트웨이를 \n생성하고 리소스가 동일한 가용 영역에서 NAT 게이트웨이를 사용하도록 라우팅을 \n구성합니다. \nhttps://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-gateway.html#nat-gateway\n-basics \n \n설명2: \n이 권장 사항은 NAT 게이트웨이를 여러 AZ 에 분산하여 고가용성과 내결함성을 보장합니다. \n\nNAT 게이트웨이는 확장 가능하고 가용성이 높은 아웃바운드 NAT 기능을 제공하는 관리형 \nAWS 서비스입니다. 서로 다른 AZ 에 NAT 게이트웨이를 배포함으로써 회사는 중복성을 \n확보하고 단일 장애 지점을 방지할 수 있습니다. 또한 이 솔루션은 수동 개입 없이 \n증가하는 트래픽을 처리할 수 있는 자동 크기 조정을 제공합니다. \n \n두 NAT 게이트웨이를 동일한 가용 영역에 배치하면 내결함성이 제공되지 않으므로 옵션 \nA 는 올바르지 않습니다. \n옵션 B 는 Network Load Balancer 와 함께 Auto Scaling 그룹을 사용하는 것이 NAT \n인스턴스에 권장되는 접근 방식이 아니기 때문에 올바르지 않습니다. \n옵션 D 는 스팟 인스턴스가 NAT 인스턴스와 같은 중요한 인프라 구성 요소에 적합하지 \n않기 때문에 올바르지 않습니다.", "answer_choice": "C"}, "231": {"q_num": 231, "question": "애플리케이션은 VPC A 에 탄력적 IP 주소가 있는 Amazon EC2 인스턴스에서 실행됩니다. \n애플리케이션은 VPC B 의 데이터베이스에 액세스해야 합니다. 두 VPC 모두 동일한 AWS \n계정에 있습니다. \n필요한 액세스를 가장 안전하게 제공하는 솔루션은 무엇입니까? \nA. VPC A 에 있는 애플리케이션 서버의 퍼블릭 IP 주소에서 오는 모든 트래픽을 허용하는 \nDB 인스턴스 보안 그룹을 생성합니다. \nB. VPC A 와 VPC B 사이에 VPC 피어링 연결을 구성합니다. \nC. DB 인스턴스를 공개적으로 액세스할 수 있도록 합니다. 퍼블릭 IP 주소를 DB \n인스턴스에 할당합니다. \nD. 탄력적 IP 주소가 있는 EC2 인스턴스를 VPC B 로 시작합니다. 새 EC2 인스턴스를 통해 \n모든 요청을 프록시합니다.", "answer_block": "Answer: B  \nhttps://www.examtopics.com/discussions/amazon/view/95323-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nVPC 피어링 연결은 사용자가 프라이빗 IP 주소를 사용하여 트래픽을 라우팅할 수 있도록 \n하는 두 VPC 간의 네트워킹 연결입니다. 각 VPC 의 인스턴스는 마치 동일한 네트워크 내에 \n있는 것처럼 서로 통신할 수 있습니다. VPC 피어링 연결은 같거나 다른 AWS 계정과 \nRegions1 의 VPC 간에 생성할 수 있습니다. 솔루션은 VPC A 와 VPC B 간에 VPC 피어링 \n연결을 구성하여 필요한 액세스를 가장 안전하게 제공할 수 있습니다. \n1. VPC A 에 있는 애플리케이션 서버의 퍼블릭 IP 주소에서 오는 모든 트래픽을 허용하는 \n\nDB 인스턴스 보안 그룹을 생성합니다. 이 솔루션은 DB 인스턴스를 퍼블릭 인터넷에 \n노출하고 액세스 제어를 위한 단일 IP 주소. \n2. DB 인스턴스를 공개적으로 액세스할 수 있도록 합니다. 퍼블릭 IP 주소를 DB \n인스턴스에 할당합니다. 이 솔루션은 DB 인스턴스를 퍼블릭 인터넷에 노출하고 모든 \n소스에 연결할 수 있도록 허용하므로 필요한 액세스를 가장 안전하게 제공하지 않습니다. \n3. 탄력적 IP 주소가 있는 EC2 인스턴스를 VPC B 로 시작합니다. 새 EC2 인스턴스를 통해 \n모든 요청을 프록시합니다. 이 솔루션은 대기 시간과 복잡성을 유발할 수 있는 추가 리소스 \n생성 및 프록시 서버 구성과 관련되므로 필요한 액세스를 가장 안전하게 제공하지 \n않습니다. \n참조 URL: https://docs.aws.amazon.com/vpc/latest/peering/what-is-vpc-peering.html \n \n설명2: \nVPC A 와 VPC B 간에 VPC 피어링 연결을 구성하면 VPC A 의 EC2 인스턴스와 VPC B 의 \n데이터베이스 간에 비공개 보안 통신을 설정할 수 있습니다. 공용 IP 주소가 필요하거나 \n데이터베이스를 인터넷에 노출해야 합니다. \n \n옵션 A 는 덜 안전할 수 있는 응용 프로그램 서버의 공용 IP 주소에서 오는 모든 트래픽을 \n허용해야 하므로 최상의 솔루션이 아닙니다. \n옵션 C 는 DB 인스턴스를 공개적으로 액세스 가능하게 만드는 것과 관련이 있으며, 이는 \n데이터베이스를 인터넷에 직접 노출함으로써 보안 위험을 초래합니다. \n옵션 D 는 VPC B 에서 추가 EC2 인스턴스를 시작하고 이를 통해 모든 요청을 프록시하여 \n불필요한 복잡성을 추가합니다. 이는 이 시나리오에서 가장 효율적이고 안전한 접근 방식이 \n아닙니다.", "answer_choice": "B"}, "232": {"q_num": 232, "question": "회사는 Amazon EC2 인스턴스에서 고객을 위한 데모 환경을 실행합니다. 각 환경은 자체 \nVPC 에서 격리됩니다. 환경에 대한 RDP 또는 SSH 액세스가 설정되면 회사의 운영 팀에 \n알려야 합니다. \nA. RDP 또는 SSH 액세스가 감지되면 AWS Systems Manager OpsItems 를 생성하도록 \nAmazon CloudWatch Application Insights 를 구성합니다. \nB. AmazonSSMManagedInstanceCore 정책이 연결된 IAM 역할이 있는 IAM 인스턴스 \n프로필로 EC2 인스턴스를 구성합니다. \nC. Amazon CloudWatch Logs 에 VPC 흐름 로그를 게시합니다. 필요한 메트릭 필터를 \n만듭니다. 경보가 ALARM 상태일 때 알림 작업이 포함된 Amazon CloudWatch 지표 경보를 \n생성합니다. \n\nD. EC2 인스턴스 상태 변경 알림 유형의 이벤트를 수신하도록 Amazon EventBridge 규칙을 \n구성합니다. Amazon Simple Notification Service(Amazon SNS) 주제를 대상으로 구성합니다. \n주제에 대한 운영 팀을 구독하십시오.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/95324-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nCloudWatch Logs 에 VPC 흐름 로그를 게시하고 RDP 또는 SSH 액세스를 감지하는 지표 \n필터를 생성함으로써 운영 팀은 경보가 트리거될 때 이를 알리도록 CloudWatch 지표 \n경보를 구성할 수 있습니다. 이렇게 하면 환경에 대한 RDP 또는 SSH 액세스가 설정될 때 \n원하는 알림이 제공됩니다. \n \nCloudWatch Application Insights 는 RDP 또는 SSH 액세스를 감지하도록 설계되지 않았기 \n때문에 옵션 A 는 올바르지 않습니다. \n \n옵션 B 도 올바르지 않습니다. AmazonSSMManagedInstanceCore 정책으로 IAM 인스턴스 \n프로필을 구성하면 RDP 또는 SSH 액세스가 발생할 때 운영 팀에 알려야 하는 요구 \n사항이 직접 해결되지 않기 때문입니다. \n \nEC2 인스턴스 상태 변경 알림 이벤트를 수신하도록 EventBridge 규칙을 구성하고 SNS \n주제를 대상으로 사용하면 운영 팀에 인스턴스 시작 또는 중지와 같은 인스턴스 상태 변경 \n사항을 알릴 수 있으므로 옵션 D 는 잘못된 것입니다. 그러나 질문에 명시된 요구 사항인 \nRDP 또는 SSH 액세스가 설정된 시기를 구체적으로 감지하거나 알리지는 않습니다. \n \n참고: \nhttps://aws.amazon.com/blogs/security/how-to-monitor-and-visualize-failed-ssh-acce\nss-attemptsto-amazon-ec2-linux-instances/", "answer_choice": "C"}, "233": {"q_num": 233, "question": "솔루션 설계자가 새 AWS 계정을 생성했으며 AWS 계정 루트 사용자 액세스를 보호해야 \n합니다. \n어떤 작업 조합이 이를 달성합니까? (2 개 선택) \nA. 루트 사용자가 강력한 암호를 사용하는지 확인하십시오. \nB. 루트 사용자에 대한 다단계 인증을 활성화합니다. \n\nC. 암호화된 Amazon S3 버킷에 루트 사용자 액세스 키를 저장합니다. \nD. 관리 권한이 포함된 그룹에 루트 사용자를 추가합니다. \nE. 인라인 정책 문서를 사용하여 루트 사용자에게 필요한 권한을 적용합니다.", "answer_block": "Answer: A, B  \nhttps://www.examtopics.com/discussions/amazon/view/95084-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nA. 루트 사용자에 대해 강력한 암호를 설정하는 것은 무단 액세스를 방지하기 위한 필수 \n보안 조치입니다. \nB. MFA 를 활성화하면 암호 외에 모바일 앱의 코드 또는 하드웨어 토큰과 같은 추가 인증 \n요소를 요구하여 추가 보안 계층을 추가합니다. \nC. 루트 사용자 액세스 키는 가능하면 피해야 하며 대신 권한이 제한된 IAM 사용자를 \n사용하는 것이 가장 좋습니다. \nD. 루트 사용자는 이미 계정의 모든 리소스 및 서비스에 대한 무제한 액세스 권한을 \n가지고 있으므로 추가 관리 권한을 부여하면 무단 작업의 위험이 높아질 수 있습니다. \nE. 대신 적절한 권한을 가진 IAM 사용자를 생성하고 해당 사용자를 일상적인 작업에 \n사용하는 동시에 루트 사용자를 보호하고 필요한 관리 작업에만 사용하는 것이 좋습니다. \n \n설명2: \nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html \nhttps://docs.aws.amazon.com/accounts/latest/reference/best-practices-root-user.html \n* AWS 계정 루트 사용자에서 AWS Multi-Factor Authentication(MFA)을 활성화합니다. \n자세한 내용은 IAM 사용 설명서의 AWS 에서 멀티 팩터 인증(MFA) 사용을 참조하십시오. \n* AWS 계정 루트 사용자 암호 또는 액세스 키를 누구와도 공유하지 마십시오. \n* 강력한 암호를 사용하여 AWS Management Console 에 대한 액세스를 보호하십시오. AWS \n계정 루트 사용자 암호 관리에 대한 자세한 내용은 루트 사용자 암호 변경 단원을 \n참조하십시오.", "answer_choice": "A"}, "234": {"q_num": 234, "question": "회사에서 \n새로운 \n웹 \n기반 \n고객 \n관계 \n관리 \n애플리케이션을 \n구축하고 \n있습니다. \n애플리케이션은 Application Load Balancer(ALB) 뒤에 있는 Amazon Elastic Block \nStore(Amazon EBS) 볼륨이 지원하는 여러 Amazon EC2 인스턴스를 사용합니다. 이 \n애플리케이션은 Amazon Aurora 데이터베이스도 사용합니다. 애플리케이션의 모든 데이터는 \n유휴 및 전송 중에 암호화되어야 합니다. \n\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. ALB 에서 AWS Key Management Service(AWS KMS) 인증서를 사용하여 전송 중인 \n데이터를 암호화합니다. AWS Certificate Manager(ACM)를 사용하여 유휴 상태의 EBS 볼륨 \n및 Aurora 데이터베이스 스토리지를 암호화합니다. \nB. AWS 루트 계정을 사용하여 AWS Management Console 에 로그인합니다. 회사의 암호화 \n인증서를 업로드합니다. 루트 계정에 있는 동안 계정의 저장 및 전송 중인 모든 데이터에 \n대해 암호화를 켜는 옵션을 선택합니다. \nC. AWS Key Management Service(AWS KMS)를 사용하여 유휴 상태의 EBS 볼륨 및 Aurora \n데이터베이스 스토리지를 암호화합니다. ALB 에 AWS Certificate Manager(ACM) 인증서를 \n연결하여 전송 중인 데이터를 암호화합니다. \nD. BitLocker 를 사용하여 유휴 상태의 모든 데이터를 암호화합니다. 회사의 TLS 인증서 \n키를 AWS Key Management Service(AWS KMS)로 가져옵니다. KMS 키를 ALB 에 연결하여 \n전송 중인 데이터를 암호화합니다.", "answer_block": "Answer: C  \nhttps://www.examtopics.com/discussions/amazon/view/95325-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n이 옵션은 AWS Key Management Service(AWS KMS)를 사용하기 때문에 가장 효율적입니다. \n이 서비스는 암호화 키를 쉽게 생성 및 관리하고 다양한 AWS 서비스와 실행 중인 \n애플리케이션에서 키 사용을 제어할 수 있게 해줍니다. AWS 에서. 또한 AWS KMS 를 \n사용하여 EBS 볼륨과 유휴 Aurora 데이터베이스 스토리지를 암호화하여 관리하는 암호화 \n키로 데이터를 암호화하여 데이터 보호를 제공합니다. 또한 AWS 서비스 및 내부 연결 \n리소스와 함께 사용할 공용 및 개인 SSL/TLS(Secure Sockets Layer/Transport Layer \nSecurity) 인증서를 쉽게 프로비저닝, 관리 및 배포할 수 있는 서비스인 AWS Certificate \nManager(ACM)를 사용합니다. . 또한 ACM 인증서를 ALB 에 연결하여 전송 중인 데이터를 \n암호화합니다. 이는 클라이언트와 로드 밸런서 간의 연결에 SSL/TLS 암호화를 활성화하여 \n데이터 보호를 제공합니다. 이 솔루션은 미사용 및 전송 중인 애플리케이션의 모든 \n데이터를 암호화해야 한다는 요구 사항을 충족합니다. \n \n옵션 A 는 ALB 에서 AWS KMS 인증서를 사용하여 전송 중인 데이터를 암호화하기 때문에 \n효율성이 떨어집니다. 이는 AWS KMS 가 인증서를 제공하지 않고 키만 제공하기 때문에 \n불가능합니다. 또한 AWS Certificate Manager(ACM)를 사용하여 유휴 EBS 볼륨 및 Aurora \n데이터베이스 스토리지를 암호화합니다. 이는 ACM 이 암호화를 제공하지 않고 인증서만 \n제공하기 때문에 불가능합니다. \n \n\n옵션 B 는 AWS 루트 계정을 사용하여 AWS Management Console 에 로그인하기 때문에 \n효율성이 떨어집니다. 이 방법은 계정의 모든 리소스에 대한 무제한 액세스 권한이 \n있으므로 권장되지 않습니다. 또한 회사의 암호화 인증서를 업로드하는데 ACM 은 인증서를 \n무료로 제공할 수 있으므로 필요하지 않습니다. 또한 계정에 대해 저장 및 전송 중인 모든 \n데이터에 대해 암호화를 켜는 옵션을 선택합니다. 이는 암호화 설정이 각 서비스 및 \n리소스에 따라 다르기 때문에 불가능합니다. \n \n옵션 D 는 Windows 서버의 볼륨에 대한 암호화를 제공하는 Windows 기능인 BitLocker 를 \n사용하여 미사용 데이터를 모두 암호화하기 때문에 효율성이 떨어집니다. 그러나 이것은 \nAurora 가 Linux 서버에서 실행되기 때문에 미사용 Aurora 데이터베이스 스토리지에 대한 \n암호화를 제공하지 않습니다. 또한 회사의 TLS 인증서 키를 AWS KMS 로 가져오는데, 이는 \nACM 이 인증서를 무료로 제공할 수 있으므로 필요하지 않습니다. 또한 KMS 키를 ALB 에 \n연결하여 전송 중인 데이터를 암호화합니다. ALB 에는 키가 아닌 인증서가 필요하기 때문에 \n불가능합니다. \n \n설명2: \nAWS KMS 를 사용하여 유휴 상태의 EBS 및 Aurora 데이터베이스 스토리지를 암호화할 수 \n있습니다. \nACM\n을 사용하여 SSL/TLS 인증서를 가져와 ALB\n에 연결할 수 있습니다. 이는 \n클라이언트와 ALB 간에 전송 중인 데이터를 암호화합니다. \n \nA 는 EBS 를 암호화하기 위한 올바른 서비스가 아닌 EBS 를 암호화하기 위해 ACM 을 \n사용하도록 제안하기 때문에 올바르지 않습니다. \n \nB 는 정답이 아닙니다. AWS 루트 계정에 의존하고 AWS Management Console 에서 유휴 및 \n전송 중인 모든 데이터에 대한 암호화를 활성화하는 옵션을 선택하는 것은 유효한 접근 \n방식이 아니기 때문입니다. \n \nBitLocker는 AWS 서비스에서 데이터를 암호화하는 데 적합한 솔루션이 아니기 때문에 D는 \n틀렸습니다. 주로 Windows 기반 운영 체제에서 데이터를 암호화하는 데 사용됩니다. 또한 \nTLS 인증서 키를 AWS KMS\n로 가져와 ALB\n에 연결하는 것은 전송 중인 데이터를 \n암호화하는 데 권장되는 접근 방식이 아닙니다.", "answer_choice": "C"}, "235": {"q_num": 235, "question": "회사에서 온프레미스 Oracle 데이터베이스를 Amazon Aurora PostgreSQL 로 이전하고 \n\n있습니다. 데이터베이스에는 동일한 테이블에 쓰는 여러 응용 프로그램이 있습니다. 응용 \n프로그램은 각 마이그레이션 사이에 한 달씩 하나씩 마이그레이션해야 합니다. 경영진은 \n데이터베이스에 많은 수의 읽기 및 쓰기가 있다는 우려를 표명했습니다. 데이터는 \n마이그레이션하는 동안 두 데이터베이스에서 동기화 상태를 유지해야 합니다. \n솔루션 설계자는 무엇을 추천해야 합니까? \nA. 초기 마이그레이션에는 AWS DataSync 를 사용하십시오. AWS Database Migration \nService(AWS DMS)를 사용하여 변경 데이터 캡처(CDC) 복제 작업 및 테이블 매핑을 \n생성하여 모든 테이블을 선택합니다. \nB. 초기 마이그레이션에 AWS DataSync\n를 사용합니다. AWS Database Migration \nService(AWS DMS)를 사용하여 전체 로드 및 변경 데이터 캡처(CDC) 복제 작업과 테이블 \n매핑을 생성하여 모든 테이블을 선택합니다. \nC. 메모리 최적화 복제 인스턴스를 사용하여 AWS DMS(AWS Database Migration Service)와 \n함께 AWS Schema Conversion Tool 을 사용합니다. 전체 로드 및 CDC(변경 데이터 캡처) \n복제 작업과 테이블 매핑을 생성하여 모든 테이블을 선택합니다. \nD. 컴퓨팅 최적화 복제 인스턴스를 사용하여 AWS DMS(AWS Database Migration Service)와 \n함께 AWS Schema Conversion Tool 을 사용합니다. 전체 로드 및 변경 데이터 캡처(CDC) \n복제 작업과 테이블 매핑을 생성하여 가장 큰 테이블을 선택합니다.", "answer_block": "Answer: C  \nhttps://www.examtopics.com/discussions/amazon/view/95326-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nAWS SCT 는 Oracle 데이터베이스의 스키마와 코드를 Aurora PostgreSQL 과 호환되도록 \n변환하는 데 사용됩니다. AWS DMS 는 Oracle 데이터베이스에서 Aurora PostgreSQL 로 \n데이터를 마이그레이션하는 데 활용됩니다. 마이그레이션 프로세스 중에 많은 수의 읽기 및 \n쓰기를 처리하려면 메모리 최적화 복제 인스턴스를 사용하는 것이 좋습니다. \n전체 로드 및 CDC 복제 작업을 생성하면 초기 데이터 마이그레이션이 수행되고 Oracle \n데이터베이스의 진행 중인 변경 사항이 지속적으로 캡처되어 Aurora PostgreSQL \n데이터베이스에 적용됩니다. 테이블 매핑을 위해 모든 테이블을 선택하면 동일한 테이블에 \n쓰는 모든 응용 프로그램이 마이그레이션됩니다. \n \nAWS DataSync 를 단독으로 사용하는 것은 데이터베이스 마이그레이션 및 데이터 동기화에 \n충분하지 않기 때문에 옵션 A 및 B 는 올바르지 않습니다. \n \n계산에 최적화된 복제 인스턴스를 사용하는 것이 많은 수의 읽기 및 쓰기를 처리하는 데 \n가장 적합한 선택이 아니기 때문에 옵션 D 는 올바르지 않습니다. \n\n \n참고 \nhttps://repost.aws/ko/knowledge-center/dms-memory-optimization", "answer_choice": "C"}, "236": {"q_num": 236, "question": "회사에 이미지 공유를 위한 3 계층 애플리케이션이 있습니다. 이 애플리케이션은 프런트 \n엔드 계층에 Amazon EC2 인스턴스를 사용하고, 애플리케이션 계층에 또 다른 EC2 \n인스턴스를 사용하고, MySQL 데이터베이스에 세 번째 EC2 인스턴스를 사용합니다. 솔루션 \n설계자는 응용 프로그램에 최소한의 변경만 필요한 확장 가능하고 가용성이 높은 솔루션을 \n설계해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. Amazon S3 를 사용하여 프런트 엔드 계층을 호스팅하십시오. 애플리케이션 계층에 AWS \nLambda 함수를 사용합니다. 데이터베이스를 Amazon DynamoDB 테이블로 이동합니다. \nAmazon S3 를 사용하여 사용자 이미지를 저장하고 제공합니다. \nB. 프런트엔드 계층과 애플리케이션 계층에 로드 밸런싱된 다중 AZ AWS Elastic Beanstalk \n환경을 사용합니다. 데이터베이스를 여러 읽기 전용 복제본이 있는 Amazon RDS DB \n인스턴스로 이동하여 사용자 이미지를 제공합니다. \nC. Amazon S3 를 사용하여 프런트 엔드 계층을 호스팅합니다. 애플리케이션 계층에 대한 \nAuto Scaling 그룹의 EC2 인스턴스 플릿을 사용합니다. 데이터베이스를 메모리 최적화 \n인스턴스 유형으로 이동하여 사용자 이미지를 저장하고 제공합니다. \nD. 프런트엔드 계층과 애플리케이션 계층에 로드 밸런싱된 다중 AZ AWS Elastic Beanstalk \n환경을 사용합니다. 데이터베이스를 Amazon RDS 다중 AZ DB 인스턴스로 이동합니다. \nAmazon S3 를 사용하여 사용자 이미지를 저장하고 제공합니다.", "answer_block": "Answer: D  \nhttps://www.examtopics.com/discussions/amazon/view/94990-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \n로드 밸런싱된 다중 AZ AWS EBS 를 사용하면 애플리케이션을 크게 변경하지 않고도 두 \n계층 모두에 대한 확장성과 고가용성을 얻을 수 있습니다. DB 를 RDS 다중 AZ DB 로 \n이동하면 고가용성과 자동 장애 조치가 보장됩니다. S3 를 통해 사용자 이미지를 저장하고 \n제공하면 확장 가능하고 가용성이 높은 솔루션을 제공합니다. \n \n프런트 엔드 계층에 S3\n를 사용하고 애플리케이션 계층에 Lambda\n를 사용하려면 \n애플리케이션 아키텍처를 크게 변경해야 하므로 A 는 정답이 아닙니다. DB 를 DynamoDB 로 \n\n이동하려면 DB 관련 코드를 다시 작성해야 합니다. \n \n이미지를 제공하기 위해 로드 밸런싱된 다중 AZ AWS EBS 환경과 읽기 전용 복제본이 있는 \nRDS DB 를 사용하는 것이 더 적합한 솔루션이기 때문에 B 는 틀렸습니다. 읽기 전용 \n복제본이 있는 RDS 는 이러한 용도로 S3 를 사용하는 것보다 이미지 제공 워크로드를 더 \n효율적으로 처리할 수 있습니다. \n \n프런트 엔드 계층에 S3 를 사용하고 애플리케이션 계층에 EC2 의 ASG 를 사용하려면 \n애플리케이션 아키텍처를 수정해야 하므로 C 는 올바르지 않습니다. 메모리 최적화 EC2 \n유형의 이미지를 저장하고 제공하는 것은 S3 를 사용할 때보다 가장 효율적이고 확장 \n가능한 접근 방식이 아닐 수 있습니다. \n \n설명2: \nAWS Fargate\n는 Amazon EC2 인스턴스의 서버 또는 클러스터를 관리할 필요 없이 \n컨테이너를 실행하기 위해 Amazon ECS 와 함께 사용할 수 있는 기술입니다. Fargate 를 \n사용하면 더 이상 컨테이너를 실행하기 위해 가상 머신의 클러스터를 프로비저닝, 구성 \n또는 확장할 필요가 없습니다. \nhttps://docs.aws.amazon.com/AmazonECS/latest/userguide/what-is-fargate.html \n \n\"고가용성\"의 경우: 다중 AZ 및 \"애플리케이션에 대한 최소 변경 사항\"의 경우: Elastic \nBeanstalk 는 용량 프로비저닝, 로드 밸런싱, 자동 확장에서 애플리케이션 상태 모니터링에 \n이르기까지 배포를 자동으로 처리합니다.", "answer_choice": "D"}, "237": {"q_num": 237, "question": "VPC-A 의 Amazon EC2 인스턴스에서 실행 중인 애플리케이션은 VPC-B 의 다른 EC2 \n인스턴스에 있는 파일에 액세스해야 합니다. 두 VPC 모두 별도의 AWS 계정에 있습니다. \n네트워크 관리자는 VPC-A 에서 VPC-B 의 EC2 인스턴스에 대한 보안 액세스를 구성하는 \n솔루션을 설계해야 합니다. 연결에는 단일 장애 지점이나 대역폭 문제가 없어야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. VPC-A 와 VPC-B 간에 VPC 피어링 연결을 설정합니다. \nB. VPC-B 에서 실행되는 EC2 인스턴스에 대한 VPC 게이트웨이 엔드포인트를 설정합니다. \nC. 가상 프라이빗 게이트웨이를 VPC-B 에 연결하고 VPC-A 에서 라우팅을 설정합니다. \nD. VPC-B 에서 실행 중인 EC2 인스턴스에 대한 프라이빗 가상 인터페이스(VIF)를 생성하고 \nVPC-A 에서 적절한 경로를 추가합니다.", "answer_block": "Answer: A \n\nhttps://www.examtopics.com/discussions/amazon/view/95144-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nVPC 피어링 연결을 사용하면 인터넷 게이트웨이, VPN 연결 또는 NAT 장치 없이 프라이빗 \nIP 주소를 사용하여 서로 다른 VPC 의 인스턴스 간에 안전한 통신이 가능합니다. 이를 \n설정하면 VPC-A 에서 실행 중인 애플리케이션이 공용 인터넷이나 단일 장애 지점을 거치지 \n않고 VPC-B 의 EC2 에 직접 액세스할 수 있습니다. \n \nB 는 VPC 게이트웨이 엔드포인트가 인터넷을 통하지 않고 VPC 에서 S3 또는 DynamoDB 에 \n액세스하는 데 사용되기 때문에 올바르지 않습니다. 서로 다른 VPC 에 있는 EC2 인스턴스 \n간에 연결을 설정하도록 설계되지 않았습니다. \n \nC 는 VPC 간에 VPN 연결을 구성해야 하므로 올바르지 않습니다. 이로 인해 추가적인 \n복잡성과 잠재적인 단일 실패 지점이 발생합니다. \n \nD 는 프라이빗 VIF 를 생성하고 경로를 추가하면 Direct Connect 를 사용하여 온프레미스 \n인프라와 VPC-B 간에 직접 연결을 설정하는 데 적용할 수 있기 때문에 올바르지 않지만 \n서로 다른 VPC 내의 별도 VPC 에 있는 EC2 인스턴스 간의 통신 시나리오에는 적합하지 \n않습니다. AWS 계정. \n \n설명2: \nAWS 는 VPC 의 기존 인프라를 사용하여 VPC 피어링 연결을 생성합니다. 게이트웨이나 \nVPN 연결이 아니며 별도의 물리적 하드웨어에 의존하지 않습니다. 통신 또는 대역폭 병목 \n현상에 대한 단일 장애 지점이 없습니다. \nhttps://docs.aws.amazon.com/vpc/latest/peering/what-is-vpc-peering.html", "answer_choice": "A"}, "238": {"q_num": 238, "question": "회사에서 엔지니어 팀을 위해 개별 AWS 계정을 실험하려고 합니다. 회사는 지정된 달의 \nAmazon EC2 인스턴스 사용량이 각 계정의 특정 임계값을 초과하는 즉시 알림을 받기를 \n원합니다. \n이 요구 사항을 가장 비용 효율적으로 충족하기 위해 솔루션 설계자는 무엇을 해야 \n합니까? \nA. Cost Explorer 를 사용하여 서비스별 비용에 대한 일일 보고서를 생성합니다. EC2 \n인스턴스별로 \n보고서를 \n필터링합니다. \n임계값을 \n초과하면 \nAmazon \nSimple \nEmail \n\nService(Amazon SES) 알림을 보내도록 Cost Explorer 를 구성합니다. \nB. Cost Explorer 를 사용하여 서비스별 월별 비용 보고서를 생성합니다. EC2 인스턴스별로 \n보고서를 필터링합니다. 임계값을 초과하면 Amazon Simple Email Service(Amazon SES) \n알림을 보내도록 Cost Explorer 를 구성합니다. \nC. AWS 예산을 사용하여 각 계정에 대한 비용 예산을 생성합니다. 기간을 매월로 \n설정합니다. 범위를 EC2 인스턴스로 설정합니다. 예산에 대한 경고 임계값을 설정합니다. \n임계값 초과 시 알림을 받도록 Amazon Simple Notification Service(Amazon SNS) 주제를 \n구성합니다. \nD. AWS 비용 및 사용 보고서를 사용하여 시간 단위로 보고서를 생성합니다. 보고서 \n데이터를 Amazon Athena 와 통합합니다. Amazon EventBridge 를 사용하여 Athena 쿼리를 \n예약합니다. 임계값 초과 시 알림을 받도록 Amazon Simple Notification Service(Amazon \nSNS) 주제를 구성합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/94996-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \n각 계정에 대한 비용 예산을 생성하고 기간을 월 단위로 지정하고 범위를 EC2 로 지정하면 \nEC2 와 관련된 비용을 구체적으로 추적하고 모니터링할 수 있습니다. 예산에 경고 임계값을 \n설정하면 지정된 임계값이 초과될 때 알림이 트리거됩니다. 알림을 받도록 SNS\n를 \n구성합니다. 회사에서 구독하면 즉시 알림을 받을 수 있습니다. \n \nA 와 B 는 Cost Explorer 를 사용하여 임계값을 초과할 때 실시간 알림을 제공하지 않을 수 \n있는 보고서를 생성하기 때문에 가장 비용 효율적인 솔루션이 아닙니다. 또한 A.는 일일 \n보고서 사용을 제안하고 B.는 월별 보고서 사용을 제안합니다. 이는 즉각적인 알림에 대해 \n원하는 수준의 세분성을 제공하지 않을 수 있습니다. \n \nD 는 Athena 및 EventBridge 와 함께 비용 및 사용 보고서를 사용하는 것과 관련됩니다. 이 \n솔루션은 더 많은 유연성과 데이터 분석 기능을 제공하며 더 복잡하고 Athena 를 사용하고 \n시간별 보고서를 생성하는 데 추가 비용이 발생할 수 있습니다. \n \n설명2: \nAWS 예산을 사용하면 AWS 계정에 대한 예산을 생성하고 사용량이 특정 임계값을 초과할 \n때 알림을 설정할 수 있습니다. 각 계정에 대한 예산을 생성하고 기간을 월 단위로 \n지정하고 범위를 EC2 인스턴스로 지정하면 각 계정의 EC2 사용량을 효과적으로 추적하고 \n임계값을 초과할 때 알림을 받을 수 있습니다. 이 솔루션은 Amazon Athena 또는 Amazon \n\nEventBridge 와 같은 추가 리소스가 필요하지 않기 때문에 가장 비용 효율적인 옵션입니다.", "answer_choice": "C"}, "239": {"q_num": 239, "question": "솔루션 설계자는 회사의 애플리케이션을 위한 새로운 마이크로서비스를 설계해야 합니다. \n클라이언트는 마이크로 서비스에 도달하기 위해 HTTPS 끝점을 호출할 수 있어야 합니다. \n또한 마이크로서비스는 AWS Identity and Access Management(IAM)를 사용하여 호출을 \n인증해야 합니다. 솔루션 설계자는 Go 1.x 로 작성된 단일 AWS Lambda 함수를 사용하여 \n이 마이크로서비스에 대한 논리를 작성합니다. \n어떤 솔루션이 운영상 가장 효율적인 방식으로 기능을 배포합니까? \nA. Amazon API Gateway REST API 를 생성합니다. Lambda 함수를 사용하도록 메서드를 \n구성합니다. API 에서 IAM 인증을 활성화합니다. \nB. 함수에 대한 Lambda 함수 URL 을 생성합니다. 인증 유형으로 AWS_IAM 을 지정합니다. \nC. Amazon CloudFront 배포를 생성합니다. 함수를 Lambda@Edge 에 배포합니다. IAM 인증 \n로직을 Lambda@Edge 함수에 통합합니다. \nD. Amazon CloudFront 배포를 생성합니다. CloudFront Functions 에 함수를 배포합니다. \n인증 유형으로 AWS_IAM 을 지정합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/95365-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n \n설명: \nAPI Gateway REST API 를 생성하면 클라이언트가 마이크로서비스에 도달하기 위해 호출할 \n수 있는 HTTPS 엔드포인트를 정의할 수 있습니다. API 에서 IAM 인증을 활성화하여 API \n호출에 대한 인증을 적용합니다. 이렇게 하면 인증된 요청만 마이크로서비스에 도달할 수 \n있습니다. 이 솔루션은 API 게이트웨이의 기본 제공 기능을 활용하여 HTTP 엔드포인트, \n요청 라우팅 및 IAM 인증을 처리하므로 운영상 효율적입니다. 추가 인프라 구성 요소 없이 \n확장 가능하고 관리되는 솔루션을 제공합니다. \n \nB 는 Lambda URL 을 생성하고 인증 유형으로 AWS IAM 을 지정할 것을 제안합니다. 이것은 \nIAM 인증을 제공할 수 있지만 요청 유효성 검사, 속도 제한 및 API 구성의 손쉬운 관리와 \n같은 API Gateway 의 이점이 없습니다. \n \nC 와 D 에는 CloudFront, Lambda@Edge 및 CloudFront 함수 사용이 포함됩니다. 이러한 \n서비스는 유연성과 에지 위치에서 논리를 실행할 수 있는 기능을 제공하지만 추가적인 \n\n복잡성을 야기하며 지정된 요구 사항에 필요하지 않을 수 있습니다.", "answer_choice": "A"}, "240": {"q_num": 240, "question": "한 회사가 이전에 데이터 웨어하우스 솔루션을 AWS 로 마이그레이션했습니다. 회사에는 \nAWS Direct Connect 연결도 있습니다. 본사 사용자는 시각화 도구를 사용하여 데이터 \n웨어하우스를 쿼리합니다. 데이터 웨어하우스에서 반환한 쿼리의 평균 크기는 50MB 이고 \n시각화 도구에서 보낸 각 웹 페이지는 약 500KB 입니다. 데이터 웨어하우스에서 반환된 \n결과 집합은 캐시되지 않습니다. \n회사에 가장 낮은 데이터 전송 송신 비용을 제공하는 솔루션은 무엇입니까? \nA. 온프레미스에서 시각화 도구를 호스팅하고 인터넷을 통해 직접 데이터 웨어하우스를 \n쿼리합니다. \nB. 데이터 웨어하우스와 동일한 AWS 리전에서 시각화 도구를 호스팅합니다. 인터넷을 통해 \n액세스하십시오. \nC. 온프레미스에서 시각화 도구를 호스팅하고 동일한 AWS 리전의 위치에서 Direct \nConnect 연결을 통해 직접 데이터 웨어하우스를 쿼리합니다. \nD. 데이터 웨어하우스와 동일한 AWS 리전에서 시각화 도구를 호스팅하고 동일한 리전의 \n위치에서 Direct Connect 연결을 통해 액세스합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/94998-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n데이터 웨어하우스와 동일한 AWS 리전에서 시각화 도구를 호스팅하고 동일한 리전 내에서 \nDirect Connect 연결을 통해 액세스하면 데이터 전송 비용이 없어지고 지연 시간이 짧은 \n고대역폭 연결이 보장됩니다. \n \nA. 온프레미스에서 시각화 도구를 호스팅하고 인터넷을 통해 데이터 웨어하우스를 쿼리하면 \n모든 쿼리 결과에 대한 데이터 전송 비용과 잠재적 대기 시간 및 대역폭 제한이 \n발생합니다. \n \nB. 데이터 웨어하우스와 동일한 AWS 리전에서 시각화 도구를 호스팅하지만 인터넷을 통해 \n액세스하면 여전히 각 쿼리 결과에 대한 데이터 전송 비용이 발생합니다. \n \nC. 온프레미스에서 시각화 도구를 호스팅하고 동일한 AWS 리전 내에서 Direct Connect \n연결을 통해 데이터 웨어하우스를 쿼리하면 모든 쿼리 결과에 대한 데이터 전송 비용이 \n\n발생하고 온프레미스 인프라가 필요하여 복잡성이 추가됩니다. \n \n참고: \nhttps://aws.amazon.com/directconnect/pricing/ \nhttps://aws.amazon.com/blogs/aws/aws-data-transfer-prices-reduced/", "answer_choice": "D"}, "241": {"q_num": 241, "question": "온라인 학습 회사가 AWS 클라우드로 마이그레이션하고 있습니다. 회사는 PostgreSQL \n데이터베이스에 학생 기록을 유지합니다. 회사는 여러 AWS 리전에서 데이터를 항상 \n온라인으로 사용할 수 있는 솔루션이 필요합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. PostgreSQL 데이터베이스를 Amazon EC2 인스턴스의 PostgreSQL 클러스터로 \n마이그레이션합니다. \nB. PostgreSQL 데이터베이스를 다중 AZ 기능이 켜진 PostgreSQL DB 인스턴스용 Amazon \nRDS 로 마이그레이션합니다. \nC. \nPostgreSQL \n데이터베이스를 \nAmazon \nRDS \nfor \nPostgreSQL \nDB \n인스턴스로 \n마이그레이션합니다. 다른 리전에서 읽기 전용 복제본을 생성합니다. \nD. \nPostgreSQL \n데이터베이스를 \nAmazon \nRDS \nfor \nPostgreSQL \nDB \n인스턴스로 \n마이그레이션합니다. 다른 리전에 복사할 DB 스냅샷을 설정합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/95000-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nPostgreSQL 데이터베이스를 PostgreSQL DB 유지용 RDS 로 늘리고 다른 AWS 리전에 \n읽기 전용 복제본을 생성하면 여러 리전에서 데이터 가용성과 온라인 액세스를 충분히 할 \n수 있습니다. 이 솔루션은 EC2 폐쇄에서 PostgreSQL 클러스터를 관리하거나(옵션 A) \n스냅샷을 사용하여 수동 복제를 설정하는 것(옵션 D)에 비해 연산된 헤드가 적입니다. 또한 \nAmazon RDS 는 기본 복원 및 복제 설정을 처리하여 회사의 운영 문제를 줄입니다. \n \nB 는 단일 AWS 리전 내에서 고가용성을 누릴 수 있습니다. 그러나 질문에 여러 개의 AWS \n리전에서 항상 데이터를 온라인으로 사용할 수 있어야만 요구 사항을 충족할 수 없습니다. \nRDS 의 다중 AZ 기능은 동일한 리전 내에서 자동으로 조치를 취하지만 데이터를 여러 \n리전으로 복제하지 않습니다. \n \n\n설명2: \n\"항상 여러 AWS 리전에서 온라인으로\". 현재 읽기 전용 복제본만 지역 간 지원, 다중 AZ 는 \n지역 간 지원하지 않음(동일한 지역에서만 작동) \nhttps://aws.amazon.com/ko/about-aws/whats-new/2018/01/amazon-rds-read-replicas-\nnow-support-multi-az-deployments/", "answer_choice": "C"}, "242": {"q_num": 242, "question": "회사는 7\n개의 Amazon EC2 인스턴스를 사용하여 AWS\n에서 웹 애플리케이션을 \n호스팅합니다. 회사는 DNS 쿼리에 대한 응답으로 모든 정상적인 EC2 인스턴스의 IP \n주소가 반환되도록 요구합니다. \n이 요구 사항을 충족하려면 어떤 정책을 사용해야 합니까? \nA. 단순 라우팅 정책(Simple routing policy) \nB. 레이턴시 라우팅 정책(Latency routing policy) \nC. 다중값 라우팅 정책(Multivalue routing policy) \nD. 지리적 위치 라우팅 정책(Geolocation routing policy)", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/95001-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \n다중 응답 라우팅 정책을 사용하여 여러 리소스에 DNS 응답을 배포할 수 있습니다. \n예를 들어 라우팅 레코드를 Route 53 상태 확인과 연결하려는 경우 다중값 응답 라우팅을 \n사용합니다. 예를 들어 DNS 쿼리에 대해 여러 값을 반환하고 트래픽을 여러 IP 주소로 \n라우팅해야 하는 경우 다중 값 응답 라우팅을 사용합니다. \nhttps://aws.amazon.com/premiumsupport/knowledge-center/multivalue-versus-simple-p\nolicies/ \n \n설명2: \n다중값 라우팅 정책은 Route 53 이 동일한 리소스에 대한 여러 정상 IP 주소로 DNS 쿼리에 \n응답하도록 허용합니다. 이는 여러 인스턴스가 동일한 용도로 사용되며 부하 분산 또는 \n장애 조치가 가능한 시나리오에서 특히 유용합니다. 다중 값 라우팅 정책을 사용하면 \nRoute 53 은 여러 IP 주소를 무작위 순서로 반환하여 모든 정상 인스턴스에 트래픽을 \n분산합니다. \n \n옵션 A(단순 라우팅 정책)는 DNS 쿼리에 대한 응답으로 단일 IP 주소만 반환하며 여러 \n\n주소 반환을 지원하지 않습니다. \n \n옵션 B(대기 시간 라우팅 정책)는 리소스에 대한 최저 대기 시간을 기반으로 트래픽을 \n라우팅하는 데 사용되며 모든 정상 IP 주소를 반환해야 하는 요구 사항을 충족하지 \n않습니다. \n \n옵션 \nD(Geolocation \n라우팅 \n정책)는 \n사용자의 \n지리적 \n위치를 \n기반으로 \n트래픽을 \n라우팅하는 데 사용되며 정상 IP 주소를 모두 반환해야 하는 요구 사항을 충족하지 \n않습니다. \n \n따라서 다중 값 라우팅 정책은 DNS 쿼리에 대한 응답으로 모든 정상 EC2 인스턴스의 IP \n주소를 반환하는 데 가장 적합한 옵션입니다.", "answer_choice": "C"}, "243": {"q_num": 243, "question": "의학 연구실에서 새로운 연구와 관련된 데이터를 생성합니다. 연구소는 온프레미스 파일 \n기반 애플리케이션을 위해 전국의 클리닉에 최소한의 대기 시간으로 데이터를 제공하고자 \n합니다. 데이터 파일은 각 클리닉에 대한 읽기 전용 권한이 있는 Amazon S3 버킷에 \n저장됩니다. \n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까? \nA. 각 클리닉에서 온프레미스로 AWS Storage Gateway 파일 게이트웨이를 가상 \n머신(VM)으로 배포합니다. \nB. 처리를 위해 AWS DataSync 를 사용하여 각 클리닉의 온프레미스 애플리케이션으로 \n파일을 마이그레이션합니다. \nC. 각 클리닉에서 온프레미스로 AWS Storage Gateway 볼륨 게이트웨이를 가상 \n머신(VM)으로 배포합니다. \nD. Amazon Elastic File System(Amazon EFS) 파일 시스템을 각 클리닉의 온프레미스 \n서버에 연결합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/95002-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nAWS Storage Gateway 는 온프레미스 소프트웨어 어플라이언스와 클라우드 기반 스토리지를 \n연결하여 조직의 온프레미스 IT 환경과 AWS 스토리지 인프라 간의 원활하고 안전한 \n통합을 제공하는 서비스입니다. 각 진료소 구내에 파일 게이트웨이를 가상 머신으로 \n\n배포함으로써 의료 연구실은 각 진료소에 대한 읽기 전용 권한을 유지하면서 S3 버킷에 \n저장된 데이터에 대한 짧은 대기 시간 액세스를 제공할 수 있습니다. 이 솔루션을 통해 \n클리닉은 데이터 전송이나 마이그레이션 없이 온프레미스 파일 기반 애플리케이션에서 직접 \n데이터 파일에 액세스할 수 있습니다. \n \n설명2: \nA. 클리닉에서 파일 인터페이스를 통해 S3 버킷에 저장된 데이터 파일에 액세스할 수 \n있습니다. 파일 게이트웨이는 자주 액세스하는 데이터를 로컬로 캐시하여 대기 시간을 \n줄이고 데이터에 대한 빠른 액세스를 제공합니다. \n \nB. AWS DataSync\n를 사용하여 Amazon S3 버킷에서 각 클리닉의 온프레미스 \n애플리케이션으로 데이터 파일을 전송하는 작업이 포함됩니다. 이렇게 하면 데이터 \n마이그레이션이 가능하지만 실시간 액세스를 제공하지 않을 수 있으며 추가 대기 시간이 \n발생할 수 있습니다. \n \nC. 파일 수준의 접근보다는 데이터에 대한 블록 수준의 접근에 적합하다. 파일 기반 \n애플리케이션을 위한 가장 효율적인 솔루션이 아닐 수도 있습니다. \n \nD. 확장 가능한 파일 스토리지 서비스인 Amazon EFS 를 사용하여 데이터에 대한 파일 \n수준 액세스를 제공합니다. 그러나 파일 게이트웨이 솔루션을 사용할 때보다 복잡성과 대기 \n시간이 추가로 발생할 수 있습니다.", "answer_choice": "A"}, "244": {"q_num": 244, "question": "회사에서 단일 Amazon EC2 인스턴스에서 실행되는 콘텐츠 관리 시스템을 사용하고 \n있습니다. EC2 인스턴스에는 웹 서버와 데이터베이스 소프트웨어가 모두 포함되어 있습니다. \n회사는 웹 사이트 플랫폼을 고가용성으로 만들고 사용자 요구에 맞게 웹 사이트를 확장할 \n수 있어야 합니다. \n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까? \nA. 데이터베이스를 Amazon RDS 로 이동하고 자동 백업을 활성화합니다. 동일한 가용 \n영역에서 다른 EC2 인스턴스를 수동으로 시작합니다. 가용 영역에서 Application Load \nBalancer 를 구성하고 두 인스턴스를 대상으로 설정합니다. \nB. 기존 EC2 인스턴스와 동일한 가용 영역에 있는 읽기 전용 복제본이 있는 Amazon \nAurora 인스턴스로 데이터베이스를 마이그레이션합니다. 동일한 가용 영역에서 다른 EC2 \n인스턴스를 수동으로 시작합니다. Application Load Balancer 를 구성하고 두 개의 EC2 \n인스턴스를 대상으로 설정합니다. \n\nC. 다른 가용 영역에 읽기 전용 복제본이 있는 Amazon Aurora\n로 데이터베이스를 \n이동합니다. EC2 인스턴스에서 Amazon 머신 이미지(AMI)를 생성합니다. 두 가용 영역에서 \nApplication Load Balancer 를 구성합니다. 두 가용 영역에서 AMI 를 사용하는 Auto Scaling \n그룹을 연결합니다. \nD. 데이터베이스를 별도의 EC2 인스턴스로 이동하고 Amazon S3 로 백업을 예약합니다. \n원래 EC2 인스턴스에서 Amazon 머신 이미지(AMI)를 생성합니다. 두 가용 영역에서 \nApplication Load Balancer 를 구성합니다. 두 가용 영역에서 AMI 를 사용하는 Auto Scaling \n그룹을 연결합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/95336-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \n이 접근 방식은 웹 사이트 플랫폼에 고가용성과 확장성을 모두 제공합니다. 데이터베이스를 \n다른 가용 영역에 있는 읽기 전용 복제본이 있는 Amazon Aurora\n로 이동하면 \n데이터베이스에 대한 장애 조치 옵션이 제공됩니다. 두 가용 영역에서 Application Load \nBalancer 및 Auto Scaling 그룹을 사용하면 증가하는 사용자 수요를 충족하기 위해 웹 \n사이트를 자동으로 확장할 수 있습니다. 또한 원래 EC2 인스턴스에서 AMI 를 생성하면 \n장애 발생 시 인스턴스를 쉽게 복제할 수 있습니다. \n \n설명2: \n옵션 A 는 고가용성 또는 확장성을 위한 솔루션을 제공하지 않습니다. 동일한 AZ 에서 다른 \nEC2 인스턴스를 수동으로 시작하면 해당 AZ 에 장애가 발생하면 다운타임이 발생하므로 \n고가용성이 보장되지 않을 수 있습니다. \n \n옵션 B 는 데이터베이스 성능을 개선하고 내결함성 수준을 제공하지만 웹 사이트 플랫폼의 \n확장성 측면을 다루지는 않습니다. \n \n옵션 C\n는 고가용성과 내결함성을 모두 제공합니다. AMI\n를 생성하면 AZ 간에 EC2 \n인스턴스를 쉽게 복제할 수 있습니다. 두 AZ 에서 ALB 를 구성하고 ASG 를 연결하면 여러 \n인스턴스에 걸쳐 확장성과 부하 분산이 보장됩니다. \n \n옵션 D 는 회사에서 요구하는 고가용성 및 확장성을 제공하지 않습니다. S3 에 예약된 \n백업은 데이터 보호를 다루지만 웹사이트 가용성이나 확장성에 기여하지는 않습니다.", "answer_choice": "C"}, "245": {"q_num": 245, "question": "회사가 AWS 에서 애플리케이션을 시작하고 있습니다. 애플리케이션은 Application Load \nBalancer(ALB)를 사용하여 단일 대상 그룹에 있는 최소 2 개의 Amazon EC2 인스턴스로 \n트래픽을 보냅니다. 인스턴스는 각 환경의 Auto Scaling 그룹에 있습니다. 회사는 개발 \n환경과 생산 환경이 필요합니다. 프로덕션 환경에는 트래픽이 많은 기간이 있습니다. \n개발 환경을 가장 비용 효율적으로 구성하는 솔루션은 무엇입니까? \nA. 하나의 EC2 인스턴스만 대상으로 하도록 개발 환경에서 대상 그룹을 재구성합니다. \nB. ALB 밸런싱 알고리즘을 최소 미해결 요청으로 변경합니다. \nC. 두 환경 모두에서 EC2 인스턴스의 크기를 줄입니다. \nD. 개발 환경의 Auto Scaling 그룹에서 최대 EC2 인스턴스 수를 줄입니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/95337-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명 \n대상으로 하나의 EC2 인스턴스만 포함하도록 개발 환경에서 대상 그룹을 구성하면 해당 \n환경에 할당된 리소스를 효과적으로 줄일 수 있습니다. 이렇게 하면 더 적은 수의 EC2 \n인스턴스 및 관련 리소스를 활용하여 비용을 최소화할 수 있습니다. \n \n옵션 B 는 개발 환경의 비용 효율성을 직접 다루지 않습니다. 비용 최적화보다는 로드 \n밸런싱 전략에 중점을 둡니다. \n \n옵션 C 는 현재 인스턴스 크기가 과도하게 프로비저닝되거나 애플리케이션 요구 사항에 \n불필요하지 않는 한 가장 비용 효율적인 솔루션이 아닐 수 있습니다. \n \n옵션 D 는 비용 절감에 도움이 될 수 있지만 특히 부하가 증가하는 기간 동안 트래픽을 \n처리하고 효율적으로 확장하는 환경의 기능에 영향을 미칠 수 있습니다. \n \n전반적으로 \n옵션 \nA\n는 \n기능 \n설정을 \n유지하면서 \n개발 \n환경에 \n할당된 \n리소스를 \n최소화함으로써 비용 효율적인 접근 방식을 제공합니다.", "answer_choice": "A"}, "246": {"q_num": 246, "question": "한 회사가 여러 가용 영역의 Amazon EC2 인스턴스에서 웹 애플리케이션을 실행합니다. \nEC2 \n인스턴스는 \n프라이빗 \n서브넷에 \n있습니다. \n솔루션 \n설계자는 \n인터넷 \n연결 \nALB(Application Load Balancer)를 구현하고 EC2 인스턴스를 대상 그룹으로 지정합니다. \n\n그러나 인터넷 트래픽이 EC2 인스턴스에 도달하지 않습니다. \n솔루션 설계자는 이 문제를 해결하기 위해 아키텍처를 어떻게 재구성해야 합니까? \nA. ALB 를 Network Load Balancer 로 교체하십시오. 인터넷 트래픽을 허용하도록 퍼블릭 \n서브넷에서 NAT 게이트웨이를 구성합니다. \nB. EC2 인스턴스를 퍼블릭 서브넷으로 이동합니다. EC2 인스턴스의 보안 그룹에 규칙을 \n추가하여 0.0.0.0/0 으로의 아웃바운드 트래픽을 허용합니다. \nC. 인터넷 게이트웨이 경로를 통해 0.0.0.0/0 트래픽을 보내도록 EC2 인스턴스의 서브넷에 \n대한 경로 테이블을 업데이트합니다. EC2 인스턴스의 보안 그룹에 규칙을 추가하여 \n0.0.0.0/0 으로의 아웃바운드 트래픽을 허용합니다. \nD. 각 가용 영역에서 퍼블릭 서브넷을 생성합니다. 퍼블릭 서브넷을 ALB 와 연결합니다. \n프라이빗 서브넷에 대한 경로로 퍼블릭 서브넷에 대한 경로 테이블을 업데이트합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/95003-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nA. 다른 유형의 로드 밸런서를 사용하고 NAT 게이트웨이를 구성할 것을 제안하지만 EC2 \n인스턴스에 도달하는 인터넷 트래픽 문제는 다루지 않습니다. \n \nB.는 EC2 인스턴스를 퍼블릭 인터넷에 노출할 것을 제안합니다. 이는 보안 위험을 초래할 \n수 있으며 인스턴스에 도달하는 인바운드 인터넷 트래픽 문제를 해결하지 않습니다. \n \nC.는 아웃바운드 인터넷 액세스를 갖도록 EC2 인스턴스를 구성할 것을 제안하지만 \n인스턴스에 도달하는 인바운드 인터넷 트래픽 문제를 해결하지는 않습니다. \n \nD.가 정답입니다. 퍼블릭 서브넷을 생성하고 이를 ALB\n와 연결하면 인바운드 인터넷 \n트래픽이 ALB 에 도달할 수 있습니다. 프라이빗 서브넷에 대한 경로를 포함하도록 퍼블릭 \n서브넷의 라우팅 테이블이 업데이트되어 트래픽이 프라이빗 서브넷의 EC2 인스턴스에 \n도달할 수 있습니다. 이 설정을 사용하면 인터넷 트래픽이 ALB 를 통해 EC2 인스턴스에 \n도달하도록 허용하면서 애플리케이션에 대한 보안 액세스가 가능합니다. \n \n참고: \nhttps://repost.aws/ko/knowledge-center/public-load-balancer-private-ec2", "answer_choice": "D"}, "247": {"q_num": 247, "question": "한 회사에서 MySQL 용 Amazon RDS 에 데이터베이스를 배포했습니다. 트랜잭션 증가로 \n인해 데이터베이스 지원 팀은 DB 인스턴스에 대한 느린 읽기를 보고하고 있으며 읽기 전용 \n복제본을 추가할 것을 권장합니다. \n이 변경 사항을 구현하기 전에 솔루션 설계자가 수행해야 하는 작업 조합은 무엇입니까? \n(2 개 선택) \nA. RDS 기본 노드에서 binlog 복제를 활성화합니다. \nB. 원본 DB 인스턴스의 장애 조치 우선 순위를 선택합니다. \nC. 원본 DB 인스턴스에서 장기 실행 트랜잭션이 완료되도록 허용합니다. \nD. 글로벌 테이블을 생성하고 테이블을 사용할 수 있는 AWS 리전을 지정합니다. \nE. 백업 보존 기간을 0 이외의 값으로 설정하여 원본 인스턴스에서 자동 백업을 \n활성화합니다.", "answer_block": "Answer: C, E \nhttps://www.examtopics.com/discussions/amazon/view/95004-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nA. 읽기 복제본 설정에 필요한 RDS 기본 노드에서 이진 로그 복제 기능을 활성화합니다. \n \nB. 장애 조치 시나리오 중에 DB 인스턴스가 기본 역할로 승격되는 순서를 결정합니다. \n느린 읽기 문제를 해결하기 위해 읽기 전용 복제본을 추가하는 것과 직접적인 관련이 \n없습니다. \n \nC. 원본 DB 인스턴스에서 진행 중인 모든 트랜잭션이 변경 사항을 구현하기 전에 \n완료되도록 합니다. 읽기 전용 복제본으로 전환하는 동안 데이터 무결성과 일관성을 \n유지하는 데 도움이 됩니다. \n \nD.는 DynamoDB 전용 기능입니다. DynamoDB\n에서 다중 리전 복제 및 고가용성을 \n허용하지만 이 시나리오에는 적용할 수 없습니다. \n \nE. 원본 DB 인스턴스에 대해 정기적인 백업이 수행되는지 확인합니다. 이는 읽기 전용 \n복제본을 추가하는 동안 또는 이후에 문제가 발생할 경우 특정 시점 복원을 허용하므로 \n데이터 보호 및 복구 목적에 중요합니다. \n \n설명2: \n\"오래 실행되는 활성 트랜잭션은 읽기 전용 복제본 생성 프로세스를 느리게 할 수 있습니다. \n읽기 전용 복제본을 생성하기 전에 장기 실행 트랜잭션이 완료될 때까지 기다리는 것이 \n\n좋습니다. 동일한 원본 DB 인스턴스에서 여러 읽기 전용 복제본을 병렬로 생성하는 경우 , \nAmazon RDS 는 첫 번째 생성 작업 시작 시 하나의 스냅샷만 찍습니다. 읽기 전용 복제본을 \n생성할 때 고려해야 할 몇 가지 사항이 있습니다. 먼저 백업 보존 기간을 0 이외의 값. \n이 요구 사항은 다른 읽기 전용 복제본의 원본 DB 인스턴스인 읽기 전용 복제본에도 \n적용됩니다.\" \nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html", "answer_choice": "C"}, "248": {"q_num": 248, "question": "회사는 Amazon EC2 인스턴스에서 분석 소프트웨어를 실행합니다. 소프트웨어는 Amazon \nS3 에 업로드된 데이터를 처리하기 위해 사용자의 작업 요청을 수락합니다. 일부 제출된 \n데이터가 처리되지 않고 있다고 사용자가 보고합니다. Amazon CloudWatch\n는 EC2 \n인스턴스의 일관된 CPU 사용률이 100% 또는 거의 100%에 가깝다고 밝혔습니다. 회사는 \n시스템 성능을 개선하고 사용자 부하에 따라 시스템을 확장하려고 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. 인스턴스의 복사본을 만듭니다. Application Load Balancer 뒤에 모든 인스턴스를 \n배치합니다. \nB. Amazon S3 용 S3 VPC 엔드포인트를 생성합니다. 엔드포인트를 참조하도록 소프트웨어를 \n업데이트합니다. \nC. EC2 인스턴스를 중지합니다. CPU 와 메모리가 더 강력한 인스턴스 유형으로 인스턴스 \n유형을 수정합니다. 인스턴스를 다시 시작하십시오. \nD. 들어오는 요청을 Amazon Simple Queue Service(Amazon SQS)로 라우팅합니다. 대기열 \n크기에 따라 EC2 Auto Scaling 그룹을 구성합니다. 대기열에서 읽을 수 있도록 \n소프트웨어를 업데이트합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/95329-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nA. 인스턴스 사본을 생성하고 모든 인스턴스를 ALB 뒤에 배치하는 것은 높은 CPU 사용률 \n문제를 해결하거나 사용자 부하에 따라 확장성을 제공하지 않습니다. \n \nB. S3\n용 S3 VPC 엔드포인트를 생성하고 엔드포인트를 참조하도록 소프트웨어를 \n업데이트하면 네트워크 성능이 향상되지만 높은 CPU 사용률 문제를 해결하거나 사용자 \n부하에 따라 확장성을 제공하지 않습니다. \n \n\nC. EC2 인스턴스를 중지하고 인스턴스 유형을 더 강력한 CPU 와 더 많은 메모리를 가진 \n인스턴스 유형으로 수정하면 성능이 향상될 수 있지만 사용자 부하에 따른 확장성은 \n해결되지 않습니다. \n \nD. 들어오는 요청을 SQS 로 라우팅하고, 대기열 크기에 따라 EC2 ASG 를 구성하고, \n대기열에서 읽을 수 있도록 소프트웨어를 업데이트하면 시스템 성능이 향상되고 사용자 \n로드에 따라 확장성이 제공됩니다. \n \n따라서 옵션 D 는 높은 CPU 사용률을 해결하고 시스템 성능을 개선하며 사용자 부하에 \n따라 확장성을 활성화하므로 올바른 선택입니다.", "answer_choice": "D"}, "249": {"q_num": 249, "question": "회사는 AWS 클라우드에서 호스팅되는 미디어 애플리케이션을 위한 공유 스토리지 \n솔루션을 구현하고 있습니다. 회사는 SMB 클라이언트를 사용하여 데이터에 액세스할 수 \n있는 기능이 필요합니다. 솔루션은 완전히 관리되어야 합니다. \n어떤 AWS 솔루션이 이러한 요구 사항을 충족합니까? \nA. AWS Storage Gateway 볼륨 게이트웨이를 생성합니다. 필요한 클라이언트 프로토콜을 \n사용하는 파일 공유를 만듭니다. 응용 프로그램 서버를 파일 공유에 연결합니다. \nB. AWS Storage Gateway 테이프 게이트웨이를 생성합니다. Amazon S3 를 사용하도록 \n테이프를 구성합니다. 애플리케이션 서버를 테이프 게이트웨이에 연결합니다. \nC. Amazon EC2 Windows 인스턴스를 생성합니다. 인스턴스에 Windows 파일 공유 역할을 \n설치하고 구성합니다. 응용 프로그램 서버를 파일 공유에 연결합니다. \nD. Windows 파일 서버 파일 시스템용 Amazon FSx 를 생성합니다. 원본 서버에 파일 \n시스템을 연결합니다. 애플리케이션 서버를 파일 시스템에 연결하십시오.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/95006-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nA. Storage Gateway 사용과 관련이 있지만 SMB 클라이언트에 대한 지원을 구체적으로 \n언급하지는 않습니다. SMB 클라이언트를 사용하여 데이터에 액세스해야 하는 요구 사항을 \n충족하지 못할 수 있습니다. \n \nB. S3 에 데이터를 보관하는 데 주로 사용되는 테이프 게이트웨이 구성과 함께 Storage \nGateway 를 사용하는 것과 관련됩니다. SMB 클라이언트가 데이터에 액세스할 수 있도록 \n\n기본 지원을 제공하지 않습니다. \n \nC. EC2 Windows 인스턴스에서 Windows 파일 공유를 수동으로 설정하고 구성하는 작업이 \n포함됩니다. SMB 클라이언트가 데이터에 액세스할 수 있지만 수동 설정 및 유지 관리가 \n필요하므로 완전히 관리되는 솔루션은 아닙니다. \n \nD. SMB 클라이언트를 지원하는 완전히 관리되는 Windows 파일 시스템인 FSx for Windows \n파일 서버 파일 시스템 생성이 포함됩니다. 기본 SMB 를 지원하는 사용하기 쉬운 공유 \n스토리지 솔루션을 제공합니다. \n \nSMB 클라이언트를 사용하고 완전히 관리되는 솔루션이 필요한 요구 사항을 기반으로 옵션 \nD 가 가장 적합한 선택입니다. \n \n설명2: \nhttps://aws.amazon.com/fsx/lustre/ \nAmazon FSx 는 Windows 파일 시스템 기능과 업계 표준 서버를 기본적으로 지원합니다. \n네트워크를 통해 파일 저장소에 액세스하기 위한 메시지 블록(SMB) 프로토콜. \nhttps://docs.aws.amazon.com/fsx/latest/WindowsGuide/what-is.html \n \n온프레미스-AWS 간 스토리지 서비스 중 SMB 지원하는 건 Storage Gateway File \nGateway 나 Amazon FSx for Windows 라고 보면 됨.", "answer_choice": "D"}, "250": {"q_num": 250, "question": "회사의 보안 팀이 VPC 흐름 로그에서 네트워크 트래픽을 캡처하도록 요청합니다. 로그는 \n90 일 동안 자주 액세스한 후 간헐적으로 액세스합니다. \n솔루션 설계자는 로그를 구성할 때 이러한 요구 사항을 충족하기 위해 무엇을 해야 \n합니까? \nA. Amazon CloudWatch 를 대상으로 사용하십시오. 90 일 만료로 CloudWatch 로그 그룹 \n설정 \nB. Amazon Kinesis 를 대상으로 사용합니다. 항상 90 일 동안 로그를 유지하도록 Kinesis \n스트림을 구성합니다. \nC. AWS CloudTrail 을 대상으로 사용합니다. Amazon S3 버킷에 저장하도록 CloudTrail 을 \n구성하고 S3 Intelligent-Tiering 을 활성화합니다. \nD. Amazon S3 를 대상으로 사용합니다. S3 수명 주기 정책을 활성화하여 90 일 후에 로그를 \nS3 Standard-Infrequent Access(S3 Standard-IA)로 전환합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/95007-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nA. CloudWatch 를 VPC 흐름 로그의 대상으로 사용할 것을 제안합니다. 그러나 90 일 동안 \n로그 보존을 관리한 다음 간헐적으로 액세스하는 메커니즘을 제공하지 않습니다. \n \nB. Kinesis를 VPC 흐름 로그의 대상으로 사용할 것을 제안합니다. 90일 동안 로그를 보관할 \n수 있지만 로그에 대한 간헐적 액세스 요구 사항은 다루지 않습니다. \n \nC. CloudTrail 을 VPC 흐름 로그의 대상으로 사용할 것을 제안합니다. 그러나 CloudTrail 은 \n네트워크 트래픽 로그 캡처가 아니라 API 활동을 감사 및 모니터링하도록 설계되었습니다. \nVPC 흐름 로그 캡처 요구 사항을 충족하지 않습니다. \n \nD. S3 를 VPC 흐름 로그의 대상으로 사용하고 S3 수명 주기 정책을 활용하여 90 일 후에 \n로그를 비용 효율적인 스토리지 클래스로 전환할 것을 제안합니다. 90 일 동안 로그를 \n유지해야 하는 요구 사항을 충족하고 스토리지 비용을 최적화하면서 간헐적인 액세스에 \n대한 유연성을 제공합니다. \n \n설명2: \n여기에는 VPC 흐름 로그가 S3\n로 직접 이동할 수 있음을 지정하는 표가 있습니다. \nCloudTrail 을 거쳐 S3 로 이동할 필요가 없습니다. CW 를 통해서도 아닙니다. \nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AWS-logs-and-resourcep\nolicy.html#AWS-logs-i", "answer_choice": "D"}, "251": {"q_num": 251, "question": "Amazon EC2 인스턴스는 새 VPC\n의 프라이빗 서브넷에 있습니다. 이 서브넷에는 \n아웃바운드 인터넷 액세스 권한이 없지만 EC2 인스턴스에는 외부 공급업체로부터 월별 \n보안 업데이트를 다운로드할 수 있는 기능이 필요합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. 인터넷 게이트웨이를 생성하고 VPC 에 연결합니다. 인터넷 게이트웨이를 기본 경로로 \n사용하도록 프라이빗 서브넷 경로 테이블을 구성합니다. \nB. NAT 게이트웨이를 생성하고 퍼블릭 서브넷에 배치합니다. NAT 게이트웨이를 기본 \n경로로 사용하도록 프라이빗 서브넷 경로 테이블을 구성합니다. \n\nC. NAT 인스턴스를 생성하고 EC2 인스턴스가 있는 동일한 서브넷에 배치합니다. NAT \n인스턴스를 기본 경로로 사용하도록 프라이빗 서브넷 경로 테이블을 구성합니다. \nD. 인터넷 게이트웨이를 생성하고 VPC 에 연결합니다. NAT 인스턴스를 생성하고 EC2 \n인스턴스가 \n있는 \n동일한 \n서브넷에 \n배치합니다. \n인터넷 \n게이트웨이를 \n기본 \n경로로 \n사용하도록 프라이빗 서브넷 경로 테이블을 구성합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/95023-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nA. 사설 서브넷에 직접 인터넷 액세스를 제공합니다. 이는 아웃바운드 인터넷 액세스를 \n제한하는 것이 목표이므로 이 경우에는 바람직하지 않습니다. \n \nB. 프라이빗 서브넷의 EC2\n가 프록시 역할을 하는 NAT 게이트웨이를 통해 인터넷에 \n액세스할 수 있습니다. 프라이빗 서브넷의 보안을 유지하면서 통제된 아웃바운드 인터넷 \n액세스를 제공합니다. \n \nC. NAT 게이트웨이를 사용하는 것과 유사하지만 NAT 인스턴스를 사용하는 것과 관련이 \n있습니다. NAT 인스턴스는 NAT 게이트웨이에 비해 더 많은 수동 구성 및 관리가 \n필요하므로 덜 선호되는 옵션입니다. \n \nD. 필요하지 않은 인터넷 게이트웨이와 NAT 인스턴스의 사용을 결합합니다. 불필요한 \n복잡성이 발생하고 추가 관리가 필요한 NAT 인스턴스가 추가됩니다. \n \n전반적으로 옵션 B 는 퍼블릭 서브넷에 배치된 NAT 게이트웨이를 활용하여 프라이빗 \n서브넷의 EC2 인스턴스에 대해 제어된 아웃바운드 인터넷 액세스를 활성화하므로 가장 \n적합한 솔루션입니다. \n \nNAT 게이트웨이는 AWS 및 일반적으로 NAT 인스턴스보다 선호됩니다. \n \n설명2: \n이 접근 방식을 사용하면 EC2 인스턴스가 여전히 프라이빗 서브넷에 있는 동안 인터넷에 \n액세스하고 월별 보안 업데이트를 다운로드할 수 있습니다. NAT 게이트웨이를 만들어 \n퍼블릭 서브넷에 배치하면 프라이빗 서브넷의 인스턴스가 NAT 게이트웨이를 통해 인터넷에 \n액세스할 수 있습니다. 그런 다음 NAT 게이트웨이를 기본 경로로 사용하도록 프라이빗 \n서브넷 \n경로 \n테이블을 \n구성합니다. \n이렇게 \n하면 \n모든 \n아웃바운드 \n트래픽이 \nNAT \n\n게이트웨이를 통해 전달되어 EC2 인스턴스가 프라이빗 서브넷의 보안을 유지하면서 \n인터넷에 액세스할 수 있습니다.", "answer_choice": "B"}, "252": {"q_num": 252, "question": "솔루션 설계자는 고객 사례 파일을 저장할 시스템을 설계해야 합니다. 파일은 핵심 회사 \n자산이며 중요합니다. 파일 수는 시간이 지남에 따라 증가합니다. \n파일은 Amazon EC2 인스턴스에서 실행되는 여러 애플리케이션 서버에서 동시에 액세스할 \n수 있어야 합니다. 솔루션에는 중복성이 내장되어 있어야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. Amazon Elastic File System(Amazon EFS) \nB. Amazon Elastic Block Store(Amazon EBS) \nC. Amazon S3 Glacier Deep 아카이브(Amazon S3 Glacier Deep Archive) \nD. AWS 백업(AWS Backup)", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/95024-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n \n설명1: \nEFS 는 여러 EC2 에서 동시에 액세스할 수 있는 확장 가능하고 완벽하게 관리되는 파일 \n스토리지 서비스를 제공합니다. 리전 내의 여러 AZ\n에 데이터를 저장하여 기본 제공 \n중복성을 제공합니다. EFS\n를 사용하면 여러 애플리케이션 서버에서 클라이언트 사례 \n파일에 동시에 액세스할 수 있으므로 시간이 지남에 따라 파일 수가 증가함에 따라 \n고가용성과 확장성이 보장됩니다. \n \n옵션 B 인 EBS 는 일반적으로 개별 EC2 에 연결하는 데 사용되는 블록 수준 스토리지 \n서비스이며 여러 인스턴스에 대한 동시 액세스를 제공하지 않으므로 이 시나리오에 \n적합하지 않습니다. \n \n옵션 C, S3 Glacier Deep Archive 는 장기 아카이브 스토리지 서비스이며 활성 파일 액세스 \n및 여러 애플리케이션 서버의 동시 액세스에 적합하지 않을 수 있습니다. \n \n옵션 D, AWS Backup 은 중앙 집중식 백업 관리 서비스이며 필요한 동시 파일 액세스 및 \n중복 기능을 제공하지 않습니다. \n \n\n따라서 가장 적합한 솔루션은 Amazon EFS(옵션 A)입니다. \n \n설명2: \nAmazon EFS 는 여러 EC2 인스턴스에서 동시에 액세스할 수 있는 간단하고 확장 가능한 \n완전 관리형 파일 시스템을 제공하며 내장된 중복성을 제공합니다. 동일한 파일에 \n액세스하기 위해 여러 EC2 인스턴스에 최적화되어 있으며 가용성, 내구성 및 보안성이 \n우수하도록 설계되었습니다. 데이터를 페타바이트까지 확장할 수 있고 수천 개의 동시 \n연결을 처리할 수 있으며 대량의 데이터를 저장하고 액세스하기 위한 비용 효율적인 \n솔루션입니다.", "answer_choice": "A"}, "253": {"q_num": 253, "question": "솔루션 아키텍트가 Policy1 과 Policy2 라는 두 가지 IAM 정책을 만들었습니다. 두 정책 \n모두 IAM 그룹에 연결됩니다. \n \n\n \n클라우드 엔지니어가 IAM 그룹에 IAM 사용자로 추가됩니다. 클라우드 엔지니어는 어떤 \n작업을 수행할 수 있습니까? \nA. IAM 사용자 삭제 \nB. 디렉토리 삭제 \nC. Amazon EC2 인스턴스 삭제 \nD. Amazon CloudWatch Logs 에서 로그 삭제", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/95008-exam-aws-certified-solut\nions-architect-associate-saa-c03/", "answer_choice": "C"}, "254": {"q_num": 254, "question": "한 회사에서 최근 3 계층 애플리케이션을 VPC 로 마이그레이션하는 것을 검토하고 있습니다. \n보안 팀은 최소 권한 원칙이 애플리케이션 계층 간의 Amazon EC2 보안 그룹 수신 및 송신 \n규칙에 적용되지 않는다는 사실을 발견했습니다. \n솔루션 설계자는 이 문제를 해결하기 위해 무엇을 해야 합니까? \nA. 인스턴스 ID 를 소스 또는 대상으로 사용하여 보안 그룹 규칙을 생성합니다. \nB. 보안 그룹 ID 를 소스 또는 대상으로 사용하여 보안 그룹 규칙을 생성합니다. \nC. VPC CIDR 블록을 소스 또는 대상으로 사용하여 보안 그룹 규칙을 생성합니다. \nD. 서브넷 CIDR 블록을 소스 또는 대상으로 사용하여 보안 그룹 규칙을 생성합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/95009-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n\nA. 특정 인스턴스를 기반으로 트래픽을 제한하므로 애플리케이션 계층 간에 최소 권한 \n원칙을 적용하는 데 가장 적합한 솔루션이 아닐 수 있습니다. \nB. 규칙에서 보안 그룹 ID 를 사용하면 필요한 통신만 허용하고 최소 권한 원칙을 준수하여 \n애플리케이션 계층 간의 트래픽을 정밀하게 제어할 수 있습니다. \nC. 전체 VPC CIDR 블록을 기반으로 광범위한 규칙을 적용하여 특정 애플리케이션 계층 \n간의 보안 통신에 필요한 수준의 세분성을 제공하지 못할 수 있습니다. \nD. 서브넷 CIDR 블록을 기반으로 트래픽을 제한하므로 애플리케이션 계층 간의 적절한 \n보안을 보장하기에 충분하지 않을 수 있습니다. \n \n요약하면 보안 그룹 ID(옵션 B)를 사용하면 최소 권한 원칙에 따라 애플리케이션 계층 간의 \n트래픽을 정밀하게 제어할 수 있으므로 권장되는 접근 방식입니다. \n \n참고 \nhttps://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/security-group-rules.html", "answer_choice": "B"}, "255": {"q_num": 255, "question": "회사에는 데이터베이스에 주문을 작성하고 지불을 처리하기 위해 서비스를 호출하는 전자 \n상거래 체크아웃 워크플로우가 있습니다. 사용자는 체크아웃 프로세스 중에 시간 초과를 \n경험하고 있습니다. 사용자가 체크아웃 양식을 다시 제출하면 동일한 원하는 거래에 대해 \n여러 고유 주문이 생성됩니다. \n여러 주문 생성을 방지하기 위해 솔루션 설계자는 이 워크플로우를 어떻게 리팩터링해야 \n합니까? \nA. Amazon Kinesis Data Firehose 로 주문 메시지를 보내도록 웹 애플리케이션을 구성합니다. \nKinesis Data Firehose\n에서 메시지를 검색하고 주문을 처리하도록 결제 서비스를 \n설정합니다. \nB. 로깅된 애플리케이션 경로 요청을 기반으로 AWS Lambda 함수를 호출하기 위해 AWS \nCloudTrail 에서 규칙을 생성합니다. Lambda 를 사용하여 데이터베이스를 쿼리하고 결제 \n서비스를 호출하고 주문 정보를 전달합니다. \nC. 데이터베이스에 주문을 저장합니다. 주문 번호가 포함된 메시지를 Amazon Simple \nNotification Service(Amazon SNS)로 보냅니다. Amazon SNS 를 폴링하고 메시지를 검색하고 \n주문을 처리하도록 결제 서비스를 설정합니다. \nD. 데이터베이스에 주문을 저장합니다. 주문 번호가 포함된 메시지를 Amazon Simple \nQueue Service(Amazon SQS) FIFO 대기열로 보냅니다. 메시지를 검색하고 주문을 \n처리하도록 결제 서비스를 설정합니다. 대기열에서 메시지를 삭제합니다.", "answer_block": "Answer: D \n\nhttps://www.examtopics.com/discussions/amazon/view/95026-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nA. 다중 주문 생성 방지에 적합한 솔루션이 아닙니다. 이 접근 방식은 순차적이고 안정적인 \n주문 처리를 보장하지 않습니다. \nB. 다중 주문 생성을 방지하기 위한 적절한 해결책이 아닙니다. CloudTrail 은 주로 API \n활동을 기록하고 감사하는 데 사용되며 기록된 요청을 기반으로 Lambda 를 호출하면 \n올바른 주문 처리가 보장되지 않습니다. \nC.는 적절한 솔루션이 아닙니다. SNS 는 게시-구독 메시징 서비스이며 이를 폴링하면 \n처리가 지연되고 잠재적인 주문 중복이 발생할 수 있습니다. \nD.가 정답입니다. SQS FIFO 를 사용하면 주문이 순차적이고 안정적인 방식으로 처리되어 \n동일한 거래에 대해 여러 주문이 생성되는 것을 방지할 수 있습니다. \n \n설명2: \nVPC 내에 있는 프라이빗 서브넷의 EC2 인스턴스와 DynamoDB 간 가장 안전한 AWS \n네트워크 통신 = VPC Gateway Endpoint. \n게이트웨이 엔드포인트는 VPC 용 인터넷 게이트웨이 또는 NAT 디바이스가 없어도 Amazon \nS3 및 DynamoDB 에 대한 안정적인 연결을 제공합니다. \nhttps://docs.aws.amazon.com/ko_kr/vpc/latest/privatelink/vpce-gateway.html#vpc-endp\noints-limitations \n \n \n설명3: \nDynamoDB 용 VPC 엔드포인트를 사용하면 VPC 의 Amazon EC2 인스턴스가 프라이빗 IP \n주소를 사용하여 퍼블릭 인터넷에 노출되지 않고 DynamoDB 에 액세스할 수 있습니다. EC2 \n인스턴스에는 퍼블릭 IP 주소가 필요하지 않으며 VPC 에 인터넷 게이트웨이, NAT 디바이스 \n또는 가상 프라이빗 게이트웨이가 필요하지 않습니다. 엔드포인트 정책을 사용하여 \nDynamoDB 에 대한 액세스를 제어합니다. VPC 와 AWS 서비스 간의 트래픽은 Amazon \n네트워크를 벗어나지 않습니다.", "answer_choice": "D"}, "256": {"q_num": 256, "question": "솔루션 설계자는 Amazon S3 버킷을 저장용으로 사용하여 문서 검토 애플리케이션을 \n구현하고 있습니다. 솔루션은 우발적인 문서 삭제를 방지하고 문서의 모든 버전을 사용할 \n수 있도록 보장해야 합니다. 사용자는 문서를 다운로드, 수정 및 업로드할 수 있어야 \n\n합니다. \n이러한 요구 사항을 충족하려면 어떤 조합의 조치를 취해야 합니까? (2 개 선택) \nA. 읽기 전용 버킷 ACL 을 활성화합니다. \nB. 버킷에서 버전 관리를 활성화합니다. \nC. IAM 정책을 버킷에 연결합니다. \nD. 버킷에서 MFA 삭제를 활성화합니다. \nE. AWS KMS 를 사용하여 버킷을 암호화합니다.", "answer_block": "Answer: B, D \nhttps://www.examtopics.com/discussions/amazon/view/95460-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nB. S3 버킷에 여러 버전의 객체를 저장할 수 있습니다. 이렇게 하면 문서를 실수로 \n덮어쓰거나 삭제하더라도 모든 버전의 문서를 사용할 수 있습니다. \nD. 버킷의 객체를 우발적으로 삭제하지 않도록 추가 보호 계층을 추가합니다. MFA 삭제가 \n활성화된 상태에서 사용자는 버킷에서 객체를 성공적으로 삭제하려면 추가 인증 요소를 \n제공해야 합니다. 이를 통해 우발적 삭제 또는 무단 삭제를 방지하고 중요한 문서에 대한 \n추가 보안 수준을 제공합니다. \n \nA. 사용자가 문서를 수정하거나 업로드하는 것을 제한합니다. 사용자가 문서를 다운로드, \n수정 및 업로드할 수 있도록 허용하는 요구 사항을 충족하지 않습니다. \nC. 버킷에 대한 액세스 권한을 제어할 수 있지만 우발적인 삭제를 방지하거나 문서의 모든 \n버전의 가용성을 보장하는 요구 사항을 구체적으로 다루지는 않습니다. \nE. 암호화는 버전 관리 및 삭제 방지보다는 데이터 보호에 중점을 둡니다.", "answer_choice": "B"}, "257": {"q_num": 257, "question": "회사는 AWS 계정의 모든 애플리케이션에서 Amazon EC2 Auto Scaling 이벤트를 보고하는 \n솔루션을 구축하고 있습니다. 회사는 Amazon S3 에 EC2 Auto Scaling 상태 데이터를 \n저장하기 위해 서버리스 솔루션을 사용해야 합니다. 그런 다음 회사는 Amazon S3 의 \n데이터를 사용하여 대시보드에서 거의 실시간 업데이트를 제공합니다. 솔루션은 EC2 \n인스턴스 시작 속도에 영향을 미치지 않아야 합니다. \n회사는 이러한 요구 사항을 충족하기 위해 어떻게 데이터를 Amazon S3 로 이동해야 \n합니까? \nA. Amazon CloudWatch 지표 스트림을 사용하여 EC2 Auto Scaling 상태 데이터를 Amazon \nKinesis Data Firehose 로 보냅니다. 데이터를 Amazon S3 에 저장합니다. \n\nB. Amazon EMR 클러스터를 시작하여 EC2 Auto Scaling 상태 데이터를 수집하고 데이터를 \nAmazon Kinesis Data Firehose 로 보냅니다. 데이터를 Amazon S3 에 저장합니다. \nC. Amazon EventBridge 규칙을 생성하여 일정에 따라 AWS Lambda 함수를 호출합니다. \nEC2 Auto Scaling 상태 데이터를 Amazon S3 로 직접 보내도록 Lambda 함수를 구성합니다. \nD. EC2 인스턴스를 시작하는 동안 부트스트랩 스크립트를 사용하여 Amazon Kinesis \n에이전트를 설치합니다. EC2 Auto Scaling 상태 데이터를 수집하고 데이터를 Amazon \nKinesis Data Firehose 로 보내도록 Kinesis 에이전트를 구성합니다. 데이터를 Amazon S3 에 \n저장합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/95027-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nB. EC2 Auto Scaling 상태 데이터를 수집하고 S3\n로 보내는 데 불필요한 복잡성과 \n오버헤드가 발생합니다. 이 특정 요구 사항에 가장 효율적인 서버리스 솔루션은 아닙니다. \n \nC. 실시간으로 트리거되지 않기 때문에 데이터 업데이트가 지연될 수 있습니다. 또한 직접 \n데이터 스트림을 사용하는 것과 비교할 때 불필요한 오버헤드와 복잡성이 추가됩니다. \n \nD. 추가 종속성 및 관리 오버헤드를 도입합니다. 또한 피해야 할 요구 사항인 EC2 \n인스턴스 시작 속도에 영향을 미칠 수 있습니다. \n \n전반적으로 옵션 A 는 CloudWatch 지표 스트림과 Kinesis Data Firehose 를 활용하여 EC2 \n인스턴스 시작 속도에 영향을 주지 않고 S3\n에서 EC2 Auto Scaling 상태 데이터를 \n효율적으로 캡처하고 저장함으로써 간소화된 서버리스 솔루션을 제공합니다. \n \n설명2: \n지표 스트림을 사용하여 CloudWatch 지표를 거의 실시간으로 제공하고 낮은 지연 \n시간으로 선택한 대상으로 지속적으로 스트리밍할 수 있습니다. 사용 사례 중 하나는 \n데이터 레이크입니다. 지표 스트림을 생성하고 CloudWatch 지표를 Amazon S3 와 같은 \n데이터 레이크에 전달하는 Amazon Kinesis Data Firehose 전달 스트림으로 보냅니다. \nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-Metric\n-Streams.html", "answer_choice": "A"}, "258": {"q_num": 258, "question": "회사에는 매시간 수백 개의 .csv 파일을 Amazon S3 버킷에 배치하는 애플리케이션이 \n있습니다. 파일 크기는 1GB\n입니다. 파일이 업로드될 때마다 회사는 파일을 Apache \nParquet 형식으로 변환하고 출력 파일을 S3 버킷에 배치해야 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. .csv 파일을 다운로드하고 파일을 Parquet 형식으로 변환하고 출력 파일을 S3 버킷에 \n배치하는 AWS Lambda 함수를 생성합니다. 각 S3 PUT 이벤트에 대해 Lambda 함수를 \n호출합니다. \nB. Apache Spark 작업을 생성하여 .csv 파일을 읽고, 파일을 Parquet 형식으로 변환하고, \n출력 파일을 S3 버킷에 배치합니다. Spark 작업을 호출하기 위해 각 S3 PUT 이벤트에 대한 \nAWS Lambda 함수를 생성합니다. \nC. 애플리케이션이 .csv 파일을 배치하는 S3 버킷에 대한 AWS Glue 테이블과 AWS Glue \n크롤러를 생성합니다. Amazon Athena를 주기적으로 사용하여 AWS Glue 테이블을 쿼리하고, \n쿼리 결과를 Parquet 형식으로 변환하고, 출력 파일을 S3 버킷에 배치하도록 AWS Lambda \n함수를 예약합니다. \nD. AWS Glue 추출, 변환 및 로드(ETL) 작업을 생성하여 .csv 파일을 Parquet 형식으로 \n변환하고 출력 파일을 S3 버킷에 배치합니다. 각 S3 PUT 이벤트에 대한 AWS Lambda \n함수를 생성하여 ETL 작업을 호출합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/95028-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nA. 상당한 운영 오버헤드가 발생합니다. 이 접근 방식에는 Lambda 관리, 동시성 처리, 큰 \n파일 크기에 대한 적절한 오류 처리 보장이 필요하며 이는 어려울 수 있습니다. \nB. 불필요한 복잡성과 운영 오버헤드를 추가합니다. Spark 작업 관리, 확장성 처리 및 각 \n파일 업로드에 대한 Lambda 호출 조정은 번거로울 수 있습니다. \nC. 추가 복잡성을 도입하고 가장 효율적인 솔루션이 아닐 수 있습니다. 여기에는 Glue \n리소스 관리, Lambda 예약, 새 파일이 업로드되지 않은 경우에도 데이터 쿼리가 \n포함됩니다. \n \n옵션 D 는 AWS Glue 의 ETL 기능을 활용하여 규모에 맞게 데이터 변환 작업을 정의하고 \n실행할 수 있습니다. 각 S3 PUT 이벤트에 대해 Lambda 함수를 사용하여 ETL 작업을 \n호출하면 수동 개입 없이 파일이 Parquet 형식으로 효율적으로 변환되도록 할 수 있습니다. \n이 접근 방식은 운영 오버헤드를 최소화하고 간소화되고 확장 가능한 솔루션을 제공합니다. \n \n참고: \n\nhttps://docs.aws.amazon.com/ko_kr/prescriptive-guidance/latest/patterns/three-aws-glu\ne-etl-job-types-for-converting-data-to-apache-parquet.html", "answer_choice": "D"}, "259": {"q_num": 259, "question": "회사는 Amazon RDS DB 인스턴스에서 실행되는 모든 데이터베이스에 대해 새로운 데이터 \n보존 정책을 구현하고 있습니다. 회사는 최소 2 년 동안 일일 백업을 유지해야 합니다. \n백업은 일관되고 복원 가능해야 합니다. \n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 솔루션을 권장해야 합니까? \nA. RDS 백업을 유지하기 위해 AWS Backup 에서 백업 볼트를 생성합니다. 일일 일정과 \n생성 후 2\n년의 만료 기간으로 새 백업 계획을 생성합니다. 백업 계획에 RDS DB \n인스턴스를 할당합니다. \nB. 일일 스냅샷을 위해 RDS DB 인스턴스의 백업 기간을 구성합니다. 각 RDS DB \n인스턴스에 2 년의 스냅샷 보존 정책을 할당합니다. Amazon DLM(Amazon Data Lifecycle \nManager)을 사용하여 스냅샷 삭제를 예약합니다. \nC. 만료 기간이 2 년인 Amazon CloudWatch Logs 에 자동으로 백업되도록 데이터베이스 \n트랜잭션 로그를 구성합니다. \nD. AWS Database Migration Service(AWS DMS) 복제 작업을 구성합니다. 복제 인스턴스를 \n배포하고 변경 데이터 캡처(CDC) 작업을 구성하여 데이터베이스 변경 사항을 대상으로 \nAmazon S3\n에 스트리밍합니다. 2\n년 후 스냅샷을 삭제하도록 S3 수명 주기 정책을 \n구성합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/95030-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nA. 중앙 집중식 백업 관리 서비스인 AWS Backup 을 사용하여 RDS 백업을 유지할 것을 \n제안합니다. 백업 볼트가 생성되고 일일 일정과 2 년의 백업 보존 기간으로 백업 계획이 \n정의됩니다. RDS DB 인스턴스가 이 백업 계획에 할당됩니다. \nB. 일관되고 복원 가능한 백업에 대한 요구 사항을 다루지 않습니다. 스냅샷은 시점 \n백업이며 원하는 수준의 일관성을 제공하지 못할 수 있습니다. \nC. 데이터베이스에 필요한 백업 및 복원 기능을 제공하도록 설계되지 않았습니다. 백업의 \n일관성을 보장하거나 쉬운 복원 메커니즘을 제공하지 않습니다. \nD. 일일 백업 및 일관된 백업 보존에 대한 요구 사항을 다루지 않습니다. 백업 및 \n복원보다는 복제 및 변경 데이터 캡처에 더 중점을 둡니다. \n \n\n설명2: \nAWS Backup 은 사용자가 AWS 서비스 전체에서 데이터 백업을 중앙 집중화하고 자동화할 \n수 있는 완전 관리형 서비스입니다. 백업 빈도 및 보존 기간을 지정하는 백업 계획을 \n생성하고 관리할 수 있습니다. 또한 백업 데이터를 저장하는 컨테이너인 백업 볼트에 백업 \n리소스를 할당할 수도 있습니다\n1. 솔루션은 AWS Backup\n을 사용하여 RDS 백업이 \n일관되고 복원 가능하며 최소 2 년 동안 유지되도록 할 수 있습니다. \n1. 일일 스냅샷을 위해 RDS DB 인스턴스의 백업 기간을 구성합니다. 각 RDS DB \n인스턴스에 2 년의 스냅샷 보존 정책을 할당합니다. Amazon DLM(Amazon Data Lifecycle \nManager)을 사용하여 스냅샷 삭제를 예약합니다. Amazon DLM 은 RDS 스냅샷과 호환되지 \n않고 스냅샷 삭제를 예약하는 데 사용할 수 없기 때문에 이 솔루션은 백업의 일관성과 복원 \n가능성을 보장해야 하는 요구 사항을 충족하지 않습니다. \n2. 만료 기간이 2 년인 Amazon CloudWatch Logs 에 자동으로 백업되도록 데이터베이스 \n트랜잭션 로그를 구성합니다. 이 솔루션은 데이터베이스를 특정 시점으로 복원하는 데 \n데이터베이스 트랜잭션 로그가 충분하지 않기 때문에 백업이 일관되고 복원 가능한지 \n확인해야 하는 요구 사항을 충족하지 않습니다. 데이터베이스의 전체 상태가 아니라 \n데이터베이스에 대한 변경 사항만 캡처합니다. \n3. AWS Database Migration Service(AWS DMS) 복제 작업을 구성합니다. 복제 인스턴스를 \n배포하고 변경 데이터 캡처(CDC) 작업을 구성하여 데이터베이스 변경 사항을 대상으로 \nAmazon S3\n에 스트리밍합니다. 2\n년 후 스냅샷을 삭제하도록 S3 수명 주기 정책을 \n구성합니다. AWS DMS\n는 사용자가 데이터베이스를 백업하는 것이 아니라 AWS\n로 \n데이터베이스를 마이그레이션하는 데 도움이 되는 서비스이므로 이 솔루션은 백업의 \n일관성과 복원 가능성을 보장해야 하는 요구 사항을 충족하지 않습니다. 또한 복제 \n인스턴스 및 CDC 작업과 같은 추가 리소스 및 구성이 필요합니다. \n참조 URL: \nhttps://docs.aws.amazon.com/aws-backup/latest/devguide/whatisbackup.html", "answer_choice": "A"}, "260": {"q_num": 260, "question": "회사의 규정 준수 팀은 파일 공유를 AWS 로 이동해야 합니다. 공유는 Windows Server SMB \n파일 공유에서 실행됩니다. 자체 관리형 온프레미스 Active Directory 는 파일 및 폴더에 \n대한 액세스를 제어합니다. \n이 회사는 Windows File Server 용 Amazon FSx 를 솔루션의 일부로 사용하려고 합니다. \n회사는 온프레미스 Active Directory 그룹이 AWS 로 이동한 후 FSx for Windows File Server \nSMB 규정 준수 공유, 폴더 및 파일에 대한 액세스를 제한하는지 확인해야 합니다. 이 \n회사는 Windows 파일 서버 파일 시스템용 FSx 를 만들었습니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \n\nA. Active Directory 에 연결할 Active Directory 커넥터를 만듭니다. Active Directory 그룹을 \nIAM 그룹에 매핑하여 액세스를 제한합니다. \nB. 제한 태그 키와 규정 준수 태그 값을 사용하여 태그를 할당합니다. Active Directory \n그룹을 IAM 그룹에 매핑하여 액세스를 제한합니다. \nC. 액세스를 제한하기 위해 FSx for Windows File Server 에 직접 연결된 IAM 서비스 연결 \n역할을 생성합니다. \nD. 파일 시스템을 Active Directory 에 연결하여 액세스를 제한합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/95343-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nD. 파일 시스템이 인증 및 액세스 제어를 위해 기존 AD 인프라를 활용할 수 있습니다. \n \n이 시나리오에서는 AD 그룹을 IAM 그룹에 매핑하는 것이 적용되지 않기 때문에 옵션 A 가 \n올바르지 않습니다. IAM 은 주로 AWS 리소스에 대한 액세스를 관리하는 데 사용되지만 \n요구 사항은 액세스 제어를 위해 온프레미스 AD 와 통합하는 것입니다. \n \nRestrict 태그 키와 규정 준수 태그 값이 있는 태그를 할당하면 액세스 제어를 위해 \n온프레미스 AD 와의 필수 통합이 제공되지 않기 때문에 옵션 B 는 올바르지 않습니다. \n태그는 리소스를 구성하고 분류하는 데 사용되며 인증 또는 액세스 제어 메커니즘을 \n제공하지 않습니다. \n \nFSx for Windows File Server 에 직접 연결된 IAM 서비스 연결 역할 생성이 온프레미스 \nAD 와 통합되지 않기 때문에 옵션 C 는 올바르지 않습니다. IAM 역할은 권한 관리를 위해 \nAWS 내에서 사용되며 외부 AD 시스템과의 필수 통합을 제공하지 않습니다. \n \n설명2: \nFSx for Windows File Server 파일 시스템을 온프레미스 Active Directory 에 결합하면 \n회사에서 기존 Active Directory 그룹을 사용하여 AWS 로 이동한 후 파일 공유, 폴더 및 \n파일에 대한 액세스를 제한할 수 있습니다. 이 옵션을 사용하면 회사는 기존 액세스 제어 \n및 관리 구조를 계속 사용하여 AWS 로 보다 원활하게 전환할 수 있습니다.", "answer_choice": "D"}, "261": {"q_num": 261, "question": "한 회사가 최근 전 세계 고객을 대상으로 소매 웹 사이트를 배포한다고 발표했습니다. 웹 \n\n사이트는 Elastic Load Balancer 뒤에 있는 여러 Amazon EC2 인스턴스에서 실행됩니다. \n인스턴스는 여러 가용 영역의 Auto Scaling 그룹에서 실행됩니다. \n회사는 고객이 웹 사이트에 액세스하는 데 사용하는 장치에 따라 다양한 버전의 콘텐츠를 \n고객에게 제공하려고 합니다. \n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 작업 조합을 수행해야 합니까? \n(2 개 선택) \nA. 여러 버전의 콘텐츠를 캐시하도록 Amazon CloudFront 를 구성합니다. \nB. 트래픽을 다른 인스턴스로 전달하도록 Network Load Balancer 에서 호스트 헤더를 \n구성합니다. \nC. User-Agent 헤더를 기반으로 사용자에게 특정 객체를 보내도록 Lambda@Edge 함수를 \n구성합니다. \nD. AWS Global Accelerator\n를 구성합니다. NLB(Network Load Balancer)에 요청을 \n전달합니다. 다른 EC2 인스턴스에 대한 호스트 기반 라우팅을 설정하도록 NLB\n를 \n구성합니다. \nE. AWS Global Accelerator\n를 구성합니다. NLB(Network Load Balancer)에 요청을 \n전달합니다. 다른 EC2 인스턴스에 대한 경로 기반 라우팅을 설정하도록 NLB\n를 \n구성합니다.", "answer_block": "Answer: A, C \nhttps://www.examtopics.com/discussions/amazon/view/95011-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nA. 고객이 위치 및 장치 유형에 따라 적절한 버전의 콘텐츠를 받을 수 있습니다. \nC. Lambda@Edge 를 생성하면 들어오는 요청의 User-Agent 헤더를 검사하고 사용 중인 \n장치 유형을 확인할 수 있습니다. 이 정보를 기반으로 응답을 사용자 지정하고 적절한 \n버전의 콘텐츠를 사용자에게 보낼 수 있습니다. \nB. 장치 유형에 따라 다른 콘텐츠 버전을 제공해야 하는 요구 사항을 다루지 않습니다. \nD. & E.는 장치별 콘텐츠 요구 사항을 다루지 않습니다. \n \n따라서 옵션 A 와 C 는 고객이 웹 사이트에 액세스하는 데 사용하는 장치에 따라 다양한 \n버전의 콘텐츠를 제공해야 하는 요구 사항을 충족하기 위한 올바른 작업 조합입니다. \n \n설명 \nC 의 경우: 향상된 사용자 경험 Lambda@Edge 는 성능 저하 없이 콘텐츠를 개인화할 수 \n있도록 하여 전 세계 웹 사이트 및 웹 애플리케이션에 대한 사용자 경험을 개선하는 데 \n도움을 줄 수 있습니다. 실시간 이미지 변환 사용자 특성에 따라 즉시 이미지를 변환하여 \n\n사용자 경험을 사용자 정의할 수 있습니다. 예를 들어 뷰어의 장치 유형(모바일, 데스크톱 \n또는 태블릿)에 따라 이미지 크기를 조정할 수 있습니다. 또한 CloudFront Edge 위치에서 \n변환된 이미지를 캐싱하여 이미지를 제공할 때 성능을 더욱 향상시킬 수 있습니다.  \nhttps://aws.amazon.com/lambda/edge/", "answer_choice": "A"}, "262": {"q_num": 262, "question": "회사에서 다중 계층 웹 애플리케이션에 Amazon ElastiCache 를 사용할 계획입니다. 솔루션 \n설계자는 ElastiCache 클러스터용 캐시 VPC 와 애플리케이션의 Amazon EC2 인스턴스용 앱 \nVPC 를 생성합니다. 두 VPC 모두 us-east-1 리전에 있습니다. \n솔루션 설계자는 애플리케이션의 EC2 인스턴스에 ElastiCache 클러스터에 대한 액세스 \n권한을 제공하는 솔루션을 구현해야 합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. VPC 간에 피어링 연결을 생성합니다. 두 VPC 모두에서 피어링 연결을 위한 라우팅 \n테이블 항목을 추가합니다. 애플리케이션의 보안 그룹에서 인바운드 연결을 허용하도록 \nElastiCache 클러스터의 보안 그룹에 대한 인바운드 규칙을 구성합니다. \nB. 전송 VPC 를 생성합니다. 전송 VPC 를 통해 트래픽을 라우팅하도록 캐시 VPC 및 앱 \nVPC 의 VPC 라우팅 테이블을 업데이트합니다. 애플리케이션의 보안 그룹에서 인바운드 \n연결을 허용하도록 ElastiCache 클러스터의 보안 그룹에 대한 인바운드 규칙을 구성합니다. \nC. VPC 간에 피어링 연결을 생성합니다. 두 VPC 모두에서 피어링 연결을 위한 라우팅 \n테이블 항목을 추가합니다. 애플리케이션의 보안 그룹에서 인바운드 연결을 허용하도록 \n피어링 연결의 보안 그룹에 대한 인바운드 규칙을 구성합니다. \nD. 전송 VPC 를 생성합니다. 전송 VPC 를 통해 트래픽을 라우팅하도록 캐시 VPC 및 앱 \nVPC 의 VPC 라우팅 테이블을 업데이트합니다. 애플리케이션의 보안 그룹에서 인바운드 \n연결을 허용하도록 Transit VPC 의 보안 그룹에 대한 인바운드 규칙을 구성합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/95463-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nVPC 간에 피어링 연결을 생성하는 것은 연결을 설정하는 비용 효율적인 방법입니다. 두 \nVPC 에서 피어링 연결을 위한 라우팅 테이블 항목을 추가하면 두 VPC 간에 트래픽이 흐를 \n수 \n있습니다. \nElastiCache \n클러스터의 \n보안 \n그룹에서 \n인바운드 \n규칙을 \n구성하면 \n애플리케이션 보안 그룹의 인바운드 연결이 허용되어 앱 VPC\n의 EC2 인스턴스에서 \nElastiCache 클러스터에 액세스할 수 있습니다. \n옵션 B\n는 이 시나리오에 불필요한 복잡성과 비용을 추가하는 Transit VPC 생성을 \n\n제안합니다. \n옵션 C 는 인바운드 연결을 제어하는 데 ElastiCache 클러스터의 보안 그룹을 사용해야 \n하므로 필요하지 않은 피어링 연결의 보안 그룹에 대한 인바운드 규칙 구성을 제안합니다. \n옵션 D 는 Transit VPC 의 보안 그룹에 대한 인바운드 규칙 구성을 제안하며, 이는 이 \n경우에 필요하지 않으며 불필요한 복잡성을 추가합니다. \n따라서 옵션 A 는 애플리케이션의 EC2 인스턴스에 ElastiCache 클러스터에 대한 액세스 \n권한을 제공하는 가장 비용 효율적인 솔루션입니다. \n \n설명2: \n두 VPC 간에 피어링 연결을 생성하고 ElastiCache 클러스터의 보안 그룹에 대한 인바운드 \n규칙을 구성하여 애플리케이션의 보안 그룹에서 인바운드 연결을 허용하는 것이 가장 비용 \n효율적인 솔루션입니다. 피어링 연결은 무료이며 보안 그룹 규칙을 구성하는 비용만 \n발생합니다. Transit VPC 솔루션에는 추가 비용이 발생하는 추가 VPC 및 관련 리소스가 \n필요합니다. \nhttps://aws.amazon.com/certification/policies/before-testing/", "answer_choice": "A"}, "263": {"q_num": 263, "question": "회사에서 여러 마이크로서비스로 구성된 애플리케이션을 구축하고 있습니다. 이 회사는 \n컨테이너 기술을 사용하여 AWS 에 소프트웨어를 배포하기로 결정했습니다. 회사는 유지 \n관리 및 확장을 위한 지속적인 노력을 최소화하는 솔루션이 필요합니다. 회사는 추가 \n인프라를 관리할 수 없습니다. \n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 작업 조합을 수행해야 합니까? \n(2 개 선택) \nA. Amazon Elastic Container Service(Amazon ECS) 클러스터를 배포합니다. \nB. 여러 가용 영역에 걸쳐 있는 Amazon EC2 인스턴스에 Kubernetes 제어 평면을 \n배포합니다. \nC. Amazon EC2 시작 유형으로 Amazon Elastic Container Service(Amazon ECS) 서비스를 \n배포합니다. 2 보다 크거나 같은 원하는 태스크 번호 레벨을 지정하십시오. \nD. Fargate 시작 유형으로 Amazon Elastic Container Service(Amazon ECS) 서비스를 \n배포합니다. 2 보다 크거나 같은 원하는 태스크 번호 레벨을 지정하십시오. \nE. 여러 가용 영역에 걸쳐 있는 Amazon EC2 인스턴스에 Kubernetes 작업자 노드를 \n배포합니다. 각 마이크로 서비스에 대해 두 개 이상의 복제본을 지정하는 배포를 만듭니다.", "answer_block": "Answer: A, D \nhttps://www.examtopics.com/discussions/amazon/view/95012-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n\n \n설명1: \n옵션 B 와 E 는 Kubernetes 컨트롤 플레인과 작업자 노드를 EC2 인스턴스에 배포할 것을 \n제안합니다. 이렇게 하려면 노력을 최소화해야 한다는 요구 사항과 달리 인프라를 관리하고 \n지속적인 유지 관리 오버헤드를 추가해야 합니다. \n \n옵션 C 는 ECS 에 대해 Amazon EC2 시작 유형을 사용할 것을 제안합니다. 이 유형은 \n여전히 EC2 인스턴스 관리가 필요하고 Fargate 를 사용하는 것만큼 비용 효율적이고 확장 \n가능하지 않습니다. \n \n따라서 Amazon ECS 클러스터와 ECS 서비스를 Fargate 시작 유형(옵션 A 및 D)으로 \n배포하는 조합은 추가 인프라를 관리하지 않고 유지 관리 및 확장 노력을 최소화하는 데 \n가장 적합합니다. \n \n \n설명2: \nAWS Fargate\n는 Amazon EC2 인스턴스의 서버 또는 클러스터를 관리할 필요 없이 \n컨테이너를 실행하기 위해 Amazon ECS 와 함께 사용할 수 있는 기술입니다. Fargate 를 \n사용하면 더 이상 컨테이너를 실행하기 위해 가상 머신의 클러스터를 프로비저닝, 구성 \n또는 확장할 필요가 없습니다. \nhttps://docs.aws.amazon.com/AmazonECS/latest/userguide/what-is-fargate.html", "answer_choice": "A"}, "264": {"q_num": 264, "question": "회사에는 Amazon Route 53 에서 전달하는 트래픽이 있는 10 개 이상의 Amazon EC2 \n인스턴스를 호스팅하는 웹 애플리케이션이 있습니다. 회사에서 애플리케이션을 검색하려고 \n할 때 때때로 시간 초과 오류가 발생합니다. 네트워킹 팀은 일부 DNS 쿼리가 비정상 \n인스턴스의 IP 주소를 반환하여 시간 초과 오류가 발생했음을 발견했습니다. \n이러한 시간 초과 오류를 극복하기 위해 솔루션 설계자는 무엇을 구현해야 합니까? \nA. 각 EC2 인스턴스에 대해 Route 53 단순 라우팅 정책 레코드를 생성합니다. 상태 확인을 \n각 레코드와 연결합니다. \nB. 각 EC2 인스턴스에 대해 Route 53 장애 조치 라우팅 정책 레코드를 생성합니다. 상태 \n확인을 각 레코드와 연결합니다. \nC. EC2 인스턴스를 원본으로 사용하여 Amazon CloudFront 배포를 생성합니다. 상태 \n확인을 EC2 인스턴스와 연결합니다. \nD. EC2 인스턴스 앞에서 상태 확인을 통해 Application Load Balancer(ALB)를 생성합니다. \n\n루트 53 에서 ALB 로 이동합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/95345-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \n설계자는 ALB 를 생성하고 상태 확인을 구성하여 정상 인스턴스만 트래픽을 수신하도록 \n합니다. ALB 는 구성된 상태 확인 설정을 기반으로 EC2 인스턴스의 상태를 주기적으로 \n확인합니다. \nRoute 53 에서 ALB 로 트래픽을 라우팅하면 DNS 쿼리가 개별 인스턴스 대신 ALB 의 IP \n주소를 반환합니다. 이를 통해 ALB\n는 정상 인스턴스에만 트래픽을 분산하여 비정상 \n인스턴스로 인한 시간 초과를 방지할 수 있습니다. \nA & B: 상태 확인을 각 레코드와 연결하면 비정상 인스턴스를 식별하는 데 도움이 될 수 \n있지만 자동 로드 밸런싱 및 정상 인스턴스에 대한 트래픽 배포를 제공하지 않습니다. \nC: CloudFront 는 성능과 가용성을 향상시킬 수 있지만 기본적으로 CDN 이며 로드 밸런싱 \n및 정상 인스턴스에 대한 트래픽 분산 문제를 직접적으로 해결하지 못할 수 있습니다. \n따라서 옵션 D 는 상태 확인이 포함된 ALB 를 구현하고 Route 53 을 통해 트래픽을 \n라우팅하여 시간 초과 오류를 극복하는 데 가장 적합한 솔루션입니다. \n \n설명2: \nALB(Application Load Balancer)를 사용하면 들어오는 트래픽을 여러 백엔드 인스턴스에 \n분산하고 비정상 인스턴스에서 트래픽을 제거하면서 정상 인스턴스로 트래픽을 자동으로 \n라우팅할 수 있습니다. EC2 인스턴스 앞에 ALB 를 사용하고 Route 53 에서 ALB 로 트래픽을 \n라우팅함으로써 로드 밸런서는 인스턴스에 대한 상태 확인을 수행하고 정상 인스턴스로만 \n트래픽을 라우팅할 수 있으므로 비정상 인스턴스로 인한 시간 초과 오류를 줄이거나 \n제거하는 데 도움이 됩니다.", "answer_choice": "D"}, "265": {"q_num": 265, "question": "솔루션 \n설계자는 \n웹, \n애플리케이션 \n및 \n데이터베이스 \n계층으로 \n구성된 \n고가용성 \n애플리케이션을 설계해야 합니다. HTTPS 콘텐츠 전송은 전송 시간을 최소화하면서 가능한 \n한 에지에 가까워야 합니다. \n이러한 요구 사항을 충족하고 가장 안전한 솔루션은 무엇입니까? \nA. 퍼블릭 서브넷에서 여러 중복 Amazon EC2 인스턴스로 퍼블릭 Application Load \nBalancer(ALB)를 구성합니다. 퍼블릭 ALB\n를 오리진으로 사용하여 HTTPS 콘텐츠를 \n제공하도록 Amazon CloudFront 를 구성합니다. \n\nB. 프라이빗 서브넷에서 여러 중복 Amazon EC2 인스턴스로 퍼블릭 Application Load \nBalancer 를 구성합니다. EC2 인스턴스를 오리진으로 사용하여 HTTPS 콘텐츠를 제공하도록 \nAmazon CloudFront 를 구성합니다. \nC. 프라이빗 서브넷에서 여러 중복 Amazon EC2 인스턴스로 퍼블릭 ALB(Application Load \nBalancer)를 구성합니다. 퍼블릭 ALB 를 오리진으로 사용하여 HTTPS 콘텐츠를 제공하도록 \nAmazon CloudFront 를 구성합니다. \nD. 퍼블릭 서브넷에서 여러 중복 Amazon EC2 인스턴스로 퍼블릭 Application Load \nBalancer 를 구성합니다. EC2 인스턴스를 오리진으로 사용하여 HTTPS 콘텐츠를 제공하도록 \nAmazon CloudFront 를 구성합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/95013-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nA. EC2 인스턴스를 퍼블릭 인터넷에 직접 노출하므로 보안이 손상될 수 있습니다. \nB. 효율적인 부하 분산과 고가용성을 위해 필요한 퍼블릭 서브넷의 부하 분산 장치가 \n부족합니다. \nD. 로드 밸런싱 및 HTTPS 콘텐츠 전송을 제공하며 EC2 인스턴스를 공용 인터넷에 직접 \n노출하므로 보안 위험이 발생할 수 있습니다. \nC. 퍼블릭 ALB 를 오리진으로 하는 CloudFront 를 사용하여 고가용성, 프라이빗 서브넷을 \n통한 보안 액세스 및 최적화된 HTTPS 콘텐츠 전송을 제공합니다. \n \n설명2: \n이 솔루션은 웹, 애플리케이션 및 데이터베이스 계층이 있는 고가용성 애플리케이션에 대한 \n요구 사항을 충족할 뿐만 아니라 에지 기반 콘텐츠 전달을 제공합니다. 또한 웹 서버에 \n대한 직접 액세스를 제한하는 프라이빗 서브넷에 ALB 를 두어 보안을 최대화하는 동시에 \n퍼블릭 ALB 를 통해 인터넷을 통해 트래픽을 제공할 수 있습니다. 이렇게 하면 웹 서버가 \n공용 인터넷에 노출되지 않으므로 공격 표면이 줄어들고 애플리케이션에 안전하게 액세스할 \n수 있습니다.", "answer_choice": "C"}, "266": {"q_num": 266, "question": "회사에는 AWS 에서 실행되는 인기 있는 게임 플랫폼이 있습니다. 대기 시간은 사용자 \n경험에 영향을 미치고 일부 플레이어에게 부당한 이점을 제공할 수 있기 때문에 \n애플리케이션은 대기 시간에 민감합니다. 애플리케이션은 모든 AWS 리전에 배포됩니다. \nApplication Load Balancer(ALB) 뒤에 구성된 Auto Scaling 그룹의 일부인 Amazon EC2 \n\n인스턴스에서 실행됩니다. 솔루션 설계자는 애플리케이션의 상태를 모니터링하고 트래픽을 \n정상 엔드포인트로 리디렉션하는 메커니즘을 구현해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. AWS Global Accelerator 에서 액셀러레이터를 구성합니다. 애플리케이션이 청취하는 \n포트에 대한 리스너를 추가하고 각 리전의 리전 엔드포인트에 연결합니다. ALB\n를 \n엔드포인트로 추가하십시오. \nB. Amazon CloudFront 배포를 생성하고 ALB 를 원본 서버로 지정합니다. 원본 캐시 헤더를 \n사용하도록 \n캐시 \n동작을 \n구성합니다. \nAWS \nLambda \n함수를 \n사용하여 \n트래픽을 \n최적화하십시오. \nC. Amazon CloudFront 배포를 생성하고 Amazon S3 를 원본 서버로 지정합니다. 원본 캐시 \n헤더를 사용하도록 캐시 동작을 구성합니다. AWS Lambda 함수를 사용하여 트래픽을 \n최적화하십시오. \nD. 애플리케이션의 데이터 저장소 역할을 하도록 Amazon DynamoDB 데이터베이스를 \n구성합니다. 애플리케이션 데이터를 호스팅하는 DynamoDB 의 인 메모리 캐시 역할을 할 \nDynamoDB Accelerator(DAX) 클러스터를 생성합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/95014-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nB. CloudFront 는 캐싱 및 콘텐츠 전송에 도움이 될 수 있지만 애플리케이션의 상태를 \n모니터링하거나 상태 확인을 기반으로 트래픽 리디렉션을 수행하는 메커니즘을 제공하지 \n않습니다. \nC. 이 구성은 정적 콘텐츠 전달에 적합하지만 응용 프로그램의 상태 모니터링 및 트래픽 \n리디렉션 요구 사항을 다루지 않습니다. \nD. 이렇게 하면 성능이 향상될 수 있지만 애플리케이션의 상태를 모니터링하거나 상태 \n확인을 기반으로 트래픽을 리디렉션하지 않습니다. \n따라서 옵션 A 는 AWS Global Accelerator 를 활용하여 애플리케이션 상태를 모니터링하고, \n트래픽을 정상 엔드포인트로 라우팅하고, 지연 시간 문제를 해결하면서 사용자 경험을 \n최적화하므로 가장 적합한 솔루션입니다. \n \n설명2: \nAWS Global Accelerator 는 상태 확인을 기반으로 최적의 정상 엔드포인트로 트래픽을 \n전달하고 클라이언트의 지리적 위치를 기반으로 가장 가까운 정상 엔드포인트로 트래픽을 \n라우팅할 수도 있습니다. 액셀러레이터를 구성하고 이를 각 리전의 지역 엔드포인트에 \n연결하고 ALB\n를 엔드포인트로 추가함으로써 솔루션은 트래픽을 정상 엔드포인트로 \n\n리디렉션하여 대기 시간을 줄이고 애플리케이션이 최적으로 실행되도록 함으로써 사용자 \n경험을 개선합니다. 이 솔루션은 트래픽이 가장 가까운 정상 엔드포인트로 전달되도록 하고 \n전반적인 사용자 경험을 개선하는 데 도움이 됩니다.", "answer_choice": "A"}, "267": {"q_num": 267, "question": "회사에 모바일 앱을 사용하는 백만 명의 사용자가 있습니다. 회사는 거의 실시간으로 \n데이터 사용량을 분석해야 합니다. 회사는 또한 거의 실시간으로 데이터를 암호화하고 추가 \n처리를 위해 데이터를 Apache Parquet 형식의 중앙 위치에 저장해야 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Amazon Kinesis 데이터 스트림을 생성하여 Amazon S3\n에 데이터를 저장합니다. \n데이터를 분석할 Amazon Kinesis Data Analytics 애플리케이션을 생성합니다. AWS Lambda \n함수를 호출하여 데이터를 Kinesis Data Analytics 애플리케이션으로 보냅니다. \nB. Amazon Kinesis 데이터 스트림을 생성하여 Amazon S3\n에 데이터를 저장합니다. \n데이터를 분석할 Amazon EMR 클러스터를 생성합니다. AWS Lambda 함수를 호출하여 \n데이터를 EMR 클러스터로 보냅니다. \nC. Amazon Kinesis Data Firehose 전송 스트림을 생성하여 Amazon S3 에 데이터를 \n저장합니다. 데이터를 분석할 Amazon EMR 클러스터를 생성합니다. \nD. Amazon Kinesis Data Firehose 전송 스트림을 생성하여 Amazon S3 에 데이터를 \n저장합니다. 데이터를 분석할 Amazon Kinesis Data Analytics 애플리케이션을 생성합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/95347-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nA. 데이터를 분석 애플리케이션으로 보내려면 Lambda 를 호출해야 합니다. 이로 인해 \n추가적인 운영 오버헤드와 복잡성이 발생합니다. \n \nB. EMR 은 빅 데이터 처리를 위한 강력한 도구이지만 Kinesis Data Analytics 에 비해 더 \n많은 운영 관리 및 구성이 필요합니다. \n \nC. Kinesis Data Analytics 가 보다 간소화되고 자동화된 방식으로 분석을 수행할 때 데이터 \n분석에 EMR 을 포함하여 불필요한 복잡성을 도입합니다. \n \n따라서 옵션 D 는 데이터 수집에 Kinesis Data Firehose 를 활용하고 S3 에 데이터를 \n저장하며 거의 실시간 분석을 위해 Kinesis Data Analytics 를 활용하여 데이터 사용 분석 및 \n\n암호화를 위한 운영 오버헤드가 낮은 솔루션을 제공하므로 가장 적합한 솔루션입니다. . \n \n설명2: \n이 솔루션은 거의 실시간으로 데이터 수집, 데이터 변환, 암호화 및 데이터 저장을 \n자동으로 처리할 수 있는 완전관리형 서비스인 Amazon Kinesis Data Firehose\n를 \n사용하므로 최소한의 운영 오버헤드로 요구 사항을 충족합니다. Kinesis Data Firehose 는 \n추가 처리를 위해 Amazon S3 에 Apache Parquet 형식으로 데이터를 자동으로 저장할 수 \n있습니다. \n또한 Amazon Kinesis Data Analytics 애플리케이션을 생성하여 인프라를 관리하거나 \nLambda 함수를 호출할 필요 없이 거의 실시간으로 데이터를 분석할 수 있습니다. 이렇게 \n하면 최소한의 운영 오버헤드로 많은 양의 데이터를 처리할 수 있습니다.", "answer_choice": "D"}, "268": {"q_num": 268, "question": "게임 회사에는 점수를 표시하는 웹 애플리케이션이 있습니다. 애플리케이션은 Application \nLoad Balancer 뒤의 Amazon EC2 인스턴스에서 실행됩니다. 애플리케이션은 Amazon RDS \nfor MySQL 데이터베이스에 데이터를 저장합니다. 사용자는 데이터베이스 읽기 성능으로 \n인해 긴 지연과 중단을 경험하기 시작했습니다. 회사는 애플리케이션 아키텍처의 변경을 \n최소화하면서 사용자 경험을 개선하고자 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. 데이터베이스 앞에서 Amazon ElastiCache 를 사용하십시오. \nB. 애플리케이션과 데이터베이스 간에 RDS 프록시를 사용합니다. \nC. 애플리케이션을 EC2 인스턴스에서 AWS Lambda 로 마이그레이션합니다. \nD. \nMySQL\n용 \nAmazon \nRDS\n에서 \nAmazon \nDynamoDB\n로 \n데이터베이스를 \n마이그레이션합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/95016-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nA. ElastiCache 는 자주 액세스하는 데이터를 캐싱하여 읽기 성능을 향상시킬 수 있지만 \n애플리케이션 아키텍처를 변경해야 합니다. 또한 특히 애플리케이션의 데이터베이스 사용에 \n복잡한 쿼리 또는 빈번한 데이터 업데이트가 포함되는 경우 RDS Proxy 와 동일한 수준의 \n읽기 성능 향상을 제공하지 못할 수 있습니다. \nC. Lambda\n는 확장성 및 운영 오버헤드 감소와 같은 이점을 제공할 수 있지만 \n데이터베이스 \n읽기 \n성능 \n문제를 \n직접 \n해결하지 \n못할 \n수 \n있습니다. \nLambda\n로 \n\n마이그레이션하려면 애플리케이션의 아키텍처 및 코드베이스를 크게 변경해야 합니다. \nD. DynamoDB 는 확장 가능한 고성능 NoSQL 데이터베이스이지만 MySQL 과 같은 관계형 \n데이터베이스에서 DynamoDB 로 마이그레이션하려면 애플리케이션의 데이터 모델과 쿼리 \n패턴을 크게 변경해야 합니다. \n따라서 옵션 B 는 RDS Proxy 를 활용하여 데이터베이스 연결을 최적화하고 읽기 성능을 \n개선하고 애플리케이션 아키텍처의 변경을 최소화하며 데이터베이스 읽기 성능 문제를 \n해결하기 위한 확장 가능하고 효율적인 솔루션을 제공하므로 가장 적합한 솔루션입니다.", "answer_choice": "B"}, "269": {"q_num": 269, "question": "전자 상거래 회사는 Amazon RDS 기반 웹 애플리케이션의 성능 저하를 발견했습니다. 성능 \n저하의 원인은 비즈니스 분석가가 트리거하는 읽기 전용 SQL 쿼리 수가 증가했기 \n때문입니다. 솔루션 설계자는 기존 웹 애플리케이션에 대한 최소한의 변경으로 문제를 \n해결해야 합니다. \n솔루션 설계자는 무엇을 추천해야 합니까? \nA. 데이터를 Amazon DynamoDB\n로 내보내고 비즈니스 분석가가 쿼리를 실행하도록 \n합니다. \nB. Amazon ElastiCache\n에 데이터를 로드하고 비즈니스 분석가가 쿼리를 실행하도록 \n합니다. \nC. 기본 데이터베이스의 읽기 복제본을 생성하고 비즈니스 분석가가 쿼리를 실행하도록 \n합니다. \nD. 데이터를 Amazon Redshift 클러스터로 복사하고 비즈니스 분석가가 쿼리를 실행하도록 \n합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/95032-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \nA. DynamoDB 는 확장 가능한 NoSQL 데이터베이스이지만 애플리케이션의 데이터 모델 및 \n쿼리 패턴을 변경해야 합니다. \nB. ElastiCache 는 쿼리 성능을 향상시킬 수 있는 인메모리 데이터 저장소이지만 주로 \n복잡한 쿼리를 실행하기보다는 캐싱에 사용됩니다. \nD. Redshift 는 강력한 데이터 웨어하우징 솔루션이지만 데이터를 마이그레이션하고 쿼리를 \nRedshift 의 열 기반 아키텍처에 적용하려면 애플리케이션 및 쿼리 논리를 크게 변경해야 \n합니다. \n따라서 옵션 C 는 RDS 의 읽기 전용 복제본을 활용하여 기본 데이터베이스에서 읽기 전용 \n\n쿼리 트래픽을 오프로드하므로 비즈니스 분석가가 웹 애플리케이션의 성능에 영향을 주지 \n않고 쿼리를 실행할 수 있으므로 가장 적합한 권장 사항입니다. 기존 웹 애플리케이션에 \n대한 최소한의 변경으로 확장 가능하고 효율적인 솔루션을 제공합니다. \n \n설명2: \n기본 RDS 데이터베이스의 읽기 복제본을 생성하면 기본 데이터베이스에서 읽기 전용 SQL \n쿼리를 오프로드하여 웹 애플리케이션의 성능을 향상시키는 데 도움이 됩니다. 읽기 \n복제본은 읽기 전용 트래픽을 처리하는 데 사용할 수 있는 기본 데이터베이스의 정확한 \n복사본으로, 기본 데이터베이스의 부하를 줄이고 웹 애플리케이션의 성능을 향상시킵니다. \n이 솔루션은 기존 웹 애플리케이션에 대한 최소한의 변경으로 구현할 수 있습니다. \n분석가는 코드를 수정하지 않고 읽기 복제본에서 쿼리를 계속 실행할 수 있습니다.", "answer_choice": "C"}, "270": {"q_num": 270, "question": "회사는 중앙 집중식 AWS 계정을 사용하여 다양한 Amazon S3 버킷에 로그 데이터를 \n저장합니다. 솔루션 설계자는 데이터가 S3 버킷에 업로드되기 전에 미사용 데이터가 \n암호화되었는지 확인해야 합니다. 또한 데이터는 전송 중에 암호화되어야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 클라이언트 측 암호화를 사용하여 S3 버킷에 업로드되는 데이터를 암호화합니다. \nB. 서버 측 암호화를 사용하여 S3 버킷에 업로드되는 데이터를 암호화합니다. \nC. S3 업로드를 위해 S3 관리형 암호화 키(SSE-S3)로 서버 측 암호화를 사용해야 하는 \n버킷 정책을 만듭니다. \nD. 기본 AWS Key Management Service(AWS KMS) 키를 사용하여 S3 버킷을 암호화하는 \n보안 옵션을 활성화합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/95031-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n클라이언트 측 암호화는 데이터를 Amazon S3 에 업로드하기 전에 데이터를 암호화하는 \n방법입니다. 이를 통해 사용자는 암호화 프로세스, 암호화 키 및 관련 도구를 관리할 수 \n있습니다. 클라이언트 측 암호화를 사용하면 Amazon S3 가 암호화 키나 암호화되지 않은 \n데이터에 액세스할 수 없기 때문에 솔루션은 유휴 및 전송 중에 데이터를 암호화할 수 \n있습니다.", "answer_choice": "A"}, "271": {"q_num": 271, "question": "솔루션 설계자는 원하는 Amazon EC2 용량에 도달하기 전에 야간 배치 처리 작업이 1 시간 \n동안 자동으로 확장되는 것을 관찰합니다. 최대 용량은 '매일 밤 동일하고 배치 작업은 \n항상 오전 1 시에 시작됩니다. 솔루션 설계자는 원하는 EC2 용량에 빠르게 도달하고 배치 \n작업이 완료된 후 Auto Scaling 그룹이 축소될 수 있는 비용 효율적인 솔루션을 찾아야 \n합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. Auto Scaling 그룹의 최소 용량을 늘립니다. \nB. Auto Scaling 그룹의 최대 용량을 늘립니다. \nC. 원하는 컴퓨팅 수준으로 확장하도록 예약된 확장을 구성합니다. \nD. 각 조정 작업 중에 더 많은 EC2 인스턴스를 추가하도록 조정 정책을 변경합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/95018-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n예약된 조정을 구성하여 솔루션 설계자는 배치 작업이 시작될 때 특정 시간(IAM)에 원하는 \n컴퓨팅 수준으로 자동으로 확장한 다음 작업이 완료되면 자동으로 축소하도록 Auto Scaling \n그룹을 설정할 수 있습니다. 이렇게 하면 원하는 EC2 용량에 빠르게 도달할 수 있고 비용 \n절감에도 도움이 됩니다.", "answer_choice": "C"}, "272": {"q_num": 272, "question": "회사는 Application Load Balancer(ALB) 뒤에 있는 Amazon EC2 인스턴스 플릿에서 동적 \n웹 사이트를 제공합니다. 웹 사이트는 전 세계 고객에게 서비스를 제공하기 위해 여러 \n언어를 지원해야 합니다. 웹 사이트의 아키텍처는 us-west-1 지역에서 실행 중이며 세계의 \n다른 지역에 있는 사용자에 대해 높은 요청 지연 시간을 보이고 있습니다. \n웹사이트는 사용자의 위치에 관계없이 빠르고 효율적으로 요청을 처리해야 합니다. 그러나 \n회사는 여러 지역에 걸쳐 기존 아키텍처를 다시 생성하기를 원하지 않습니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. 기존 아키텍처를 Amazon S3 버킷에서 제공되는 웹 사이트로 교체하십시오. S3 버킷을 \n오리진으로 사용하여 Amazon CloudFront 배포를 구성합니다. Accept-Language 요청 \n헤더를 기반으로 캐시 동작 설정을 캐시로 설정합니다. \nB. ALB 를 오리진으로 사용하여 Amazon CloudFront 배포를 구성합니다. Accept-Language \n요청 헤더를 기반으로 캐시 동작 설정을 캐시로 설정합니다. \nC. ALB 와 통합되는 Amazon API Gateway API 를 생성합니다. HTTP 통합 유형을 사용하도록 \n\nAPI 를 구성합니다. Accept-Language 요청 헤더를 기반으로 API 캐시를 활성화하도록 API \nGateway 단계를 설정합니다. \nD. 각 추가 지역에서 EC2 인스턴스를 시작하고 해당 지역의 캐시 서버 역할을 하도록 \nNGINX 를 구성합니다. 지리적 위치 라우팅 정책을 사용하여 Amazon Route 53 레코드 세트 \n뒤에 모든 EC2 인스턴스와 ALB 를 배치합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/99865-exam-aws-certified-solut\nions-architect-associate-saa-c03/", "answer_choice": "B"}, "273": {"q_num": 273, "question": "빠르게 성장하는 전자상거래 회사는 단일 AWS 리전에서 워크로드를 실행하고 있습니다. \n솔루션 설계자는 다른 AWS 리전을 포함하는 재해 복구(DR) 전략을 생성해야 합니다. \n회사는 대기 시간을 최소화하면서 DR 지역에서 데이터베이스를 최신 상태로 유지하기를 \n원합니다. DR 지역의 나머지 인프라는 감소된 용량으로 실행되어야 하며 필요한 경우 \n확장할 수 있어야 합니다. \n가장 낮은 RTO(복구 시간 목표)로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 파일럿 라이트 배포와 함께 Amazon Aurora 글로벌 데이터베이스를 사용합니다. \nB. 웜 대기 배포와 함께 Amazon Aurora 글로벌 데이터베이스를 사용합니다. \nC. 파일럿 라이트 배포와 함께 Amazon RDS 다중 AZ DB 인스턴스를 사용합니다. \nD. 웜 대기 배포와 함께 Amazon RDS 다중 AZ DB 인스턴스를 사용합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/99505-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n・웜 스탠바이는 감소된 수준의 트래픽을 즉시 처리할 수 있습니다. 그런 다음 이 기존 \n배포를 확장해야 하므로 파일럿 라이트보다 RTO 시간이 더 짧습니다. 파일럿 라이트를 \n사용하려면 먼저 인프라를 배포한 다음 워크로드가 요청을 처리할 수 있기 전에 리소스를 \n확장해야 하기 때문입니다. \nhttps://aws.amazon.com/ko/blogs/architecture/disaster-recovery-dr-architecture-on-aw\ns-part-iii-pilot-light-and-warm-standby/ \nA(X) : 파일럿 라이트를 사용하기 때문에 오답. \nB(O) : Amazon Aurora 글로벌 데이터베이스는 여러 리전에 걸쳐 자동으로 복제를 진행 \nAmazon Aurora Global Database 는 단일 Amazon Aurora 데이터베이스를 여러 AWS \n리전으로 확장할 수 있는 기능입니다. 데이터베이스 성능에 전혀 영향을 주지 않고 \n\n데이터를 복제하고, 각 리전에서 보통 1 초 미만의 짧은 대기 시간으로 빠른 로컬 읽기를 \n지원하며, \n리전 \n규모의 \n가동 \n중단 \n발생 \n시 \n재해 \n복구를 \n제공합니다.\"\" \nhttps://aws.amazon.com/ko/rds/aurora/faqs/ \nC(X) : 파일럿 라이트를 사용하기 때문에 오답. \nD(X) : RDS Multi AZ 는 동일 리전 내로 한정됨. \nAmazon RDS 다중 AZ 배포는 단일 AWS 리전 내의 데이터베이스 인스턴스에 대한 향상된 \n가용성을 제공합니다. \nhttps://aws.amazon.com/ko/about-aws/whats-new/2018/01/amazon-rds-read-replicas-\nnow-support-multi-az-deployments/", "answer_choice": "B"}, "274": {"q_num": 274, "question": "회사는 Amazon EC2 인스턴스에서 애플리케이션을 실행합니다. 회사는 애플리케이션에 \n재해 복구(DR) 솔루션을 구현해야 합니다. DR 솔루션은 RTO(복구 시간 목표)가 4 시간 \n미만이어야 합니다. 또한 DR 솔루션은 정상 작동 중에 가능한 한 적은 AWS 리소스를 \n사용해야 합니다. \n운영상 가장 효율적인 방식으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Amazon 머신 이미지(AMI)를 생성하여 EC2 인스턴스를 백업합니다. AMI 를 보조 AWS \n리전에 복사합니다. AWS Lambda 및 사용자 지정 스크립트를 사용하여 보조 리전에서 \n인프라 배포를 자동화합니다. \nB. Amazon 머신 이미지(AMI)를 생성하여 EC2 인스턴스를 백업합니다. AMI 를 보조 AWS \n리전에 복사합니다. AWS CloudFormation\n을 사용하여 보조 리전에서 인프라 배포를 \n자동화합니다. \nC. 보조 AWS 리전에서 EC2 인스턴스를 시작합니다. 보조 리전의 EC2 인스턴스를 항상 \n활성 상태로 유지하십시오. \nD. 보조 가용 영역에서 EC2 인스턴스를 시작합니다. 보조 가용 영역의 EC2 인스턴스를 \n항상 활성 상태로 유지합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/99459-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n이를 통해 회사는 RTO(복구 시간 목표)가 4 시간 미만이고 정상 운영 중에 AWS 리소스를 \n최대한 적게 사용하는 애플리케이션에 대한 재해 복구(DR) 솔루션을 구현할 수 있습니다. \nAmazon 머신 이미지(AMI)를 생성하여 EC2 인스턴스를 백업하고 AMI 를 보조 AWS 리전에 \n복사함으로써 회사는 애플리케이션의 특정 시점 스냅샷을 생성하고 이를 다른 지리적 \n\n위치에 저장할 수 있습니다. AWS CloudFormation 을 사용하여 보조 지역의 인프라 배포를 \n자동화함으로써 회사는 재해 발생 시 템플릿에서 리소스 스택을 신속하게 시작할 수 \n있습니다. 이는 EC2 인스턴스용 DR 솔루션을 구현하는 비용 효율적이고 운영 효율적인 \n방법입니다.", "answer_choice": "B"}, "275": {"q_num": 275, "question": "회사에서 내부 브라우저 기반 애플리케이션을 실행합니다. 애플리케이션은 Application \nLoad Balancer 뒤의 Amazon EC2 인스턴스에서 실행됩니다. 인스턴스는 여러 가용 영역에 \n걸쳐 Amazon EC2 Auto Scaling 그룹에서 실행됩니다. Auto Scaling 그룹은 근무 시간 동안 \n최대 20\n개의 인스턴스로 확장되지만 밤에는 2\n개의 인스턴스로 축소됩니다. 오전 \n중반까지는 잘 돌아가는데도 하루가 시작되면 애플리케이션이 매우 느리다고 직원들이 \n불평하고 있다. \n직원 불만을 해결하고 비용을 최소화하기 위해 확장을 어떻게 변경해야 합니까? \nA. 사무실이 열리기 직전에 원하는 수용 인원을 20\n명으로 설정하는 예약 작업을 \n구현합니다. \nB. 더 낮은 CPU 임계값에서 트리거되는 단계 조정 작업을 구현하고 휴지 기간을 줄입니다. \nC. 더 낮은 CPU 임계값에서 트리거되는 대상 추적 작업을 구현하고 휴지 기간을 줄입니다. \nD. 사무실이 열리기 직전에 최소 및 최대 수용 인원을 20 명으로 설정하는 예약 조치를 \n구현합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/99584-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n이 옵션은 아침에 용량을 더 빠르게 확장하여 성능을 개선하지만 작업 외 시간에도 여전히 \n용량을 축소할 수 있습니다. 다음과 같이 이를 달성합니다. \n* 대상 추적 작업은 CPU 사용률 대상에 따라 확장됩니다. 아침에 더 낮은 CPU 임계값에서 \n트리거함으로써 Auto Scaling 그룹은 트래픽이 증가함에 따라 더 빨리 확장을 시작하여 \n사용률이 너무 높아져 성능에 영향을 미치기 전에 인스턴스를 시작합니다. \n* 휴지 기간을 줄이면 Auto Scaling 이 보다 적극적으로 확장하여 목표에 도달할 때까지 더 \n많은 인스턴스를 더 빠르게 시작할 수 있습니다. 이렇게 하면 용량 증가 속도가 \n빨라집니다. \n* 그러나 고정된 최소/최대 용량을 설정하는 예약된 작업과 달리 대상 추적을 사용하면 \n수요에 따라 근무 외 시간에도 그룹을 축소할 수 있습니다. 이는 비용을 최소화하는 데 \n도움이 됩니다.", "answer_choice": "C"}, "276": {"q_num": 276, "question": "한 회사에 Auto Scaling 그룹의 여러 Amazon EC2 인스턴스에 배포된 다중 계층 \n애플리케이션이 있습니다. Amazon RDS for Oracle 인스턴스는 Oracle 관련 PL/SQL 기능을 \n사용하는 애플리케이션의 데이터 계층입니다. 애플리케이션에 대한 트래픽은 꾸준히 \n증가하고 있습니다. 이로 인해 EC2 인스턴스가 과부하되고 RDS 인스턴스의 스토리지가 \n부족해집니다. Auto Scaling 그룹에는 조정 지표가 없으며 최소 정상 인스턴스 수만 \n정의합니다. 이 회사는 트래픽이 안정되기 전에 꾸준하지만 예측할 수 없는 속도로 계속 \n증가할 것이라고 예측합니다. \n증가된 트래픽에 대해 시스템이 자동으로 확장될 수 있도록 하려면 솔루션 설계자가 무엇을 \n해야 합니까? (2 개 선택) \nA. RDS for Oracle 인스턴스에서 스토리지 Auto Scaling 을 구성합니다. \nB. \nAuto \nScaling \n스토리지를 \n사용하려면 \n데이터베이스를 \nAmazon \nAurora\n로 \n마이그레이션하십시오. \nC. 사용 가능한 저장 공간 부족에 대해 Oracle 인스턴스용 RDS 에서 경보를 구성합니다. \nD. 평균 CPU 를 조정 지표로 사용하도록 Auto Scaling 그룹을 구성합니다. \nE. 평균 여유 메모리를 조정 지표로 사용하도록 Auto Scaling 그룹을 구성합니다.", "answer_block": "Answer: A, D \nhttps://www.examtopics.com/discussions/amazon/view/99739-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nAuto Scaling Storage RDS 는 스토리지 문제를 완화하고 Oracle Pl/Sql 을 Aurora 로 \n마이그레이션하는 것은 번거롭습니다. 또한 Aurora 에는 기본적으로 자동 스토리지 확장 \n기능이 있습니다. \nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PIOPS.StorageTypes.\nhtml#USER_PIOPS.Autoscaling", "answer_choice": "A"}, "277": {"q_num": 277, "question": "회사는 \n비디오 \n콘텐츠를 \n게시하고 \n모든 \n모바일 \n플랫폼에서 \n사용할 \n수 \n있도록 \n트랜스코딩하는 온라인 서비스를 제공합니다. 애플리케이션 아키텍처는 Amazon Elastic File \nSystem(Amazon EFS) Standard 를 사용하여 여러 Amazon EC2 Linux 인스턴스가 처리를 \n위해 비디오 콘텐츠에 액세스할 수 있도록 비디오를 수집하고 저장합니다. 시간이 지남에 \n따라 서비스의 인기가 높아짐에 따라 스토리지 비용이 너무 비싸졌습니다. \n\n가장 비용 효율적인 스토리지 솔루션은 무엇입니까? \nA. 파일용 AWS Storage Gateway 를 사용하여 동영상 콘텐츠를 저장하고 처리합니다. \nB. 볼륨에 AWS Storage Gateway 를 사용하여 비디오 콘텐츠를 저장하고 처리합니다. \nC. Amazon EFS 를 사용하여 비디오 콘텐츠를 저장합니다. 처리가 완료되면 파일을 Amazon \nElastic Block Store(Amazon EBS)로 전송합니다. \nD. 동영상 콘텐츠 저장을 위해 Amazon S3 를 사용합니다. 처리를 위해 파일을 서버에 \n연결된 Amazon Elastic Block Store(Amazon EBS) 볼륨으로 임시로 이동합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/99509-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n* 비디오 콘텐츠의 대규모, 내구성 및 저렴한 스토리지를 위한 Amazon S3. S3 스토리지 \n비용은 EFS 보다 훨씬 저렴합니다. \n* Amazon EBS 는 처리 중에 일시적으로만 가능합니다. 비디오를 처리해야 할 때만 EBS \n볼륨을 마운트하고 그 후에 마운트를 해제함으로써 컨텐츠가 고가의 EBS 스토리지에 \n소요되는 시간을 최소화합니다. \n* EBS 볼륨은 활성 처리에 필요한 워크로드에 맞게 크기를 조정하여 비용을 낮출 수 \n있습니다. 볼륨은 전체 비디오 라이브러리를 장기간 저장할 필요가 없습니다.", "answer_choice": "D"}, "278": {"q_num": 278, "question": "회사에서 계층적 구조 관계로 직원 데이터를 저장하는 애플리케이션을 만들고자 합니다. \n회사는 직원 데이터에 대한 트래픽이 많은 쿼리에 대한 최소 대기 시간 응답이 필요하며 \n민감한 데이터를 보호해야 합니다. 회사는 또한 직원 데이터에 재무 정보가 있는 경우 월별 \n이메일 메시지를 받아야 합니다. \n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 단계 조합을 수행해야 합니까? \n(2 개 선택) \nA. Amazon Redshift 를 사용하여 직원 데이터를 계층에 저장하십시오. 매월 Amazon S3 에 \n데이터를 언로드합니다. \nB. Amazon DynamoDB 를 사용하여 직원 데이터를 계층에 저장합니다. 매월 데이터를 \nAmazon S3 로 내보냅니다. \nC. AWS 계정에 대해 Amazon Macie 를 구성합니다. Macie 를 Amazon EventBridge 와 \n통합하여 월별 이벤트를 AWS Lambda 로 전송합니다. \nD. Amazon Athena 를 사용하여 Amazon S3 에서 직원 데이터를 분석합니다. Athena 를 \nAmazon QuickSight\n와 통합하여 분석 대시보드를 게시하고 사용자와 대시보드를 \n\n공유합니다. \nE. AWS 계정에 대해 Amazon Macie 를 구성합니다. Macie 를 Amazon EventBridge 와 \n통합하여 Amazon Simple Notification Service(Amazon SNS) 구독을 통해 월별 알림을 \n보냅니다.", "answer_block": "Answer: B, E \nhttps://www.examtopics.com/discussions/amazon/view/99940-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n참고: \nhttps://docs.aws.amazon.com/ko_kr/prescriptive-guidance/latest/dynamodb-hierarchical\n-data-model/introduction.html", "answer_choice": "B"}, "279": {"q_num": 279, "question": "회사에 Amazon DynamoDB 테이블이 지원하는 애플리케이션이 있습니다. 회사의 규정 \n준수 요구 사항은 데이터베이스 백업을 매월 수행하고 6 개월 동안 사용할 수 있어야 하며 \n7 년 동안 유지해야 한다고 지정합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 매월 1 일에 DynamoDB 테이블을 백업하는 AWS Backup 계획을 생성합니다. 6 개월 후 \n백업을 콜드 스토리지로 전환하는 수명 주기 정책을 지정합니다. 각 백업의 보존 기간을 \n7 년으로 설정합니다. \nB. 매월 1 일에 DynamoDB 테이블의 DynamoDB 온디맨드 백업을 생성합니다. 6 개월 후 \n백업을 Amazon S3 Glacier Flexible Retrieval 로 전환합니다. 7 년보다 오래된 백업을 \n삭제하려면 S3 수명 주기 정책을 생성하십시오. \nC. AWS SDK 를 사용하여 DynamoDB 테이블의 온디맨드 백업을 생성하는 스크립트를 \n개발합니다. 매월 1 일에 스크립트를 실행하는 Amazon EventBridge 규칙을 설정합니다. \n6 개월 이상 된 DynamoDB 백업을 콜드 스토리지로 전환하고 7 년 이상 된 백업을 \n삭제하기 위해 매월 2 일에 실행할 두 번째 스크립트를 생성합니다. \nD. AWS CLI 를 사용하여 DynamoDB 테이블의 온디맨드 백업을 생성합니다. Cron 표현식을 \n사용하여 매월 1 일에 명령을 실행하는 Amazon EventBridge 규칙을 설정합니다. 6 개월 후 \n백업을 콜드 스토리지로 전환하고 7 년 후 백업을 삭제하도록 명령에 지정합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/99793-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n\n이 솔루션은 다음과 같은 요구 사항을 충족합니다. \n* AWS Backup 은 백업 계획에 정의된 일정(매월 1 일)에 따라 DynamoDB 테이블의 전체 \n백업을 자동으로 수행합니다. \n* 수명 주기 정책은 6 개월 후에 백업을 콜드 스토리지로 전환하여 해당 요구 사항을 \n충족할 수 있습니다. \n* 백업 계획에서 7 년 보존 기간을 설정하면 필요에 따라 각 백업이 7 년 동안 보존됩니다. \n* AWS Backup 은 백업 작업 및 수명 주기 정책을 관리하므로 사용자 지정 스크립팅 또는 \n관리가 필요하지 않습니다.", "answer_choice": "A"}, "280": {"q_num": 280, "question": "회사는 웹 사이트에서 Amazon CloudFront\n를 사용하고 있습니다. 회사는 CloudFront \n배포에서 로깅을 활성화했으며 로그는 회사의 Amazon S3 버킷 중 하나에 저장됩니다. \n회사는 로그에 대한 고급 분석을 수행하고 시각화를 구축해야 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. Amazon Athena\n에서 표준 SQL 쿼리를 사용하여 S3 버킷의 CloudFront 로그를 \n분석합니다. AWS Glue 로 결과를 시각화합니다. \nB. Amazon Athena\n에서 표준 SQL 쿼리를 사용하여 S3 버킷의 CloudFront 로그를 \n분석합니다. Amazon QuickSight 로 결과를 시각화합니다. \nC. Amazon DynamoDB 에서 표준 SQL 쿼리를 사용하여 S3 버킷의 CloudFront 로그를 \n분석합니다. AWS Glue 로 결과를 시각화합니다. \nD. Amazon DynamoDB 에서 표준 SQL 쿼리를 사용하여 S3 버킷의 CloudFront 로그를 \n분석합니다. Amazon QuickSight 로 결과를 시각화합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/99508-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nhttps://docs.aws.amazon.com/quicksight/latest/user/welcome.html \nAthena 를 사용하여 S3 버킷의 CloudFront 로그를 쿼리하고 QuickSight 를 사용하여 결과를 \n시각화하는 것이 비용 효율적이고 확장 가능하며 인프라 설정이 필요하지 않기 때문에 \n최상의 솔루션입니다. 또한 전담 개발자 팀 없이 회사에서 고급 분석을 수행하고 대화형 \n시각화를 구축할 수 있는 강력한 솔루션을 제공합니다.", "answer_choice": "B"}, "281": {"q_num": 281, "question": "회사는 PostgreSQL DB 인스턴스용 Amazon RDS 를 사용하여 웹 서버 플릿을 실행합니다. \n일상적인 규정 준수 검사 후 회사는 모든 프로덕션 데이터베이스에 대해 1 초 미만의 복구 \n지점 목표(RPO)를 요구하는 표준을 설정합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. DB 인스턴스에 대해 다중 AZ 배포를 활성화합니다. \nB. 하나의 가용 영역에서 DB 인스턴스에 대해 Auto Scaling 을 활성화합니다. \nC. 하나의 가용 영역에서 DB 인스턴스를 구성하고 별도의 가용 영역에서 여러 읽기 전용 \n복제본을 생성합니다. \nD. 하나의 가용 영역에서 DB 인스턴스를 구성하고 AWS DMS(AWS Database Migration \nService) 변경 데이터 캡처(CDC) 작업을 구성합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/99511-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n이 옵션은 다른 가용 영역에 있는 대기 인스턴스에 데이터를 자동으로 복제하여 RDS \n데이터베이스 인스턴스에 향상된 가용성과 내구성을 제공하는 DB 인스턴스용 다중 AZ \n배포를 사용하기 때문에 가장 효율적입니다. 또한 대기 인스턴스가 동기식 물리적 복제를 \n사용하여 기본 인스턴스와 동기화 상태를 유지하므로 모든 프로덕션 데이터베이스에 대해 \n1\n초 \n미만의 \n복구 \n지점 \n목표(RPO)를 \n제공합니다. \n이 \n솔루션은 \n모든 \n프로덕션 \n데이터베이스에 대해 1 초 미만의 RPO 요구 사항을 충족합니다. \n옵션 B 는 로드 또는 일정에 따라 DB 인스턴스의 컴퓨팅 용량을 자동으로 조정하는 방법인 \n하나의 가용 영역에서 DB 인스턴스에 대해 Auto Scaling 을 사용하기 때문에 효율성이 \n떨어집니다. \n그러나 이것은 데이터를 다른 가용 영역에 복제하지 않기 때문에 모든 프로덕션 \n데이터베이스에 대해 1 초 미만의 RPO 를 제공하지 않습니다. \n옵션 C 는 읽기 트래픽을 제공하고 조정을 지원할 수 있는 기본 데이터베이스의 읽기 전용 \n복사본인 별도의 가용 영역에서 읽기 전용 복제본을 사용하기 때문에 효율성이 떨어집니다. \n그러나 읽기 전용 복제본은 비동기식 복제를 사용하고 기본 데이터베이스보다 지연될 수 \n있으므로 모든 프로덕션 데이터베이스에 대해 1 초 미만의 RPO 를 제공하지 않습니다. \n옵션 D 는 원본 데이터에 대한 변경 사항을 캡처하고 대상 데이터에 적용하는 작업인 AWS \nDMS(AWS Database Migration Service) 변경 데이터 캡처(CDC) 작업을 사용하기 때문에 \n효율성이 \n떨어집니다. \n그러나 \nAWS \nDMS\n는 \n비동기식 \n복제를 \n사용하고 \n소스 \n데이터베이스보다 지연될 수 있으므로 모든 프로덕션 데이터베이스에 대해 1 초 미만의 \nRPO 를 제공하지 않습니다.", "answer_choice": "A"}, "282": {"q_num": 282, "question": "회사는 VPC의 프라이빗 서브넷에 있는 Amazon EC2 인스턴스에 배포된 웹 애플리케이션을 \n실행합니다. 퍼블릭 서브넷에서 확장되는 ALB(Application Load Balancer)는 웹 트래픽을 \nEC2 인스턴스로 보냅니다. 회사는 ALB\n에서 EC2 인스턴스로의 인바운드 트래픽을 \n제한하는 동시에 EC2 인스턴스의 프라이빗 서브넷 내부 또는 외부의 다른 소스로부터의 \n액세스를 방지하는 새로운 보안 조치를 구현하려고 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 인터넷에서 EC2 인스턴스의 프라이빗 IP 주소로 트래픽을 보내도록 라우팅 테이블의 \n경로를 구성합니다. \nB. ALB\n의 보안 그룹에서 오는 트래픽만 허용하도록 EC2 인스턴스의 보안 그룹을 \n구성합니다. \nC. EC2 인스턴스를 퍼블릭 서브넷으로 이동합니다. EC2 인스턴스에 탄력적 IP 주소 집합을 \n제공합니다. \nD. 모든 포트에서 모든 TCP 트래픽을 허용하도록 ALB 에 대한 보안 그룹을 구성합니다.", "answer_block": "Answer: B  \nhttps://www.examtopics.com/discussions/amazon/view/99660-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nALB 에서 EC2 인스턴스로의 인바운드 트래픽을 제한하려면 EC2 인스턴스의 보안 그룹은 \nALB 의 보안 그룹에서 들어오는 트래픽만 허용해야 합니다. 이렇게 하면 EC2 인스턴스는 \nALB 에서만 요청을 받을 수 있으며 프라이빗 서브넷 내부 또는 외부의 다른 소스에서는 \n요청을 받을 수 없습니다.", "answer_choice": "B"}, "283": {"q_num": 283, "question": "연구 회사는 시뮬레이션 응용 프로그램과 시각화 응용 프로그램으로 구동되는 실험을 \n실행합니다. 시뮬레이션 애플리케이션은 Linux 에서 실행되며 5 분마다 NFS 공유에 중간 \n데이터를 출력합니다. 시각화 응용 프로그램은 시뮬레이션 출력을 표시하고 SMB 파일 \n시스템이 필요한 Windows 데스크톱 응용 프로그램입니다. \n회사는 두 개의 동기화된 파일 시스템을 유지 관리합니다. 이 전략은 데이터 중복 및 \n비효율적인 리소스 사용을 유발합니다. 회사는 애플리케이션에 코드를 변경하지 않고 \n애플리케이션을 AWS 로 마이그레이션해야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 두 애플리케이션을 모두 AWS Lambda\n로 마이그레이션합니다. 애플리케이션 간에 \n\n데이터를 교환할 Amazon S3 버킷을 생성합니다. \nB. \n두 \n애플리케이션을 \n모두 \nAmazon \nElastic \nContainer \nService(Amazon \nECS)로 \n마이그레이션합니다. 스토리지용 Amazon FSx 파일 게이트웨이를 구성합니다. \nC. 시뮬레이션 애플리케이션을 Linux Amazon EC2 인스턴스로 마이그레이션합니다. 시각화 \n애플리케이션을 \nWindows \nEC2 \n인스턴스로 \n마이그레이션합니다. \n애플리케이션 \n간에 \n데이터를 교환하도록 Amazon Simple Queue Service(Amazon SQS)를 구성합니다. \nD. 시뮬레이션 애플리케이션을 Linux Amazon EC2 인스턴스로 마이그레이션합니다. 시각화 \n애플리케이션을 Windows EC2 인스턴스로 마이그레이션합니다. 스토리지용 NetApp \nONTAP 용 Amazon FSx 를 구성합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/99512-exam-aws-certified-solut\nions-architect-associate-saa-c03/", "answer_choice": "D"}, "284": {"q_num": 284, "question": "예산 계획의 일환으로 경영진은 사용자별로 나열된 AWS 청구 항목에 대한 보고서를 \n원합니다. 데이터는 부서 예산을 만드는 데 사용됩니다. 솔루션 설계자는 이 보고서 정보를 \n얻는 가장 효율적인 방법을 결정해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. Amazon Athena 로 쿼리를 실행하여 보고서를 생성합니다. \nB. Cost Explorer 에서 보고서를 생성하고 보고서를 다운로드합니다. \nC. 청구 대시보드에서 청구서 세부 정보에 액세스하고 청구서를 다운로드합니다. \nD. Amazon Simple Email Service(Amazon SES)로 알리도록 AWS 예산에서 비용 예산을 \n수정합니다.", "answer_block": "Answer: B  \nhttps://www.examtopics.com/discussions/amazon/view/99513-exam-aws-certified-solut\nions-architect-associate-saa-c03/", "answer_choice": "B"}, "285": {"q_num": 285, "question": "회사는 Amazon S3 를 사용하여 정적 웹 사이트를 호스팅합니다. 회사는 웹 페이지에 \n연락처 양식을 추가하려고 합니다. 연락처 양식에는 사용자가 이름, 이메일 주소, 전화번호 \n및 사용자 메시지를 입력할 수 있는 동적 서버 측 구성 요소가 있습니다. 회사는 매월 \n100 회 미만의 사이트 방문이 있을 것으로 예상합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. Amazon Elastic Container Service(Amazon ECS)에서 동적 문의 양식 페이지를 \n\n호스팅합니다. 타사 이메일 공급자에 연결하도록 Amazon Simple Email Service(Amazon \nSES)를 설정합니다. \nB. Amazon Simple Email Service(Amazon SES)를 호출하는 AWS Lambda 백엔드로 Amazon \nAPI Gateway 엔드포인트를 생성합니다. \nC. Amazon Lightsail 을 배포하여 정적 웹 페이지를 동적으로 변환합니다. 클라이언트 측 \n스크립팅을 사용하여 연락처 양식을 작성하십시오. 양식을 Amazon WorkMail 과 통합합니다. \nD. t2.micro Amazon EC2 인스턴스를 생성합니다. LAMP(Linux, Apache, MySQL, \nPHP/Perl/Python) 스택을 배포하여 웹 페이지를 호스팅합니다. 클라이언트 측 스크립팅을 \n사용하여 연락처 양식을 작성하십시오. 양식을 Amazon WorkMail 과 통합합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/99680-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n이 옵션은 시간 경과에 따른 AWS 비용 및 사용량을 시각화, 이해 및 관리할 수 있는 \n도구인 Cost Explorer 를 사용하기 때문에 가장 효율적입니다. 비용 탐색기에서 사용자 이름 \n태그를 필터로 사용하여 사용자별로 AWS 청구 항목을 나열하는 보고서를 생성할 수 \n있습니다. 그런 다음 보고서를 CSV 파일로 다운로드하여 예산 계획에 사용할 수 있습니다. \n \n옵션 A 는 표준 SQL 을 사용하여 Amazon S3 의 데이터를 분석할 수 있는 서버리스 대화형 \n쿼리 서비스인 Amazon Athena 를 사용하기 때문에 효율성이 떨어집니다. S3 에서 AWS 비용 \n및 사용 보고서 데이터를 가리키는 Athena 테이블을 설정한 다음 쿼리를 실행하여 \n보고서를 생성해야 합니다. 이렇게 하면 추가 비용과 복잡성이 발생합니다. \n \n옵션 C 는 AWS 비용 및 사용량에 대한 높은 수준의 요약을 제공하는 결제 대시보드를 \n사용하기 때문에 효율성이 떨어집니다. 청구 대시보드에서 청구 세부 정보에 액세스하고 \n청구서를 통해 다운로드할 수 있지만 사용자별로 청구 항목이 나열되지 않습니다. 추가 \n단계가 필요한 사용자 이름별로 비용을 그룹화하려면 태그를 사용해야 합니다. \n \n옵션 D 는 서비스 사용량, 서비스 비용 및 인스턴스 예약을 계획할 수 있는 도구인 AWS \n예산을 사용하기 때문에 효율성이 떨어집니다. Amazon Simple Email Service(Amazon \nSES)로 알리도록 AWS 예산에서 비용 예산을 수정할 수 있지만 이렇게 하면 사용자별로 \nAWS 청구 항목 보고서가 생성되지 않습니다. 이는 실제 또는 예상 비용이 예산 금액을 \n초과하거나 초과할 것으로 예상되는 경우에만 알려줍니다.", "answer_choice": "B"}, "286": {"q_num": 286, "question": "회사에는 Amazon S3 앞의 Amazon CloudFront 에서 호스팅되는 정적 웹 사이트가 있습니다. \n정적 웹 사이트는 데이터베이스 백엔드를 사용합니다. 회사는 웹사이트가 웹사이트의 Git \n리포지토리에서 이루어진 업데이트를 반영하지 않는다는 사실을 알게 되었습니다. 회사는 \nGit 리포지토리와 Amazon S3 간의 지속적 통합 및 지속적 전달(CI/CD) 파이프라인을 \n확인합니다. 회사는 webhook\n이 제대로 구성되었는지, CI/CD 파이프라인이 성공적인 \n배포를 나타내는 메시지를 보내고 있는지 확인합니다. \n솔루션 설계자는 웹 사이트에 업데이트를 표시하는 솔루션을 구현해야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Application Load Balancer 를 추가합니다. \nB. Redis 또는 Memcached 용 Amazon ElastiCache 를 웹 애플리케이션의 데이터베이스 \n계층에 추가합니다. \nC. CloudFront 캐시를 무효화합니다. \nD. AWS Certificate Manager(ACM)를 사용하여 웹 사이트의 SSL 인증서를 확인합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/99669-exam-aws-certified-solut\nions-architect-associate-saa-c03/", "answer_choice": "C"}, "287": {"q_num": 287, "question": "회사에서 \nWindows \n기반 \n애플리케이션을 \n온프레미스에서 \nAWS \n클라우드로 \n마이그레이션하려고 합니다. 애플리케이션에는 애플리케이션 계층, 비즈니스 계층 및 \nMicrosoft SQL Server 가 포함된 데이터베이스 계층의 세 가지 계층이 있습니다. 회사는 \n기본 백업 및 데이터 품질 서비스와 같은 SQL Server 의 특정 기능을 사용하려고 합니다. \n또한 회사는 계층 간에 처리를 위해 파일을 공유해야 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 아키텍처를 어떻게 설계해야 합니까? \nA. Amazon EC2 인스턴스에서 세 계층을 모두 호스팅합니다. 계층 간 파일 공유를 위해 \nAmazon FSx File Gateway 를 사용합니다. \nB. Amazon EC2 인스턴스에서 세 계층을 모두 호스팅합니다. 계층 간 파일 공유를 위해 \nAmazon FSx for Windows File Server 를 사용하십시오. \nC. Amazon EC2 인스턴스에서 애플리케이션 계층과 비즈니스 계층을 호스팅합니다. \nAmazon RDS 에서 데이터베이스 계층을 호스팅합니다. 계층 간 파일 공유를 위해 Amazon \nElastic File System(Amazon EFS)을 사용합니다. \nD. Amazon EC2 인스턴스에서 애플리케이션 계층과 비즈니스 계층을 호스팅합니다. \nAmazon RDS\n에서 데이터베이스 계층을 호스팅합니다. 계층 간 파일 공유를 위해 \n프로비저닝된 IOPS SSD(io2) Amazon Elastic Block Store(Amazon EBS) 볼륨을 사용합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/99670-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n이 솔루션을 통해 회사는 Amazon FSx for Windows File Server 를 사용하여 계층 간에 \nWindows 기반 파일 공유를 제공하면서 Amazon EC2 인스턴스에서 세 계층을 모두 \n호스팅할 수 있습니다. 이를 통해 회사는 기본 백업 및 데이터 품질 서비스와 같은 SQL \nServer 의 특정 기능을 사용하면서 계층 간에 처리를 위해 파일을 공유할 수 있습니다.", "answer_choice": "B"}, "288": {"q_num": 288, "question": "회사에서 Linux 기반 웹 서버 그룹을 AWS 로 마이그레이션하고 있습니다. 웹 서버는 일부 \n콘텐츠에 대해 공유 파일 저장소의 파일에 액세스해야 합니다. 회사는 신청서를 변경해서는 \n안됩니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. 웹 서버에 대한 액세스 권한이 있는 Amazon S3 Standard 버킷을 생성합니다. \nB. Amazon S3 버킷을 원본으로 사용하여 Amazon CloudFront 배포를 구성합니다. \nC. Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성합니다. 모든 웹 서버에 \nEFS 파일 시스템을 마운트합니다. \nD. 범용 SSD(gp3) Amazon Elastic Block Store(Amazon EBS) 볼륨을 구성합니다. 모든 웹 \n서버에 EBS 볼륨을 마운트합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/99671-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nAmazon Elastic File System(Amazon EFS) 파일 시스템을 생성합니다. 모든 웹 서버에 EFS \n파일 시스템을 마운트합니다. 애플리케이션을 변경하지 않고 Linux 기반 웹 서버용 공유 \n파일 스토어를 제공해야 한다는 요구 사항을 충족하려면 Amazon EFS 파일 시스템을 \n사용하는 것이 가장 좋은 솔루션입니다. \nAmazon EFS 는 여러 Linux 기반 인스턴스에서 파일에 대한 공유 액세스를 제공하는 관리형 \nNFS 파일 시스템 서비스이므로 이 사용 사례에 적합합니다. Amazon S3 는 파일 시스템이 \n아닌 객체 스토리지 서비스이고 S3 버킷을 파일 시스템으로 탑재하려면 추가 도구 또는 \n라이브러리가 필요하기 때문에 이 시나리오에 적합하지 않습니다. Amazon CloudFront 는 \n콘텐츠 전송 성능을 개선하는 데 사용할 수 있지만 이 요구 사항에는 필요하지 않습니다. \n\n또한 Amazon EBS 볼륨은 한 번에 하나의 인스턴스에만 탑재할 수 있으므로 여러 \n인스턴스에서 파일을 공유하는 데 적합하지 않습니다.", "answer_choice": "C"}, "289": {"q_num": 289, "question": "회사에는 동일한 AWS 계정에 있는 Amazon S3 버킷에 대한 읽기 액세스 권한이 필요한 \nAWS Lambda 함수가 있습니다. \n가장 안전한 방식으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. S3 버킷에 대한 읽기 액세스 권한을 부여하는 S3 버킷 정책을 적용합니다. \nB. Lambda 함수에 IAM 역할을 적용합니다. 역할에 IAM 정책을 적용하여 S3 버킷에 대한 \n읽기 액세스 권한을 부여합니다. \nC. Lambda 함수의 코드에 액세스 키와 비밀 키를 내장하여 S3 버킷에 대한 읽기 액세스에 \n필요한 IAM 권한을 부여합니다. \nD. Lambda 함수에 IAM 역할을 적용합니다. 역할에 IAM 정책을 적용하여 계정의 모든 S3 \n버킷에 대한 읽기 액세스 권한을 부여합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/99756-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n이 옵션은 최소 권한 원칙을 따르고 코드의 자격 증명을 노출하지 않고 Lambda 함수에 \n필요한 권한만 부여하기 때문에 가장 안전합니다. IAM 역할은 Lambda 함수의 실행 역할로 \n구성할 수 있으며 IAM 정책은 S3 버킷 ARN 및 s3:GetObject 작업을 지정할 수 있습니다. \n옵션 A 는 Lambda 함수보다 더 많은 S3 버킷에 대한 액세스 권한이 있는 보안 주체에게 \n읽기 액세스 권한을 부여하기 때문에 덜 안전합니다. \n옵션 C 는 손상되거나 노출될 수 있는 자격 증명을 코드에 내장하기 때문에 덜 안전합니다. \n옵션 D\n는 계정의 모든 S3 버킷에 대한 읽기 액세스 권한을 부여하기 때문에 덜 \n안전합니다. 이는 Lambda 함수에 필요한 것보다 많을 수 있습니다.", "answer_choice": "B"}, "290": {"q_num": 290, "question": "회사는 여러 Amazon EC2 인스턴스에서 웹 애플리케이션을 호스팅합니다. EC2 인스턴스는 \n사용자 요구에 따라 확장되는 Auto Scaling 그룹에 있습니다. 회사는 장기적인 약정 없이 \n비용 절감을 최적화하기를 원합니다. \n이러한 요구 사항을 충족하기 위해 솔루션 설계자가 권장해야 하는 EC2 인스턴스 구매 \n옵션은 무엇입니까? \n\nA. 전용 인스턴스만 해당 \nB. 온디맨드 인스턴스 전용 \nC. 온디맨드 인스턴스와 스팟 인스턴스의 혼합 \nD. 온디맨드 인스턴스와 예약 인스턴스의 혼합", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/100006-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n참고 \nhttps://docs.aws.amazon.com/ko_kr/autoscaling/ec2/userguide/ec2-auto-scaling-mixed\n-instances-groups.html", "answer_choice": "C"}, "291": {"q_num": 291, "question": "미디어 회사는 공개적으로 사용 가능한 스트리밍 비디오 콘텐츠에 Amazon CloudFront 를 \n사용합니다. 이 회사는 액세스 권한이 있는 사용자를 제어하여 Amazon S3 에서 호스팅되는 \n비디오 콘텐츠를 보호하려고 합니다. 회사의 일부 사용자는 쿠키를 지원하지 않는 사용자 \n지정 HTTP 클라이언트를 사용하고 있습니다. 회사의 일부 사용자는 액세스에 사용하는 \n하드코딩된 URL 을 변경할 수 없습니다. \n사용자에게 미치는 영향을 최소화하면서 이러한 요구 사항을 충족하는 서비스 또는 방법은 \n무엇입니까? (2 개 선택) \nA. 서명된 쿠키 \nB. 서명된 URL \nC. AWS 앱싱크 \nD. JSON 웹 토큰(JWT) \nE. AWS Secrets Manager", "answer_block": "Answer: A, B \nhttps://www.examtopics.com/discussions/amazon/view/99831-exam-aws-certified-solut\nions-architect-associate-saa-c03/", "answer_choice": "A"}, "292": {"q_num": 292, "question": "한 회사가 여러 소스에서 실시간 스트리밍 데이터를 수집할 새로운 데이터 플랫폼을 \n준비하고 있습니다. 회사는 Amazon S3 에 데이터를 쓰기 전에 데이터를 변환해야 합니다. \n회사는 SQL 을 사용하여 변환된 데이터를 쿼리할 수 있는 기능이 필요합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? (두 가지를 선택하세요.) \n\nA. Amazon Kinesis Data Streams 를 사용하여 데이터를 스트리밍합니다. Amazon Kinesis \nData Analytics 를 사용하여 데이터를 변환합니다. Amazon Kinesis Data Firehose 를 사용하여 \nAmazon S3 에 데이터를 씁니다. Amazon Athena 를 사용하여 Amazon S3 에서 변환된 \n데이터를 쿼리합니다. \nB. Amazon Managed Streaming for Apache Kafka(Amazon MSK)를 사용하여 데이터를 \n스트리밍합니다. AWS Glue 를 사용하여 데이터를 변환하고 데이터를 Amazon S3 에 씁니다. \nAmazon Athena 를 사용하여 Amazon S3 에서 변환된 데이터를 쿼리합니다. \nC. AWS Database Migration Service(AWS DMS)를 사용하여 데이터를 수집합니다. Amazon \nEMR 을 사용하여 데이터를 변환하고 Amazon S3 에 데이터를 씁니다. Amazon Athena 를 \n사용하여 Amazon S3 에서 변환된 데이터를 쿼리합니다. \nD. Amazon Managed Streaming for Apache Kafka(Amazon MSK)를 사용하여 데이터를 \n스트리밍합니다. Amazon Kinesis Data Analytics 를 사용하여 데이터를 변환하고 데이터를 \nAmazon S3 에 씁니다. Amazon RDS 쿼리 편집기를 사용하여 Amazon S3 에서 변환된 \n데이터를 쿼리합니다. \nE. Amazon Kinesis Data Streams 를 사용하여 데이터를 스트리밍합니다. AWS Glue 를 \n사용하여 데이터를 변환합니다. Amazon Kinesis Data Firehose 를 사용하여 Amazon S3 에 \n데이터를 씁니다. Amazon RDS 쿼리 편집기를 사용하여 Amazon S3 에서 변환된 데이터를 \n쿼리합니다.", "answer_block": "Answer: A, B \nhttps://www.examtopics.com/discussions/amazon/view/99834-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n여러 소스에서 실시간 스트리밍 데이터를 수집, 변환 및 쿼리하려면 Amazon Kinesis 와 \nAmazon MSK 가 적합한 솔루션입니다. Amazon Kinesis Data Streams 는 다양한 소스의 \n데이터를 스트리밍하고 다른 AWS 서비스와 통합할 수 있습니다. Amazon Kinesis Data \nAnalytics 는 SQL 또는 Apache Flink 를 사용하여 데이터를 변환할 수 있습니다. Amazon \nKinesis Data Firehose 는 Amazon S3 또는 다른 대상에 데이터를 쓸 수 있습니다. Amazon \nAthena 는 표준 SQL 을 사용하여 Amazon S3 에서 변환된 데이터를 쿼리할 수 있습니다. \nAmazon MSK 는 데이터 스트리밍을 위한 인기 있는 오픈 소스 플랫폼인 Apache Kafka 를 \n사용하여 데이터를 스트리밍할 수 있습니다. AWS Glue 는 Apache Spark 또는 Python \n스크립트를 사용하여 데이터를 변환하고 Amazon S3 또는 기타 대상에 데이터를 쓸 수 \n있습니다. Amazon Athena 는 표준 SQL 을 사용하여 Amazon S3 에서 변환된 데이터를 \n쿼리할 수도 있습니다.", "answer_choice": "A"}, "293": {"q_num": 293, "question": "회사에는 수명이 다한 온프레미스 볼륨 백업 솔루션이 있습니다. 회사는 AWS 를 새로운 \n백업 솔루션의 일부로 사용하고 AWS 에 백업되는 동안 모든 데이터에 대한 로컬 액세스를 \n유지하려고 합니다. 회사는 AWS\n에 백업된 데이터가 자동으로 안전하게 전송되기를 \n원합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. AWS Snowball\n을 사용하여 온프레미스 솔루션에서 Amazon S3\n로 데이터를 \n마이그레이션합니다. \n데이터에 \n대한 \n로컬 \n액세스를 \n제공하기 \n위해 \nSnowball \nS3 \n엔드포인트를 탑재하도록 온프레미스 시스템을 구성합니다. \nB. AWS Snowball Edge 를 사용하여 온프레미스 솔루션에서 Amazon S3 로 데이터를 \n마이그레이션합니다. Snowball Edge 파일 인터페이스를 사용하여 온프레미스 시스템에 \n데이터에 대한 로컬 액세스를 제공합니다. \nC. \nAWS \nStorage \nGateway\n를 \n사용하고 \n캐시된 \n볼륨 \n게이트웨이를 \n구성합니다. \n온프레미스에서 Storage Gateway 소프트웨어 어플라이언스를 실행하고 로컬로 캐시할 \n데이터 비율을 구성합니다. 데이터에 대한 로컬 액세스를 제공하기 위해 게이트웨이 \n스토리지 볼륨을 마운트합니다. \nD. \nAWS \nStorage \nGateway\n를 \n사용하고 \n저장된 \n볼륨 \n게이트웨이를 \n구성합니다. \n온프레미스에서 \nStorage \nGateway \n소프트웨어 \n어플라이언스를 \n실행하고 \n게이트웨이 \n스토리지 볼륨을 온프레미스 스토리지에 매핑합니다. 데이터에 대한 로컬 액세스를 \n제공하기 위해 게이트웨이 스토리지 볼륨을 마운트합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/99692-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n이 옵션은 온프레미스 소프트웨어 어플라이언스와 클라우드 기반 스토리지를 연결하여 \n온프레미스 IT 환경과 AWS 스토리지 인프라 간의 데이터 보안 기능과의 원활한 통합을 \n제공하는 서비스인 AWS Storage Gateway 를 사용하기 때문에 가장 효율적입니다. . 또한 \n기본 데이터를 로컬에 저장하고 데이터의 특정 시점 스냅샷을 Amazon S3 에 비동기식으로 \n백업하는 \n볼륨 \n게이트웨이 \n유형인 \n저장된 \n볼륨 \n게이트웨이를 \n사용합니다. \n또한 \n온프레미스에서 \nStorage \nGateway \n소프트웨어 \n애플리케이션을 \n실행하고 \n게이트웨이 \n스토리지 볼륨을 온프레미스 스토리지에 매핑하므로 기존 스토리지 하드웨어 및 네트워크 \n인프라를 사용할 수 있습니다. 또한 게이트웨이 스토리지 볼륨을 탑재하여 데이터에 대한 \n로컬 액세스를 제공하므로 온프레미스에서 지연 시간이 짧은 액세스를 위해 데이터를 \n사용할 수 있으며 동시에 AWS 에 백업할 수 있습니다. 이 솔루션은 AWS 에 백업되는 동안 \n모든 데이터에 대한 로컬 액세스를 유지하고 AWS 에 백업된 데이터가 자동으로 안전하게 \n\n전송되도록 하는 요구 사항을 충족합니다. \n옵션 A 는 대량의 데이터를 AWS 안팎으로 전송할 수 있는 물리적 장치인 AWS Snowball 을 \n사용하기 때문에 효율성이 떨어집니다. 그러나 이것은 장치의 수동 취급 및 배송을 필요로 \n하기 때문에 주기적인 백업 솔루션을 제공하지 않습니다. 또한 데이터에 대한 로컬 \n액세스를 제공하기 위해 Snowball S3 엔드포인트를 탑재하도록 온프레미스 시스템을 \n구성하므로 추가적인 복잡성과 지연 시간이 발생할 수 있습니다. \n옵션 B\n는 일부 AWS 기능을 위한 온보드 스토리지 및 컴퓨팅 기능이 있는 물리적 \n디바이스인 AWS Snowball Edge 를 사용하기 때문에 효율성이 떨어집니다. 그러나 이것은 \n장치의 수동 취급 및 배송을 필요로 하기 때문에 주기적인 백업 솔루션을 제공하지 \n않습니다. 또한 Snowball Edge 파일 인터페이스를 사용하여 온프레미스 시스템에 데이터에 \n대한 로컬 액세스를 제공하므로 추가적인 복잡성과 지연 시간이 발생할 수 있습니다. \n옵션 C 는 AWS Storage Gateway 를 사용하고 기본 데이터를 Amazon S3 에 저장하고 자주 \n액세스하는 데이터 하위 집합의 복사본을 로컬에 보관하는 일종의 볼륨 게이트웨이인 \n캐시된 볼륨 게이트웨이를 구성하기 때문에 효율성이 떨어집니다. 그러나 일부 데이터 하위 \n집합만 로컬로 캐시되기 때문에 모든 데이터에 대한 로컬 액세스를 제공하지는 않습니다. \n또한 로컬로 캐시할 데이터의 비율을 구성하므로 저장된 볼륨 게이트웨이를 사용하는 \n것보다 더 높은 비용과 복잡성이 발생할 수 있습니다.", "answer_choice": "D"}, "294": {"q_num": 294, "question": "Amazon EC2 인스턴스에서 호스팅되는 애플리케이션은 Amazon S3 버킷에 액세스해야 \n합니다. 트래픽이 인터넷을 통과하면 안 됩니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 액세스를 어떻게 구성해야 합니까? \nA. Amazon Route 53 을 사용하여 프라이빗 호스팅 영역을 생성합니다. \nB. VPC 에서 Amazon S3 에 대한 게이트웨이 VPC 엔드포인트를 설정합니다. \nC. NAT 게이트웨이를 사용하여 S3 버킷에 액세스하도록 EC2 인스턴스를 구성합니다. \nD. VPC 와 S3 버킷 간에 AWS Site-to-Site VPN 연결을 설정합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/99954-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n이 옵션은 인터넷 게이트웨이나 VPC 용 NAT 장치 없이 Amazon S3 에 대한 안정적인 \n연결을 제공하는 Amazon S3 용 게이트웨이 VPC 엔드포인트를 사용하기 때문에 가장 \n효율적입니다. 게이트웨이 VPC 엔드포인트는 서비스의 접두사 목록을 사용하여 VPC 에서 \nAmazon S3 로 트래픽을 라우팅하고 AWS 네트워크를 벗어나지 않습니다. 이것은 인터넷을 \n\n통과하지 않는다는 요구 사항을 충족합니다. \n옵션 A 는 VPC 내의 리소스에 대한 사용자 지정 도메인 이름을 생성할 수 있는 DNS \n서비스인 Amazon Route 53 을 사용하여 프라이빗 호스팅 영역을 사용하기 때문에 효율성이 \n떨어집니다. 그러나 이것은 인터넷 게이트웨이나 NAT 장치 없이는 Amazon S3 에 대한 \n연결을 제공하지 않습니다. \n옵션 C 는 NAT 게이트웨이를 사용하여 S3 버킷에 액세스하기 때문에 효율성이 떨어집니다. \nS3 버킷은 개인 서브넷의 인스턴스가 인터넷 또는 다른 AWS 서비스에 연결할 수 있도록 \n지원하지만 인터넷이 이러한 인스턴스와의 연결을 시작하지 못하도록 하는 고가용성 관리형 \nNAT(Network Address Translation) 서비스입니다. 그러나 이것은 인터넷을 통과하지 않는 \n요구 사항을 충족하지 못합니다.그러나 이것은 인터넷을 통과하지 않는다는 요구 사항을 \n충족하지 않습니다. \n옵션 D는 온프레미스 네트워크와 VPC 간의 안전하고 암호화된 네트워크 연결인 S3 버킷과 \nVPC 간에 AWS Site-to-Site VPN 연결을 사용하기 때문에 효율성이 떨어집니다. 그러나 \n이것은 인터넷을 통과하지 않는다는 요구 사항을 충족하지 않습니다.", "answer_choice": "C"}, "295": {"q_num": 295, "question": "전자상거래 회사는 테라바이트 규모의 고객 데이터를 AWS 클라우드에 저장합니다. \n데이터에는 개인 식별 정보(PII)가 포함되어 있습니다. 회사는 세 가지 응용 프로그램에서 \n데이터를 사용하려고 합니다. 애플리케이션 중 하나만 PII 를 처리해야 합니다. 다른 두 \n애플리케이션이 데이터를 처리하기 전에 PII 를 제거해야 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Amazon DynamoDB 테이블에 데이터를 저장합니다. 각 애플리케이션이 요청하는 \n데이터를 가로채서 처리할 프록시 애플리케이션 계층을 생성합니다. \nB. 데이터를 Amazon S3 버킷에 저장합니다. 요청 애플리케이션에 데이터를 반환하기 전에 \nS3 객체 Lambda 를 사용하여 데이터를 처리하고 변환합니다. \nC. 데이터를 처리하고 변환된 데이터를 3 개의 개별 Amazon S3 버킷에 저장하여 각 \n애플리케이션이 고유한 사용자 지정 데이터 세트를 갖도록 합니다. 각 애플리케이션이 해당 \nS3 버킷을 가리키도록 합니다. \nD. 데이터를 처리하고 변환된 데이터를 3 개의 별도 Amazon DynamoDB 테이블에 저장하여 \n각 애플리케이션이 자체 사용자 지정 데이터 세트를 갖도록 합니다. 각 애플리케이션이 \n해당 DynamoDB 테이블을 가리키도록 합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/99956-exam-aws-certified-solut\nions-architect-associate-saa-c03/", "answer_choice": "B"}, "296": {"q_num": 296, "question": "개발 팀이 개발 VPC 내부의 Amazon EC2 인스턴스에서 호스팅되는 새로운 애플리케이션을 \n출시했습니다. 솔루션 설계자는 동일한 계정에 새 VPC 를 생성해야 합니다. 새 VPC 는 개발 \nVPC 와 피어링됩니다. 개발용 VPC 의 VPC CIDR 블록은 192.168.0.0/24 입니다. 솔루션 \n설계자는 새 VPC 에 대한 CIDR 블록을 생성해야 합니다. CIDR 블록은 개발 VPC 에 대한 \nVPC 피어링 연결에 대해 유효해야 합니다. \n이러한 요구 사항을 충족하는 가장 작은 CIDR 블록은 무엇입니까? \nA. 10.0.1.0/32 \nB. 192.168.0.0/24 \nC. 192.168.1.0/32 \nD. 10.0.1.0/24", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/99651-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n허용되는 블록 크기는 /28 넷마스크와 /16 넷마스크 사이입니다. CIDR 블록은 VPC 와 \n연결된 기존 CIDR 블록과 겹치지 않아야 합니다. \nhttps://docs.aws.amazon.com/vpc/latest/userguide/configure-your-vpc.html", "answer_choice": "D"}, "297": {"q_num": 297, "question": "회사에서 5 개의 Amazon EC2 인스턴스에 애플리케이션을 배포합니다. ALB(Application \nLoad Balancer)는 대상 그룹을 사용하여 인스턴스에 트래픽을 분산합니다. 각 인스턴스의 \n평균 CPU 사용량은 대부분 10% 미만이며 때때로 65%까지 급증합니다. \n솔루션 설계자는 애플리케이션의 확장성을 자동화하는 솔루션을 구현해야 합니다. 솔루션은 \n아키텍처의 비용을 최적화하고 급증이 발생할 때 애플리케이션에 충분한 CPU 리소스가 \n있는지 확인해야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. CPUUtilization 지표가 20% 미만일 때 ALARM 상태로 들어가는 Amazon CloudWatch \n경보를 생성합니다. ALB 대상 그룹의 EC2 인스턴스 중 하나를 종료하기 위해 CloudWatch \n경보가 호출하는 AWS Lambda 함수를 생성합니다. \nB. EC2 Auto Scaling 그룹을 생성합니다. 기존 ALB 를 로드 밸런서로 선택하고 기존 대상 \n그룹을 대상 그룹으로 선택하십시오. ASGAverageCPUUtilization 지표를 기반으로 하는 대상 \n추적 조정 정책을 설정합니다. 최소 인스턴스를 2\n로, 원하는 용량을 3\n으로, 최대 \n\n인스턴스를 6 으로, 목표 값을 50%로 설정합니다. Auto Scaling 그룹에 EC2 인스턴스를 \n추가합니다. \nC. EC2 Auto Scaling 그룹을 생성합니다. 기존 ALB 를 로드 밸런서로 선택하고 기존 대상 \n그룹을 대상 그룹으로 선택하십시오. 최소 인스턴스를 2 로, 원하는 용량을 3 으로, 최대 \n인스턴스를 6 으로 설정합니다. Auto Scaling 그룹에 EC2 인스턴스를 추가합니다. \nD. 두 개의 Amazon CloudWatch 경보를 생성합니다. 평균 CPUUtilization 지표가 20% \n미만일 때 ALARM 상태로 들어가도록 첫 번째 CloudWatch 경보를 구성합니다. 평균 \nCPUUtilization 지표가 50%를 초과하면 ALARM 상태로 들어가도록 두 번째 CloudWatch \n경보를 \n구성합니다. \n이메일 \n메시지를 \n보내기 \n위해 \nAmazon \nSimple \nNotification \nService(Amazon SNS) 주제에 게시하도록 경보를 구성합니다. 메시지를 받은 후 로그인하여 \n실행 중인 EC2 인스턴스 수를 줄이거나 늘립니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/99652-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n* Auto Scaling 그룹은 수요 변화에 맞춰 EC2 인스턴스를 자동으로 확장합니다. 이는 \n필요한 만큼의 인스턴스만 실행하여 비용을 최적화합니다. \n* 대상 추적 조정 정책은 ASGAverageCPUUtilization 지표를 모니터링하고 평균 CPU 를 약 \n50% 대상 값으로 유지하도록 조정합니다. 이렇게 하면 CPU 가 급증하는 동안 리소스가 \n충분해집니다. \n* ALB 와 대상 그룹은 재사용되므로 애플리케이션 아키텍처가 변경되지 않습니다. Auto \nScaling 그룹은 기존 로드 밸런서 설정에 연결됩니다. \n* 최소 2 개에서 최대 6 개의 인스턴스는 수요에 따라 필요에 따라 3 개에서 6 개 사이의 \n인스턴스를 확장할 수 있는 기능을 제공합니다. \n* 단 3 개의 인스턴스(원하는 용량)로 시작하고 필요에 따라 확장하여 비용을 최적화합니다. \nCPU 사용량이 떨어지면 원하는 용량에 맞게 인스턴스가 종료됩니다.", "answer_choice": "B"}, "298": {"q_num": 298, "question": "회사는 Application Load Balancer 뒤의 Amazon EC2 인스턴스에서 중요한 비즈니스 \n애플리케이션을 실행하고 있습니다. EC2 인스턴스는 Auto Scaling 그룹에서 실행되며 \nAmazon RDS DB 인스턴스에 액세스합니다. \nEC2 인스턴스와 DB 인스턴스가 모두 단일 가용 영역에 있기 때문에 설계가 운영 검토를 \n통과하지 \n못했습니다. \n솔루션 \n설계자는 \n두 \n번째 \n가용 \n영역을 \n사용하도록 \n설계를 \n업데이트해야 합니다. \n\n애플리케이션의 가용성을 높이는 솔루션은 무엇입니까? \nA. 각 가용 영역에서 서브넷을 프로비저닝합니다. 두 가용 영역에 EC2 인스턴스를 \n배포하도록 Auto Scaling 그룹을 구성합니다. 각 네트워크에 대한 연결로 DB 인스턴스를 \n구성합니다. \nB. 두 가용 영역에 걸쳐 확장되는 두 개의 서브넷을 프로비저닝합니다. 두 가용 영역에 \nEC2 인스턴스를 배포하도록 Auto Scaling 그룹을 구성합니다. 각 네트워크에 대한 연결로 \nDB 인스턴스를 구성합니다. \nC. 각 가용 영역에서 서브넷을 프로비저닝합니다. 두 가용 영역에 EC2 인스턴스를 \n배포하도록 Auto Scaling 그룹을 구성합니다. 다중 AZ 배포를 위해 DB 인스턴스를 \n구성합니다. \nD. 두 가용 영역에 걸쳐 확장되는 서브넷을 프로비저닝합니다. 두 가용 영역에 EC2 \n인스턴스를 배포하도록 Auto Scaling 그룹을 구성합니다. 다중 AZ 배포를 위해 DB \n인스턴스를 구성합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/99653-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n참고: \nhttps://aws.amazon.com/ko/vpc/faqs/#:~:text=Can%20a%20subnet%20span%20Availabil\nity", "answer_choice": "C"}, "299": {"q_num": 299, "question": "연구소는 약 8TB 의 데이터를 처리해야 합니다. 실험실에는 스토리지 하위 시스템에 대해 \n1 밀리초 미만의 대기 시간과 최소 6GBps 의 처리량이 필요합니다. Amazon Linux 를 \n실행하는 수백 개의 Amazon EC2 인스턴스가 데이터를 배포하고 처리합니다. \n성능 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. NetApp ONTAP 파일 시스템용 Amazon FSx 를 생성합니다. 각 볼륨의 계층화 정책을 \nALL 로 설정했습니다. 원시 데이터를 파일 시스템으로 가져옵니다. EC2 인스턴스에 fila \n시스템을 탑재합니다. \nB. 원시 데이터를 저장할 Amazon S3 버킷을 생성합니다. 영구 SSD 스토리지를 사용하는 \nAmazon FSx for Lustre 파일 시스템을 생성합니다. Amazon S3 에서 데이터를 가져오고 \n내보내는 옵션을 선택합니다. EC2 인스턴스에 파일 시스템을 탑재합니다. \nC. 원시 데이터를 저장할 Amazon S3 버킷을 생성합니다. 영구 HDD 스토리지를 사용하는 \nAmazon FSx for Lustre 파일 시스템을 생성합니다. Amazon S3 에서 데이터를 가져오고 \n내보내는 옵션을 선택합니다. EC2 인스턴스에 파일 시스템을 탑재합니다. \n\nD. NetApp ONTAP 파일 시스템용 Amazon FSx 를 생성합니다. 각 볼륨의 계층화 정책을 \nNONE 으로 설정합니다. 원시 데이터를 파일 시스템으로 가져옵니다. EC2 인스턴스에 파일 \n시스템을 탑재합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/99676-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n원시 데이터를 저장할 Amazon S3 버킷 생성 영구 SSD 스토리지를 사용하는 Amazon FSx \nfor Lustre 파일 시스템 생성 Amazon S3 에서 데이터를 가져오고 내보내는 옵션 선택 EC2 \n인스턴스에 파일 시스템을 탑재합니다. Amazon FSx for Lustre 는 밀리초 미만의 지연 \n시간과 최대 6GBps 의 처리량을 위해 SSD 스토리지를 사용하고 Amazon S3 에서 데이터를 \n가져오고 내보낼 수 있습니다. 또한 영구 SSD 스토리지를 선택하는 옵션은 데이터가 \n디스크에 저장되고 파일 시스템이 중지되어도 손실되지 않도록 합니다.", "answer_choice": "B"}, "300": {"q_num": 300, "question": "회사는 하드웨어 용량 제약으로 인해 온프레미스 데이터 센터에서 AWS 클라우드로 레거시 \n애플리케이션을 마이그레이션해야 합니다. 응용 프로그램은 하루 24\n시간, 주 7\n일 \n실행됩니다. \n애플리케이션의 \n데이터베이스 \n스토리지는 \n시간이 \n지남에 \n따라 \n계속 \n증가합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하기 위해 솔루션 설계자는 무엇을 해야 \n합니까? \nA. 애플리케이션 계층을 Amazon EC2 스팟 인스턴스로 마이그레이션합니다. 데이터 \n스토리지 계층을 Amazon S3 로 마이그레이션합니다. \nB. 애플리케이션 계층을 Amazon EC2 예약 인스턴스로 마이그레이션합니다. 데이터 \n스토리지 계층을 Amazon RDS 온디맨드 인스턴스로 마이그레이션합니다. \nC. 애플리케이션 계층을 Amazon EC2 예약 인스턴스로 마이그레이션합니다. 데이터 \n스토리지 계층을 Amazon Aurora 예약 인스턴스로 마이그레이션합니다. \nD. 애플리케이션 계층을 Amazon EC2 온디맨드 인스턴스로 마이그레이션합니다. 데이터 \n스토리지 계층을 Amazon RDS 예약 인스턴스로 마이그레이션합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/99948-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n참고: \n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.AuroraMySQL.\nhtml", "answer_choice": "C"}, "301": {"q_num": 301, "question": "대학 연구소는 온프레미스 Windows 파일 서버에서 Amazon FSx for Windows File Server 로 \n30TB\n의 데이터를 마이그레이션해야 합니다. 실험실에는 대학의 다른 많은 부서에서 \n공유하는 1Gbps 네트워크 링크가 있습니다. \n실험실은 데이터 전송 성능을 최대화할 데이터 마이그레이션 서비스를 구현하려고 합니다. \n그러나 실험실은 서비스가 다른 부서에 미치는 영향을 최소화하기 위해 사용하는 대역폭의 \n양을 제어할 수 있어야 합니다. 데이터 마이그레이션은 향후 5 일 이내에 이루어져야 \n합니다. \n이러한 요구 사항을 충족하는 AWS 솔루션은 무엇입니까? \nA. AWS 스노우콘 \nB. Amazon FSx 파일 게이트웨이 \nC. AWS 데이터싱크 \nD. AWS Transfer Family", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/99659-exam-aws-certified-solut\nions-architect-associate-saa-c03/", "answer_choice": "C"}, "302": {"q_num": 302, "question": "회사에서 사용자가 모바일 장치에서 슬로우 모션 비디오 클립을 스트리밍할 수 있는 모바일 \n앱을 만들고자 합니다. 현재 이 앱은 비디오 클립을 캡처하고 원시 형식의 비디오 클립을 \nAmazon S3 버킷에 업로드합니다. 앱은 S3 버킷에서 직접 이러한 비디오 클립을 \n검색합니다. 그러나 비디오는 원시 형식이 큽니다. \n사용자는 모바일 장치에서 버퍼링 및 재생 문제를 겪고 있습니다. 회사는 운영 오버헤드를 \n최소화하면서 앱의 성능과 확장성을 극대화하는 솔루션을 구현하고자 합니다. \n이러한 요구 사항을 충족하는 솔루션 조합은 무엇입니까? (2 개 선택) \nA. 콘텐츠 전송 및 캐싱을 위해 Amazon CloudFront 를 배포합니다. \nB. AWS DataSync\n를 사용하여 다른 S3 버킷의 AW'S 지역 전체에 비디오 파일을 \n복제합니다. \nC. Amazon Elastic Transcoder\n를 사용하여 비디오 파일을 보다 적절한 형식으로 \n변환합니다. \nD. 콘텐츠 전송 및 캐싱을 위해 로컬 영역에 Amazon EC2 인스턴스의 Auto Sealing 그룹을 \n\n배포합니다. \nE. Amazon EC2 인스턴스의 Auto Scaling 그룹을 배포하여 비디오 파일을 보다 적절한 \n형식으로 변환합니다.", "answer_block": "Answer: A, C \nhttps://www.examtopics.com/discussions/amazon/view/99693-exam-aws-certified-solut\nions-architect-associate-saa-c03/", "answer_choice": "A"}, "303": {"q_num": 303, "question": "회사에서 Amazon Elastic Container Service(Amazon ECS) 클러스터에 배포된 새 \n애플리케이션을 시작하고 ECS 작업에 Fargate 시작 유형을 사용하고 있습니다. 회사는 \n실행 시 애플리케이션에 대한 높은 트래픽이 예상되기 때문에 CPU 및 메모리 사용량을 \n모니터링하고 있습니다. 그러나 회사는 활용도가 감소할 때 비용을 절감하기를 원합니다. \n솔루션 설계자는 무엇을 추천해야 합니까? \nA. Amazon EC2 Auto Scaling 을 사용하여 이전 트래픽 패턴을 기반으로 특정 기간에 \n조정합니다. \nB. AWS Lambda 함수를 사용하여 Amazon CloudWatch 경보를 트리거하는 메트릭 위반을 \n기반으로 Amazon ECS 를 확장합니다. \nC. 간단한 조정 정책과 함께 Amazon EC2 Auto Scaling 을 사용하여 ECS 메트릭 위반이 \nAmazon CloudWatch 경보를 트리거할 때 조정합니다. \nD. 대상 추적 정책과 함께 AWS Application Auto Scaling 을 사용하여 ECS 메트릭 위반이 \nAmazon CloudWatch 경보를 트리거할 때 조정합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/99813-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n참고 \nhttps://docs.aws.amazon.com/ko_kr/autoscaling/application/userguide/what-is-applicati\non-auto-scaling.html", "answer_choice": "D"}, "304": {"q_num": 304, "question": "한 회사가 최근 다른 AWS 리전에 재해 복구 사이트를 만들었습니다. 회사는 정기적으로 두 \n리전의 NFS 파일 시스템 간에 대량의 데이터를 주고 받아야 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. AWS DataSync 를 사용하십시오. \n\nB. AWS Snowball 디바이스를 사용합니다. \nC. Amazon EC2 에서 SFTP 서버를 설정합니다. \nD. AWS 데이터베이스 마이그레이션 서비스(AWS DMS)를 사용합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/99949-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n이 옵션은 온프레미스와 AWS 스토리지 서비스 간에 데이터 이동을 자동화하고 가속화하는 \n안전한 온라인 서비스인 AWS DataSync 를 사용하기 때문에 가장 효율적입니다. 또한 \nDataSync 를 사용하여 정기적으로 두 리전의 NFS 파일 시스템 간에 대량의 데이터를 \n주고받으며 최소한의 운영 오버헤드로 데이터 전송 프로세스를 단순화하고 가속화합니다. \n이 솔루션은 최소한의 운영 오버헤드로 정기적으로 두 리전의 NFS 파일 시스템 간에 \n대량의 데이터를 주고받는 요구 사항을 충족합니다. \n \n옵션 B 는 대량의 데이터를 AWS 안팎으로 전송할 수 있는 물리적 디바이스인 AWS \nSnowball 디바이스를 사용하기 때문에 효율성이 떨어집니다. 그러나 이것은 장치의 수동 \n취급 및 배송을 필요로 하기 때문에 주기적인 데이터 전송 솔루션을 제공하지 않습니다. \n \n옵션 C 는 Amazon S33 에 저장된 파일에 대한 보안 파일 전송 프로토콜(SFTP) 액세스를 \n제공하는 방법인 Amazon EC2 에 SFTP 서버를 설정하기 때문에 효율성이 떨어집니다. \n그러나 파일 전송을 수동으로 시작하고 모니터링해야 하므로 주기적인 데이터 전송 \n솔루션을 제공하지 않습니다. \n \n옵션 D 는 데이터베이스를 AWS 로 빠르고 안전하게 마이그레이션하는 데 도움이 되는 \n서비스인 AWS DMS(AWS Database Migration Service)를 사용하기 때문에 효율성이 \n떨어집니다. 그러나 이것은 관계형 데이터베이스 및 비관계형 데이터 저장소만 지원하므로 \nNFS 파일 시스템용 데이터 전송 솔루션을 제공하지 않습니다.", "answer_choice": "A"}, "305": {"q_num": 305, "question": "회사는 AWS 클라우드에서 호스팅되는 게임 애플리케이션을 위한 공유 스토리지 솔루션을 \n설계하고 있습니다. 회사는 SMB 클라이언트를 사용하여 데이터에 액세스할 수 있는 기능이 \n필요합니다. 솔루션은 완전히 관리되어야 합니다. \n어떤 AWS 솔루션이 이러한 요구 사항을 충족합니까? \nA. 탑재 가능한 파일 시스템으로 데이터를 공유하는 AWS DataSync 작업을 생성합니다. \n\n파일 시스템을 애플리케이션 서버에 마운트하십시오. \nB. Amazon EC2 Windows 인스턴스를 생성합니다. 인스턴스에 Windows 파일 공유 역할을 \n설치하고 구성합니다. 응용 프로그램 서버를 파일 공유에 연결합니다. \nC. Windows 파일 서버 파일 시스템용 Amazon FSx 를 생성합니다. 원본 서버에 파일 \n시스템을 연결합니다. 애플리케이션 서버를 파일 시스템에 연결하십시오. \nD. Amazon S3 버킷을 생성합니다. 애플리케이션에 IAM 역할을 할당하여 S3 버킷에 대한 \n액세스 권한을 부여합니다. S3 버킷을 애플리케이션 서버에 마운트합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/99809-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nAmazon FSx for Windows File Server(Amazon FSx)는 서버 메시지 블록(SMB) 프로토콜을 \n사용하는 Windows Server 에 구축된 완전 관리형, 고가용성 및 확장 가능한 파일 스토리지 \n솔루션입니다. 다른 중요한 엔터프라이즈 기능 중에서 Microsoft Active Directory 통합, \n데이터 중복 제거 및 완전히 관리되는 백업을 허용합니다.  \nhttps://aws.amazon.com/blogs/storage/accessing-smb-fileshares-remotely-with-amazo\nn-fsx-for-windows-file-server/", "answer_choice": "C"}, "306": {"q_num": 306, "question": "회사는 Amazon EC2 인스턴스에서 실행되는 지연 시간에 민감한 애플리케이션을 위해 인 \n메모리 데이터베이스를 실행하려고 합니다. 애플리케이션은 분당 100,000\n개 이상의 \n트랜잭션을 처리하며 높은 네트워크 처리량이 필요합니다. 솔루션 설계자는 데이터 전송 \n비용을 최소화하는 비용 효율적인 네트워크 설계를 제공해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 동일한 AWS 리전 내의 동일한 가용 영역에서 모든 EC2 인스턴스를 시작합니다. EC2 \n인스턴스를 시작할 때 클러스터 전략으로 배치 그룹을 지정합니다. \nB. 동일한 AWS 지역 내의 다른 가용 영역에서 모든 EC2 인스턴스를 시작합니다. EC2 \n인스턴스를 시작할 때 파티션 전략으로 배치 그룹을 지정합니다. \nC. Auto Scaling 그룹을 배포하여 네트워크 활용 목표에 따라 다른 가용 영역에서 EC2 \n인스턴스를 시작합니다. \nD. 서로 다른 가용 영역에서 EC2 인스턴스를 시작하기 위해 단계 조정 정책으로 Auto \nScaling 그룹을 배포합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/99807-exam-aws-certified-solut\n\nions-architect-associate-saa-c03/ \n \n설명: \n* 단일 AZ 내에서 인스턴스를 시작하고 클러스터 배치 그룹을 사용하면 네트워크 대기 \n시간이 가장 짧고 인스턴스 간 대역폭이 가장 높습니다. 이는 메모리 데이터베이스 및 \n처리량이 많은 애플리케이션의 성능을 최대화합니다. \n* 동일한 AZ 에 있는 인스턴스와 배치 그룹 간의 통신은 무료이므로 데이터 전송 요금이 \n최소화됩니다. AZ 간 및 퍼블릭 IP 트래픽에는 요금이 발생할 수 있습니다. \n* 클러스터 배치 그룹을 사용하면 인스턴스를 AZ 내에서 서로 가깝게 배치할 수 있으므로 \n필요한 높은 네트워크 처리량이 가능합니다. 파티션 그룹은 AZ 에 걸쳐 있으므로 대역폭이 \n줄어듭니다. \n* 영역 간 Auto Scaling 은 AZ 에서 인스턴스를 시작하여 데이터 전송 요금을 증가시킬 수 \n있습니다. 네트워크 처리량이 줄어들어 성능에 영향을 미칠 수 있습니다.", "answer_choice": "A"}, "307": {"q_num": 307, "question": "주로 온프레미스에서 애플리케이션 서버를 실행하는 회사가 AWS 로 마이그레이션하기로 \n결정했습니다. 회사는 온프레미스에서 iSCSI(Internet Small Computer Systems Interface) \n스토리지를 확장해야 할 필요성을 최소화하려고 합니다. 회사는 최근에 액세스한 데이터만 \n로컬에 저장하기를 원합니다. \n회사는 이러한 요구 사항을 충족하기 위해 어떤 AWS 솔루션을 사용해야 합니까? \nA. Amazon S3 파일 게이트웨이 \nB. AWS Storage Gateway 테이프 게이트웨이 \nC. AWS Storage Gateway 볼륨 게이트웨이 저장 볼륨 \nD. AWS Storage Gateway 볼륨 게이트웨이 캐시 볼륨", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/99611-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nAWS Storage Gateway Volume Gateway 는 iSCSI 스토리지에 연결하기 위한 두 가지 구성, \n즉 저장 볼륨과 캐시 볼륨을 제공합니다. 저장된 볼륨 구성은 전체 데이터 세트를 \n온프레미스에 저장하고 데이터를 AWS 에 비동기식으로 백업합니다. 캐싱된 볼륨 구성은 \n최근에 액세스한 데이터를 온프레미스에 저장하고 나머지 데이터는 Amazon S3\n에 \n저장합니다. 회사는 최근에 액세스한 데이터만 로컬에 저장하기를 원하므로 캐시된 볼륨 \n구성이 가장 적절할 것입니다. 이를 통해 회사는 자주 액세스하는 데이터를 온프레미스에 \n\n보관하고 iSCSI 스토리지 확장의 필요성을 줄이면서 AWS 클라우드를 통해 모든 데이터에 \n대한 액세스를 계속 제공할 수 있습니다. 또한 이 구성은 자주 액세스하는 데이터에 대한 \n짧은 대기 시간 액세스와 자주 액세스하지 않는 데이터에 대한 비용 효율적인 오프사이트 \n백업을 제공합니다. \nhttps://docs.amazonaws.cn/en_us/storagegateway/latest/vgw/StorageGatewayConcepts.\nhtml#stora", "answer_choice": "D"}, "308": {"q_num": 308, "question": "회사에 통합 결제를 사용하는 여러 AWS 계정이 있습니다. 이 회사는 90 일 동안 여러 개의 \n활성 고성능 Amazon RDS for Oracle 온디맨드 DB 인스턴스를 실행합니다. 회사의 재무 \n팀은 통합 결제 계정 및 기타 모든 AWS 계정에서 AWS Trusted Advisor 에 액세스할 수 \n있습니다. \n재무 팀은 적절한 AWS 계정을 사용하여 RDS 에 대한 Trusted Advisor 확인 권장 사항에 \n액세스해야 합니다. 재무팀은 적절한 Trusted Advisor 수표를 검토하여 RDS 비용을 줄여야 \n합니다. \n이러한 요구 사항을 충족하기 위해 재무 팀은 어떤 조합의 단계를 수행해야 합니까? (2 개 \n선택) \nA. RDS 인스턴스가 실행 중인 계정의 Trusted Advisor 권장 사항을 사용합니다. \nB. 통합 결제 계정의 Trusted Advisor 권장 사항을 사용하여 모든 RDS 인스턴스 확인을 \n동시에 확인합니다. \nC. Amazon RDS 예약 인스턴스 최적화에 대한 Trusted Advisor 검사를 검토합니다. \nD. Amazon RDS 유휴 DB 인스턴스에 대한 Trusted Advisor 검사를 검토합니다. \nE. Amazon Redshift 예약 노드 최적화에 대한 Trusted Advisor 검사를 검토합니다.", "answer_block": "Answer: B, D \nhttps://www.examtopics.com/discussions/amazon/view/99936-exam-aws-certified-solut\nions-architect-associate-saa-c03/", "answer_choice": "B"}, "309": {"q_num": 309, "question": "솔루션 설계자는 스토리지 비용을 최적화해야 합니다. 솔루션 설계자는 더 이상 액세스하지 \n않거나 거의 액세스하지 않는 Amazon S3 버킷을 식별해야 합니다. \n최소한의 운영 오버헤드로 이 목표를 달성할 수 있는 솔루션은 무엇입니까? \nA. 고급 활동 메트릭에 대한 S3 Storage Lens 대시보드를 사용하여 버킷 액세스 패턴을 \n분석합니다. \nB. AWS Management Console\n에서 S3 대시보드를 사용하여 버킷 액세스 패턴을 \n\n분석합니다. \nC. 버킷에 대한 Amazon CloudWatch BucketSizeBytes 지표를 켭니다. Amazon Athena 에서 \n메트릭 데이터를 사용하여 버킷 액세스 패턴을 분석합니다. \nD. S3 객체 모니터링을 위해 AWS CloudTrail 을 켭니다. Amazon CloudWatch Logs 와 \n통합된 CloudTrail 로그를 사용하여 버킷 액세스 패턴을 분석합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/99803-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nS3 Storage Lens 는 객체 스토리지 사용량, 활동 추세 및 비용 최적화를 위한 권장 사항에 \n대한 종합적인 보기를 제공하는 완전관리형 S3 스토리지 분석 솔루션입니다. Storage \nLens 를 사용하면 모든 S3 버킷에서 객체 액세스 패턴을 분석하고 자세한 지표와 보고서를 \n생성할 수 있습니다.", "answer_choice": "A"}, "310": {"q_num": 310, "question": "회사에서 인공 지능 및 기계 학습(AI/ML)을 연구하는 고객에게 데이터 세트를 판매합니다. \n데이터 세트는 us-east-1 리전의 Amazon S3 버킷에 저장되는 형식이 지정된 대용량 \n파일입니다. 회사는 고객이 주어진 데이터 세트에 대한 액세스를 구매하는 데 사용하는 웹 \n애플리케이션을 호스팅합니다. 웹 애플리케이션은 Application Load Balancer 뒤의 여러 \nAmazon EC2 인스턴스에 배포됩니다. 구매 후 고객은 파일에 대한 액세스를 허용하는 S3 \n서명 URL 을 받습니다. \n고객은 북미와 유럽 전역에 분산되어 있습니다. 회사는 데이터 전송과 관련된 비용을 \n줄이고 성능을 유지하거나 개선하고자 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. 기존 S3 버킷에서 S3 Transfer Acceleration 을 구성합니다. 고객 요청을 S3 Transfer \nAcceleration 엔드포인트로 안내합니다. 액세스 제어를 위해 S3 서명 URL\n을 계속 \n사용하십시오. \nB. 기존 S3 버킷을 원본으로 사용하여 Amazon CloudFront 배포를 배포합니다. 고객 \n요청을 CloudFront URL 로 전달합니다. 액세스 제어를 위해 CloudFront 서명 URL 로 \n전환하십시오. \nC. 버킷 사이에 S3 교차 리전 복제가 있는 eu-central-1 리전에서 두 번째 S3 버킷을 \n설정합니다. 가장 가까운 지역으로 고객 요청을 전달합니다. 액세스 제어를 위해 S3 서명 \nURL 을 계속 사용하십시오. \nD. 데이터세트를 최종 사용자에게 스트리밍할 수 있도록 웹 애플리케이션을 수정합니다. \n\n기존 S3 버킷에서 데이터를 읽도록 웹 애플리케이션을 구성합니다. 애플리케이션에서 직접 \n액세스 제어를 구현합니다.", "answer_block": "Answer: B  \nhttps://www.examtopics.com/discussions/amazon/view/99697-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n참고: \nhttps://docs.aws.amazon.com/ko_kr/AmazonCloudFront/latest/DeveloperGuide/PrivateCo\nntent.html", "answer_choice": "B"}, "311": {"q_num": 311, "question": "한 회사에서 AWS 를 사용하여 보험 견적을 처리할 웹 애플리케이션을 설계하고 있습니다. \n사용자는 애플리케이션에서 견적을 요청합니다. 견적은 견적 유형별로 구분되어야 하며, \n24 시간 이내에 응답해야 하며 분실해서는 안 됩니다. 솔루션은 운영 효율성을 극대화하고 \n유지 보수를 최소화해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 견적 유형에 따라 여러 Amazon Kinesis 데이터 스트림을 생성합니다. 적절한 데이터 \n스트림으로 메시지를 보내도록 웹 애플리케이션을 구성합니다. Kinesis Client Library(KCL)를 \n사용하여 자체 데이터 스트림에서 메시지를 풀링하도록 애플리케이션 서버의 각 백엔드 \n그룹을 구성합니다. \nB. \n각 견적 유형에 \n대해 AWS Lambda \n함수 및 Amazon Simple Notification \nService(Amazon SNS) 주제를 생성합니다. 연결된 SNS 주제에 Lambda 함수를 구독합니다. \n견적 요청을 적절한 SNS 주제에 게시하도록 애플리케이션을 구성합니다. \nC. 단일 Amazon Simple Notification Service(Amazon SNS) 주제를 생성합니다. SNS 주제에 \n대한 Amazon Simple Queue Service(Amazon SQS) 대기열을 구독합니다. 견적 유형에 따라 \n적절한 SQS 대기열에 메시지를 게시하도록 SNS 메시지 필터링을 구성합니다. 자체 SQS \n대기열을 사용하도록 각 백엔드 애플리케이션 서버를 구성합니다. \nD. 데이터 스트림을 Amazon OpenSearch Service 클러스터로 전달하기 위해 견적 유형을 \n기반으로 여러 Amazon Kinesis Data Firehose 전달 스트림을 생성합니다. 적절한 전송 \n스트림으로 메시지를 보내도록 애플리케이션을 구성합니다. OpenSearch Service\n에서 \n메시지를 검색하고 그에 따라 처리하도록 애플리케이션 서버의 각 백엔드 그룹을 \n구성합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/99627-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n\n \n참고: \nhttps://aws.amazon.com/getting-started/hands-on/filter-messages-published-to-topics\n/", "answer_choice": "C"}, "312": {"q_num": 312, "question": "한 회사에 여러 Amazon EC2 인스턴스에서 실행되는 애플리케이션이 있습니다. 각 EC2 \n인스턴스에는 여러 Amazon Elastic Block Store(Amazon EBS) 데이터 볼륨이 연결되어 \n있습니다. 애플리케이션의 EC2 인스턴스 구성 및 데이터는 야간에 백업해야 합니다. 또한 \n애플리케이션은 다른 AWS 리전에서 복구 가능해야 합니다. \n운영상 가장 효율적인 방식으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 애플리케이션 EBS 볼륨의 야간 스냅샷을 예약하고 스냅샷을 다른 리전에 복사하는 \nAWS Lambda 함수를 작성하십시오. \nB. 야간 백업을 수행하기 위해 AWS Backup 을 사용하여 백업 계획을 생성합니다. 백업을 \n다른 리전에 복사합니다. 애플리케이션의 EC2 인스턴스를 리소스로 추가합니다. \nC. 야간 백업을 수행하기 위해 AWS Backup 을 사용하여 백업 계획을 만듭니다. 백업을 \n다른 리전에 복사합니다. 애플리케이션의 EBS 볼륨을 리소스로 추가합니다. \nD. 애플리케이션 EBS 볼륨의 야간 스냅샷을 예약하고 스냅샷을 다른 가용 영역에 복사하는 \nAWS Lambda 함수를 작성합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/99785-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n이러한 요구 사항을 충족하는 운영상 가장 효율적인 솔루션은 AWS Backup 을 사용하여 \n야간 백업을 수행하고 백업을 다른 리전에 복사하는 백업 계획을 만드는 것입니다. \n애플리케이션의 EBS 볼륨을 리소스로 추가하면 애플리케이션의 EC2 인스턴스 구성 및 \n데이터가 백업되고 백업을 다른 리전에 복사하면 애플리케이션을 다른 AWS 리전에서 \n복구할 수 있습니다.", "answer_choice": "B"}, "313": {"q_num": 313, "question": "회사가 AWS 에서 모바일 앱을 구축하고 있습니다. 회사는 수백만 명의 사용자에게 도달 \n범위를 확장하려고 합니다. 회사는 승인된 사용자가 모바일 장치에서 회사의 콘텐츠를 볼 \n수 있도록 플랫폼을 구축해야 합니다. \n\n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까? \nA. 퍼블릭 Amazon S3 버킷에 콘텐츠를 게시합니다. AWS Key Management Service(AWS \nKMS) 키를 사용하여 콘텐츠를 스트리밍합니다. \nB. 모바일 앱과 AWS 환경 간에 IPsec VPN 을 설정하여 콘텐츠를 스트리밍합니다. \nC. Amazon CloudFront 를 사용합니다. 스트리밍 콘텐츠에 서명된 URL 을 제공합니다. \nD. 모바일 앱과 AWS 환경 간에 AWS Client VPN 을 설정하여 콘텐츠를 스트리밍합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/100130-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nAmazon CloudFront 는 짧은 지연 시간과 높은 전송 속도로 데이터, 비디오, 애플리케이션 \n및 API\n를 전 세계 고객에게 안전하게 전달하는 콘텐츠 전송 네트워크(CDN)입니다. \nCloudFront 는 콘텐츠에 대한 인증된 액세스를 제공하는 서명된 URL 을 지원합니다. 이 \n기능을 통해 회사는 콘텐츠에 액세스할 수 있는 사람과 기간을 제어하여 수백만 명의 \n사용자에게 안전하고 확장 가능한 솔루션을 제공할 수 있습니다.", "answer_choice": "C"}, "314": {"q_num": 314, "question": "회사에는 드물게 액세스하는 패턴으로 글로벌 영업 팀에서 사용하는 온프레미스 MySQL \n데이터베이스가 있습니다. 영업팀은 데이터베이스의 가동 중지 시간을 최소화해야 합니다. \n데이터베이스 관리자는 향후 더 많은 사용자를 예상하여 특정 인스턴스 유형을 선택하지 \n않고 이 데이터베이스를 AWS 로 마이그레이션하려고 합니다. \n솔루션 설계자는 어떤 서비스를 추천해야 합니까? \nA. 아마존 오로라 MySQL \nB. MySQL 용 Amazon Aurora 서버리스 \nC. 아마존 레드시프트 스펙트럼 \nD. MySQL 용 Amazon RDS", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/99769-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nAmazon Aurora Serverless for MySQL 은 애플리케이션 수요에 따라 자동으로 확장 또는 \n축소되는 완전관리형 자동 확장 관계형 데이터베이스 서비스입니다. 이 서비스는 고객이 \n데이터베이스 인스턴스를 프로비저닝할 필요 없이 고가용성, 내구성 및 보안과 같은 \n\nAmazon Aurora 의 모든 기능을 제공합니다. Amazon Aurora Serverless for MySQL 을 \n사용하면 증가한 트래픽을 수용할 수 있도록 데이터베이스가 자동으로 확장되도록 \n설계되었기 때문에 영업 팀은 다운타임을 최소화할 수 있습니다. 또한 이 서비스를 통해 \n고객은 사용한 용량에 대해서만 비용을 지불할 수 있으므로 자주 사용하지 않는 액세스 \n패턴에 대해 비용 효율적입니다. Amazon RDS for MySQL 도 옵션이 될 수 있지만 고객이 \n인스턴스 유형을 선택해야 하고 데이터베이스 관리자는 증가하는 트래픽을 수용하기 위해 \n수동으로 인스턴스 크기를 모니터링하고 조정해야 합니다.", "answer_choice": "B"}, "315": {"q_num": 315, "question": "회사는 온프레미스 데이터 센터의 여러 애플리케이션에 영향을 미치는 위반을 경험했습니다. \n공격자는 서버에서 실행 중인 맞춤형 애플리케이션의 취약점을 이용했습니다. 이 회사는 \n현재 Amazon EC2 인스턴스에서 실행되도록 애플리케이션을 마이그레이션하고 있습니다. \n이 회사는 EC2 인스턴스의 취약성을 능동적으로 스캔하고 결과를 자세히 설명하는 \n보고서를 보내는 솔루션을 구현하려고 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. AWS Shield\n를 배포하여 EC2 인스턴스의 취약점을 스캔합니다. 결과를 AWS \nCloudTrail 에 기록하는 AWS Lambda 함수를 생성합니다. \nB. Amazon Macie 및 AWS Lambda 함수를 배포하여 EC2 인스턴스의 취약점을 스캔합니다. \n결과를 AWS CloudTrail 에 기록합니다. \nC. Amazon GuardDuty 를 켭니다. GuardDuty 에이전트를 EC2 인스턴스에 배포합니다. \n결과를 자세히 설명하는 보고서의 생성 및 배포를 자동화하도록 AWS Lambda 함수를 \n구성합니다. \nD. Amazon Inspector를 켭니다. Amazon Inspector 에이전트를 EC2 인스턴스에 배포합니다. \n결과를 자세히 설명하는 보고서의 생성 및 배포를 자동화하도록 AWS Lambda 함수를 \n구성합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/99808-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nAmazon Inspector(Amazon 검사기): \n* EC2 인스턴스의 활성 취약성 스캔을 수행합니다. 소프트웨어 취약성, 의도하지 않은 \n네트워크 접근성 및 기타 보안 문제를 찾습니다. \n* 스캔을 수행하려면 EC2 인스턴스에 에이전트를 설치해야 합니다. 에이전트는 각 \n인스턴스에 배포되어야 합니다. \n\n* 보안 위험 또는 취약점에 대한 발견 사항을 자세히 설명하는 예약 검사 보고서를 \n제공합니다. 이러한 보고서는 문제를 패치하거나 수정하는 데 사용할 수 있습니다. \n* AWS 환경에서 보안 취약점 및 잘못된 구성을 사전에 감지하는 데 가장 적합합니다.", "answer_choice": "D"}, "316": {"q_num": 316, "question": "회사는 Amazon EC2 인스턴스를 사용하여 스크립트를 실행하여 Amazon Simple Queue \nService(Amazon SQS) 대기열에서 메시지를 폴링하고 처리합니다. 이 회사는 대기열에 \n추가되는 점점 더 많은 수의 메시지를 처리할 수 있는 능력을 유지하면서 운영 비용을 \n절감하고자 합니다. \n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까? \nA. 메시지를 더 빠르게 처리하려면 EC2 인스턴스의 크기를 늘리십시오. \nB. 인스턴스가 충분히 활용되지 않을 때 Amazon EventBridge 를 사용하여 EC2 인스턴스를 \n끕니다. \nC. \nEC2 \n인스턴스의 \n스크립트를 \n적절한 \n런타임이 \n있는 \nAWS \nLambda \n함수로 \n마이그레이션합니다. \nD. AWS Systems Manager Run Command 를 사용하여 요청 시 스크립트를 실행합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/99698-exam-aws-certified-solut\nions-architect-associate-saa-c03/", "answer_choice": "C"}, "317": {"q_num": 317, "question": "회사에서 레거시 애플리케이션을 사용하여 데이터를 CSV 형식으로 생성합니다. 레거시 \n애플리케이션은 출력 데이터를 Amazon S3 에 저장합니다. 이 회사는 복잡한 SQL 쿼리를 \n수행하여 Amazon Redshift 및 Amazon S3 에만 저장된 데이터를 분석할 수 있는 새로운 \n상용 기성품(COTS) 애플리케이션을 배포하고 있습니다. 그러나 COTS 애플리케이션은 \n레거시 애플리케이션이 생성하는 .csv 파일을 처리할 수 없습니다. \n회사는 레거시 애플리케이션을 업데이트하여 다른 형식으로 데이터를 생성할 수 없습니다. \n회사는 COTS 애플리케이션이 레거시 애플리케이션이 생성하는 데이터를 사용할 수 있도록 \n솔루션을 구현해야 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 일정에 따라 실행되는 AWS Glue 추출, 변환 및 로드(ETL) 작업을 생성합니다. .csv \n파일을 처리하고 처리된 데이터를 Amazon Redshift 에 저장하도록 ETL 작업을 구성합니다. \nB. Amazon EC2 인스턴스에서 실행되는 Python 스크립트를 개발하여 .csv 파일을 .sql \n파일로 변환합니다. Cron 일정에서 Python 스크립트를 호출하여 출력 파일을 Amazon S3 에 \n\n저장합니다. \nC. AWS Lambda 함수와 Amazon DynamoDB 테이블을 생성합니다. S3 이벤트를 사용하여 \nLambda 함수를 호출합니다. ETL(추출, 변환 및 로드) 작업을 수행하여 .csv 파일을 \n처리하고 처리된 데이터를 DynamoDB 테이블에 저장하도록 Lambda 함수를 구성합니다. \nD. Amazon EventBridge\n를 사용하여 매주 일정에 따라 Amazon EMR 클러스터를 \n시작합니다. 추출, 변환 및 로드(ETL) 작업을 수행하여 .csv 파일을 처리하고 처리된 \n데이터를 Amazon Redshift 테이블에 저장하도록 EMR 클러스터를 구성합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/99817-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n이 솔루션은 COTS 애플리케이션이 최소한의 운영 오버헤드로 레거시 애플리케이션이 \n생성하는 데이터를 사용할 수 있도록 솔루션 구현 요구 사항을 충족합니다. AWS Glue 는 \n분석을 위해 데이터를 준비하고 로드하는 서버리스 ETL 플랫폼을 제공하는 완전 관리형 \n서비스입니다. \nAWS Glue 는 .csv 파일을 비롯한 다양한 형식의 데이터를 처리하고 복잡한 SQL 쿼리를 \n지원하는 완전관리형 데이터 웨어하우스 서비스인 Amazon Redshift 에 처리된 데이터를 \n저장할 수 있습니다. AWS Glue 는 데이터 처리 및 로드 프로세스를 자동화할 수 있는 \n일정에 따라 ETL 작업을 실행할 수 있습니다. \n \n옵션 B 는 올바르지 않습니다. Amazon EC2 인스턴스에서 실행되는 Python 스크립트를 \n개발하여 .csv 파일을 sql 파일로 변환하면 운영 오버헤드와 복잡성이 증가하고 COTS \n애플리케이션에 일관된 데이터 처리 및 로드를 제공하지 못할 수 있기 때문입니다. \n \n.csv 파일을 처리하고 처리된 데이터를 DynamoDB 테이블에 저장하기 위해 AWS Lambda \n함수 및 Amazon DynamoDB 테이블을 생성하는 것은 Amazon Redshift\n를 COTS \n애플리케이션의 데이터 소스로 사용하기 위한 요구 사항을 충족하지 않기 때문에 옵션 C 는 \n올바르지 않습니다. \n \nAmazon EventBridge(Amazon CloudWatch Events)를 사용하여 주간 일정에 따라 Amazon \nEMR 클러스터를 시작하여 .csv 파일을 처리하고 처리된 데이터를 Amazon Redshift \n테이블에 저장할 수 있으므로 옵션 D 는 올바르지 않습니다. COTS 애플리케이션에 적시에 \n데이터 처리 및 로드를 제공하지 않습니다. \n참조: \nhttps://aws.amazon.com/glue/ \n\nhttps://aws.amazon.com/redshift/", "answer_choice": "A"}, "318": {"q_num": 318, "question": "한 회사가 최근 전체 IT 환경을 AWS 클라우드로 마이그레이션했습니다. 회사는 사용자가 \n적절한 변경 제어 프로세스를 사용하지 않고 과도한 크기의 Amazon EC2 인스턴스를 \n프로비저닝하고 보안 그룹 규칙을 수정하고 있음을 발견했습니다. 솔루션 설계자는 이러한 \n인벤토리 및 구성 변경 사항을 추적하고 감사하기 위한 전략을 고안해야 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 조치를 취해야 합니까? (2 개 \n선택) \nA. AWS CloudTrail 을 활성화하고 감사에 사용하십시오. \nB. Amazon EC2 인스턴스에 대한 데이터 수명 주기 정책을 사용합니다. \nC. AWS Trusted Advisor 를 활성화하고 보안 대시보드를 참조합니다. \nD. AWS Config 를 활성화하고 감사 및 규정 준수를 위한 규칙을 생성합니다. \nE. AWS CloudFormation 템플릿을 사용하여 이전 리소스 구성을 복원합니다.", "answer_block": "Answer: A, D \nhttps://www.examtopics.com/discussions/amazon/view/99804-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nA) AWS CloudTrail 을 활성화하고 감사에 사용합니다. AWS CloudTrail 은 API 호출 기록을 \n제공하며 EC2 인스턴스 및 보안 그룹에 대한 변경 사항을 감사하는 데 사용할 수 있습니다. \n솔루션 설계자는 CloudTrail 로그를 분석하여 적절한 승인 없이 누가 대규모 인스턴스를 \n프로비저닝했거나 보안 그룹을 수정했는지 추적할 수 있습니다. \nD) AWS Config 를 활성화하고 감사 및 규정 준수를 위한 규칙을 생성합니다. AWS Config 는 \nEC2 인스턴스 및 보안 그룹과 같은 리소스에 대한 구성 변경 사항을 기록할 수 있습니다. \n솔루션 설계자는 특정 인스턴스 유형을 시작하거나 권한 없이 보안 그룹 포트를 여는 것과 \n같은 비준수 변경 사항을 모니터링하기 위해 AWS Config 규칙을 생성할 수 있습니다. AWS \nConfig 는 이러한 규칙 위반에 대해 경고합니다.", "answer_choice": "A"}, "319": {"q_num": 319, "question": "회사는 AWS 클라우드에 수백 개의 Amazon EC2 Linux 기반 인스턴스를 보유하고 있습니다. \n시스템 관리자는 공유 SSH 키를 사용하여 인스턴스를 관리했습니다. 최근 감사 후 회사의 \n보안 팀은 모든 공유 키를 제거하도록 지시하고 있습니다. 솔루션 설계자는 EC2 \n인스턴스에 대한 보안 액세스를 제공하는 솔루션을 설계해야 합니다. \n\n최소한의 관리 오버헤드로 이 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. AWS Systems Manager Session Manager 를 사용하여 EC2 인스턴스에 연결합니다. \nB. AWS Security Token Service(AWS STS)를 사용하여 온디맨드 방식으로 일회성 SSH 키를 \n생성합니다. \nC. 배스천 인스턴스 집합에 대한 공유 SSH 액세스를 허용합니다. 배스천 인스턴스에서 \nSSH 액세스만 허용하도록 다른 모든 인스턴스를 구성합니다. \nD. Amazon Cognito 사용자 지정 권한 부여자를 사용하여 사용자를 인증합니다. AWS \nLambda 함수를 호출하여 임시 SSH 키를 생성합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/99628-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nSession Manager\n는 완전히 관리되는 AWS Systems Manager 기능입니다. Session \nManager 를 사용하여 Amazon Elastic Compute Cloud(Amazon EC2) 인스턴스, 에지 장치, \n온프레미스 서버 및 가상 머신(VM)을 관리할 수 있습니다. 대화형 원클릭 브라우저 기반 셸 \n또는 AWS Command Line Interface(AWS CLI)를 사용할 수 있습니다. Session Manager 는 \n인바운드 포트를 열거나 배스천 호스트를 유지하거나 SSH 키를 관리할 필요 없이 안전하고 \n감사 가능한 노드 관리를 제공합니다. \n또한 Session Manager 를 사용하면 관리 노드에 대한 제어된 액세스, 엄격한 보안 관행, \n노드 액세스 세부 정보가 포함된 완전히 감사 가능한 로그가 필요한 기업 정책을 준수하는 \n동시에 최종 사용자에게 관리 노드에 대한 간단한 원클릭 교차 플랫폼 액세스를 제공할 수 \n있습니다. \nhttps://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager.html", "answer_choice": "A"}, "320": {"q_num": 320, "question": "회사에서 Amazon EC2 인스턴스 플릿을 사용하여 온프레미스 데이터 소스에서 데이터를 \n수집하고 있습니다. 데이터는 JSON 형식이며 수집 속도는 최대 1MB/s\n입니다. EC2 \n인스턴스가 재부팅되면 진행 중인 데이터가 손실됩니다. 회사의 데이터 과학 팀은 거의 \n실시간으로 수집된 데이터를 쿼리하려고 합니다. \n데이터 손실을 최소화하면서 확장 가능한 거의 실시간 데이터 쿼리를 제공하는 솔루션은 \n무엇입니까? \nA. Amazon Kinesis Data Streams 에 데이터를 게시하고 Kinesis Data Analytics 를 사용하여 \n데이터를 쿼리합니다. \nB. Amazon Redshift 를 대상으로 사용하여 Amazon Kinesis Data Firehose 에 데이터를 \n\n게시합니다. Amazon Redshift 를 사용하여 데이터를 쿼리합니다. \nC. 수집된 데이터를 EC2 인스턴스 스토어에 저장합니다. Amazon S3 를 대상으로 Amazon \nKinesis Data Firehose 에 데이터를 게시합니다. Amazon Athena 를 사용하여 데이터를 \n쿼리합니다. \nD. 수집된 데이터를 Amazon Elastic Block Store(Amazon EBS) 볼륨에 저장합니다. Redis 용 \nAmazon ElastiCache 에 데이터를 게시합니다. Redis 채널을 구독하여 데이터를 쿼리합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/99752-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n참고 \nhttps://docs.aws.amazon.com/ko_kr/kinesisanalytics/latest/dev/what-is.html", "answer_choice": "A"}, "321": {"q_num": 321, "question": "솔루션 설계자는 Amazon S3 버킷에 업로드된 모든 객체가 암호화되도록 하려면 어떻게 \n해야 합니까? \nA. PutObject\n에 s3:x-amz-acl 헤더 세트가 없는 경우 거부하도록 버킷 정책을 \n업데이트합니다. \nB. PutObject 에 프라이빗으로 설정된 s3:x-amz-acl 헤더가 없는 경우 거부하도록 버킷 \n정책을 업데이트합니다. \nC. PutObject 에 true 로 설정된 aws:SecureTransport 헤더가 없는 경우 거부하도록 버킷 \n정책을 업데이트합니다. \nD. PutObject 에 x-amz-server-side-encryption 헤더 세트가 없는 경우 거부하도록 버킷 \n정책을 업데이트합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/99685-exam-aws-certified-solut\nions-architect-associate-saa-c03/", "answer_choice": "D"}, "322": {"q_num": 322, "question": "솔루션 설계자는 회사를 위한 다중 계층 애플리케이션을 설계하고 있습니다. 애플리케이션 \n사용자는 모바일 장치에서 이미지를 업로드합니다. 애플리케이션은 각 이미지의 썸네일을 \n생성하고 이미지가 성공적으로 업로드되었음을 확인하는 메시지를 사용자에게 반환합니다. \n썸네일 생성에는 최대 60\n초가 소요될 수 있지만 회사는 사용자에게 원본 이미지가 \n수신되었음을 알리기 위해 더 빠른 응답 시간을 제공하고자 합니다. 솔루션 설계자는 서로 \n\n다른 애플리케이션 계층에 요청을 비동기식으로 전달하도록 애플리케이션을 설계해야 \n합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. 사용자 지정 AWS Lambda 함수를 작성하여 썸네일을 생성하고 사용자에게 알립니다. \n이미지 업로드 프로세스를 이벤트 소스로 사용하여 Lambda 함수를 호출합니다. \nB. AWS Step Functions 워크플로를 생성합니다. 애플리케이션 계층 간의 오케스트레이션을 \n처리하고 썸네일 생성이 완료되면 사용자에게 알리도록 Step Functions 를 구성합니다. \nC. Amazon Simple Queue Service(Amazon SQS) 메시지 대기열을 생성합니다. 이미지가 \n업로드되면 \n썸네일 \n생성을 \n위해 \nSQS \n대기열에 \n메시지를 \n배치합니다. \n이미지가 \n수신되었음을 애플리케이션 메시지를 통해 사용자에게 알립니다. \nD. Amazon Simple Notification Service(Amazon SNS) 알림 주제 및 구독을 생성합니다. \n애플리케이션과 함께 하나의 구독을 사용하여 이미지 업로드가 완료된 후 썸네일을 \n생성하십시오. 섬네일 생성이 완료된 후 푸시 알림을 통해 사용자의 모바일 앱에 메시지를 \n보내려면 두 번째 구독을 사용하십시오.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/99753-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n이 옵션은 메시지 손실이나 다른 서비스를 사용할 필요 없이 모든 볼륨의 소프트웨어 구성 \n요소 간에 메시지를 전송, 저장 및 수신할 수 있는 완전 관리형 메시지 대기열 서비스인 \nAmazon SQS 를 사용하기 때문에 가장 효율적입니다. 또한 SQS 메시지 대기열을 사용하여 \n서로 다른 애플리케이션 계층에 요청을 비동기식으로 전달하여 썸네일 생성 프로세스에서 \n이미지 업로드 프로세스를 분리하고 확장성과 안정성을 활성화합니다. 또한 이미지가 \n수신되었다는 애플리케이션 메시지를 통해 사용자에게 경고하므로 섬네일 생성이 완료될 \n때까지 기다리는 것보다 사용자에게 더 빠른 응답 시간을 제공합니다. \n \n옵션 A 는 서버를 프로비저닝하거나 관리하지 않고 코드를 실행하는 방법인 사용자 지정 \nAWS Lambda 함수를 사용하여 썸네일을 생성하고 사용자에게 경고하기 때문에 효율성이 \n떨어집니다. \n그러나 이것은 썸네일 생성 프로세스에서 이미지 업로드 프로세스를 분리하기 위해 비동기 \n디스패치 메커니즘을 사용하지 않습니다. 또한 이미지 업로드 프로세스를 이벤트 소스로 \n사용하여 Lambda 함수를 호출하므로 한 번에 업로드된 이미지가 많은 경우 동시성 문제가 \n발생할 수 있습니다. \n \n옵션 B 는 애플리케이션의 구성 요소를 일련의 단계로 배열하고 시각화하는 그래픽 콘솔을 \n\n제공하는 완전관리형 서비스인 AWS Step Functions\n를 사용하기 때문에 효율성이 \n떨어집니다. 그러나 이것은 썸네일 생성 프로세스에서 이미지 업로드 프로세스를 분리하기 \n위해 비동기 디스패치 메커니즘을 사용하지 않습니다. 또한 Step Functions 를 사용하여 \n애플리케이션 계층 간의 오케스트레이션을 처리하고 썸네일 생성이 완료되면 사용자에게 \n경고하므로 추가적인 복잡성과 대기 시간이 발생할 수 있습니다. \n \n옵션 D 는 SMS 문자 메시지 또는 이메일을 통해 메시지 또는 알림을 사용자에게 직접 보낼 \n수 있는 완전 관리형 메시징 서비스인 Amazon SNS\n를 사용하기 때문에 효율성이 \n떨어집니다. 그러나 이것은 썸네일 생성 프로세스에서 이미지 업로드 프로세스를 분리하기 \n위해 비동기 디스패치 메커니즘을 사용하지 않습니다. 또한 SNS 알림 주제 및 구독을 \n사용하여 이미지 업로드가 완료된 후 썸네일을 생성하고 썸네일 생성이 완료된 후 푸시 \n알림을 통해 사용자의 모바일 앱에 메시지를 보내므로 추가적인 복잡성과 대기 시간이 \n발생할 수 있습니다.", "answer_choice": "C"}, "323": {"q_num": 323, "question": "회사 시설에는 건물 전체의 모든 입구에 배지 판독기가 있습니다. 배지를 스캔하면 \n판독기가 HTTPS\n를 통해 메시지를 보내 누가 해당 입구에 액세스하려고 시도했는지 \n나타냅니다. \n솔루션 설계자는 센서에서 보내는 이러한 메시지를 처리하는 시스템을 설계해야 합니다. \n솔루션은 가용성이 높아야 하며 회사의 보안 팀이 분석할 수 있도록 결과를 제공해야 \n합니다. \n솔루션 설계자는 어떤 시스템 아키텍처를 추천해야 합니까? \nA. Amazon EC2 인스턴스를 시작하여 HTTPS 엔드포인트 역할을 하고 메시지를 처리합니다. \n결과를 Amazon S3 버킷에 저장하도록 EC2 인스턴스를 구성합니다. \nB. Amazon API Gateway 에서 HTTPS 엔드포인트를 생성합니다. AWS Lambda 함수를 \n호출하여 메시지를 처리하고 결과를 Amazon DynamoDB 테이블에 저장하도록 API \nGateway 엔드포인트를 구성합니다. \nC. Amazon Route 53 을 사용하여 들어오는 센서 메시지를 AWS Lambda 함수로 보냅니다. \n메시지를 처리하고 결과를 Amazon DynamoDB 테이블에 저장하도록 Lambda 함수를 \n구성합니다. \nD. Amazon S3\n용 게이트웨이 VPC 엔드포인트를 생성합니다. 센서 데이터가 VPC \n엔드포인트를 통해 S3 버킷에 직접 기록될 수 있도록 시설 네트워크에서 VPC\n로의 \nSite-to-Site VPN 연결을 구성합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/99699-exam-aws-certified-solut\n\nions-architect-associate-saa-c03/ \n \n설명: \nAmazon API Gateway 를 HTTPS 엔드포인트로 배포하고 AWS Lambda 를 배포하여 메시지를 \n처리하고 Amazon DynamoDB 테이블에 저장합니다. 이 옵션은 대량의 데이터를 쉽게 \n처리할 수 있는 가용성과 확장성이 뛰어난 솔루션을 제공합니다. 또한 다른 AWS 서비스와 \n통합되어 보안 팀의 데이터를 보다 쉽게 분석하고 시각화할 수 있습니다.", "answer_choice": "B"}, "324": {"q_num": 324, "question": "회사는 기본 온프레미스 파일 스토리지 볼륨에 대한 재해 복구 계획을 구현하려고 합니다. \n파일 스토리지 볼륨은 로컬 스토리지 서버의 iSCSI(Internet Small Computer Systems \nInterface) 장치에서 마운트됩니다. 파일 스토리지 볼륨은 수백 테라바이트(TB)의 데이터를 \n보유합니다. \n회사는 최종 사용자가 대기 시간 없이 온프레미스 시스템의 모든 파일 유형에 즉시 \n액세스할 수 있기를 원합니다. \n회사의 기존 인프라를 최소한으로 변경하면서 이러한 요구 사항을 충족하는 솔루션은 \n무엇입니까? \nA. 온프레미스에서 호스팅되는 가상 머신(VM)으로 Amazon S3 파일 게이트웨이를 \n프로비저닝합니다. 로컬 캐시를 10TB\n로 설정합니다. NFS 프로토콜을 통해 파일에 \n액세스하도록 기존 애플리케이션을 수정합니다. 재해에서 복구하려면 Amazon EC2 \n인스턴스를 프로비저닝하고 파일이 포함된 S3 버킷을 탑재합니다. \nB. AWS Storage Gateway 테이프 게이트웨이를 프로비저닝합니다. 데이터 백업 솔루션을 \n사용하여 모든 기존 데이터를 가상 테이프 라이브러리에 백업하십시오. 초기 백업이 완료된 \n후 야간에 실행되도록 데이터 백업 솔루션을 구성합니다. 재해에서 복구하려면 Amazon \nEC2 인스턴스를 프로비저닝하고 가상 테이프 라이브러리의 볼륨에서 Amazon Elastic Block \nStore(Amazon EBS) 볼륨으로 데이터를 복원합니다. \nC. AWS Storage Gateway 볼륨 게이트웨이 캐시 볼륨을 프로비저닝합니다. 로컬 캐시를 \n10TB 로 설정합니다. iSCSI 를 사용하여 볼륨 게이트웨이 캐싱 볼륨을 기존 파일 서버에 \n마운트하고 모든 파일을 스토리지 볼륨에 복사합니다. 스토리지 볼륨의 예약된 스냅샷을 \n구성합니다. 재해에서 복구하려면 스냅샷을 Amazon Elastic Block Store(Amazon EBS) \n볼륨으로 복원하고 EBS 볼륨을 Amazon EC2 인스턴스에 연결합니다. \nD. 기존 파일 스토리지 볼륨과 동일한 양의 디스크 공간으로 AWS Storage Gateway 볼륨 \n게이트웨이 저장 볼륨을 프로비저닝합니다. iSCSI 를 사용하여 볼륨 게이트웨이 저장 볼륨을 \n기존 파일 서버에 마운트하고 모든 파일을 스토리지 볼륨에 복사합니다. 스토리지 볼륨의 \n예약된 스냅샷을 구성합니다. 재해에서 복구하려면 스냅샷을 Amazon Elastic Block \n\nStore(Amazon EBS) 볼륨으로 복원하고 EBS 볼륨을 Amazon EC2 인스턴스에 연결합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/99711-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n\"회사는 최종 사용자가 온프레미스 시스템의 모든 파일 유형에 즉시 액세스할 수 있기를 \n원합니다.\" \n- 캐싱된 볼륨(Cached volumes): 가장 최근 데이터에 대한 액세스 대기 시간이 짧습니다. \n- 저장 볼륨(Stored volumes): 전체 데이터 세트는 온프레미스이며 S3 로 예약 백업되므로 \n볼륨 게이트웨이 저장 볼륨이 적절한 선택입니다.", "answer_choice": "D"}, "325": {"q_num": 325, "question": "회사는 Amazon S3 버킷에서 웹 애플리케이션을 호스팅하고 있습니다. 이 애플리케이션은 \nAmazon Cognito 를 자격 증명 공급자로 사용하여 사용자를 인증하고 다른 S3 버킷에 \n저장된 보호된 리소스에 대한 액세스를 제공하는 JSON 웹 토큰(JWT)을 반환합니다. \n응용 프로그램 배포 시 사용자는 오류를 보고하고 보호된 콘텐츠에 액세스할 수 없습니다. \n솔루션 설계자는 사용자가 보호된 콘텐츠에 액세스할 수 있도록 적절한 권한을 제공하여 이 \n문제를 해결해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. Amazon Cognito 자격 증명 풀을 업데이트하여 보호된 콘텐츠에 액세스하기 위한 적절한 \nIAM 역할을 맡습니다. \nB. 애플리케이션이 보호된 콘텐츠에 액세스할 수 있도록 S3 ACL 을 업데이트합니다. \nC. 애플리케이션을 Amazon S3 에 재배포하여 S3 버킷의 최종적으로 일관된 읽기가 보호된 \n콘텐츠에 액세스하는 사용자의 기능에 영향을 미치지 않도록 합니다. \nD. 자격 증명 풀 내에서 사용자 지정 속성 매핑을 사용하고 사용자에게 보호된 콘텐츠에 \n액세스할 수 있는 적절한 권한을 부여하도록 Amazon Cognito 풀을 업데이트합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/99754-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nAmazon Cognito 자격 증명 풀은 인증된 사용자에게 AWS 리소스에 액세스할 수 있는 \n권한이 제한된 임시 자격 증명 세트를 할당합니다. 각 사용자의 권한은 생성한 IAM 역할을 \n통해 \n제어됩니다. \n\nhttps://docs.aws.amazon.com/cognito/latest/developerguide/role-basedaccess-control.\nhtml", "answer_choice": "A"}, "326": {"q_num": 326, "question": "이미지 호스팅 회사는 대규모 자산을 Amazon S3 Standard 버킷에 업로드합니다. 회사는 \nS3 API 를 사용하여 멀티파트 업로드를 병렬로 사용하고 동일한 객체가 다시 업로드되면 \n덮어씁니다. 업로드 후 처음 30 일 동안 개체에 자주 액세스합니다. 개체는 30 일 후에 덜 \n자주 사용되지만 각 개체에 대한 액세스 패턴은 일관되지 않습니다. 회사는 저장된 자산의 \n고가용성과 탄력성을 유지하면서 S3 스토리지 비용을 최적화해야 합니다. \n이러한 요구 사항을 충족하기 위해 솔루션 설계자가 권장해야 하는 작업 조합은 무엇입니까? \n(두 가지를 선택하세요.) \nA. 30 일 후에 자산을 S3 Intelligent-Tiering 으로 이동합니다. \nB. 불완전한 멀티파트 업로드를 정리하도록 S3 수명 주기 정책을 구성합니다. \nC. 만료된 개체 삭제 마커를 정리하도록 S3 수명 주기 정책을 구성합니다. \nD. 30 일 후에 자산을 S3 Standard-Infrequent Access(S3 Standard-IA)로 이동합니다. \nE. 30 일 후 자산을 S3 One Zone-Infrequent Access(S3 One Zone-IA)로 이동합니다.", "answer_block": "Answer: A, B \nhttps://www.examtopics.com/discussions/amazon/view/99755-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nS3 Intelligent-Tiering 은 성능 영향, 검색 비용 또는 운영 오버헤드 없이 액세스 빈도에 \n따라 가장 비용 효율적인 액세스 계층으로 데이터를 자동으로 이동하는 스토리지 \n클래스입니다. 회사 자산과 같이 액세스 패턴을 알 수 없거나 변경하는 데이터에 \n이상적입니다. 30 일 후에 자산을 S3 Intelligent-Tiering 으로 이동함으로써 회사는 저장된 \n자산의 고가용성과 복원력을 유지하면서 스토리지 비용을 최적화할 수 있습니다. \nS3 수명 주기는 개체가 수명 주기 동안 비용 효율적으로 저장되도록 개체를 관리할 수 \n있게 해주는 기능입니다. 수명 주기 규칙을 생성하여 Amazon S3 가 객체 그룹에 적용하는 \n작업을 정의할 수 있습니다. 작업 중 하나는 업로드가 중단될 때 발생할 수 있는 불완전한 \n멀티파트 업로드를 중단하는 것입니다. 불완전한 멀티파트 업로드를 정리하도록 S3 수명 \n주기 정책을 구성함으로써 회사는 스토리지 비용을 줄이고 사용하지 않는 부분에 대한 비용 \n지불을 피할 수 있습니다. \n만료된 객체 삭제 마커는 Amazon S3 에서 자동으로 삭제되고 스토리지 비용이 발생하지 \n않기 때문에 옵션 C 는 올바르지 않습니다. 따라서 만료된 객체 삭제 마커를 정리하도록 S3 \n수명 주기 정책을 구성해도 회사의 스토리지 비용에는 영향을 미치지 않습니다. \n\n옵션 D 는 올바르지 않습니다. S3 Standard-IA 는 자주 액세스하지 않지만 필요할 때 \n신속하게 액세스해야 하는 데이터용 스토리지 클래스이기 때문입니다. S3 Standard 보다 \n저장 비용은 낮지만 검색 비용은 더 높고 최소 저장 기간 요금은 30 일입니다. 따라서 30 일 \n후에 자산을 S3 Standard-IA 로 이동해도 자산에 여전히 가끔 액세스하는 경우 회사의 \n스토리지 비용이 최적화되지 않을 수 있습니다. \n옵션 E 는 올바르지 않습니다. S3 One Zone-IA 는 자주 액세스하지 않지만 필요할 때 \n신속하게 액세스해야 하는 데이터용 스토리지 클래스이기 때문입니다. S3 Standard-IA 보다 \n스토리지 비용이 저렴하지만 하나의 가용 영역에만 데이터를 저장하고 다른 스토리지 \n클래스보다 복원력이 떨어집니다. 또한 검색 비용이 더 높고 최소 저장 기간 요금이 \n30 일입니다. 따라서 30 일 후에 자산을 S3 One Zone-IA 로 이동하면 자산이 여전히 가끔씩 \n액세스되거나 고가용성이 필요한 경우 회사의 스토리지 비용이 최적화되지 않을 수 \n있습니다. \n참조 URL: \nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/storage-class-intro.html \nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lifecycle-mgmt.html \nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/delete-or-empty-bucket.html\n#deletebucket-considerations \nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/mpuoverview.html \nhttps://aws.amazon.com/certification/certified-solutions-architect-associate/", "answer_choice": "A"}, "327": {"q_num": 327, "question": "솔루션 설계자는 Amazon EC2 인스턴스를 호스팅하는 VPC 네트워크를 보호해야 합니다. \nEC2 인스턴스는 매우 민감한 데이터를 포함하고 프라이빗 서브넷에서 실행됩니다. 회사 \n정책에 따라 VPC 에서 실행되는 EC2 인스턴스는 타사 URL 을 사용하는 소프트웨어 제품 \n업데이트를 위해 인터넷에서 승인된 타사 소프트웨어 리포지토리에만 액세스할 수 있습니다. \n다른 인터넷 트래픽은 차단되어야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 아웃바운드 트래픽을 AWS 네트워크 방화벽 방화벽으로 라우팅하도록 프라이빗 \n서브넷의 라우팅 테이블을 업데이트합니다. 도메인 목록 규칙 그룹을 구성합니다. \nB. AWS WAF 웹 ACL 을 설정합니다. 소스 및 대상 IP 주소 범위 집합을 기반으로 트래픽 \n요청을 필터링하는 사용자 지정 규칙 집합을 만듭니다. \nC. 엄격한 인바운드 보안 그룹 규칙을 구현합니다. URL 을 지정하여 인터넷에서 승인된 \n소프트웨어 리포지토리에 대한 트래픽만 허용하는 아웃바운드 규칙을 구성합니다. \nD. EC2 인스턴스 앞에 Application Load Balancer(ALB)를 구성합니다. 모든 아웃바운드 \n트래픽을 ALB 로 보냅니다. 인터넷에 대한 아웃바운드 액세스를 위해 ALB 의 대상 그룹에서 \n\nURL 기반 규칙 리스너를 사용합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/99795-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nEC2\n에서 네트워크 방화벽으로 아웃바운드 연결을 보냅니다. 네트워크 방화벽에서 \n소프트웨어 패치 다운로드를 위해 특정 도메인을 허용하고 다른 모든 도메인을 거부하는 \n상태 저장 아웃바운드 규칙을 생성합니다.", "answer_choice": "A"}, "328": {"q_num": 328, "question": "한 회사가 AWS 클라우드에서 3 계층 전자상거래 애플리케이션을 호스팅하고 있습니다. \n회사는 Amazon S3 에서 웹사이트를 호스팅하고 웹사이트를 판매 요청을 처리하는 API 와 \n통합합니다. 이 회사는 ALB(Application Load Balancer) 뒤에 있는 3 개의 Amazon EC2 \n인스턴스에서 API 를 호스팅합니다. API 는 판매 요청을 비동기식으로 처리하는 백엔드 \n작업자와 함께 정적 및 동적 프런트 엔드 콘텐츠로 구성됩니다. \n회사는 신제품 출시 이벤트 기간 동안 판매 요청 건수가 급격하게 급증할 것으로 예상하고 \n있다. \n모든 요청이 성공적으로 처리되도록 하려면 솔루션 설계자가 무엇을 권장해야 합니까? \nA. 동적 콘텐츠에 대한 Amazon CloudFront 배포를 추가합니다. 트래픽 증가를 처리하기 \n위해 EC2 인스턴스 수를 늘립니다. \nB. 정적 콘텐츠에 대한 Amazon CloudFront 배포를 추가합니다. Auto Scaling 그룹에 EC2 \n인스턴스를 배치하여 네트워크 트래픽을 기반으로 새 인스턴스를 시작합니다. \nC. 동적 콘텐츠에 대한 Amazon CloudFront 배포를 추가합니다. ALB 앞에 Amazon \nElastiCache 인스턴스를 추가하여 API 가 처리할 트래픽을 줄입니다. \nD. 정적 콘텐츠에 대한 Amazon CloudFront 배포를 추가합니다. Amazon Simple Queue \nService(Amazon SQS) 대기열을 추가하여 나중에 EC2 인스턴스에서 처리할 수 있도록 웹 \n사이트에서 요청을 수신합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/99704-exam-aws-certified-solut\nions-architect-associate-saa-c03/", "answer_choice": "D"}, "329": {"q_num": 329, "question": "보안 감사 결과 Amazon EC2 인스턴스가 정기적으로 패치되지 않는 것으로 나타났습니다. \n\n솔루션 설계자는 대규모 EC2 인스턴스 전체에 대해 정기적인 보안 스캔을 실행할 솔루션을 \n제공해야 합니다. 또한 솔루션은 정기적으로 EC2 인스턴스를 패치하고 각 인스턴스의 패치 \n상태에 대한 보고서를 제공해야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. EC2 인스턴스에서 소프트웨어 취약성을 스캔하도록 Amazon Macie 를 설정합니다. 각 \nEC2 인스턴스에서 cron 작업을 설정하여 정기적인 일정에 따라 인스턴스를 패치합니다. \nB. 계정에서 Amazon GuardDuty 를 켭니다. 소프트웨어 취약성에 대해 EC2 인스턴스를 \n스캔하도록 GuardDuty 를 구성합니다. 정기적인 일정에 따라 EC2 인스턴스를 패치하도록 \nAWS Systems Manager Session Manager 를 설정합니다. \nC. 소프트웨어 취약성에 대해 EC2 인스턴스를 스캔하도록 Amazon Detective 를 설정합니다. \n정기적인 일정에 따라 EC2 인스턴스를 패치하도록 Amazon EventBridge 예약 규칙을 \n설정합니다. \nD. 계정에서 Amazon Inspector 를 켭니다. 소프트웨어 취약성에 대해 EC2 인스턴스를 \n스캔하도록 Amazon Inspector\n를 구성합니다. 정기적인 일정에 따라 EC2 인스턴스를 \n패치하도록 AWS Systems Manager Patch Manager 를 설정합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/99796-exam-aws-certified-solut\nions-architect-associate-saa-c03/", "answer_choice": "D"}, "330": {"q_num": 330, "question": "회사에서 Amazon RDS DB 인스턴스에 데이터를 저장할 계획입니다. 회사는 미사용 \n데이터를 암호화해야 합니다. \n솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. AWS Key Management Service(AWS KMS)에서 키를 생성합니다. DB 인스턴스에 대한 \n암호화를 활성화합니다. \nB. 암호화 키를 생성합니다. AWS Secrets Manager 에 키를 저장합니다. 키를 사용하여 DB \n인스턴스를 암호화합니다. \nC. AWS Certificate Manager(ACM)에서 인증서를 생성합니다. 인증서를 사용하여 DB \n인스턴스에서 SSL/TLS 를 활성화합니다. \nD. AWS Identity and Access Management(IAM)에서 인증서를 생성합니다. 인증서를 \n사용하여 DB 인스턴스에서 SSL/TLS 를 활성화합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/99702-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n\n설명: \nAmazon RDS 의 유휴 데이터를 암호화하려면 AWS Key Management Service(AWS KMS)를 \n사용하는 Amazon RDS 의 암호화 기능을 사용할 수 있습니다. 이 기능을 통해 Amazon \nRDS 는 고유한 키로 각 데이터베이스 인스턴스를 암호화합니다. 이 키는 AWS KMS 에 의해 \n안전하게 저장됩니다. 자체 키를 관리하거나 기본 AWS 관리형 키를 사용할 수 있습니다. \nDB 인스턴스에 대한 암호화를 활성화하면 Amazon RDS 가 자동 백업, 읽기 전용 복제본 및 \n스냅샷을 비롯한 기본 스토리지를 암호화합니다.", "answer_choice": "A"}, "331": {"q_num": 331, "question": "회사는 30일 이내에 데이터 센터에서 AWS 클라우드로 20TB의 데이터를 마이그레이션해야 \n합니다. 회사의 네트워크 대역폭은 15Mbps\n로 제한되며 사용률이 70%를 초과할 수 \n없습니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. AWS Snowball 을 사용하십시오. \nB. AWS DataSync 를 사용합니다. \nC. 안전한 VPN 연결을 사용하십시오. \nD. Amazon S3 Transfer Acceleration 을 사용합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/99603-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nAWS Snowball 은 AWS 클라우드 안팎으로 대량의 데이터 이동을 가속화하는 안전한 데이터 \n전송 솔루션입니다. 한 번에 최대 80TB 의 데이터를 이동할 수 있고 최대 50Mbps 의 \n네트워크 대역폭을 제공하므로 작업에 적합합니다. 또한 안전하고 사용하기 쉬우므로 이 \n마이그레이션에 이상적인 솔루션입니다.", "answer_choice": "A"}, "332": {"q_num": 332, "question": "회사는 직원들에게 기밀 및 민감한 파일에 대한 안전한 액세스를 제공해야 합니다. 회사는 \n권한이 있는 사용자만 파일에 액세스할 수 있기를 원합니다. 파일은 직원의 장치에 \n안전하게 다운로드되어야 합니다. \n파일은 온프레미스 Windows 파일 서버에 저장됩니다. 그러나 원격 사용량의 증가로 인해 \n파일 서버의 용량이 부족합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \n\nA. 파일 서버를 퍼블릭 서브넷의 Amazon EC2 인스턴스로 마이그레이션합니다. 인바운드 \n트래픽을 직원의 IP 주소로 제한하도록 보안 그룹을 구성합니다. \nB. 파일을 Amazon FSx for Windows File Server 파일 시스템으로 마이그레이션합니다. \nAmazon FSx 파일 시스템을 온프레미스 Active Directory 와 통합합니다. AWS 클라이언트 \nVPN 을 구성합니다. \nC. 파일을 Amazon S3\n로 마이그레이션하고 프라이빗 VPC 엔드포인트를 생성합니다. \n다운로드를 허용하려면 서명된 URL 을 만듭니다. \nD. 파일을 Amazon S3 로 마이그레이션하고 퍼블릭 VPC 엔드포인트를 생성합니다. 직원이 \nAWS IAM Identity Center(AWS Single Sign-On)로 로그인하도록 허용합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/99792-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \nWindows 파일 서버는 온프레미스이며 데이터를 클라우드에 복제할 무언가가 필요합니다. \n우리가 가진 유일한 옵션은 Windows 파일 서버용 AWS FSx 입니다. 또한 정보가 기밀이고 \n민감하기 때문에 적절한 사용자가 안전한 방식으로 정보에 액세스할 수 있도록 해야 \n합니다. \nhttps://docs.aws.amazon.com/fsx/latest/WindowsGuide/what-is.html", "answer_choice": "B"}, "333": {"q_num": 333, "question": "회사의 애플리케이션은 ALB(Application Load Balancer) 뒤의 Amazon EC2 인스턴스에서 \n실행됩니다. 인스턴스는 여러 가용 영역에 걸쳐 Amazon EC2 Auto Scaling 그룹에서 \n실행됩니다. 매월 1 일 자정에 월말 재무 계산 일괄 처리가 실행되면 응용 프로그램이 훨씬 \n느려집니다. \n이로 \n인해 \nEC2 \n인스턴스의 \nCPU \n사용률이 \n즉시 \n100%에 \n도달하여 \n애플리케이션이 중단됩니다. \n애플리케이션이 워크로드를 처리하고 다운타임을 방지할 수 있도록 하기 위해 솔루션 \n설계자는 무엇을 권장해야 합니까? \nA. ALB 앞에 Amazon CloudFront 배포를 구성합니다. \nB. CPU 사용률을 기반으로 EC2 Auto Scaling 단순 조정 정책을 구성합니다. \nC. 월별 일정을 기반으로 EC2 Auto Scaling 예약 조정 정책을 구성합니다. \nD. EC2 인스턴스에서 일부 워크로드를 제거하도록 Amazon ElastiCache 를 구성합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/99791-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n\n \n설명: \n월별 일정을 기반으로 EC2 Auto Scaling 예약 조정 정책을 구성하는 것이 가장 좋은 \n옵션입니다. 이는 월별 배치 실행이 시작되기 전에 EC2 인스턴스의 사전 조정을 허용하기 \n때문입니다. 이렇게 하면 애플리케이션이 다운타임 없이 증가된 워크로드를 처리할 수 \n있습니다. 예약된 조정 정책은 배치 실행 몇 시간 전에 Auto Scaling 그룹의 인스턴스 수를 \n늘리고 배치 실행이 완료된 후 인스턴스 수를 줄이도록 구성할 수 있습니다. 이렇게 하면 \n필요할 때 리소스를 사용할 수 있고 필요하지 않을 때 리소스를 낭비하지 않을 수 있습니다. \n월별 배치 실행 중에 증가된 워크로드를 처리하고 다운타임을 방지하는 가장 적절한 \n솔루션은 월별 일정을 기반으로 EC2 Auto Scaling 예약 조정 정책을 구성하는 것입니다. \nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-scheduled-\nscaling.html", "answer_choice": "C"}, "334": {"q_num": 334, "question": "회사는 고객이 온프레미스 Microsoft Active Directory 를 사용하여 Amazon S3 에 저장된 \n파일을 다운로드할 수 있는 기능을 제공하려고 합니다. 고객의 애플리케이션은 SFTP \n클라이언트를 사용하여 파일을 다운로드합니다. \n운영 오버헤드를 최소화하고 고객의 애플리케이션을 변경하지 않으면서 이러한 요구 사항을 \n충족하는 솔루션은 무엇입니까? \nA. Amazon S3 용 SFTP 로 AWS Transfer Family 를 설정합니다. 통합된 Active Directory \n인증을 구성합니다. \nB. 온프레미스 클라이언트를 Amazon S3\n와 동기화하도록 AWS DMS(AWS Database \nMigration Service)를 설정합니다. 통합된 Active Directory 인증을 구성합니다. \nC. AWS IAM Identity Center(AWS Single Sign-On)를 사용하여 온프레미스 위치와 S3 위치 \n간에 동기화하도록 AWS DataSync 를 설정합니다. \nD. SFTP 로 Windows Amazon EC2 인스턴스를 설정하여 온프레미스 클라이언트를 Amazon \nS3 와 연결합니다. AWS Identity and Access Management(IAM)를 통합합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/99703-exam-aws-certified-solut\nions-architect-associate-saa-c03/", "answer_choice": "A"}, "335": {"q_num": 335, "question": "회사에서 갑자기 수요가 증가하고 있습니다. 회사는 Amazon 머신 이미지(AMI)에서 대규모 \nAmazon EC2 인스턴스를 프로비저닝해야 합니다. 인스턴스는 Auto Scaling 그룹에서 \n\n실행됩니다. 회사는 요구 사항을 충족하기 위해 최소 초기화 대기 시간을 제공하는 \n솔루션이 필요합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. aws ec2 register-image 명령을 사용하여 스냅샷에서 AMI 를 생성합니다. AWS Step \nFunctions 를 사용하여 Auto Scaling 그룹의 AMI 를 교체하십시오. \nB. 스냅샷에서 Amazon Elastic Block Store(Amazon EBS) 빠른 스냅샷 복원을 활성화합니다. \n스냅샷을 사용하여 AMI 를 프로비저닝합니다. Auto Scaling 그룹의 AMI 를 새 AMI 로 \n교체합니다. \nC. Amazon Data Lifecycle Manager(Amazon DLM)에서 AMI 생성을 활성화하고 수명 주기 \n규칙을 정의합니다. Auto Scaling 그룹에서 AMI\n를 수정하는 AWS Lambda 함수를 \n생성합니다. \nD. Amazon EventBridge 를 사용하여 AMI 를 프로비저닝하는 AWS Backup 수명 주기 정책을 \n호출합니다. EventBridge 에서 Auto Scaling 그룹 용량 제한을 이벤트 소스로 구성합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/99686-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명 \n스냅샷에서 Amazon Elastic Block Store(Amazon EBS) 빠른 스냅샷 복원을 활성화하면 \n스냅샷에서 새 Amazon Machine Image(AMI)를 빠르게 생성할 수 있으므로 새 인스턴스를 \n프로비저닝할 때 초기화 지연 시간을 줄이는 데 도움이 됩니다. AMI 가 프로비저닝되면 \nAuto Scaling 그룹의 AMI 를 새 AMI 로 교체할 수 있습니다. 이렇게 하면 업데이트된 \nAMI 에서 새 인스턴스가 시작되고 증가된 수요를 신속하게 충족할 수 있습니다.", "answer_choice": "B"}, "336": {"q_num": 336, "question": "회사는 Amazon Aurora MySQL DB 클러스터를 스토리지로 사용하는 다중 계층 웹 \n애플리케이션을 \n호스팅합니다. \n애플리케이션 \n계층은 \nAmazon \nEC2 \n인스턴스에서 \n호스팅됩니다. 회사의 IT 보안 지침에 따라 데이터베이스 자격 증명을 암호화하고 14 일마다 \n교체해야 합니다. \n최소한의 운영 노력으로 이 요구 사항을 충족하려면 솔루션 설계자가 무엇을 해야 합니까? \nA. 새 AWS Key Management Service(AWS KMS) 암호화 키를 생성합니다. AWS Secrets \nManager 를 사용하여 적절한 자격 증명과 함께 KMS 키를 사용하는 새 암호를 생성합니다. \n암호를 Aurora DB 클러스터와 연결합니다. 14 일의 사용자 지정 순환 기간을 구성합니다. \nB. AWS Systems Manager Parameter Store 에서 두 개의 매개변수를 생성합니다. 하나는 \n사용자 이름을 문자열 매개변수로 사용하고 다른 하나는 SecureString 유형을 암호로 \n\n사용합니다. 암호 매개변수에 대해 AWS Key Management Service(AWS KMS) 암호화를 \n선택하고 애플리케이션 계층에서 이러한 매개변수를 로드합니다. 14 일마다 암호를 교체하는 \nAWS Lambda 함수를 구현합니다. \nC. 자격 증명이 포함된 파일을 AWS KMS(AWS Key Management Service) 암호화 Amazon \nElastic File System(Amazon EFS) 파일 시스템에 저장합니다. 애플리케이션 계층의 모든 \nEC2 인스턴스에 EFS 파일 시스템을 탑재합니다. 응용 프로그램이 파일을 읽을 수 있고 \n슈퍼 사용자만 파일을 수정할 수 있도록 파일 시스템의 파일에 대한 액세스를 제한합니다. \n14 일마다 Aurora 에서 키를 교체하고 새 자격 증명을 파일에 쓰는 AWS Lambda 함수를 \n구현합니다. \nD. 애플리케이션이 자격 증명을 로드하는 데 사용하는 AWS KMS(AWS Key Management \nService) 암호화 Amazon S3 버킷에 자격 증명이 포함된 파일을 저장합니다. 올바른 자격 \n증명이 사용되도록 정기적으로 파일을 응용 프로그램에 다운로드하십시오. 14 일마다 Aurora \n자격 증명을 교체하고 이 자격 증명을 S3 버킷의 파일에 업로드하는 AWS Lambda 함수를 \n구현합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/99790-exam-aws-certified-solut\nions-architect-associate-saa-c03/", "answer_choice": "A"}, "337": {"q_num": 337, "question": "회사에서 AWS 에 웹 애플리케이션을 배포했습니다. 이 회사는 조정 요구 사항을 지원하기 \n위해 기본 DB 인스턴스와 5 개의 읽기 전용 복제본을 사용하여 MySQL 용 Amazon \nRDS 에서 백엔드 데이터베이스를 호스팅합니다. 읽기 전용 복제본은 기본 DB 인스턴스보다 \n1 초 이상 뒤처져서는 안 됩니다. 데이터베이스는 정기적으로 예약된 저장 프로시저를 \n실행합니다. \n웹 사이트의 트래픽이 증가함에 따라 복제본은 피크 로드 기간 동안 추가 지연을 \n경험합니다. 솔루션 설계자는 복제 지연을 최대한 줄여야 합니다. 솔루션 설계자는 \n애플리케이션 코드에 대한 변경을 최소화하고 지속적인 운영 오버헤드를 최소화해야 \n합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 데이터베이스를 Amazon Aurora MySQL 로 마이그레이션합니다. 읽기 전용 복제본을 \nAurora 복제본으로 교체하고 Aurora Auto Scaling 을 구성합니다. 저장 프로시저를 Aurora \nMySQL 기본 함수로 바꿉니다. \nB. 데이터베이스 앞에 Redis 클러스터용 Amazon ElastiCache\n를 배포합니다. 응용 \n프로그램이 \n데이터베이스를 \n쿼리하기 \n전에 \n캐시를 \n확인하도록 \n응용 \n프로그램을 \n수정하십시오. 저장 프로시저를 AWS Lambda 함수로 바꿉니다. \n\nC. \n데이터베이스를 \nAmazon \nEC2 \n인스턴스에서 \n실행되는 \nMySQL \n데이터베이스로 \n마이그레이션합니다. 모든 복제본 노드에 대해 컴퓨팅에 최적화된 대규모 EC2 인스턴스를 \n선택합니다. EC2 인스턴스에서 저장 프로시저를 유지합니다. \nD. 데이터베이스를 Amazon DynamoDB 로 마이그레이션합니다. 필요한 처리량을 지원하고 \n온디맨드 용량 확장을 구성하기 위해 많은 수의 RCU(읽기 용량 단위)를 프로비저닝합니다. \n저장 프로시저를 DynamoDB 스트림으로 바꿉니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/99871-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명: \n옵션 A 는 애플리케이션 코드를 크게 변경하지 않고 복제 지연을 줄이고 진행 중인 운영 \n오버헤드를 최소화하는 가장 적합한 솔루션입니다. 데이터베이스를 Amazon Aurora \nMySQL 로 마이그레이션하면 MySQL 용 Amazon RDS 에 비해 복제 성능과 확장성이 \n향상됩니다. Aurora 복제본은 더 빠른 복제를 제공하여 복제 지연을 줄이고 Aurora Auto \nScaling 은 들어오는 트래픽을 처리하기에 충분한 Aurora 복제본이 있는지 확인합니다. 또한 \nAurora MySQL 기본 기능은 저장 프로시저를 대체하여 데이터베이스의 부하를 줄이고 \n성능을 향상시킬 수 있습니다.", "answer_choice": "A"}, "338": {"q_num": 338, "question": "솔루션 설계자는 대용량 SaaS(Software as a Service) 플랫폼에 대한 재해 복구(DR) 계획을 \n만들어야 합니다. 플랫폼의 모든 데이터는 Amazon Aurora MySQL DB 클러스터에 \n저장됩니다. \nDR 계획은 데이터를 보조 AWS 리전에 복제해야 합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. 보조 리전의 Aurora 클러스터에 MySQL 바이너리 로그 복제를 사용합니다. 보조 \n리전에서 Aurora 클러스터용 DB 인스턴스 1 개를 프로비저닝합니다. \nB. DB 클러스터에 대한 Aurora 글로벌 데이터베이스를 설정합니다. 설정이 완료되면 보조 \n리전에서 DB 인스턴스를 제거합니다. \nC. AWS Database Migration Service(AWS DMS)를 사용하여 데이터를 보조 리전의 Aurora \n클러스터에 지속적으로 복제합니다. 보조 리전에서 DB 인스턴스를 제거합니다. \nD. DB 클러스터에 대한 Aurora 글로벌 데이터베이스를 설정합니다. 보조 리전에서 최소 \n하나의 DB 인스턴스를 지정합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/99758-exam-aws-certified-solut\n\nions-architect-associate-saa-c03/ \n \n설명: \n기본 DB 클러스터에서 모든 보조로의 복제는 데이터베이스 엔진이 아닌 Aurora 스토리지 \n계층에서 처리하므로 변경 사항 복제 지연 시간은 일반적으로 1 초 미만으로 최소화됩니다. \n데이터베이스 엔진을 복제 프로세스에서 제외한다는 것은 데이터베이스 엔진이 워크로드 \n처리 전용임을 의미합니다. 또한 Aurora MySQL binlog(이진 로깅) 복제를 구성하거나 \n관리할 필요가 없음을 의미합니다.", "answer_choice": "D"}, "339": {"q_num": 339, "question": "회사에는 Amazon RDS MySQL DB 인스턴스에서 정보를 검색하는 자격 증명이 내장된 \n사용자 \n지정 \n애플리케이션이 \n있습니다. \n경영진은 \n최소한의 \n프로그래밍 \n노력으로 \n애플리케이션을 더 안전하게 만들어야 한다고 말합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. AWS Key Management Service(AWS KMS)를 사용하여 키를 생성합니다. AWS KMS 에서 \n데이터베이스 자격 증명을 로드하도록 애플리케이션을 구성합니다. 자동 키 순환을 \n활성화합니다. \nB. 애플리케이션 사용자를 위해 RDS for MySQL 데이터베이스에서 자격 증명을 생성하고 \n자격 증명을 AWS Secrets Manager 에 저장합니다. Secrets Manager 에서 데이터베이스 자격 \n증명을 로드하도록 애플리케이션을 구성합니다. Secret Manager 에서 자격 증명을 교체하는 \nAWS Lambda 함수를 생성합니다. \nC. 애플리케이션 사용자를 위해 RDS for MySQL 데이터베이스에서 자격 증명을 생성하고 \n자격 증명을 AWS Secrets Manager 에 저장합니다. Secrets Manager 에서 데이터베이스 자격 \n증명을 로드하도록 애플리케이션을 구성합니다. Secrets Manager 를 사용하여 RDS for \nMySQL 데이터베이스에서 애플리케이션 사용자의 자격 증명 교체 일정을 설정합니다. \nD. 애플리케이션 사용자를 위해 RDS for MySQL 데이터베이스에서 자격 증명을 생성하고 \n자격 증명을 AWS Systems Manager Parameter Store 에 저장합니다. Parameter Store 에서 \n데이터베이스 자격 증명을 로드하도록 애플리케이션을 구성합니다. Parameter Store 를 \n사용하여 RDS for MySQL 데이터베이스에서 애플리케이션 사용자에 대한 자격 증명 교체 \n일정을 설정합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/99705-exam-aws-certified-solut\nions-architect-associate-saa-c03/", "answer_choice": "C"}, "340": {"q_num": 340, "question": "미디어 회사는 AWS\n에서 웹 사이트를 호스팅합니다. 웹 사이트 애플리케이션의 \n아키텍처에는 Application Load Balancer(ALB) 뒤에 있는 Amazon EC2 인스턴스 플릿과 \nAmazon Aurora 에서 호스팅되는 데이터베이스가 포함됩니다. 회사의 사이버 보안 팀은 \n애플리케이션이 SQL 주입에 취약하다고 보고합니다. \n회사는 이 문제를 어떻게 해결해야 할까요? \nA. ALB 앞에서 AWS WAF 를 사용합니다. 적절한 웹 ACL 을 AWS WAF 와 연결합니다. \nB. 고정 응답으로 SQL 주입에 응답하는 ALB 수신기 규칙을 생성합니다. \nC. 모든 SQL 삽입 시도를 자동으로 차단하려면 AWS Shield Advanced 에 가입하십시오. \nD. 모든 SQL 주입 시도를 자동으로 차단하도록 Amazon Inspector 를 설정합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/99708-exam-aws-certified-solut\nions-architect-associate-saa-c03/", "answer_choice": "A"}, "341": {"q_num": 341, "question": "회사에는 AWS Lake Formation 에서 관리하는 Amazon S3 데이터 레이크가 있습니다. 이 \n회사는 데이터 레이크의 데이터를 Amazon Aurora MySQL 데이터베이스에 저장된 운영 \n데이터와 결합하여 Amazon QuickSight 에서 시각화를 생성하려고 합니다. 회사는 회사의 \n마케팅 팀이 데이터베이스의 열 하위 집합에만 액세스할 수 있도록 열 수준 권한을 \n적용하려고 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Amazon EMR 을 사용하여 데이터베이스에서 QuickSight SPICE 엔진으로 직접 데이터를 \n수집하십시오. 필요한 열만 포함합니다. \nB. AWS Glue Studio\n를 사용하여 데이터베이스에서 S3 데이터 레이크로 데이터를 \n수집합니다. IAM 정책을 QuickSight 사용자에게 연결하여 열 수준 액세스 제어를 \n적용합니다. QuickSight 에서 Amazon S3 를 데이터 원본으로 사용합니다. \nC. AWS Glue Elastic Views 를 사용하여 Amazon S3 의 데이터베이스에 대한 구체화된 \n보기를 생성합니다. QuickSight 사용자에 대한 열 수준 액세스 제어를 적용하려면 S3 버킷 \n정책을 생성합니다. QuickSight 에서 Amazon S3 를 데이터 원본으로 사용합니다. \nD. Lake Formation 청사진을 사용하여 데이터베이스에서 S3 데이터 레이크로 데이터를 \n수집합니다. Lake Formation 을 사용하여 QuickSight 사용자에 대한 열 수준 액세스 제어를 \n적용합니다. QuickSight 에서 Amazon Athena 를 데이터 원본으로 사용합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/99710-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n\n \n설명: \nAmazon QuickSight 및 AWS Lake Formation 을 사용하여 열 수준 권한 부여를 시행합니다. \nhttps://aws.amazon.com/ko/blogs/big-data/enforce-column-level-authorization-with-a\nmazon-quicksight-and-aws-lake-formation/", "answer_choice": "D"}, "342": {"q_num": 342, "question": "트랜잭션 처리 회사에는 Amazon EC2 인스턴스에서 실행되는 매주 스크립팅된 배치 작업이 \n있습니다. EC2 인스턴스는 Auto Scaling 그룹에 있습니다. 트랜잭션 수는 다를 수 있지만 \n각 실행에서 기록되는 기준 CPU 사용률은 60% 이상입니다. 회사는 작업이 실행되기 30 분 \n전에 용량을 프로비저닝해야 합니다. \n현재 엔지니어는 Auto Scaling 그룹 파라미터를 수동으로 수정하여 이 작업을 완료합니다. \n회사에는 Auto Scaling 그룹 수에 필요한 용량 추세를 분석할 리소스가 없습니다. 회사는 \nAuto Scaling 그룹의 원하는 용량을 수정하는 자동화된 방법이 필요합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Auto Scaling 그룹에 대한 동적 조정 정책을 생성합니다. CPU 사용률 메트릭을 기반으로 \n확장하도록 정책을 구성합니다. 지표의 대상 값을 60%로 설정합니다. \nB. Auto Scaling 그룹에 대한 예약 조정 정책을 생성합니다. 원하는 적정 용량, 최소 용량, \n최대 용량을 설정합니다. 반복을 매주로 설정합니다. 일괄 작업이 실행되기 전 30 분으로 \n시작 시간을 설정합니다. \nC. Auto Scaling 그룹에 대한 예측 조정 정책을 생성합니다. 예측을 기반으로 확장하도록 \n정책을 구성합니다. 스케일링 지표를 CPU 사용률로 설정합니다. 지표의 대상 값을 60%로 \n설정합니다. 정책에서 작업이 실행되기 30 분 전에 사전 실행되도록 인스턴스를 설정합니다. \nD. Auto Scaling 그룹의 CPU 사용률 지표 값이 60%에 도달하면 AWS Lambda 함수를 \n호출하는 Amazon EventBridge 이벤트를 생성합니다. Auto Scaling 그룹의 원하는 용량과 \n최대 용량을 20% 늘리도록 Lambda 함수를 구성합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/100204-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n이 옵션은 기계 학습을 사용하여 CloudWatch 의 기록 데이터를 기반으로 용량 요구 사항을 \n예측하는 일종의 조정 정책인 Auto Scaling 그룹에 대한 예측 조정 정책을 사용하기 때문에 \n가장 효율적입니다. 또한 Auto Scaling 그룹이 트래픽 변경에 앞서 용량을 조정할 수 \n있도록 예측을 기반으로 확장하도록 정책을 구성합니다. 또한 조정 메트릭을 CPU 사용률로 \n\n설정하고 메트릭의 대상 값을 60%로 설정합니다. 이는 각 실행에서 기록되는 기준 CPU \n사용률과 일치합니다. 또한 작업이 실행되기 30\n분 전에 인스턴스를 사전 실행하도록 \n설정하여 매주 스크립팅된 배치 작업이 시작되기 전에 충분한 용량이 프로비저닝되도록 \n합니다. 이 솔루션은 최소한의 운영 오버헤드로 작업이 실행되기 30\n분 전에 용량을 \n프로비저닝해야 하는 요구 사항을 충족합니다. \n \n옵션 A 는 변화하는 수요에 대응하여 Auto Scaling 그룹의 용량을 조정하는 일종의 조정 \n정책인 Auto Scaling 그룹에 대한 동적 조정 정책을 사용하기 때문에 효율성이 떨어집니다. \n그러나 이것은 변화하는 트래픽에만 반응하기 때문에 작업 실행 30\n분 전에 용량을 \n프로비저닝하는 방법을 제공하지 않습니다. \n \n옵션 B 는 생성한 일정에 따라 Auto Scaling 그룹을 조정할 수 있는 조정 정책 유형인 Auto \nScaling 그룹에 대해 예약된 조정 정책을 사용하기 때문에 효율성이 떨어집니다. 그러나 \n미리 정의된 지표 및 정책에 따라서만 확장되므로 예측 또는 CPU 사용률을 기반으로 \n확장하는 방법을 제공하지 않습니다. \n \n옵션 D\n는 Auto Scaling 그룹의 CPU 사용률 지표 값이 60%에 도달할 때 Amazon \nEventBridge \n이벤트를 \n사용하여 AWS Lambda \n함수를 호출하기 때문에 효율성이 \n떨어집니다. 이는 이벤트를 기반으로 서버리스 함수를 트리거하는 방법입니다. 그러나 \n이것은 변화하는 트래픽에만 반응하기 때문에 작업 실행 30 분 전에 용량을 프로비저닝하는 \n방법을 제공하지 않습니다.", "answer_choice": "C"}, "343": {"q_num": 343, "question": "솔루션 설계자는 회사의 재해 복구(DR) 아키텍처를 설계하고 있습니다. 이 회사에는 예약된 \n백업이 \n있는 \n프라이빗 \n서브넷의 \nAmazon \nEC2 \n인스턴스에서 \n실행되는 \nMySQL \n데이터베이스가 있습니다. DR 설계에는 여러 AWS 리전이 포함되어야 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. MySQL 데이터베이스를 여러 EC2 인스턴스로 마이그레이션합니다. DR 지역에서 대기 \nEC2 인스턴스를 구성합니다. 복제를 켭니다. \nB. MySQL 데이터베이스를 Amazon RDS\n로 마이그레이션합니다. 다중 AZ 배포를 \n사용합니다. 다른 가용 영역에서 기본 DB 인스턴스에 대한 읽기 복제를 켭니다. \nC. MySQL 데이터베이스를 Amazon Aurora 글로벌 데이터베이스로 마이그레이션합니다. \n기본 리전에서 기본 DB 클러스터를 호스팅합니다. DR 리전에서 보조 DB 클러스터를 \n호스팅합니다. \nD. S3 CRR(Cross-Region Replication)용으로 구성된 Amazon S3 버킷에 MySQL \n\n데이터베이스의 예약된 백업을 저장합니다. 데이터 백업을 사용하여 DR 지역에서 \n데이터베이스를 복원하십시오.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/100302-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nMySQL 데이터베이스를 Amazon Aurora 글로벌 데이터베이스로 마이그레이션하는 것이 \n최소한의 운영 오버헤드가 필요하기 때문에 최상의 솔루션입니다. Aurora 는 자동 장애 \n조치를 제공하는 관리형 서비스이므로 대기 인스턴스를 수동으로 구성할 필요가 없습니다. \n기본 DB 클러스터는 기본 리전에서 호스팅할 수 있고 보조 DB 클러스터는 DR 리전에서 \n호스팅할 수 있습니다. 이 접근 방식을 통해 상당한 수동 개입 없이 데이터를 여러 \n리전에서 항상 사용 가능하고 최신 상태로 유지할 수 있습니다.", "answer_choice": "C"}, "344": {"q_num": 344, "question": "회사에는 Amazon Simple Queue Service(Amazon SQS)를 사용하여 메시지를 구문 분석하는 \nJava 애플리케이션이 있습니다. 애플리케이션은 크기가 256KB 보다 큰 메시지를 구문 \n분석할 수 없습니다. 회사는 응용 프로그램이 50MB 만큼 큰 메시지를 구문 분석할 수 있는 \n기능을 제공하는 솔루션을 구현하려고 합니다. \n코드를 가장 적게 변경하여 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Java\n용 Amazon SQS 확장 클라이언트 라이브러리를 사용하여 Amazon S3\n에서 \n256KB 보다 큰 메시지를 호스팅합니다. \nB. Amazon SQS 대신 Amazon EventBridge 를 사용하여 애플리케이션에서 큰 메시지를 \n게시합니다. \nC. 256KB 보다 큰 메시지를 처리하도록 Amazon SQS 의 제한을 변경합니다. \nD. Amazon Elastic File System(Amazon EFS)에 256KB 보다 큰 메시지를 저장합니다. \n메시지에서 이 위치를 참조하도록 Amazon SQS 를 구성합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/100202-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "345": {"q_num": 345, "question": "회사에서 주요 웹 애플리케이션 중 하나의 콘텐츠에 대한 액세스를 제한하고 AWS 에서 \n사용할 수 있는 권한 부여 기술을 사용하여 콘텐츠를 보호하려고 합니다. 이 회사는 \n\n서버리스 아키텍처와 100 명 미만의 사용자를 위한 인증 솔루션을 구현하려고 합니다. \n솔루션은 기본 웹 애플리케이션과 통합하고 웹 콘텐츠를 전역적으로 제공해야 합니다. \n솔루션은 또한 회사의 사용자 기반이 성장함에 따라 확장되어야 하며 가능한 한 가장 낮은 \n로그인 대기 시간을 제공해야 합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. 인증에 Amazon Cognito 를 사용하십시오. 인증을 위해 Lambda@Edge 를 사용합니다. \nAmazon CloudFront 를 사용하여 전 세계적으로 웹 애플리케이션을 제공합니다. \nB. 인증을 위해 Microsoft Active Directory 용 AWS Directory Service 를 사용합니다. 승인을 \n위해 AWS Lambda\n를 사용합니다. Application Load Balancer\n를 사용하여 웹 \n애플리케이션을 전역적으로 제공합니다. \nC. 인증에 Amazon Cognito 를 사용합니다. 승인을 위해 AWS Lambda 를 사용합니다. \nAmazon S3 Transfer Acceleration\n을 사용하여 전 세계적으로 웹 애플리케이션을 \n제공합니다. \nD. 인증을 위해 Microsoft Active Directory 용 AWS Directory Service 를 사용합니다. 인증을 \n위해 Lambda@Edge 를 사용합니다. AWS Elastic Beanstalk 를 사용하여 전 세계적으로 웹 \n애플리케이션을 제공합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/100341-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nhttps://aws.amazon.com/blogs/networking-and-content-delivery/adding-http-security-h\neadersusing-lambdaedge-and-amazon-cloudfront/ \nAmazon CloudFront 는 웹 콘텐츠, 비디오 및 API 를 대규모로 안전하게 전송할 수 있는 \n글로벌 콘텐츠 전송 네트워크(CDN) 서비스입니다. 인증을 위해 Cognito와 통합하고 인증을 \n위해 Lambda@Edge 와 통합하므로 전 세계적으로 웹 콘텐츠를 제공하는 데 이상적인 \n선택입니다. Lambda@Edge\n는 AWS Lambda 기능을 사용자에게 더 가까운 곳에서 \n전역적으로 실행할 수 있는 서비스로, 지연 시간을 줄이고 응답 시간을 단축합니다. 또한 \nCloudFront 의 콘텐츠를 보호하기 위해 에지에서 인증 로직을 처리할 수 있습니다. 이 \n시나리오에서 Lambda@Edge 는 에지에서 실행하는 짧은 대기 시간 이점을 활용하면서 웹 \n애플리케이션에 대한 권한 부여를 제공할 수 있습니다.", "answer_choice": "A"}, "346": {"q_num": 346, "question": "회사의 데이터 센터에 노후화된 NAS(Network-Attached Storage) 어레이가 있습니다. NAS \n어레이는 SMB 공유 및 NFS 공유를 클라이언트 워크스테이션에 제공합니다. 회사는 새 \n\nNAS 어레이를 구매하기를 원하지 않습니다. 회사는 또한 NAS 어레이의 지원 계약을 \n갱신하는 데 드는 비용을 원하지 않습니다. 일부 데이터는 자주 액세스되지만 대부분의 \n데이터는 비활성 상태입니다. \n솔루션 설계자는 데이터를 Amazon S3 로 마이그레이션하고 S3 수명 주기 정책을 사용하며 \n클라이언트 워크스테이션에 대해 동일한 모양과 느낌을 유지하는 솔루션을 구현해야 합니다. \n솔루션 설계자는 AWS Storage Gateway 를 솔루션의 일부로 식별했습니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 유형의 스토리지 게이트웨이를 \n프로비저닝해야 합니까? \nA. 볼륨 게이트웨이 \nB. 테이프 게이트웨이 \nC. Amazon FSx 파일 게이트웨이 \nD. Amazon S3 파일 게이트웨이", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/100220-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "D"}, "347": {"q_num": 347, "question": "회사에는 Amazon EC2 인스턴스에서 실행 중인 애플리케이션이 있습니다. 솔루션 설계자는 \n회사의 현재 요구 사항을 기반으로 특정 인스턴스 제품군 및 다양한 인스턴스 크기로 \n회사를 표준화했습니다. \n회사는 향후 3\n년 동안 애플리케이션의 비용 절감을 극대화하고자 합니다. 회사는 \n애플리케이션 인기도 및 사용량에 따라 향후 6 개월 내에 인스턴스 패밀리 및 크기를 \n변경할 수 있어야 합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. 컴퓨팅 절감 플랜(Compute Savings Plan) \nB. EC2 인스턴스 절감 계획(EC2 Instance Savings Plan) \nC. 영역 예약 인스턴스(Zonal Reserved Instances) \nD. 표준 예약 인스턴스(Standard Reserved Instances)", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/100221-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "348": {"q_num": 348, "question": "회사는 웨어러블 장치를 사용하는 많은 참가자로부터 데이터를 수집합니다. 회사는 \n\n데이터를 Amazon DynamoDB 테이블에 저장하고 애플리케이션을 사용하여 데이터를 \n분석합니다. 데이터 워크로드는 일정하고 예측 가능합니다. 회사는 DynamoDB 에 대한 \n예상 예산 이하를 유지하려고 합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. 프로비저닝 모드와 DynamoDB Standard-Infrequent Access(DynamoDB Standard-IA)를 \n사용합니다. 예상 워크로드에 대한 용량을 예약합니다. \nB. 프로비저닝 모드를 사용합니다. RCU(읽기 용량 단위) 및 WCU(쓰기 용량 단위)를 \n지정합니다. \nC. 주문형 모드를 사용합니다. 읽기 용량 단위(RCU) 및 쓰기 용량 단위(WCU)를 \n워크로드의 변경 사항을 수용할 수 있을 만큼 높게 설정합니다. \nD. 주문형 모드를 사용합니다. 예약 용량이 있는 RCU(읽기 용량 단위) 및 WCU(쓰기 용량 \n단위)를 지정합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/100222-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n이 옵션은 테이블에서 읽기 및 쓰기를 처리하기 위한 읽기/쓰기 용량 모드인 프로비저닝 \n모드를 사용하기 때문에 가장 효율적입니다. 이를 통해 애플리케이션이 수행할 것으로 \n예상되는 읽기 및 쓰기 처리량을 지정할 수 있습니다. 또한 애플리케이션이 초당 읽거나 \n써야 하는 데이터의 양인 RCU(읽기 용량 단위) 및 WCU(쓰기 용량 단위)를 지정합니다. \n또한 프로비저닝 모드는 예측 가능한 워크로드에 대해 온디맨드 모드보다 비용이 낮기 \n때문에 DynamoDB 에 대한 예상 예산 이하로 유지해야 하는 요구 사항을 충족합니다. \n이 솔루션은 일정하고 예측 가능한 데이터 워크로드가 있는 웨어러블 장치를 사용하는 많은 \n참여자로부터 데이터를 수집해야 하는 요구 사항을 충족합니다. \n \n옵션 A\n는 프로비저닝 모드와 DynamoDB Standard-Infrequent Access(DynamoDB \nStandard-IA)를 사용하기 때문에 덜 효율적입니다. DynamoDB Standard-Infrequent \nAccess 는 밀리초의 지연 시간이 필요한 자주 액세스하지 않는 항목을 위한 스토리지 \n클래스입니다. 그러나 이는 일정하고 예측 가능한 데이터 워크로드가 있는 웨어러블 장치를 \n사용하는 많은 참여자로부터 데이터를 수집해야 하는 요구 사항을 충족하지 않습니다. \nDynamoDB Standard-IA 는 액세스 빈도가 30 일에 한 번 미만인 항목에 더 적합하기 \n때문입니다. \n \n옵션 C 는 수요 변화에 따라 테이블 용량을 자동으로 조정하여 사용한 만큼만 비용을 \n지불하는 읽기/쓰기 용량 모드인 온디맨드 모드를 사용하기 때문에 효율성이 떨어집니다. \n\n그러나 온디맨드 모드는 예측 가능한 워크로드에 대해 프로비저닝된 모드보다 비용이 높기 \n때문에 DynamoDB\n에 대한 예상 예산 이하로 유지해야 하는 요구 사항을 충족하지 \n않습니다. \n \n옵션 D 는 온디맨드 모드를 사용하고 예약 용량이 있는 RCU 및 WCU 를 지정하기 때문에 \n효율성이 떨어집니다. 이는 할인된 시간당 요금과 교환하여 테이블에 대한 읽기 및 쓰기 \n용량을 예약하는 방법입니다. 그러나 온디맨드 모드는 예측 가능한 워크로드에 대해 \n프로비저닝된 모드보다 비용이 높기 때문에 DynamoDB 에 대한 예상 예산 이하로 유지해야 \n하는 요구 사항을 충족하지 않습니다. 또한 예약된 용량이 있는 RCU 및 WCU 를 지정하는 \n것은 프로비저닝 모드에만 적용되므로 온디맨드 모드에서는 불가능합니다.", "answer_choice": "B"}, "349": {"q_num": 349, "question": "회사는 ap-southeast-3 리전의 Amazon Aurora PostgreSQL 데이터베이스에 기밀 데이터를 \n저장합니다. 데이터베이스는 AWS Key Management Service(AWS KMS) 고객 관리형 키로 \n암호화됩니다. 이 회사는 최근에 인수되었으며 ap-southeast-3 에서 인수 회사의 AWS \n계정과 데이터베이스 백업을 안전하게 공유해야 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. 데이터베이스 스냅샷을 생성합니다. 스냅샷을 암호화되지 않은 새 스냅샷에 복사합니다. \n인수 회사의 AWS 계정과 새 스냅샷을 공유합니다. \nB. 데이터베이스 스냅샷을 생성합니다. 인수 회사의 AWS 계정을 KMS 키 정책에 \n추가합니다. 인수 회사의 AWS 계정과 스냅샷을 공유합니다. \nC. 다른 AWS 관리형 KMS 키를 사용하는 데이터베이스 스냅샷을 생성합니다. 인수 회사의 \nAWS 계정을 KMS 키 별칭에 추가합니다. 인수 회사의 AWS 계정과 스냅샷을 공유합니다. \nD. 데이터베이스 스냅샷을 생성합니다. 데이터베이스 스냅샷을 다운로드합니다. Amazon S3 \n버킷에 데이터베이스 스냅샷을 업로드합니다. 인수 회사의 AWS 계정에서 액세스를 \n허용하도록 S3 버킷 정책을 업데이트합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/100299-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nhttps://docs.aws.amazon.com/ko_kr/kms/latest/developerguide/key-policy-modifying-ex\nternal-accounts.html \n다른 사용자 지정 AWS KMS 키를 생성할 필요가 없습니다. \nhttps://aws.amazon.com/premiumsupport/knowledge-center/aurora-share-encrypted-sn\n\napshot/ \n원본 계정 내에서 대상 계정에 사용자 지정 AWS KMS 키에 대한 액세스 권한을 \n부여합니다. \n1. 원본 계정에 로그인하고 DB 클러스터 스냅샷과 동일한 리전의 AWS KMS 콘솔로 \n이동합니다. \n2. 탐색 창에서 고객 관리형 키를 선택합니다. \n3. 사용자 지정 AWS KMS 키(이미 생성됨)를 선택합니다. \n4. 다른 AWS 계정 섹션에서 다른 AWS 계정 추가를 선택한 다음 대상 계정의 AWS 계정 \n번호를 입력합니다. \n그런 다음 DB 클러스터 스냅샷을 복사하고 공유합니다.", "answer_choice": "B"}, "350": {"q_num": 350, "question": "한 회사에서 us-east-1 리전의 Microsoft SQL Server 단일 AZ DB 인스턴스용 100GB \nAmazon RDS\n를 사용하여 고객 트랜잭션을 저장합니다. 회사는 DB 인스턴스에 대한 \n고가용성 및 자동 복구가 필요합니다. \n또한 회사는 1 년에 여러 번 RDS 데이터베이스에 대한 보고서를 실행해야 합니다. 보고 \n프로세스로 인해 트랜잭션이 고객 계정에 게시되는 데 평소보다 오래 걸립니다. 회사는 \n보고 프로세스의 성능을 향상시킬 솔루션이 필요합니다. \n이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (2 개 선택) \nA. 단일 AZ DB 인스턴스에서 다중 AZ 배포로 DB 인스턴스를 수정합니다. \nB. 현재 DB 인스턴스의 스냅샷을 찍습니다. 다른 가용 영역의 새 RDS 배포로 스냅샷을 \n복원합니다. \nC. 다른 가용 영역에서 DB 인스턴스의 읽기 전용 복제본을 생성합니다. 보고서에 대한 \n모든 요청은 읽기 전용 복제본을 가리킵니다. \nD. 데이터베이스를 RDS Custom 으로 마이그레이션합니다. \nE. RDS Proxy 를 사용하여 보고 요청을 유지 관리 기간으로 제한합니다.", "answer_block": "Answer: A, C \nhttps://www.examtopics.com/discussions/amazon/view/100300-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "351": {"q_num": 351, "question": "회사에서 데이터 관리 애플리케이션을 AWS 로 이전하고 있습니다. 회사는 이벤트 기반 \n아키텍처로 전환하려고 합니다. 아키텍처는 워크플로의 다양한 측면을 수행하면서 더 많이 \n분산되고 서버리스 개념을 사용해야 합니다. 회사는 또한 운영 오버헤드를 최소화하기를 \n\n원합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. AWS Glue 에서 워크플로를 구축합니다. AWS Glue 를 사용하여 AWS Lambda 함수를 \n호출하여 워크플로 단계를 처리합니다. \nB. AWS Step Functions\n에서 워크플로를 구축합니다. Amazon EC2 인스턴스에 \n애플리케이션을 배포합니다. Step Functions\n를 사용하여 EC2 인스턴스에서 워크플로 \n단계를 호출합니다. \nC. Amazon EventBridge 에서 워크플로를 구축합니다. EventBridge 를 사용하여 일정에 따라 \nAWS Lambda 함수를 호출하여 워크플로 단계를 처리합니다. \nD. AWS Step Functions 에서 워크플로를 구축합니다. Step Functions 를 사용하여 상태 \n머신을 생성합니다. 상태 시스템을 사용하여 AWS Lambda 함수를 호출하여 워크플로 \n단계를 처리합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/100371-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n이 \n대답은 \n서버리스 \n개념을 \n사용하고 \n운영 \n오버헤드를 \n최소화하는 \n이벤트 \n기반 \n아키텍처로의 전환 요구 사항을 충족하기 때문에 정확합니다. AWS Step Functions 는 상태 \n시스템을 사용하여 여러 AWS 서비스를 워크플로로 조정할 수 있는 서버리스 서비스입니다. \n상태 머신은 워크플로 단계의 실행 논리와 순서를 정의하는 작업 및 전환으로 구성됩니다. \nAWS Lambda\n는 서버를 프로비저닝하거나 관리하지 않고도 코드를 실행할 수 있는 \n서버리스 FaaS(function-as-a-service) 플랫폼입니다. Lambda 함수는 Step Functions 에서 \n상태 시스템의 작업으로 호출할 수 있으며 데이터 수집, 변환, 검증 및 분석과 같은 데이터 \n관리 워크플로의 다양한 측면을 수행할 수 있습니다. Step Functions 및 Lambda\n를 \n사용함으로써 회사는 다음과 같은 이점을 얻을 수 있습니다. \n이벤트 기반: Step Functions 는 타이머, API 호출 또는 기타 AWS 서비스 이벤트와 같은 \n이벤트를 기반으로 Lambda 함수를 트리거할 수 있습니다. Lambda 함수는 이벤트 기반 \n아키텍처를 생성하여 다른 서비스나 상태 시스템에 이벤트를 내보낼 수도 있습니다. \n서버리스: Step Functions 및 Lambda 는 AWS 에서 완전히 관리하므로 회사에서 서버 또는 \n인프라를 프로비저닝하거나 관리할 필요가 없습니다. 회사는 워크플로 및 기능에서 \n사용하는 리소스에 대해서만 비용을 지불하고 수요에 따라 자동으로 확장 또는 축소할 수 \n있습니다. \n운영 오버헤드: Step Functions 및 Lambda 는 모니터링, 로깅, 추적, 오류 처리, 재시도 \n논리 및 보안과 같은 기본 제공 기능을 제공하므로 워크플로 및 기능의 개발 및 배포를 \n단순화합니다. 회사는 운영 세부 사항보다는 비즈니스 논리 및 데이터 처리에 집중할 수 \n\n있습니다.", "answer_choice": "D"}, "352": {"q_num": 352, "question": "한 회사에서 온라인 멀티플레이어 게임용 네트워크를 설계하고 있습니다. 이 게임은 UDP \n네트워킹 프로토콜을 사용하며 8 개의 AWS 리전에 배포됩니다. 네트워크 아키텍처는 최종 \n사용자에게 고품질 게임 경험을 제공하기 위해 대기 시간과 패킷 손실을 최소화해야 \n합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 각 리전에서 전송 게이트웨이를 설정합니다. 각 전송 게이트웨이 간에 리전 간 피어링 \n연결을 생성합니다. \nB. 각 리전에서 UDP 리스너 및 엔드포인트 그룹으로 AWS Global Accelerator\n를 \n설정합니다. \nC. UDP\n를 켠 상태에서 Amazon CloudFront\n를 설정합니다. 각 리전에서 오리진을 \n구성합니다. \nD. 각 지역 간에 VPC 피어링 메시를 설정합니다. 각 VPC 에 대해 UDP 를 켭니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/100197-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n이 상황에 가장 적합한 솔루션은 각 리전에서 UDP 리스너 및 엔드포인트 그룹으로 AWS \nGlobal Accelerator 를 설정하는 옵션 B 입니다. AWS Global Accelerator 는 사용자 요청을 \n가장 가까운 AWS 지역[1]으로 라우팅하여 인터넷 애플리케이션의 가용성과 성능을 \n향상시키는 네트워킹 서비스입니다. 또한 대기 시간이 짧고 패킷 손실이 적은 더 빠르고 \n안정적인 데이터 전송을 제공하여 UDP 응용 프로그램의 성능을 향상시킵니다. 각 리전에서 \nUDP 리스너와 엔드포인트 그룹을 설정함으로써 Global Accelerator 는 더 빠른 응답 시간과 \n더 나은 사용자 경험을 위해 가장 가까운 리전으로 트래픽을 라우팅합니다.", "answer_choice": "B"}, "353": {"q_num": 353, "question": "회사는 단일 가용 영역의 Amazon EC2 인스턴스에서 3\n계층 웹 애플리케이션을 \n호스팅합니다. 웹 애플리케이션은 EC2 인스턴스에서 호스팅되는 자체 관리형 MySQL \n데이터베이스를 사용하여 Amazon Elastic Block Store(Amazon EBS) 볼륨에 데이터를 \n저장합니다. MySQL 데이터베이스는 현재 1TB 프로비저닝된 IOPS SSD(io2) EBS 볼륨을 \n사용합니다. 이 회사는 피크 트래픽에서 읽기 및 쓰기 모두에 대해 1,000 IOPS 의 트래픽을 \n\n예상합니다. \n회사는 두 배의 IOPS 용량을 유지하면서 중단을 최소화하고 성능을 안정화하며 비용을 \n절감하고자 합니다. 이 회사는 데이터베이스 계층을 가용성이 높고 내결함성이 있는 완전 \n관리형 솔루션으로 이동하려고 합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. io2 Block Express EBS 볼륨이 있는 MySQL DB 인스턴스용 Amazon RDS 의 다중 AZ \n배포를 사용합니다. \nB. 범용 SSD(gp2) EBS 볼륨이 있는 MySQL DB 인스턴스용 Amazon RDS 의 다중 AZ \n배포를 사용합니다. \nC. Amazon S3 Intelligent-Tiering 액세스 계층을 사용합니다. \nD. \n두 \n개의 \n큰 \nEC2 \n인스턴스를 \n사용하여 \n활성-수동 \n모드에서 \n데이터베이스를 \n호스팅합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/100225-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nRDS 지원 스토리지: \nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html \nGP2 최대 IOPS: \nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/general-purpose.html#gp2-per\nformance \nAmazon RDS 는 범용 SSD(gp2 및 gp3 라고도 함), 프로비저닝된 IOPS SSD(io1 이라고도 함) \n및 마그네틱(표준이라고도 함)의 세 가지 스토리지 유형을 제공합니다. 성능 특성과 가격이 \n다르기 때문에 스토리지 성능과 비용을 데이터베이스 워크로드의 요구 사항에 맞게 조정할 \n수 있습니다. 최대 64TiB 의 스토리지로 MySQL, MariaDB, Oracle 및 PostgreSQL RDS DB \n인스턴스를 생성할 수 있습니다. 최대 16TiB 의 스토리지로 SQL Server RDS DB 인스턴스를 \n생성할 수 있습니다. 이 스토리지 용량에는 프로비저닝된 IOPS SSD 및 범용 SSD 스토리지 \n유형을 사용하십시오. \nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html", "answer_choice": "B"}, "354": {"q_num": 354, "question": "회사는 AWS 에서 서버리스 애플리케이션을 호스팅합니다. 이 애플리케이션은 Amazon API \nGateway, AWS Lambda 및 Amazon RDS for PostgreSQL 데이터베이스를 사용합니다. \n회사는 최대 트래픽 또는 예측할 수 없는 트래픽 시간 동안 데이터베이스 연결 시간 초과로 \n인해 발생하는 애플리케이션 오류의 증가를 확인했습니다. 회사는 최소한의 코드 변경으로 \n애플리케이션 오류를 줄이는 솔루션이 필요합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. Lambda 동시성 비율을 줄입니다. \nB. RDS DB 인스턴스에서 RDS 프록시를 활성화합니다. \nC. 더 많은 연결을 허용하도록 RDS DB 인스턴스 클래스의 크기를 조정합니다. \nD. 온디맨드 확장을 통해 데이터베이스를 Amazon DynamoDB 로 마이그레이션합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/100227-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n\n설명: \nAmazon EC2 에서 AWS Batch 를 사용합니다. AWS Batch 는 Amazon EC2 인스턴스에서 \n배치 작업을 쉽게 실행하는 데 사용할 수 있는 완전 관리형 배치 처리 서비스입니다. \n워크로드에 맞게 인스턴스 수를 확장할 수 있으므로 최소한의 운영 오버헤드로 원하는 시간 \n내에 배치 작업을 완료할 수 있습니다. \nAmazon API Gateway 에서 AWS Lambda 사용 - AWS Lambda \nhttps://docs.aws.amazon.com/lambda/latest/dg/services-apigateway.html \nAWS Lambda FAQ \nhttps://aws.amazon.com/lambda/faqs/", "answer_choice": "D"}, "356": {"q_num": 356, "question": "회사는 데이터 객체를 Amazon S3 Standard 스토리지에 저장합니다. 한 솔루션 설계자는 \n데이터의 75%가 30\n일 후에 거의 액세스되지 않는다는 사실을 발견했습니다. 회사는 \n동일한 고가용성 및 복원력으로 모든 데이터에 즉시 액세스할 수 있어야 하지만 스토리지 \n비용을 최소화하기를 원합니다. \n이러한 요구 사항을 충족하는 스토리지 솔루션은 무엇입니까? \nA. 30 일 후에 데이터 객체를 S3 Glacier Deep Archive 로 이동합니다. \nB. 30\n일 후에 데이터 객체를 S3 Standard-Infrequent Access(S3 Standard-IA)로 \n이동합니다. \nC. 30 일 후에 데이터 객체를 S3 One Zone-Infrequent Access(S3 One Zone-IA)로 \n이동합니다. \nD. 데이터 객체를 S3 One Zone-Infrequent Access(S3 One Zone-IA)로 즉시 이동합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/100229-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n30 일 후에 데이터 객체를 S3 Standard-Infrequent Access(S3 Standard-IA)로 이동하면 \n스토리지 비용을 최소화하면서 고가용성 및 복원력으로 데이터에 즉시 액세스할 수 있어야 \n한다는 요구 사항을 충족합니다. S3 Standard-IA 는 자주 액세스하지 않는 데이터를 위해 \n설계되었으며 S3 Standard 보다 낮은 스토리지 비용을 제공하는 동시에 S3 Standard 와 \n동일한 짧은 지연 시간, 높은 처리량 및 높은 내구성을 제공합니다.", "answer_choice": "B"}, "357": {"q_num": 357, "question": "게임 회사는 공개 점수판을 데이터 센터에서 AWS 클라우드로 옮기고 있습니다. 이 회사는 \nApplication Load Balancer 뒤에 Amazon EC2 Windows Server 인스턴스를 사용하여 동적 \n애플리케이션을 호스팅합니다. 회사는 애플리케이션을 위한 고가용성 스토리지 솔루션이 \n필요합니다. 애플리케이션은 정적 파일과 동적 서버 측 코드로 구성됩니다. \n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 단계 조합을 수행해야 합니까? \n(2 개 선택) \nA. Amazon S3 에 정적 파일을 저장합니다. Amazon CloudFront 를 사용하여 엣지에서 객체를 \n캐싱합니다. \nB. 정적 파일을 Amazon S3 에 저장합니다. Amazon ElastiCache 를 사용하여 엣지에서 \n객체를 캐싱합니다. \nC. Amazon Elastic File System(Amazon EFS)에 서버 측 코드를 저장합니다. 파일을 공유할 \n각 EC2 인스턴스에 EFS 볼륨을 탑재합니다. \nD. Windows File Server 용 Amazon FSx 에 서버 측 코드를 저장합니다. 파일을 공유할 각 \nEC2 인스턴스에 FSx for Windows File Server 볼륨을 탑재합니다. \nE. 범용 SSD(gp2) Amazon Elastic Block Store(Amazon EBS) 볼륨에 서버 측 코드를 \n저장합니다. 각 EC2 인스턴스에 EBS 볼륨을 탑재하여 파일을 공유합니다.", "answer_block": "Answer: A, D \nhttps://www.examtopics.com/discussions/amazon/view/100230-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nA: Elasticache 는 Amazon 당 순위표에 이상적임에도 불구하고 에지 위치에서 캐싱하지 \n않기 때문입니다. \nD: FSx 가 대기 시간이 짧은 요구 사항에 대해 더 높은 성능을 제공하기 때문입니다. \nhttps://www.techtarget.com/searchaws/tip/Amazon-FSx-vs-EFS-Compare-the-AWS-fil\ne-services \nFSx 는 솔리드 스테이트 드라이브 스토리지 볼륨을 사용하여 고성능 및 1 밀리초 미만의 \n대기 시간을 위해 구축되었습니다. 이 설계를 통해 사용자는 스토리지 용량과 대기 시간을 \n독립적으로 선택할 수 있습니다. 따라서 테라바이트 이하의 파일 시스템도 256Mbps \n이상의 처리량을 가질 수 있으며 최대 64TB 의 볼륨을 지원할 수 있습니다. Amazon S3 는 \n이미지, 동영상, 문서 등과 같은 정적 파일을 저장할 수 있는 객체 스토리지 서비스입니다. \nAmazon EFS 는 파일을 계층 구조로 저장할 수 있는 파일 스토리지 서비스이며 NFS \n프로토콜을 지원합니다. \nAmazon FSx for Windows File Server 는 파일을 계층 구조로 저장할 수 있고 SMB \n프로토콜을 지원하는 파일 스토리지 서비스입니다. Amazon EBS 는 데이터를 고정 크기 \n블록에 저장하고 EC2 인스턴스에 연결할 수 있는 블록 스토리지 서비스입니다. \n\n이러한 정의에 따라 요구 사항을 충족하기 위해 취해야 하는 단계 조합은 다음과 같습니다. \n1. 정적 파일을 Amazon S3 에 저장합니다. Amazon CloudFront 를 사용하여 엣지에서 \n객체를 캐싱합니다. \n2. Windows File Server 용 Amazon FSx 에 서버 측 코드를 저장합니다. 파일을 공유할 각 \nEC2 인스턴스에 FSx for Windows File Server 볼륨을 탑재합니다.", "answer_choice": "A"}, "358": {"q_num": 358, "question": "소셜 미디어 회사는 ALB(Application Load Balancer) 뒤의 Amazon EC2 인스턴스에서 \n애플리케이션을 실행합니다. ALB\n는 Amazon CloudFront 배포의 오리진입니다. 이 \n애플리케이션은 Amazon S3 버킷에 10 억 개 이상의 이미지가 저장되어 있으며 초당 수천 \n개의 이미지를 처리합니다. 회사는 이미지 크기를 동적으로 조정하고 고객에게 적절한 \n형식을 제공하기를 원합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. EC2 인스턴스에 외부 이미지 관리 라이브러리를 설치합니다. 이미지 관리 라이브러리를 \n사용하여 이미지를 처리합니다. \nB. CloudFront 오리진 요청 정책을 생성합니다. 정책을 사용하여 자동으로 이미지 크기를 \n조정하고 요청의 User-Agent HTTP 헤더를 기반으로 적절한 형식을 제공합니다. \nC. \n외부 \n이미지 \n관리 \n라이브러리와 \n함께 \nLambda@Edge \n함수를 \n사용합니다. \nLambda@Edge 함수를 이미지를 제공하는 CloudFront 동작과 연결합니다. \nD. CloudFront 응답 헤더 정책을 생성합니다. 정책을 사용하여 자동으로 이미지 크기를 \n조정하고 요청의 User-Agent HTTP 헤더를 기반으로 적절한 형식을 제공합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/100231-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nLambda@Edge 는 CloudFront 엣지 위치에서 Lambda 함수를 실행할 수 있게 해주는 \n서비스입니다. CloudFront 를 통과하는 요청 및 응답을 수정하는 데 사용할 수 있습니다. \nCloudFront 오리진 요청 정책은 CloudFront 가 오리진으로 보내는 요청에 포함된 값(URL \n쿼리 문자열, HTTP 헤더 및 쿠키)을 제어하는 정책입니다. 오리진에서 추가 정보를 \n수집하거나 오리진 응답을 사용자 정의하는 데 사용할 수 있습니다. CloudFront 응답 헤더 \n정책은 CloudFront 가 최종 사용자에게 보내는 응답에서 제거하거나 추가하는 HTTP 헤더를 \n지정하는 정책입니다. 응답에 보안 또는 사용자 지정 헤더를 추가하는 데 사용할 수 \n있습니다. \n이러한 정의에 따라 최소한의 운영 오버헤드로 요구 사항을 충족하는 솔루션은 다음과 \n\n같습니다. \n외부 이미지 관리 라이브러리와 함께 Lambda@Edge 함수를 사용합니다. Lambda@Edge \n함수를 이미지를 제공하는 CloudFront 동작과 연결합니다. \n이 솔루션을 사용하면 애플리케이션이 Lambda@Edge 함수를 사용하여 이미지 크기를 \n동적으로 조정하고 요청의 User-Agent HTTP 헤더를 기반으로 클라이언트에 적절한 형식을 \n제공할 수 있습니다. Lambda@Edge 기능은 엣지 위치에서 실행되어 오리진의 대기 시간과 \n부하를 줄입니다. 애플리케이션 코드는 이미지 조작 작업을 수행할 수 있는 외부 이미지 \n관리 라이브러리만 포함하면 됩니다.", "answer_choice": "C"}, "359": {"q_num": 359, "question": "병원은 환자 기록을 Amazon S3 버킷에 저장해야 합니다. 병원의 컴플라이언스 팀은 모든 \n보호 건강 정보(PHI)가 전송 및 저장 중에 암호화되도록 해야 합니다. 규정 준수 팀은 \n미사용 데이터에 대한 암호화 키를 관리해야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. AWS Certificate Manager(ACM)에서 퍼블릭 SSL/TLS 인증서를 생성합니다. 인증서를 \nAmazon S3 와 연결합니다. AWS KMS 키(SSE-KMS)로 서버 측 암호화를 사용하도록 각 S3 \n버킷에 대한 기본 암호화를 구성합니다. KMS 키를 관리할 규정 준수 팀을 할당합니다. \nB. S3 버킷 정책에서 aws:SecureTransport 조건을 사용하여 HTTPS(TLS)를 통한 암호화된 \n연결만 허용합니다. S3 관리형 암호화 키(SSE-S3)로 서버 측 암호화를 사용하도록 각 S3 \n버킷에 대한 기본 암호화를 구성합니다. SSE-S3 키를 관리할 규정 준수 팀을 할당합니다. \nC. S3 버킷 정책에서 aws:SecureTransport 조건을 사용하여 HTTPS(TLS)를 통한 암호화된 \n연결만 허용합니다. AWS KMS 키(SSE-KMS)로 서버 측 암호화를 사용하도록 각 S3 버킷에 \n대한 기본 암호화를 구성합니다. KMS 키를 관리할 규정 준수 팀을 할당합니다. \nD. S3 버킷 정책에서 aws:SecureTransport 조건을 사용하여 HTTPS(TLS)를 통한 암호화된 \n연결만 허용합니다. Amazon Macie 를 사용하여 Amazon S3 에 저장된 민감한 데이터를 \n보호하십시오. Macie 를 관리할 규정 준수 팀을 지정합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/100232-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n이를 통해 규정 준수 팀은 서버 측 암호화에 사용되는 KMS 키를 관리할 수 있으므로 \n암호화 키에 필요한 제어 기능을 제공합니다. 또한 버킷 정책에서 \"aws:SecureTransport\" \n조건을 사용하면 S3 버킷에 대한 모든 연결이 전송 중에 암호화됩니다.", "answer_choice": "C"}, "360": {"q_num": 360, "question": "회사는 Amazon API Gateway 를 사용하여 동일한 VPC 에서 두 개의 REST API 로 프라이빗 \n게이트웨이를 실행합니다. BuyStock RESTful 웹 서비스는 CheckFunds RESTful 웹 \n서비스를 호출하여 주식을 구매하기 전에 충분한 자금을 사용할 수 있는지 확인합니다. \n회사는 VPC 흐름 로그에서 BuyStock RESTful 웹 서비스가 VPC 대신 인터넷을 통해 \nCheckFunds RESTful 웹 서비스를 호출한다는 사실을 확인했습니다. 솔루션 설계자는 \nAPI 가 VPC 를 통해 통신하도록 솔루션을 구현해야 합니다. \n코드를 가장 적게 변경하여 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 인증을 위해 HTTP 헤더에 X-API-Key 헤더를 추가합니다. \nB. 인터페이스 엔드포인트를 사용합니다. \nC. 게이트웨이 엔드포인트를 사용합니다. \nD. 두 REST API 사이에 Amazon Simple Queue Service(Amazon SQS) 대기열을 \n추가합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/100238-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n인터페이스 엔드포인트를 사용하면 BuyStock RESTful 웹 서비스와 CheckFunds RESTful 웹 \n서비스가 코드를 변경하지 않고도 VPC\n를 통해 통신할 수 있습니다. 인터페이스 \n엔드포인트는 고객의 VPC 에 탄력적 네트워크 인터페이스(ENI)를 생성한 다음 API 에서 \nENI 로 트래픽을 라우팅하도록 라우팅 테이블을 구성합니다. 이렇게 하면 코드를 변경하지 \n않고도 두 API 가 VPC 를 통해 통신할 수 있습니다.", "answer_choice": "B"}, "361": {"q_num": 361, "question": "A company hosts a multiplayer gaming application on AWS. The company wants the \napplication to read data with sub-millisecond latency and run one-time queries on historical \ndata. \nWhich solution will meet these requirements with the LEAST operational overhead? \nA. Use Amazon RDS for data that is frequently accessed. Run a periodic custom script to \nexport the data to an Amazon S3 bucket. \nB. Store the data directly in an Amazon S3 bucket. Implement an S3 Lifecycle policy to move \nolder data to S3 Glacier Deep Archive for long-term storage. Run one-time queries on the \ndata in Amazon S3 by using Amazon Athena. \n\nC. Use Amazon DynamoDB with DynamoDB Accelerator (DAX) for data that is frequently \naccessed. Export the data to an Amazon S3 bucket by using DynamoDB table export. Run \none-time queries on the data in Amazon S3 by using Amazon Athena. \nD. Use Amazon DynamoDB for data that is frequently accessed. Turn on streaming to \nAmazon Kinesis Data Streams. Use Amazon Kinesis Data Firehose to read the data from \nKinesis Data Streams. Store the records in an Amazon S3 bucket.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/102119-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "362": {"q_num": 362, "question": "회사는 특정 지불 ID 에 대한 메시지가 전송된 순서대로 수신되어야 하는 지불 처리 \n시스템을 사용합니다. 그렇지 않으면 결제가 잘못 처리될 수 있습니다. \n솔루션 설계자는 이 요구 사항을 충족하기 위해 어떤 조치를 취해야 합니까? (2 개 선택) \nA. 결제 ID 를 파티션 키로 사용하여 Amazon DynamoDB 테이블에 메시지를 씁니다. \nB. 결제 ID 를 파티션 키로 사용하여 Amazon Kinesis 데이터 스트림에 메시지를 씁니다. \nC. 결제 ID 를 키로 사용하여 Amazon ElastiCache for Memcached 클러스터에 메시지를 \n씁니다. \nD. Amazon Simple Queue Service(Amazon SQS) 대기열에 메시지를 씁니다. 결제 ID 를 \n사용하도록 메시지 속성을 설정합니다. \nE. Amazon Simple Queue Service(Amazon SQS) FIFO 대기열에 메시지를 씁니다. 결제 \nID 를 사용할 메시지 그룹을 설정합니다.", "answer_block": "Answer: B, E \nhttps://www.examtopics.com/discussions/amazon/view/102121-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n1) SQS FIFO 대기열은 메시지가 전송된 정확한 순서대로 수신되도록 보장합니다. 지불 \nID 를 메시지 그룹으로 사용하면 지불 ID 에 대한 모든 메시지가 순차적으로 수신됩니다. \n2) Kinesis 데이터 스트림은 파티션 키별로 순서를 지정할 수도 있습니다. 지불 ID 를 파티션 \n키로 사용하면 각 지불 ID 에 대한 메시지의 엄격한 순서가 보장됩니다.", "answer_choice": "B"}, "363": {"q_num": 363, "question": "회사는 고유한 이벤트를 별도의 리더보드, 매치메이킹 및 인증 서비스로 동시에 전송해야 \n\n하는 게임 시스템을 구축하고 있습니다. 회사에는 이벤트 순서를 보장하는 AWS 이벤트 \n기반 시스템이 필요합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Amazon EventBridge 이벤트 버스 \nB. Amazon Simple Notification Service(Amazon SNS) FIFO 주제 \nC. Amazon Simple Notification Service(Amazon SNS) 표준 주제 \nD. Amazon Simple Queue Service(Amazon SQS) FIFO 대기열", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/102124-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "364": {"q_num": 364, "question": "한 병원에서 환자의 증상을 수집하는 새로운 애플리케이션을 설계하고 있습니다. 병원은 \n아키텍처에서 Amazon Simple Queue Service(Amazon SQS)와 Amazon Simple Notification \nService(Amazon SNS)를 사용하기로 결정했습니다. \n솔루션 설계자가 인프라 설계를 검토하고 있습니다. 저장 및 전송 중에 데이터를 \n암호화해야 합니다. 병원의 승인된 직원만 데이터에 액세스할 수 있어야 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 단계 조합을 수행해야 합니까? \n(2 개 선택) \nA. SQS 구성 요소에서 서버 측 암호화를 켭니다. 기본 키 정책을 업데이트하여 인증된 \n보안 주체 집합으로 키 사용을 제한합니다. \nB. AWS Key Management Service(AWS KMS) 고객 관리 키를 사용하여 SNS 구성 요소에서 \n서버 측 암호화를 켭니다. 키 정책을 적용하여 인증된 보안 주체 집합으로 키 사용을 \n제한합니다. \nC. SNS 구성 요소에서 암호화를 켭니다. 기본 키 정책을 업데이트하여 인증된 보안 주체 \n집합으로 키 사용을 제한합니다. TLS 를 통한 암호화된 연결만 허용하도록 주제 정책에서 \n조건을 설정합니다. \nD. AWS Key Management Service(AWS KMS) 고객 관리 키를 사용하여 SQS 구성 요소에서 \n서버 측 암호화를 켭니다. 키 정책을 적용하여 인증된 보안 주체 집합으로 키 사용을 \n제한합니다. TLS 를 통한 암호화된 연결만 허용하도록 대기열 정책에서 조건을 설정합니다. \nE. AWS Key Management Service(AWS KMS) 고객 관리 키를 사용하여 SQS 구성 요소에서 \n서버 측 암호화를 켭니다. IAM 정책을 적용하여 인증된 보안 주체 집합으로 키 사용을 \n제한합니다. TLS 를 통한 암호화된 연결만 허용하도록 대기열 정책에서 조건을 설정합니다.", "answer_block": "Answer: B, D \nhttps://www.examtopics.com/discussions/amazon/view/102125-exam-aws-certified-sol\n\nutions-architect-associate-saa-c03/ \n \n참고: \nhttps://docs.aws.amazon.com/sns/latest/dg/sns-server-side-encryption.html \nhttps://docs.aws.amazon.com/ko_kr/AWSSimpleQueueService/latest/SQSDeveloperGuide\n/sqs-server-side-encryption.html", "answer_choice": "B"}, "365": {"q_num": 365, "question": "회사는 Amazon RDS 에서 지원하는 웹 애플리케이션을 실행합니다. 새로운 데이터베이스 \n관리자가 실수로 데이터베이스 테이블의 정보를 편집하여 데이터 손실을 일으켰습니다. \n이러한 유형의 사고에서 복구하는 데 도움이 되도록 회사는 지난 30 일 동안 변경이 \n발생하기 5 분 전의 상태로 데이터베이스를 복원할 수 있는 기능을 원합니다. \n이 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 기능을 디자인에 포함해야 합니까? \nA. 읽기 복제본 \nB. 수동 스냅샷 \nC. 자동 백업 \nD. 다중 AZ 배포", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/102127-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nhttps://aws.amazon.com/rds/features/backup/ \n자동 백업은 요구 사항을 충족합니다. Amazon RDS 를 사용하면 DB 인스턴스의 백업을 \n자동으로 생성할 수 있습니다. 자동 백업을 사용하면 DB 인스턴스에 대한 PITR(특정 시점 \n복구)을 보존 기간(최대 35일) 내의 특정 초 단위로 낮출 수 있습니다. 보존 기간을 30일로 \n설정하면 최근 30 일 이내 변경 전 최대 5 분 전의 상태로 데이터베이스를 복원할 수 \n있습니다.", "answer_choice": "C"}, "366": {"q_num": 366, "question": "회사의 웹 애플리케이션은 AWS Lambda 함수 앞의 Amazon API Gateway API 와 Amazon \nDynamoDB 데이터베이스로 구성됩니다. Lambda 함수는 비즈니스 로직을 처리하고 \nDynamoDB 테이블은 데이터를 호스팅합니다. 애플리케이션은 Amazon Cognito 사용자 \n풀을 사용하여 애플리케이션의 개별 사용자를 식별합니다. 솔루션 설계자는 구독이 있는 \n\n사용자만 프리미엄 콘텐츠에 액세스할 수 있도록 애플리케이션을 업데이트해야 합니다. \n최소한의 운영 오버헤드로 이 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. API Gateway API 에서 API 캐싱 및 제한을 활성화합니다. \nB. API Gateway API 에서 AWS WAF 를 설정합니다. 구독이 있는 사용자를 필터링하는 \n규칙을 만듭니다. \nC. DynamoDB 테이블의 프리미엄 콘텐츠에 세분화된 IAM 권한을 적용합니다. \nD. 구독하지 않은 사용자의 액세스를 제한하기 위해 API 사용 계획 및 API 키를 \n구현하십시오.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/102128-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n이 옵션은 API 사용 계획 및 API 키를 사용하기 때문에 가장 효율적입니다. API 에 액세스할 \n수 있는 사람과 API 에 액세스할 수 있는 양과 속도를 제어할 수 있는 Amazon API \nGateway\n의 기능입니다. 또한 API 사용 계획 및 API 키를 구현하여 구독하지 않은 \n사용자의 액세스를 제한하므로 API 에 대한 다양한 액세스 계층을 생성하고 그에 따라 \n사용자에게 요금을 청구할 수 있습니다. 이 솔루션은 구독이 있는 사용자만 프리미엄 \n콘텐츠에 액세스할 수 있도록 애플리케이션 업데이트 요구 사항을 충족합니다. \n옵션 A 는 Amazon API Gateway 의 기능인 API Gateway API 에서 API 캐싱 및 제한을 \n사용하기 때문에 효율성이 떨어집니다. \nAPI\n의 성능과 가용성을 개선하고 트래픽 급증으로부터 백엔드 시스템을 보호할 수 \n있습니다. 그러나 이는 가입하지 않은 사용자의 액세스를 제한하는 방법을 제공하지 \n않습니다. \n옵션 B 는 가용성에 영향을 미치거나 보안을 손상시키거나 과도한 리소스를 소비할 수 있는 \n일반적인 웹 악용으로부터 웹 애플리케이션 또는 API 를 보호하는 웹 애플리케이션 방화벽 \n서비스인 API Gateway API 에서 AWS WAF 를 사용하기 때문에 효율성이 떨어집니다. 그러나 \n이는 가입하지 않은 사용자의 액세스를 제한하는 방법을 제공하지 않습니다. \n옵션 C 는 테이블 내의 특정 항목 또는 속성에 대한 액세스를 제어할 수 있는 권한인 \nDynamoDB 테이블의 프리미엄 콘텐츠에 대한 세분화된 IAM 권한을 사용하기 때문에 \n효율성이 떨어집니다. 그러나 이는 API 수준에서 구독하지 않은 사용자의 액세스를 \n제한하는 방법을 제공하지 않습니다.", "answer_choice": "D"}, "367": {"q_num": 367, "question": "한 회사에서 Amazon Route 53 지연 시간 기반 라우팅을 사용하여 전 세계 사용자를 위해 \n\nUDP 기반 애플리케이션으로 요청을 라우팅하고 있습니다. 이 애플리케이션은 미국, 아시아 \n및 유럽에 있는 회사의 온프레미스 데이터 센터에 있는 중복 서버에서 호스팅됩니다. \n회사의 규정 준수 요구 사항에 따르면 애플리케이션은 온프레미스에서 호스팅되어야 합니다. \n회사는 애플리케이션의 성능과 가용성을 개선하고자 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. 3 개의 AWS 리전에서 3 개의 NLB(Network Load Balancer)를 구성하여 온프레미스 \n엔드포인트를 처리합니다. AWS Global Accelerator 를 사용하여 가속기를 생성하고 NLB 를 \n엔드포인트로 등록합니다. 가속기 DNS 를 가리키는 CNAME 을 사용하여 애플리케이션에 \n대한 액세스를 제공합니다. \nB. 3 개의 AWS 리전에서 3 개의 Application Load Balancer(ALB)를 구성하여 온프레미스 \n엔드포인트를 처리합니다. AWS Global Accelerator 를 사용하여 가속기를 생성하고 ALB 를 \n엔드포인트로 등록합니다. 가속기 DNS 를 가리키는 CNAME 을 사용하여 애플리케이션에 \n대한 액세스를 제공합니다. \nC. 3 개의 AWS 리전에서 3 개의 NLB(Network Load Balancer)를 구성하여 온프레미스 \n엔드포인트를 처리합니다. Route 53 에서 3 개의 NLB 를 가리키는 지연 시간 기반 레코드를 \n생성하고 이를 Amazon CloudFront 배포의 오리진으로 사용합니다. CloudFront DNS 를 \n가리키는 CNAME 을 사용하여 애플리케이션에 대한 액세스를 제공합니다. \nD. 온프레미스 엔드포인트를 처리하기 위해 3 개의 AWS 리전에서 3 개의 ALB(Application \nLoad Balancer)를 구성합니다. Route 53 에서 3 개의 ALB 를 가리키는 지연 시간 기반 \n레코드를 생성하고 이를 Amazon CloudFront 배포의 오리진으로 사용합니다. CloudFront \nDNS 를 가리키는 CNAME 을 사용하여 애플리케이션에 대한 액세스를 제공합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/102131-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nhttps://aws.amazon.com/ko/step-functions/#:~:text=AWS%20Step%20Functions%20is%\n20a \nAWS Step Functions 의 일반적인 사용 사례는 사람의 개입이 필요한 작업입니다(예: 승인 \n프로세스). Step Functions 를 사용하면 분산 애플리케이션의 구성 요소를 상태 머신이라고 \n하는 시각적 워크플로의 일련의 단계로 쉽게 조정할 수 있습니다. 안정적이고 확장 가능한 \n방식으로 애플리케이션의 단계를 실행하기 위해 상태 시스템을 신속하게 구축하고 실행할 \n수 있습니다.", "answer_choice": "A"}, "368": {"q_num": 368, "question": "솔루션 설계자는 모든 신규 사용자가 특정 복잡성 요구 사항과 IAM 사용자 암호에 대한 \n필수 교체 기간을 갖기를 원합니다. \n이를 달성하기 위해 솔루션 설계자는 무엇을 해야 합니까? \nA. 전체 AWS 계정에 대한 전반적인 암호 정책을 설정합니다. \nB. AWS 계정의 각 IAM 사용자에 대한 암호 정책을 설정합니다. \nC. 타사 공급업체 소프트웨어를 사용하여 암호 요구 사항을 설정합니다. \nD. Amazon CloudWatch 규칙을 Create_newuser 이벤트에 연결하여 적절한 요구 사항으로 \n암호를 설정합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/102132-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n이 옵션은 IAM 사용자 암호에 대한 복잡성 요구 사항 및 필수 교체 기간을 지정하는 \n방법인 전체 AWS 계정에 대한 전체 암호 정책을 설정하기 때문에 가장 효율적입니다. 또한 \n암호 정책은 계정의 모든 IAM 사용자에게 적용되므로 모든 새 사용자에 대한 암호 정책 \n설정 요구 사항을 충족합니다. 이 솔루션은 IAM 사용자 암호에 대한 특정 복잡성 요구 \n사항 및 필수 교체 기간 설정 요구 사항을 충족합니다. \n옵션 B 는 AWS 계정의 각 IAM 사용자에 대해 암호 정책을 설정하기 때문에 효율성이 \n떨어집니다. 암호 정책은 계정 수준에서만 설정할 수 있으므로 불가능합니다. \n옵션 C\n는 타사 공급업체 소프트웨어를 사용하여 암호 요구 사항을 설정하기 때문에 \n효율성이 떨어집니다. IAM 은 암호 정책을 설정하는 기본 제공 방법을 제공하므로 필요하지 \n않습니다. \n옵션 D 는 Amazon CloudWatch 규칙을 Create_newuser 이벤트에 연결하여 적절한 요구 \n사항으로 암호를 설정하기 때문에 효율성이 떨어집니다. 이는 CloudWatch 규칙이 IAM \n사용자 암호를 수정할 수 없기 때문에 불가능합니다.", "answer_choice": "A"}, "369": {"q_num": 369, "question": "회사에서 애플리케이션을 Amazon EC2 Linux 인스턴스로 마이그레이션했습니다. 이러한 \nEC2 인스턴스 중 하나는 일정에 따라 여러 개의 1 시간 작업을 실행합니다. 이러한 작업은 \n서로 다른 팀에서 작성했으며 공통 프로그래밍 언어가 없습니다. 회사는 이러한 작업이 \n단일 인스턴스에서 실행되는 동안 성능과 확장성에 대해 우려하고 있습니다. 솔루션 \n설계자는 이러한 문제를 해결하기 위한 솔루션을 구현해야 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. AWS Batch 를 사용하여 작업을 작업으로 실행합니다. Amazon EventBridge(Amazon \n\nCloudWatch Events)를 사용하여 작업을 예약합니다. \nB. EC2 인스턴스를 컨테이너로 변환합니다. AWS App Runner 를 사용하여 작업을 작업으로 \n실행할 온디맨드 컨테이너를 생성합니다. \nC. 작업을 AWS Lambda 함수에 복사합니다. Amazon EventBridge(Amazon CloudWatch \nEvents)를 사용하여 Lambda 함수를 예약합니다. \nD. 작업을 실행하는 EC2 인스턴스의 Amazon 머신 이미지(AMI)를 생성합니다. AMI 로 Auto \nScaling 그룹을 생성하여 인스턴스의 여러 복사본을 실행합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/102133-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nAWS Batch 는 사용자가 AWS\n에서 배치 작업을 실행할 수 있게 해주는 완전관리형 \n서비스입니다. 다른 언어로 작성된 다양한 유형의 작업을 처리하고 EC2 인스턴스에서 \n실행할 수 있습니다. 또한 Amazon EventBridge(Amazon CloudWatch Events)와 통합되어 \n시간 또는 이벤트 트리거를 기반으로 작업을 예약합니다. 이 솔루션은 성능, 확장성 및 \n낮은 운영 오버헤드 요구 사항을 충족합니다. \n1. EC2 인스턴스를 컨테이너로 변환합니다. AWS App Runner 를 사용하여 작업을 작업으로 \n실행할 온디맨드 컨테이너를 생성합니다. 이 솔루션은 EC2 인스턴스를 컨테이너로 \n변환하고 웹 애플리케이션을 자동으로 빌드 및 배포하고 트래픽 부하를 분산하는 서비스인 \nAWS App Runner 를 사용하므로 낮은 운영 오버헤드 요구 사항을 충족하지 않습니다. 배치 \n작업을 실행하는 데는 필요하지 않습니다. \n2. 작업을 AWS Lambda 함수에 복사합니다. Amazon EventBridge(Amazon CloudWatch \nEvents)를 사용하여 Lambda 함수를 예약합니다. AWS Lambda 에는 실행 시간이 15 분, \n메모리 할당이 10GB\n로 제한되어 있으므로 이 솔루션은 성능 요구 사항을 충족하지 \n않습니다. 이러한 제한은 1 시간 작업을 실행하는 데 충분하지 않을 수 있습니다. \n3. 작업을 실행하는 EC2 인스턴스의 Amazon 머신 이미지(AMI)를 생성합니다. AMI 로 Auto \nScaling 그룹을 생성하여 인스턴스의 여러 복사본을 실행합니다. 이 솔루션은 구성 및 \n관리가 필요한 추가 리소스인 AMI 및 Auto Scaling 그룹을 생성하고 유지 관리하므로 낮은 \n운영 오버헤드 요구 사항을 충족하지 않습니다. \n참조 URL:  \nhttps://docs.aws.amazon.com/ko_kr/whitepapers/latest/aws-overview/compute-services.\nhtml \n \n설명: \nNAT 게이트웨이는 프라이빗 서브넷의 인스턴스가 인터넷이나 다른 AWS 서비스에 연결할 \n\n수 있게 해주지만 인터넷이 해당 인스턴스와의 연결을 시작하지 못하도록 하는 네트워크 \n주소 변환(NAT) 장치 유형입니다. NAT 게이트웨이는 최소한의 운영 유지 관리가 필요하고 \n최대 45Gbps 의 버스트 트래픽을 처리할 수 있는 관리형 서비스입니다. NAT 게이트웨이는 \n시나리오의 3 계층 웹 애플리케이션과 같이 프라이빗 서브넷의 EC2 인스턴스가 인터넷을 \n통해 라이선스 서버와 통신해야 하는 시나리오에 적합합니다. \n시나리오의 요구 사항을 충족하려면 솔루션 설계자가 퍼블릭 서브넷에서 NAT 게이트웨이를 \n프로비저닝해야 합니다. 솔루션 설계자는 또한 NAT 게이트웨이를 가리키는 기본 경로로 각 \n프라이빗 서브넷의 경로 테이블을 수정해야 합니다. 이렇게 하면 프라이빗 서브넷에서 \n실행되는 EC2 인스턴스가 NAT 게이트웨이를 통해 인터넷을 통해 라이선스 서버에 \n액세스할 수 있습니다.", "answer_choice": "A"}, "370": {"q_num": 370, "question": "회사는 VPC 에서 공용 3 계층 웹 애플리케이션을 실행합니다. 애플리케이션은 여러 가용 \n영역의 Amazon EC2 인스턴스에서 실행됩니다. 프라이빗 서브넷에서 실행되는 EC2 \n인스턴스는 인터넷을 통해 라이선스 서버와 통신해야 합니다. 회사는 운영 유지 보수를 \n최소화하는 관리형 솔루션이 필요합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 퍼블릭 서브넷에서 NAT 인스턴스를 프로비저닝합니다. NAT 인스턴스를 가리키는 기본 \n경로로 각 프라이빗 서브넷의 경로 테이블을 수정합니다. \nB. 프라이빗 서브넷에서 NAT 인스턴스를 프로비저닝합니다. NAT 인스턴스를 가리키는 기본 \n경로로 각 프라이빗 서브넷의 경로 테이블을 수정합니다. \nC. 퍼블릭 서브넷에서 NAT 게이트웨이를 프로비저닝합니다. NAT 게이트웨이를 가리키는 \n기본 경로로 각 프라이빗 서브넷의 경로 테이블을 수정합니다. \nD. 프라이빗 서브넷에서 NAT 게이트웨이를 프로비저닝합니다. NAT 게이트웨이를 가리키는 \n기본 경로로 각 프라이빗 서브넷의 경로 테이블을 수정합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/102134-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "371": {"q_num": 371, "question": "회사는 디지털 미디어 스트리밍 애플리케이션을 호스팅하기 위해 Amazon Elastic \nKubernetes Service(Amazon EKS) 클러스터를 생성해야 합니다. EKS 클러스터는 저장을 \n위해 Amazon Elastic Block Store(Amazon EBS) 볼륨이 지원하는 관리형 노드 그룹을 \n사용합니다. 회사는 AWS Key Management Service(AWS KMS)에 저장된 고객 관리형 키를 \n\n사용하여 유휴 상태의 모든 데이터를 암호화해야 합니다. \n최소한의 운영 오버헤드로 이 요구 사항을 충족하는 작업 조합은 무엇입니까? (2 개 선택) \nA. \n고객 \n관리 \n키를 \n사용하는 \nKubernetes \n플러그인을 \n사용하여 \n데이터 \n암호화를 \n수행합니다. \nB. EKS 클러스터 생성 후 EBS 볼륨을 찾습니다. 고객 관리형 키를 사용하여 암호화를 \n활성화합니다. \nC. EKS 클러스터가 생성될 AWS 리전에서 기본적으로 EBS 암호화를 활성화합니다. 고객 \n관리형 키를 기본 키로 선택합니다. \nD. EKS 클러스터를 생성합니다. 고객 관리형 키에 대한 권한을 부여하는 정책이 있는 IAM \n역할을 생성합니다. 역할을 EKS 클러스터와 연결합니다. \nE. 고객 관리형 키를 EKS 클러스터에 Kubernetes 비밀로 저장합니다. 고객 관리형 키를 \n사용하여 EBS 볼륨을 암호화합니다.", "answer_block": "Answer: B, D \nhttps://www.examtopics.com/discussions/amazon/view/102135-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "372": {"q_num": 372, "question": "회사에서 Oracle 데이터베이스를 AWS 로 마이그레이션하려고 합니다. 데이터베이스는 지리 \n코드로 식별되는 고해상도 지리 정보 시스템(GIS) 이미지 수백만 개가 포함된 단일 \n테이블로 구성됩니다. \n자연 재해가 발생하면 몇 분마다 수만 개의 이미지가 업데이트됩니다. 각 지리적 코드에는 \n연결된 단일 이미지 또는 행이 있습니다. 회사는 이러한 이벤트 중에 가용성과 확장성이 \n뛰어난 솔루션을 원합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. 이미지와 지리적 코드를 데이터베이스 테이블에 저장합니다. Amazon RDS 다중 AZ DB \n인스턴스에서 실행되는 Oracle 을 사용합니다. \nB. Amazon S3 버킷에 이미지를 저장합니다. 지리적 코드를 키로, 이미지 S3 URL 을 값으로 \n사용하여 Amazon DynamoDB 를 사용합니다. \nC. Amazon DynamoDB 테이블에 이미지와 지리적 코드를 저장합니다. 부하가 높은 시간 \n동안 DynamoDB Accelerator(DAX)를 구성합니다. \nD. Amazon S3 버킷에 이미지를 저장합니다. 지리 코드와 이미지 S3 URL 을 데이터베이스 \n테이블에 저장합니다. Amazon RDS 다중 AZ DB 에서 실행되는 Oracle 사용", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/102136-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n\n \n설명: \nAmazon S3 는 수백만 개의 이미지1 를 저장할 수 있는 확장성과 내구성이 뛰어나고 비용 \n효율적인 객체 스토리지 서비스입니다. Amazon DynamoDB 는 키-값 및 문서 데이터에 \n대해 \n높은 \n처리량과 \n짧은 \n지연 \n시간을 \n처리할 \n수 \n있는 \n완전관리형 \nNoSQL \n데이터베이스입니다. S3 를 사용하여 이미지를 저장하고 DynamoDB 를 사용하여 지리적 \n코드와 이미지 S3 URL 을 저장함으로써 솔루션은 자연 재해 중에 고가용성과 확장성을 \n달성할 수 있습니다. 또한 캐싱, 자동 확장, 글로벌 테이블과 같은 DynamoDB 의 기능을 \n활용하여 성능을 개선하고 비용을 절감할 수 있습니다. \n1. 데이터베이스 테이블에 이미지와 지리적 코드를 저장합니다. Amazon RDS 다중 AZ DB \n인스턴스에서 실행되는 Oracle 을 사용합니다. Oracle 은 이미지와 같은 대량의 비정형 \n데이터를 효율적으로 처리하지 못할 수 있는 관계형 데이터베이스이므로 이 솔루션은 \n확장성 및 비용 효율성 요구 사항을 충족하지 않습니다. 또한 S3 및 DynamoDB 보다 \n라이선스 및 운영 비용이 더 많이 듭니다. \n2. Amazon DynamoDB 테이블에 이미지와 지리적 코드를 저장합니다. 로드가 많은 시간 \n동안 DynamoDB Accelerator(DAX)를 구성합니다. 이 솔루션은 DynamoDB 에 이미지를 \n저장하면 S312 에 저장하는 것보다 더 많은 스토리지 공간을 사용하고 더 많은 비용이 \n발생하므로 비용 효율성 요구 사항을 충족하지 않습니다. 또한 높은 부하를 처리하기 위해 \nDAX 클러스터의 추가 구성 및 관리가 필요합니다. \n3. Amazon S3 버킷에 이미지를 저장합니다. 지리적 코드와 이미지 S3 URL 을 데이터베이스 \n테이블에 저장합니다. Amazon RDS 다중 AZ DB 인스턴스에서 실행되는 Oracle\n을 \n사용합니다. Oracle 은 지리적 코드와 같은 키-값 데이터에 대한 높은 처리량과 낮은 대기 \n시간을 효율적으로 처리하지 못할 수 있는 관계형 데이터베이스이므로 이 솔루션은 확장성 \n및 비용 효율성 요구 사항을 충족하지 않습니다. 또한 DynamoDB2 보다 라이선스 및 운영 \n비용이 더 많이 듭니다. \n참조 URL: https://dynobase.dev/dynamodb-vs-s3/", "answer_choice": "B"}, "373": {"q_num": 373, "question": "회사에 자동차의 loT 센서에서 데이터를 수집하는 애플리케이션이 있습니다. 데이터는 \nAmazon Kinesis Data 를 통해 Amazon S3 에 스트리밍 및 저장됩니다. \n소방 호스. 데이터는 매년 수조 개의 S3 객체를 생성합니다. 매일 아침 회사는 지난 30 일 \n동안의 데이터를 사용하여 일련의 기계 학습(ML) 모델을 재교육합니다. \n매년 4 회 회사는 이전 12 개월의 데이터를 사용하여 분석을 수행하고 다른 ML 모델을 \n교육합니다. 데이터는 최대 1 년 동안 최소한의 지연으로 사용할 수 있어야 합니다. 1 년 \n후에는 데이터를 보관 목적으로 보관해야 합니다. \n\n이러한 요구 사항을 가장 비용 효율적으로 충족하는 스토리지 솔루션은 무엇입니까? \nA. S3 Intelligent-Tiering 스토리지 클래스를 사용합니다. 1 년 후 객체를 S3 Glacier Deep \nArchive 로 전환하는 S3 수명 주기 정책을 생성합니다. \nB. S3 Intelligent-Tiering 스토리지 클래스를 사용합니다. 1년 후 자동으로 객체를 S3 Glacier \nDeep Archive 로 이동하도록 S3 Intelligent-Tiering 을 구성합니다. \nC. S3 Standard-Infrequent Access(S3 Standard-IA) 스토리지 클래스를 사용합니다. 1 년 후 \n객체를 S3 Glacier Deep Archive 로 전환하는 S3 수명 주기 정책을 생성합니다. \nD. S3 Standard 스토리지 클래스를 사용합니다. 30 일 후에 객체를 S3 Standard-Infrequent \nAccess(S3 Standard-IA)로 전환한 다음 1 년 후에 S3 Glacier Deep Archive 로 전환하는 S3 \n수명 주기 정책을 생성합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/102137-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "D"}, "374": {"q_num": 374, "question": "한 회사가 us-east-1 리전 내의 3 개의 별도 VPC 에서 여러 비즈니스 애플리케이션을 \n실행하고 \n있습니다. \n애플리케이션은 \nVPC \n간에 \n통신할 \n수 \n있어야 \n합니다. \n또한 \n애플리케이션은 \n단일 \n온프레미스 \n데이터 \n센터에서 \n실행되는 \n대기 \n시간에 \n민감한 \n애플리케이션에 매일 수백 기가바이트의 데이터를 지속적으로 보낼 수 있어야 합니다. \n솔루션 설계자는 비용 효율성을 극대화하는 네트워크 연결 솔루션을 설계해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 데이터 센터에서 AWS 로 3 개의 AWS Site-to-Site VPN 연결을 구성합니다. 각 VPC 에 \n대해 하나의 VPN 연결을 구성하여 연결을 설정합니다. \nB. 각 VPC 에서 타사 가상 네트워크 어플라이언스를 시작합니다. 데이터 센터와 각 가상 \n어플라이언스 간에 IPsec VPN 터널을 설정합니다. \nC. 데이터 센터에서 us-east-1 의 Direct Connect 게이트웨이로 3 개의 AWS Direct \nConnect 연결을 설정합니다. Direct Connect 연결 중 하나를 사용하도록 각 VPC 를 \n구성하여 연결을 설정합니다. \nD. 데이터 센터에서 AWS\n로 하나의 AWS Direct Connect 연결을 설정합니다. 전송 \n게이트웨이를 생성하고 각 VPC 를 전송 게이트웨이에 연결합니다. Direct Connect 연결과 \ntransit gateway 간의 연결을 설정합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/102138-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n\n설명: \nA(X) : VPC-온프레미스 간 통신은 이루어지나 VPC 간 통신은 이루어지지 않고 있음. \nB(X) : A 와 같은 이유로 오답. \nC(X) : A 와 같은 이유로 오답. \nD(O) : Transit Gateway\n는 동일한 리전 내에 있는 여러 VPC\n들을 연결하는 전송 \n'허브'이므로 Transit Gateway 를 거쳐 VPC 끼리 통신이 가능 \nAWS Transit Gateway 는 동일한 리전의 VPC 를 상호 연결하여 Amazon VPC 라우팅 구성을 \n한 곳에 통합하는 네트워크 전송 허브입니다. \nhttps://docs.aws.amazon.com/whitepapers/latest/aws-vpc-connectivity-options/aws-dir\nect-connect-aws-transit-gateway.html", "answer_choice": "D"}, "375": {"q_num": 375, "question": "전자상거래 회사는 주문 처리 작업을 완료하기 위해 여러 서버리스 기능과 AWS 서비스를 \n포함하는 분산 애플리케이션을 구축하고 있습니다. 이러한 작업에는 워크플로의 일부로 \n수동 승인이 필요합니다. 솔루션 설계자는 주문 처리 애플리케이션을 위한 아키텍처를 \n설계해야 합니다. 솔루션은 여러 AWS Lambda 기능을 반응형 서버리스 애플리케이션으로 \n결합할 수 있어야 합니다. 솔루션은 또한 Amazon EC2 인스턴스, 컨테이너 또는 \n온프레미스 서버에서 실행되는 데이터 및 서비스를 오케스트레이션해야 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. AWS Step Functions 를 사용하여 애플리케이션을 구축하십시오. \nB. AWS Glue 작업에서 모든 애플리케이션 구성 요소를 통합합니다. \nC. Amazon Simple Queue Service(Amazon SQS)를 사용하여 애플리케이션을 구축합니다. \nD. AWS Lambda 함수와 Amazon EventBridge 이벤트를 사용하여 애플리케이션을 \n구축합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/102139-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nAWS Step Functions 는 시각적 워크플로를 사용하여 분산 애플리케이션 및 마이크로 \n서비스의 구성 요소를 조정하여 애플리케이션을 쉽게 구축할 수 있게 해주는 완전 관리형 \n서비스입니다. \nStep Functions 를 사용하면 여러 AWS Lambda 함수를 반응형 서버리스 애플리케이션에 \n결합하고 Amazon EC2 인스턴스, 컨테이너 또는 온프레미스 서버에서 실행되는 데이터 및 \n서비스를 오케스트레이션할 수 있습니다. Step Functions 는 또한 워크플로의 일부로 수동 \n\n승인을 허용합니다. 이 솔루션은 최소한의 운영 오버헤드로 모든 요구 사항을 충족합니다. \nhttps://aws.amazon.com/ko/step-functions/#:~:text=AWS%20Step%20Functions%20is%\n20a", "answer_choice": "A"}, "376": {"q_num": 376, "question": "한 회사에서 MySQL DB 인스턴스용 Amazon RDS 를 출시했습니다. 데이터베이스에 대한 \n대부분의 \n연결은 \n서버리스 \n애플리케이션에서 \n발생합니다. \n데이터베이스에 \n대한 \n애플리케이션 트래픽은 임의의 간격으로 크게 변경됩니다. 수요가 많을 때 사용자는 \n애플리케이션에 데이터베이스 연결 거부 오류가 발생한다고 보고합니다. \n최소한의 운영 오버헤드로 이 문제를 해결하는 솔루션은 무엇입니까? \nA. RDS Proxy 에서 프록시를 생성합니다. RDS Proxy 를 통해 DB 인스턴스를 사용하도록 \n사용자 애플리케이션을 구성합니다. \nB. 사용자 애플리케이션과 DB 인스턴스 간에 Amazon ElastiCache for Memcached 를 \n배포합니다. \nC. I/O 용량이 더 큰 다른 인스턴스 클래스로 DB 인스턴스를 마이그레이션합니다. 새 DB \n인스턴스를 사용하도록 사용자 애플리케이션을 구성합니다. \nD. DB 인스턴스에 대한 다중 AZ 를 구성합니다. DB 인스턴스 간에 전환하도록 사용자 \n애플리케이션을 구성합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/102140-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n최신 \n서버리스 \n아키텍처에 \n구축된 \n애플리케이션을 \n포함하여 \n많은 \n애플리케이션은 \n데이터베이스 서버에 대해 많은 수의 열린 연결을 가질 수 있으며 빠른 속도로 \n데이터베이스 연결을 열고 닫을 수 있으므로 데이터베이스 메모리와 컴퓨팅 리소스가 \n고갈될 수 있습니다. Amazon RDS Proxy 를 사용하면 애플리케이션이 데이터베이스와 \n설정된 연결을 풀링하고 공유하여 데이터베이스 효율성과 애플리케이션 확장성을 개선할 수 \n있습니다.  \n(https://aws.amazon.com/pt/rds/proxy/)", "answer_choice": "A"}, "377": {"q_num": 377, "question": "한 회사는 최근 Amazon EC2 인스턴스에 대해 운영 체제 버전, 패치 및 설치된 \n소프트웨어에 대한 정보를 중앙 집중화하기 위해 새로운 감사 시스템을 배포했습니다. \n\n솔루션 설계자는 EC2 Auto Scaling 그룹을 통해 프로비저닝된 모든 인스턴스가 시작 및 \n종료되는 즉시 성공적으로 감사 시스템에 보고서를 보내도록 해야 합니다. \n이러한 목표를 가장 효율적으로 달성하는 솔루션은 무엇입니까? \nA. 예약된 AWS Lambda 함수를 사용하고 모든 EC2 인스턴스에서 원격으로 스크립트를 \n실행하여 데이터를 감사 시스템으로 보냅니다. \nB. EC2 Auto Scaling 수명 주기 후크를 사용하여 인스턴스가 시작되고 종료될 때 감사 \n시스템에 데이터를 보내는 사용자 지정 스크립트를 실행합니다. \nC. EC2 Auto Scaling 시작 구성을 사용하여 사용자 데이터를 통해 사용자 지정 스크립트를 \n실행하여 인스턴스가 시작되고 종료될 때 감사 시스템에 데이터를 보냅니다. \nD. 인스턴스 운영 체제에서 사용자 지정 스크립트를 실행하여 데이터를 감사 시스템으로 \n보냅니다. 인스턴스가 시작되고 종료될 때 EC2 Auto Scaling 그룹에서 호출할 스크립트를 \n구성합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/102142-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nAmazon EC2 Auto Scaling 은 Auto Scaling 그룹에 수명 주기 후크를 추가하는 기능을 \n제공합니다. 이러한 후크를 사용하면 Auto Scaling 인스턴스 수명 주기의 이벤트를 \n인식하는 솔루션을 생성한 다음 해당 수명 주기 이벤트가 발생할 때 인스턴스에서 사용자 \n지정 작업을 수행할 수 있습니다. \n(https://docs.aws.amazon.com/autoscaling/ec2/userguide/lifecycle-hooks.html)", "answer_choice": "B"}, "378": {"q_num": 378, "question": "한 회사에서 Auto Scaling 그룹의 클라이언트와 서버 간의 통신에 UDP 를 사용하는 실시간 \n멀티플레이어 게임을 개발하고 있습니다. 하루 동안 수요가 급증할 것으로 예상되므로 게임 \n서버 플랫폼은 그에 따라 적응해야 합니다. 개발자는 개입 없이 확장되는 데이터베이스 \n솔루션에 게이머 점수 및 기타 비관계형 데이터를 저장하기를 원합니다. \n솔루션 설계자는 어떤 솔루션을 추천해야 합니까? \nA. 트래픽 분산에는 Amazon Route 53 을 사용하고 데이터 저장에는 Amazon Aurora \nServerless 를 사용하십시오. \nB. 트래픽 분산을 위해 Network Load Balancer 를 사용하고 데이터 저장을 위해 주문형 \nAmazon DynamoDB 를 사용합니다. \nC. 트래픽 분산을 위해 Network Load Balancer 를 사용하고 데이터 저장을 위해 Amazon \nAurora Global Database 를 사용합니다. \n\nD. 트래픽 분산을 위해 Application Load Balancer\n를 사용하고 데이터 저장을 위해 \nAmazon DynamoDB 전역 테이블을 사용합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/102143-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nNetwork Load Balancer 는 연결 수준(계층 4)에서 작동하고 TCP 및 UDP 트래픽 모두의 \n부하를 분산할 수 있는 일종의 부하 분산 장치입니다. Network Load Balancer 는 실시간 \n멀티플레이어 게임과 같이 고성능과 짧은 대기 시간이 필요한 시나리오에 적합합니다. \nNetwork Load Balancer 는 가용 영역당 단일 고정 IP 주소를 사용하면서 갑작스럽고 \n변동성이 큰 트래픽 패턴을 처리할 수도 있습니다. \n시나리오의 요구 사항을 충족하려면 솔루션 설계자는 Auto Scaling 그룹의 EC2 인스턴스 \n간 트래픽 분산을 위해 Network Load Balancer\n를 사용해야 합니다. Network Load \nBalancer 는 클라이언트에서 적절한 포트의 서버로 UDP 트래픽을 라우팅할 수 있습니다. \nNetwork Load Balancer 는 클라이언트와 서버 간의 보안 통신을 위해 TLS 오프로딩도 \n지원할 수 있습니다. \nAmazon DynamoDB 는 일관된 성능과 짧은 지연 시간으로 모든 양의 데이터를 저장하고 \n검색할 수 있는 완전 관리형 NoSQL 데이터베이스 서비스입니다. Amazon DynamoDB \n온디맨드는 용량 계획이 필요 없고 테이블에서 수행되는 읽기 및 쓰기 요청에 대해서만 \n요금을 부과하는 유연한 결제 옵션입니다\n3. Amazon DynamoDB 온디맨드는 게임 \n애플리케이션과 같이 애플리케이션 트래픽을 예측할 수 없거나 산발적인 시나리오에 \n이상적입니다. \n시나리오의 요구 사항을 충족하려면 솔루션 설계자는 데이터 스토리지에 Amazon \nDynamoDB 온디맨드를 사용해야 합니다. Amazon DynamoDB 온디맨드는 개발자의 개입 \n없이 게이머 점수 및 기타 비관계형 데이터를 저장할 수 있습니다. Amazon DynamoDB \n온디맨드는 자동으로 확장하여 성능이나 가용성에 영향을 주지 않고 모든 수준의 요청 \n트래픽을 처리할 수 있습니다.", "answer_choice": "B"}, "379": {"q_num": 379, "question": "회사는 AWS Lambda 와 통합된 Amazon API Gateway API 백엔드를 사용하는 프런트엔드 \n애플리케이션을 호스팅합니다. API 가 요청을 받으면 Lambda 함수는 많은 라이브러리를 \n로드합니다. 그런 다음 Lambda 함수는 Amazon RDS 데이터베이스에 연결하여 데이터를 \n처리하고 프런트엔드 애플리케이션에 데이터를 반환합니다. 회사는 회사 운영에 대한 변경 \n횟수를 최소화하면서 모든 사용자의 응답 대기 시간을 가능한 한 낮추고자 합니다. \n\n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. API 를 우회하여 쿼리 속도를 높이려면 프런트엔드 애플리케이션과 데이터베이스 사이에 \n연결을 설정합니다. \nB. 요청을 처리하는 Lambda 함수에 대해 프로비저닝된 동시성을 구성합니다. \nC. 유사한 데이터 세트를 더 빠르게 검색하기 위해 쿼리 결과를 Amazon S3 에 캐시합니다. \nD. Lambda 가 한 번에 설정할 수 있는 연결 수를 늘리려면 데이터베이스 크기를 늘립니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/102144-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n요청을 처리하는 Lambda 함수에 대해 프로비저닝된 동시성을 구성합니다. 프로비저닝된 \n동시성을 사용하면 Lambda 함수에서 사용할 수 있는 컴퓨팅 리소스의 양을 설정할 수 \n있으므로 한 번에 더 많은 요청을 처리하고 지연 시간을 줄일 수 있습니다. 쿼리 결과를 \nAmazon S3 에 캐싱하면 대기 시간을 줄이는 데 도움이 되지만 프로비저닝된 동시성을 \n설정하는 것만큼 효과적이지는 않습니다. 데이터베이스 크기를 늘려도 지연 시간을 줄이는 \n데 도움이 되지 않습니다. 이는 Lambda 함수가 설정할 수 있는 연결 수를 늘리지 않고 \n프런트엔드 애플리케이션과 데이터베이스 사이에 직접 연결을 설정하면 API 를 우회하기 \n때문입니다. 최고의 솔루션 중 하나입니다. \nhttps://docs.aws.amazon.com/lambda/latest/dg/services-apigateway.html \nUsing AWS Lambda with Amazon API Gateway - AWS Lambda \nhttps://docs.aws.amazon.com/lambda/latest/dg/services-apigateway.html \nhttps://aws.amazon.com/lambda/faqs/ \nAWS Lambda FAQs \nhttps://aws.amazon.com/lambda/faqs/", "answer_choice": "B"}, "380": {"q_num": 380, "question": "회사에서 온프레미스 워크로드를 AWS 클라우드로 마이그레이션하고 있습니다. 이 회사는 \n이미 여러 Amazon EC2 인스턴스와 Amazon RDS DB 인스턴스를 사용하고 있습니다. \n회사는 업무 시간 외에 EC2 인스턴스와 DB 인스턴스를 자동으로 시작하고 중지하는 \n솔루션을 원합니다. 솔루션은 비용 및 인프라 유지 관리를 최소화해야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 탄력적 크기 조정을 사용하여 EC2 인스턴스를 확장합니다. 업무 시간 외에는 DB \n인스턴스를 0 으로 조정합니다. \nB. 일정에 따라 EC2 인스턴스와 DB 인스턴스를 자동으로 시작 및 중지하는 파트너 \n\n솔루션에 대한 AWS Marketplace 를 살펴보십시오. \nC. 다른 EC2 인스턴스를 시작합니다. 일정에 따라 기존 EC2 인스턴스와 DB 인스턴스를 \n시작 및 중지하는 셸 스크립트를 실행하도록 crontab 일정을 구성합니다. \nD. EC2 인스턴스와 DB 인스턴스를 시작하고 중지할 AWS Lambda 함수를 생성합니다. \n일정에 따라 Lambda 함수를 호출하도록 Amazon EventBridge 를 구성합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/102145-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n비용 및 인프라 유지 관리를 최소화하면서 일정에 따라 EC2 인스턴스 및 DB 인스턴스를 \n자동으로 시작 및 중지하는 가장 효율적인 솔루션은 AWS Lambda 함수를 생성하고 일정에 \n따라 함수를 호출하도록 Amazon EventBridge 를 구성하는 것입니다. \n옵션 A, 탄력적 크기 조정을 사용하여 EC2 인스턴스를 확장하고 업무 시간 외에 DB \n인스턴스를 0 으로 확장하는 것은 DB 인스턴스를 0 으로 확장할 수 없기 때문에 실행 \n불가능합니다. \n파트너 솔루션에 대한 AWS Marketplace 를 탐색하는 옵션 B 가 옵션일 수 있지만 가장 \n효율적인 솔루션이 아닐 수 있으며 잠재적으로 추가 비용이 추가될 수 있습니다. \n다른 EC2 인스턴스를 시작하고 일정에 따라 기존 EC2 인스턴스 및 DB 인스턴스를 시작 \n및 중지하는 셸 스크립트를 실행하도록 crontab 일정을 구성하는 옵션 C 는 불필요한 \n인프라 및 유지 관리를 추가합니다.", "answer_choice": "D"}, "381": {"q_num": 381, "question": "회사에서 PostgreSQL 데이터베이스를 포함하는 3 계층 웹 애플리케이션을 호스팅합니다. \n데이터베이스는 문서의 메타데이터를 저장합니다. 회사는 매달 보고서에서 회사가 검토하는 \n문서를 검색하기 위해 핵심 용어에 대한 메타데이터를 검색합니다. 문서는 Amazon S3 에 \n저장됩니다. 문서는 일반적으로 한 번만 작성되지만 자주 업데이트됩니다. \n보고 프로세스는 관계형 쿼리를 사용하여 몇 시간이 걸립니다. 보고 프로세스는 문서 수정 \n또는 새 문서 추가를 방해해서는 안 됩니다. 솔루션 설계자는 보고 프로세스의 속도를 \n높이는 솔루션을 구현해야 합니다. \n애플리케이션 코드를 최소한으로 변경하여 이러한 요구 사항을 충족하는 솔루션은 \n무엇입니까? \nA. 읽기 전용 복제본이 포함된 새로운 Amazon DocumentDB(MongoDB 호환) 클러스터를 \n설정합니다. 읽기 복제본을 확장하여 보고서를 생성합니다. \nB. Aurora 복제본이 포함된 새로운 Amazon Aurora PostgreSQL DB 클러스터를 설정합니다. \n\nAurora 복제본에 쿼리를 실행하여 보고서를 생성합니다. \nC. PostgreSQL 다중 AZ DB 인스턴스용 새 Amazon RDS 를 설정합니다. 보고 모듈이 기본 \n노드에 영향을 주지 않도록 보조 RDS 노드를 쿼리하도록 보고 모듈을 구성합니다. \nD. 문서를 저장할 새 Amazon DynamoDB 테이블을 설정합니다. 새 문서 항목을 \n지원하려면 고정된 쓰기 용량을 사용하십시오. 보고서를 지원하기 위해 읽기 용량을 \n자동으로 확장합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/102147-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "382": {"q_num": 382, "question": "회사는 AWS 에 사용자 장치에서 센서 데이터를 수집하는 3 계층 애플리케이션을 보유하고 \n있습니다. 트래픽은 NLB(Network Load Balancer)를 거쳐 웹 계층용 Amazon EC2 \n인스턴스로 이동한 다음 마지막으로 애플리케이션 계층용 EC2 인스턴스로 이동합니다. \n애플리케이션 계층은 데이터베이스를 호출합니다. \n솔루션 설계자는 전송 중인 데이터의 보안을 개선하기 위해 무엇을 해야 합니까? \nA. TLS 수신기를 구성합니다. NLB 에 서버 인증서를 배포합니다. \nB. AWS Shield Advanced 를 구성합니다. NLB 에서 AWS WAF 를 활성화합니다. \nC. 로드 밸런서를 Application Load Balancer(ALB)로 변경합니다. ALB 에서 AWS WAF 를 \n활성화합니다. \nD. AWS Key Management Service(AWS KMS)를 사용하여 EC2 인스턴스에서 Amazon \nElastic Block Store(Amazon EBS) 볼륨을 암호화합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/102149-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명1: \n전송 중인 데이터의 보안을 개선하는 가장 좋은 옵션은 TLS 수신기를 구성하고 NLB 에 \n서버 인증서를 배포하는 것입니다. 이렇게 하면 데이터가 네트워크를 통해 이동할 때 \n암호화되고 안전해집니다. 또한 AWS Shield Advanced 를 구성하고 NLB 에서 AWS WAF 를 \n활성화하여 악의적인 공격으로부터 네트워크를 추가로 보호할 수도 있습니다. 또는 로드 \n밸런서를 Application Load Balancer(ALB)로 변경하고 ALB 에서 AWS WAF 를 활성화할 수도 \n있습니다. \n마지막으로 AWS Key Management Service(AWS KMS)를 사용하여 EC2 인스턴스에서 \nAmazon Elastic Block Store(Amazon EBS) 볼륨을 암호화할 수도 있습니다. \n\nTLS 수신기에 대한 SSL 인증서를 지정해야 합니다. 로드 밸런서는 인증서를 사용하여 \n연결을 종료하고 대상으로 라우팅하기 전에 클라이언트의 요청을 해독합니다. \nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/network/create-listener.html \n \n설명2: \nA: 전송 중인 데이터를 어떻게 보호합니까? \n모범 사례: \n보안 키 및 인증서 관리 구현: 암호화 키 및 인증서를 안전하게 저장하고 엄격한 액세스 \n제어를 적용하면서 적절한 시간 간격으로 교체합니다. 예를 들어 AWS Certificate \nManager(ACM)와 같은 인증서 관리 서비스를 사용합니다. \n전송 중 암호화 적용: 조직, 법률 및 규정 준수 요구 사항을 충족하는 데 도움이 되는 \n적절한 표준 및 권장 사항에 따라 정의된 암호화 요구 사항을 적용합니다. \n의도하지 않은 데이터 액세스 탐지 자동화: GuardDuty 와 같은 도구를 사용하여 데이터 \n분류 수준에 따라 정의된 경계 외부로 데이터를 이동하려는 시도를 자동으로 탐지합니다. \n예를 들어 DNS 프로토콜을 사용하여 알 수 없거나 신뢰할 수 없는 네트워크에 데이터를 \n복사하는 트로이 목마를 탐지합니다. . \n네트워크 통신 인증: TLS(전송 계층 보안) 또는 IPsec 과 같은 인증을 지원하는 프로토콜을 \n사용하여 통신 ID 를 확인합니다. \nhttps://wa.aws.amazon.com/wat.question.SEC_9.en.html", "answer_choice": "A"}, "383": {"q_num": 383, "question": "한 회사가 온프레미스 데이터 센터에서 AWS 로 상용 기성 애플리케이션을 마이그레이션할 \n계획입니다. 이 소프트웨어에는 용량 및 가동 시간 요구 사항을 예측할 수 있는 소켓과 \n코어를 사용하는 소프트웨어 라이센스 모델이 있습니다. 회사는 올해 초에 구입한 기존 \n라이센스를 사용하려고 합니다. \n가장 비용 효율적인 Amazon EC2 요금 옵션은 무엇입니까? \nA. 전용 예약 호스트(Dedicated Reserved Hosts) \nB. 전용 온디맨드 호스트(Dedicated On-Demand Hosts) \nC. 전용 예약 인스턴스(Dedicated Reserved Instances) \nD. 전용 온디맨드 인스턴스(Dedicated On-Demand Instances)", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/102150-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n\nhttps://aws.amazon.com/ec2/dedicated-hosts/ \nAmazon EC2 전용 호스트를 사용하면 Amazon EC2 에서 Microsoft 및 Oracle 과 같은 \n공급업체의 적격 소프트웨어 라이선스를 사용할 수 있으므로 자체 라이선스 사용의 \n유연성과 비용 효율성을 얻으면서도 AWS 의 탄력성, 단순성 및 탄력성을 얻을 수 있습니다.", "answer_choice": "A"}, "384": {"q_num": 384, "question": "회사는 여러 가용 영역에 걸쳐 Amazon EC2 Linux 인스턴스에서 애플리케이션을 \n실행합니다. 애플리케이션에는 고가용성 및 POSIX(Portable Operating System Interface) \n호환 스토리지 계층이 필요합니다. 스토리지 계층은 최대 데이터 내구성을 제공해야 하며 \nEC2 인스턴스 간에 공유 가능해야 합니다. 저장소 계층의 데이터는 처음 30 일 동안 자주 \n액세스되고 그 이후에는 드물게 액세스됩니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. Amazon S3 Standard 스토리지 클래스를 사용하십시오. S3 수명 주기 정책을 생성하여 \n자주 액세스하지 않는 데이터를 S3 Glacier 로 이동합니다. \nB. Amazon S3 Standard 스토리지 클래스를 사용합니다. S3 수명 주기 정책을 생성하여 \n자주 액세스하지 않는 데이터를 S3 Standard-Infrequent Access(S3 Standard-IA)로 \n이동합니다. \nC. Amazon Elastic File System(Amazon EFS) Standard 스토리지 클래스를 사용합니다. 자주 \n액세스하지 않는 데이터를 EFS Standard-Infrequent Access(EFS Standard-IA)로 이동하는 \n수명 주기 관리 정책을 만듭니다. \nD. Amazon Elastic File System(Amazon EFS) One Zone 스토리지 클래스를 사용합니다. \n자주 액세스하지 않는 데이터를 EFS One Zone-Infrequent Access(EFS One Zone-IA)로 \n이동하는 수명 주기 관리 정책을 만듭니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/102152-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n참고: \nhttps://aws.amazon.com/efs/features/infrequent-access/", "answer_choice": "C"}, "385": {"q_num": 385, "question": "솔루션 아키텍트가 새로운 VPC 디자인을 만들고 있습니다. 로드 밸런서용 퍼블릭 서브넷 \n2 개, 웹 서버용 프라이빗 서브넷 2 개, MySQL 용 프라이빗 서브넷 2 개가 있습니다. 웹 \n서버는 HTTPS 만 사용합니다. 솔루션 설계자는 이미 0.0.0.0/0 에서 포트 443 을 허용하는 \n\n로드 밸런서용 보안 그룹을 생성했습니다. 회사 정책에서는 각 리소스가 작업을 수행하는 \n데 필요한 최소한의 액세스 권한을 갖도록 요구합니다. \n이러한 요구 사항을 충족하기 위해 솔루션 설계자가 사용해야 하는 추가 구성 전략은 \n무엇입니까? \nA. 웹 서버용 보안 그룹을 생성하고 0.0.0.0/0 에서 포트 443 을 허용합니다. MySQL 서버용 \n보안 그룹을 만들고 웹 서버 보안 그룹에서 포트 3306 을 허용합니다. \nB. 웹 서버용 네트워크 ACL 을 생성하고 0.0.0.0/0 에서 포트 443 을 허용합니다. MySQL \n서버용 네트워크 ACL 을 생성하고 웹 서버 보안 그룹에서 포트 3306 을 허용합니다. \nC. 웹 서버용 보안 그룹을 만들고 로드 밸런서에서 포트 443 을 허용합니다. MySQL 서버용 \n보안 그룹을 만들고 웹 서버 보안 그룹에서 포트 3306 을 허용합니다. \nD. 웹 서버에 대한 네트워크 ACL 을 생성하고 로드 밸런서에서 포트 443 을 허용합니다. \nMySQL 서버용 네트워크 ACL\n을 생성하고 웹 서버 보안 그룹에서 포트 3306\n을 \n허용합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/102153-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n이 답변은 Windows IIS 웹 서버와 호환되는 온-프레미스 파일 공유에 대한 탄력적이고 \n내구성 있는 대체를 제공하기 때문에 정확합니다. Amazon FSx for Windows File Server 는 \nWindows Server 에 구축된 공유 파일 스토리지를 제공하는 완전관리형 서비스입니다. SMB \n프로토콜을 지원하고 Windows 기반 애플리케이션에 대한 원활한 액세스 및 인증을 \n가능하게 하는 Microsoft Active Directory 와 통합됩니다. Amazon FSx for Windows File \nServer 는 또한 다음과 같은 이점을 제공합니다. \n복원력: Amazon FSx for Windows File Server 는 고가용성 및 장애 조치 보호를 제공하는 \n여러 가용 영역에 배포할 수 있습니다. 또한 자동 백업 및 복원은 물론 문제를 감지하고 \n수정하는 자가 치유 기능을 지원합니다. \n내구성: Windows File Server 용 Amazon FSx 는 가용 영역 내외에서 데이터를 복제하고 \n내구성이 뛰어난 스토리지 장치에 데이터를 저장합니다. 또한 유휴 및 전송 중 암호화는 \n물론 파일 액세스 감사 및 데이터 중복 제거를 지원합니다. \n성능: Windows File Server 용 Amazon FSx 는 파일 작업을 위한 일관된 1 밀리초 미만의 \n지연 시간과 높은 처리량을 제공합니다. 또한 SSD 스토리지, 분산 파일 시스템(DFS) \n네임스페이스 및 복제와 같은 기본 Windows 기능, 사용자 중심 성능 확장을 지원합니다. \nAWS KMS CMK 를 사용하여 파일 공유의 이미지를 암호화하도록 Amazon FSx 파일 공유를 \n구성함으로써 회사는 무단 액세스로부터 이미지를 보호하고 회사 정책을 준수할 수 \n있습니다. 이미지에 대한 NTFS 권한 집합을 사용하여 회사는 이미지를 수정하거나 삭제할 \n\n수 있는 사람을 제한하여 실수로 이미지를 삭제하는 것을 방지할 수 있습니다.", "answer_choice": "C"}, "386": {"q_num": 386, "question": "전자상거래 회사는 AWS 에서 다중 계층 애플리케이션을 실행하고 있습니다. 프런트 엔드 \n및 백엔드 계층은 모두 Amazon EC2 에서 실행되고 데이터베이스는 Amazon RDS for \nMySQL\n에서 실행됩니다. 백엔드 계층은 RDS 인스턴스와 통신합니다. 성능 저하를 \n일으키는 데이터베이스에서 동일한 데이터 세트를 반환하라는 호출이 자주 있습니다. \n백엔드의 성능을 개선하려면 어떤 조치를 취해야 합니까? \nA. Amazon SNS 를 구현하여 데이터베이스 호출을 저장합니다. \nB. Amazon ElastiCache 를 구현하여 대규모 데이터 세트를 캐싱합니다. \nC. 데이터베이스 호출을 캐시하기 위해 RDS for MySQL 읽기 전용 복제본을 구현합니다. \nD. Amazon Kinesis Data Firehose 를 구현하여 호출을 데이터베이스로 스트리밍합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/102154-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n가장 좋은 솔루션은 Amazon ElastiCache 를 구현하여 대용량 데이터 세트를 캐시하는 \n것입니다. 이렇게 하면 자주 액세스하는 데이터를 메모리에 저장하여 검색 시간을 단축할 \n수 있습니다. 이는 데이터베이스에 대한 빈번한 호출을 완화하고 대기 시간을 줄이며 \n백엔드 계층의 전반적인 성능을 향상시키는 데 도움이 될 수 있습니다.", "answer_choice": "B"}, "387": {"q_num": 387, "question": "신입 사원이 배포 엔지니어로 회사에 합류했습니다. 배포 엔지니어는 AWS CloudFormation \n템플릿을 사용하여 여러 AWS 리소스를 생성합니다. 솔루션 설계자는 배포 엔지니어가 최소 \n권한 원칙에 따라 작업 활동을 수행하기를 원합니다. \n이 목표를 달성하기 위해 솔루션 설계자가 취해야 하는 작업 조합은 무엇입니까? (2 개 \n선택) \nA. 배포 엔지니어가 AWS CloudFormation 스택 작업을 수행하기 위해 AWS 계정 루트 \n사용자 자격 증명을 사용하도록 합니다. \nB. 배포 엔지니어를 위한 새 IAM 사용자를 생성하고 PowerUsers IAM 정책이 연결된 \n그룹에 IAM 사용자를 추가합니다. \nC. 배포 엔지니어를 위한 새 IAM 사용자를 생성하고 AdministratorAccess IAM 정책이 \n연결된 그룹에 IAM 사용자를 추가합니다. \n\nD. 배포 엔지니어를 위한 새 IAM 사용자를 생성하고 AWS CloudFormation 작업만 \n허용하는 IAM 정책이 있는 그룹에 IAM 사용자를 추가합니다. \nE. 배포 엔지니어를 위한 IAM 역할을 생성하여 해당 IAM 역할을 사용하여 AWS \nCloudFormation 스택 및 시작 스택에 특정한 권한을 명시적으로 정의합니다.", "answer_block": "Answer: D, E \nhttps://www.examtopics.com/discussions/amazon/view/102155-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n배포 엔지니어가 CloudFormation 을 사용하여 필요한 작업을 전부 해결할 수 있으므로 \n관련 작업만 허용해주면 최소 권한의 원칙이 충족됨. \nA(X) : 루트 사용자 자격 증명으로 최소 권한의 원칙에 어긋나서 제외. \nB(X) : PowerUsers 는 PowerUser 사용자 그룹의 멤버는 사용자 관리 작업(예: IAM 및 \nOrganizations)을 제공하는 일부 서비스를 제외한 모든 서비스에 대해 전체 권한을 갖 \n으므로 최소 권한의 원칙에 어긋나서 제외 \nhttps://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/getting-started_create-delega\nted-user.html \nC(X) : 관리/액세스 권한을 굳이 줄 필요없음. CloudFormation 관련 권한만 부여하면 됨. \nD(O) : CloudFormation 작업만 허용하도록 하여 최소 권한 부여 조건 충족. \nE(O) : D 와 마찬가지 이유로 정답. \n \n참고: \nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html \nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/id_users.html", "answer_choice": "D"}, "388": {"q_num": 388, "question": "회사에서 VPC 에 2 계층 웹 애플리케이션을 배포하고 있습니다. 웹 계층은 여러 가용 \n영역에 걸쳐 있는 퍼블릭 서브넷이 있는 Amazon EC2 Auto Scaling 그룹을 사용하고 \n있습니다. 데이터베이스 계층은 별도의 프라이빗 서브넷에 있는 MySQL DB 인스턴스용 \nAmazon RDS\n로 구성됩니다. 웹 계층은 제품 정보를 검색하기 위해 데이터베이스에 \n액세스해야 합니다. \n웹 응용 프로그램이 의도한 대로 작동하지 않습니다. 웹 애플리케이션에서 데이터베이스에 \n연결할 수 없다고 보고합니다. 데이터베이스가 가동 및 실행 중인 것으로 확인되었습니다. \n네트워크 ACL, 보안 그룹 및 라우팅 테이블에 대한 모든 구성은 여전히 기본 상태입니다. \n애플리케이션 수정을 위해 솔루션 아키텍트는 무엇을 추천해야 합니까? \n\nA. 프라이빗 서브넷의 네트워크 ACL\n에 명시적 규칙을 추가하여 웹 티어의 EC2 \n인스턴스에서 오는 트래픽을 허용합니다. \nB. 웹 계층의 EC2 인스턴스와 데이터베이스 계층 간의 트래픽을 허용하도록 VPC 경로 \n테이블에 경로를 추가합니다. \nC. 웹 계층의 EC2 인스턴스와 데이터베이스 계층의 RDS 인스턴스를 두 개의 개별 VPC 에 \n배포하고 VPC 피어링을 구성합니다. \nD. 데이터베이스 계층 RDS 인스턴스의 보안 그룹에 인바운드 규칙을 추가하여 웹 계층 \n보안 그룹의 트래픽을 허용합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/102156-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n이 대답은 웹 계층이 보안 그룹을 소스로 사용하여 데이터베이스 계층에 액세스할 수 \n있도록 허용하기 때문에 정확합니다. 이는 VPC 연결에 권장되는 모범 사례입니다. 보안 \n그룹은 상태 저장이며 동일한 VPC 에 있는 다른 보안 그룹을 참조할 수 있으므로 방화벽 \n규칙의 구성 및 유지 관리가 간소화됩니다. 데이터베이스 계층의 보안 그룹에 인바운드 \n규칙을 추가하면 웹 계층의 EC2 인스턴스가 IP 주소나 서브넷에 관계없이 포트 3306 에서 \nRDS 인스턴스에 연결할 수 있습니다.", "answer_choice": "D"}, "389": {"q_num": 389, "question": "회사는 단일 가용 영역의 Amazon RDS for MySQL DB 인스턴스에 저장된 온라인 광고 \n비즈니스용 대규모 데이터 세트를 보유하고 있습니다. 회사는 프로덕션 DB 인스턴스에 \n대한 쓰기 작업에 영향을 주지 않고 비즈니스 보고 쿼리를 실행하기를 원합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. RDS 읽기 복제본을 배포하여 비즈니스 보고 쿼리를 처리합니다. \nB. DB 인스턴스를 Elastic Load Balancer 뒤에 배치하여 수평으로 확장합니다. \nC. DB 인스턴스를 더 큰 인스턴스 유형으로 확장하여 쓰기 작업 및 쿼리를 처리합니다. \nD. 비즈니스 보고 쿼리를 처리하기 위해 여러 가용 영역에 DB 인스턴스를 배포합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/102157-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n읽기 전용 복제본 사용 사례 - 일반 로드를 수행하는 프로덕션 데이터베이스가 있고 일부 \n\n분석을 실행하기 위해 보고 애플리케이션을 실행하려고 합니다. * 읽기 전용 복제본을 \n생성하여 그곳에서 새 워크로드를 실행합니다. * 프로덕션 애플리케이션은 영향을 받지 \n않습니다. SELECT(=읽기) 종류의 문에만 사용됨(INSERT, UPDATE, DELETE 아님)", "answer_choice": "A"}, "390": {"q_num": 390, "question": "회사는 Amazon EC2 인스턴스 플릿에서 3 계층 전자상거래 애플리케이션을 호스팅합니다. \n인스턴스는 Application Load Balancer(ALB) 뒤의 Auto Scaling 그룹에서 실행됩니다. 모든 \n전자상거래 데이터는 MariaDB 다중 AZ DB 인스턴스용 Amazon RDS 에 저장됩니다. \n회사는 트랜잭션 중에 고객 세션 관리를 최적화하려고 합니다. 애플리케이션은 세션 \n데이터를 지속적으로 저장해야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? (2 개 선택) \nA. ALB 에서 고정 세션 기능(세션 선호도)을 켭니다. \nB. Amazon DynamoDB 테이블을 사용하여 고객 세션 정보를 저장합니다. \nC. Amazon Cognito 사용자 풀을 배포하여 사용자 세션 정보를 관리합니다. \nD. Amazon ElastiCache for Redis 클러스터를 배포하여 고객 세션 정보를 저장합니다. \nE. 애플리케이션에서 AWS Systems Manager Application Manager 를 사용하여 사용자 세션 \n정보를 관리합니다.", "answer_block": "Answer: A, D \nhttps://www.examtopics.com/discussions/amazon/view/102213-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n참고: \nhttps://aws.amazon.com/caching/session-management/", "answer_choice": "A"}, "391": {"q_num": 391, "question": "회사는 3\n계층 상태 비저장 웹 애플리케이션을 위한 백업 전략이 필요합니다. 웹 \n애플리케이션은 조정 이벤트에 응답하도록 구성된 동적 조정 정책이 있는 Auto Scaling \n그룹의 Amazon EC2 인스턴스에서 실행됩니다. 데이터베이스 계층은 PostgreSQL\n용 \nAmazon RDS 에서 실행됩니다. 웹 애플리케이션은 EC2 인스턴스에 임시 로컬 스토리지가 \n필요하지 않습니다. 회사의 복구 지점 목표(RPO)는 2 시간입니다. \n백업 전략은 확장성을 최대화하고 이 환경에 대한 리소스 활용을 최적화해야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. RPO 를 충족하기 위해 2 시간마다 EC2 인스턴스 및 데이터베이스의 Amazon Elastic \nBlock Store(Amazon EBS) 볼륨의 스냅샷을 생성합니다. \n\nB. Amazon Elastic Block Store(Amazon EBS) 스냅샷을 생성하도록 스냅샷 수명 주기 \n정책을 구성합니다. RPO 를 충족하기 위해 Amazon RDS 에서 자동 백업을 활성화합니다. \nC. 웹 및 애플리케이션 계층의 최신 Amazon 머신 이미지(AMI)를 유지합니다. Amazon \nRDS 에서 자동 백업을 활성화하고 지정 시간 복구를 사용하여 RPO 를 충족합니다. \nD. 2 시간마다 EC2 인스턴스의 Amazon Elastic Block Store(Amazon EBS) 볼륨의 스냅샷을 \n생성합니다. Amazon RDS 에서 자동 백업을 활성화하고 지정 시간 복구를 사용하여 RPO 를 \n충족합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/102212-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n애플리케이션에는 인스턴스에 대한 로컬 데이터가 없으므로 AMI\n만으로는 최신 AMI \n백업에서 인스턴스를 복원하여 RPO 를 충족할 수 있습니다. 데이터베이스에 대한 자동화된 \nRDS 백업과 결합하면 이 환경에 대한 완벽한 백업 솔루션을 제공합니다. EBS 스냅샷과 \n관련된 다른 옵션은 인스턴스의 상태 비저장 특성을 고려할 때 불필요합니다. AMI 는 앱 \n계층에 필요한 모든 백업을 제공합니다. 이는 최소한의 지속적인 관리가 필요한 기본 자동 \nAWS 백업 기능을 사용합니다. - AMI 자동 백업은 상태 비저장 앱 계층에 대한 특정 시점 \n복구를 제공합니다. - RDS 자동 백업은 데이터베이스에 대한 특정 시점 복구를 제공합니다.", "answer_choice": "C"}, "392": {"q_num": 392, "question": "회사에서 AWS 에 새로운 퍼블릭 웹 애플리케이션을 배포하려고 합니다. 애플리케이션에는 \nAmazon \nEC2 \n인스턴스를 \n사용하는 \n웹 \n서버 \n계층이 \n포함되어 \n있습니다. \n이 \n애플리케이션에는 Amazon RDS for MySQL DB 인스턴스를 사용하는 데이터베이스 계층도 \n포함되어 있습니다. \n응용 프로그램은 동적 IP 주소가 있는 글로벌 고객이 안전하고 액세스할 수 있어야 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 보안 그룹을 어떻게 구성해야 합니까? \nA. 0.0.0.0/0 에서 포트 443 의 인바운드 트래픽을 허용하도록 웹 서버에 대한 보안 그룹을 \n구성합니다. 웹 서버의 보안 그룹에서 포트 3306 의 인바운드 트래픽을 허용하도록 DB \n인스턴스에 대한 보안 그룹을 구성합니다. \nB. 고객의 IP 주소에서 포트 443 의 인바운드 트래픽을 허용하도록 웹 서버에 대한 보안 \n그룹을 구성합니다. 웹 서버의 보안 그룹에서 포트 3306 의 인바운드 트래픽을 허용하도록 \nDB 인스턴스에 대한 보안 그룹을 구성합니다. \nC. 고객의 IP 주소에서 포트 443 의 인바운드 트래픽을 허용하도록 웹 서버에 대한 보안 \n그룹을 구성합니다. 고객의 IP 주소에서 포트 3306 의 인바운드 트래픽을 허용하도록 DB \n\n인스턴스에 대한 보안 그룹을 구성합니다. \nD. 0.0.0.0/0 에서 포트 443 의 인바운드 트래픽을 허용하도록 웹 서버에 대한 보안 그룹을 \n구성합니다. 0.0.0.0/0 에서 포트 3306 의 인바운드 트래픽을 허용하도록 DB 인스턴스에 \n대한 보안 그룹을 구성합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/102160-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명1: \nA(O) : S3 에 넣으면 Lambda 를 통해 자동으로 처리가 되도록 하는 거라 OK. S3 는 저렴함. \nB(X) : dynamodb 는 이미지 저장용으론… \nC(X) : 저렴한 S3 가 있는데 굳이... 인스턴스 비용도 나감. \nD(x) : C 와 마찬가지. \n \n설명2: \n웹 서버에 대한 인바운드 액세스를 HTTPS 트래픽에 사용되는 포트 443 으로만 제한하고 \n애플리케이션이 공개되어 글로벌 고객이 액세스할 수 있으므로 모든 IP 주소(0.0.0.0/0)에서 \n액세스를 허용합니다. \nDB 인스턴스에 대한 인바운드 액세스를 MySQL 트래픽에 사용되는 포트 3306 으로만 \n제한하고 웹 서버의 보안 그룹에서만 액세스를 허용하여 두 계층 간의 보안 연결을 \n생성하고 데이터베이스에 대한 무단 액세스를 방지합니다. \n아웃바운드 액세스를 두 계층에 필요한 최소 수준으로 제한합니다. 이는 질문에 지정되지 \n않았지만 인바운드 규칙과 유사하다고 가정할 수 있습니다.", "answer_choice": "A"}, "393": {"q_num": 393, "question": "결제 처리 회사는 고객과의 모든 음성 통신을 녹음하고 오디오 파일을 Amazon S3 버킷에 \n저장합니다. 회사는 오디오 파일에서 텍스트를 캡처해야 합니다. 회사는 텍스트에서 \n고객에게 속한 모든 개인 식별 정보(PII)를 제거해야 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. Amazon Kinesis Video Streams 를 사용하여 오디오 파일을 처리합니다. AWS Lambda \n함수를 사용하여 알려진 PII 패턴을 스캔합니다. \nB. 오디오 파일이 S3 버킷에 업로드되면 AWS Lambda 함수를 호출하여 Amazon Textract \n작업을 시작하여 통화 녹음을 분석합니다. \nC. PII 수정을 켠 상태로 Amazon Transcribe 전사 작업을 구성합니다. 오디오 파일이 S3 \n버킷에 업로드되면 AWS Lambda 함수를 호출하여 전사 작업을 시작합니다. 출력을 별도의 \n\nS3 버킷에 저장합니다. \nD. 트랜스크립션이 켜진 오디오 파일을 수집하는 Amazon Connect 고객 응대 흐름을 \n생성합니다. 알려진 PII 패턴을 스캔하기 위해 AWS Lambda 함수를 포함합니다. 오디오 \n파일이 S3 버킷에 업로드되면 Amazon EventBridge\n를 사용하여 고객 응대 흐름을 \n시작하십시오.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/102322-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n민감한 데이터 수정은 텍스트 스크립트와 오디오 파일의 개인 식별 가능 정보(PII)를 \n대체합니다. 수정된 내용은 원본 텍스트를 [PII]로 대체하고 수정된 오디오 파일은 음성 \n개인 정보를 침묵으로 대체합니다. 이 매개 변수는 고객 정보를 보호하는 데 유용합니다. \nhttps://docs.aws.amazon.com/transcribe/latest/dg/call-analytics-insights.html#callanalyt\nics-insights-redaction", "answer_choice": "C"}, "394": {"q_num": 394, "question": "회사는 AWS 클라우드에서 다중 계층 전자 상거래 웹 애플리케이션을 실행하고 있습니다. \n애플리케이션은 Amazon RDS for MySQL 다중 AZ DB 인스턴스와 함께 Amazon EC2 \n인스턴스에서 실행됩니다. Amazon RDS\n는 범용 SSD(gp3) Amazon Elastic Block \nStore(Amazon EBS) 볼륨에 2,000GB\n의 스토리지가 있는 최신 세대 DB 인스턴스로 \n구성됩니다. 데이터베이스 성능은 수요가 많은 기간 동안 애플리케이션에 영향을 미칩니다. \n데이터베이스 관리자는 Amazon CloudWatch Logs 의 로그를 분석하고 읽기 및 쓰기 IOPS \n수가 20,000 보다 높을 때 애플리케이션 성능이 항상 저하됨을 발견합니다. \n애플리케이션 성능을 향상시키기 위해 솔루션 설계자는 무엇을 해야 합니까? \nA. 볼륨을 마그네틱 볼륨으로 교체합니다. \nB. gp3 볼륨의 IOPS 수를 늘립니다. \nC. 프로비저닝된 IOPS SSD(io2) 볼륨으로 볼륨을 교체합니다. \nD. 2,000GB gp3 볼륨을 두 개의 1,000GB gp3 볼륨으로 교체합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/102161-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \nB??", "answer_choice": "D"}, "395": {"q_num": 395, "question": "IAM 사용자는 지난 주 프로덕션 배포 중에 회사 계정의 AWS 리소스에 대해 몇 가지 \n구성을 변경했습니다. 솔루션 설계자는 몇 가지 보안 그룹 규칙이 원하는 대로 구성되지 \n않았음을 알게 되었습니다. 솔루션 설계자는 어떤 IAM 사용자가 변경을 담당했는지 \n확인하려고 합니다. \n솔루션 설계자는 원하는 정보를 찾기 위해 어떤 서비스를 사용해야 합니까? \nA. Amazon GuardDuty \nB. 아마존 인스펙터 \nC. AWS 클라우드트레일 \nD. AWS 구성", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/102162-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n가장 좋은 방법은 AWS CloudTrail\n을 사용하여 원하는 정보를 찾는 것입니다. AWS \nCloudTrail 은 AWS 계정 활동의 거버넌스, 규정 준수, 운영 감사 및 위험 감사를 지원하는 \n서비스입니다. CloudTrail 은 IAM 사용자, EC2 인스턴스, AWS 관리 콘솔 및 기타 AWS \n서비스에 의한 변경 사항을 포함하여 AWS 계정의 리소스에 대한 모든 변경 사항을 \n기록하는 데 사용할 수 있습니다. 솔루션 설계자는 CloudTrail 을 사용하여 보안 그룹 \n규칙의 구성을 변경한 IAM 사용자를 식별할 수 있습니다.", "answer_choice": "C"}, "396": {"q_num": 396, "question": "한 회사가 AWS\n에서 자체 관리형 DNS 서비스를 구현했습니다. 솔루션은 다음으로 \n구성됩니다. \n• 다른 AWS 지역의 Amazon EC2 인스턴스 \n• AWS Global Accelerator 의 표준 가속기 엔드포인트 \n회사는 DDoS 공격으로부터 솔루션을 보호하려고 합니다. \n솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. AWS Shield Advanced 에 가입하십시오. 보호할 리소스로 액셀러레이터를 추가합니다. \nB. AWS Shield Advanced 에 가입합니다. 보호할 리소스로 EC2 인스턴스를 추가합니다. \nC. 속도 기반 규칙을 포함하는 AWS WAF 웹 ACL 을 생성합니다. 웹 ACL 을 가속기와 \n연결합니다. \nD. 비율 기반 규칙을 포함하는 AWS WAF 웹 ACL 을 생성합니다. 웹 ACL 을 EC2 \n인스턴스와 연결합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/102164-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nAWS Shield 는 AWS 에서 실행되는 애플리케이션에 대한 DDoS(Distributed Denial of Service) \n공격으로부터 보호하는 관리형 서비스입니다. AWS Shield Standard 는 추가 비용 없이 모든 \nAWS 고객에게 자동으로 활성화됩니다. AWS Shield Advanced 는 선택적 유료 서비스입니다. \nAWS Shield Advanced\n는 Amazon Elastic Compute Cloud(EC2), Elastic Load \nBalancing(ELB), Amazon CloudFront, AWS Global Accelerator 및 Route 53 에서 실행되는 \n애플리케이션에 대해 더 정교하고 더 큰 공격에 대한 추가 보호 기능을 제공합니다. \nhttps://docs.aws.amazon.com/waf/latest/developerguide/ddos-event-mitigation-logic-g\nax.html", "answer_choice": "A"}, "397": {"q_num": 397, "question": "전자상거래 회사는 분석을 위해 판매 기록을 집계하고 필터링하기 위해 예약된 일일 작업을 \n실행해야 합니다. 회사는 판매 기록을 Amazon S3 버킷에 저장합니다. 각 개체의 크기는 \n최대 10GB 입니다. 판매 이벤트 수에 따라 작업을 완료하는 데 최대 1 시간이 걸릴 수 \n있습니다. 작업의 CPU 및 메모리 사용량은 일정하며 미리 알려져 있습니다. \n솔루션 설계자는 작업을 실행하는 데 필요한 운영 노력을 최소화해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. Amazon EventBridge 알림이 있는 AWS Lambda 함수를 생성합니다. EventBridge \n이벤트가 하루에 한 번 실행되도록 예약합니다. \nB. AWS Lambda 함수를 생성합니다. Amazon API Gateway HTTP API 를 생성하고 API 를 \n함수와 통합합니다. API 를 호출하고 함수를 호출하는 Amazon EventBridge 예약 이벤트를 \n생성합니다. \nC. AWS Fargate 시작 유형으로 Amazon Elastic Container Service(Amazon ECS) 클러스터를 \n생성합니다. \n작업을 \n실행하기 \n위해 \n클러스터에서 \nECS \n작업을 \n시작하는 \nAmazon \nEventBridge 예약 이벤트를 생성합니다. \nD. Amazon EC2 시작 유형이 있는 Amazon Elastic Container Service(Amazon ECS) \n클러스터와 하나 이상의 EC2 인스턴스가 있는 Auto Scaling 그룹을 생성합니다. 작업을 \n실행하기 위해 클러스터에서 ECS 작업을 시작하는 Amazon EventBridge 예약 이벤트를 \n생성합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/102165-exam-aws-certified-sol\n\nutions-architect-associate-saa-c03/ \n \n설명: \n최소한의 운영 오버헤드로 요구 사항을 충족하는 솔루션은 속도 기반 규칙을 사용하여 리전 \nAWS WAF 웹 ACL 을 생성하고 웹 ACL 을 API 게이트웨이 단계와 연결하는 것입니다. 이 \n솔루션은 들어오는 요청을 모니터링하고 사전 정의된 속도를 초과하는 IP 주소의 요청을 \n차단하여 HTTP 플러드 공격으로부터 애플리케이션을 보호합니다. API Gateway 지역 API \n엔드포인트 앞에 Lambda@Edge 가 있는 Amazon CloudFront 배포도 좋은 솔루션이지만 \n이전 솔루션보다 더 많은 운영 오버헤드가 필요합니다. Amazon CloudWatch 지표를 \n사용하여 개수 지표를 모니터링하고 미리 정의된 속도에 도달했을 때 보안 팀에 알리는 \n것은 HTTP 플러드 공격으로부터 보호할 수 있는 솔루션이 아닙니다. 최대 TTL이 24시간인 \nAPI Gateway 지역 API 엔드포인트 앞에 Amazon CloudFront 배포를 생성하는 것은 HTTP \n플러드 공격으로부터 보호할 수 있는 솔루션이 아닙니다.", "answer_choice": "C"}, "398": {"q_num": 398, "question": "회사는 온프레미스 NAS(Network-Attached Storage) 시스템에서 AWS 클라우드로 600TB 의 \n데이터를 전송해야 합니다. 데이터 전송은 2\n주 이내에 완료되어야 합니다. 데이터는 \n민감하며 전송 중에 암호화되어야 합니다. 회사의 인터넷 연결은 100Mbps\n의 업로드 \n속도를 지원할 수 있습니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. Amazon S3 멀티파트 업로드 기능을 사용하여 HTTPS 를 통해 파일을 전송합니다. \nB. 온프레미스 NAS 시스템과 가장 가까운 AWS 리전 간에 VPN 연결을 생성합니다. VPN \n연결을 통해 데이터를 전송합니다. \nC. AWS Snow Family 콘솔을 사용하여 여러 AWS Snowball Edge Storage Optimized \n디바이스를 주문합니다. 디바이스를 사용하여 데이터를 Amazon S3 로 전송합니다. \nD. 회사 위치와 가장 가까운 AWS 리전 간에 10Gbps AWS Direct Connect 연결을 \n설정합니다. VPN 연결을 통해 데이터를 리전으로 전송하여 Amazon S3\n에 데이터를 \n저장합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/102166-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n가장 좋은 방법은 AWS Snow Family 콘솔을 사용하여 여러 AWS Snowball Edge Storage \nOptimized 디바이스를 주문하고 디바이스를 사용하여 데이터를 Amazon S3 로 전송하는 \n\n것입니다. Snowball Edge\n는 많은 양의 데이터를 안전하고 빠르게 전송할 수 있는 \n페타바이트 규모의 데이터 전송 디바이스입니다. \nSnowball Edge 를 사용하면 장거리에서 대량의 데이터를 전송하는 가장 비용 효율적인 \n솔루션이 될 수 있으며 2 주 이내에 600TB 의 데이터를 전송해야 하는 요구 사항을 충족할 \n수 있습니다.", "answer_choice": "C"}, "399": {"q_num": 399, "question": "금융 회사는 AWS 에서 웹 애플리케이션을 호스팅합니다. 이 애플리케이션은 Amazon API \nGateway 지역 API 엔드포인트를 사용하여 사용자에게 현재 주가를 검색할 수 있는 기능을 \n제공합니다. 회사의 보안 팀은 API 요청 수가 증가한 것을 확인했습니다. 보안 팀은 HTTP \n플러드 공격이 애플리케이션을 오프라인 상태로 만들 수 있다고 우려하고 있습니다. \n솔루션 설계자는 이러한 유형의 공격으로부터 애플리케이션을 보호하기 위한 솔루션을 \n설계해야 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 최대 TTL 이 24 시간인 API Gateway 지역 API 엔드포인트 앞에 Amazon CloudFront \n배포를 생성합니다. \nB. 속도 기반 규칙을 사용하여 리전 AWS WAF 웹 ACL 을 생성합니다. 웹 ACL 을 API \nGateway 단계와 연결합니다. \nC. Amazon CloudWatch 지표를 사용하여 개수 지표를 모니터링하고 미리 정의된 속도에 \n도달하면 보안 팀에 알립니다. \nD. API Gateway 지역 API 엔드포인트 앞에 Lambda@Edge\n를 사용하여 Amazon \nCloudFront 배포를 생성합니다. 사전 정의된 속도를 초과하는 IP 주소의 요청을 차단하는 \nAWS Lambda 함수를 생성합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/102167-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nAWS WAF 의 속도 기반 규칙을 사용하면 보안 팀이 속도 기반 규칙을 트리거하는 임계값을 \n구성할 수 있습니다. 이를 통해 AWS WAF 는 지정된 기간 동안 요청 속도를 추적한 다음 \n임계값이 초과되면 자동으로 차단할 수 있습니다. 이는 최소한의 운영 오버헤드로 HTTP \n플러드 공격을 방지하는 기능을 제공합니다. \n \n참조: \nhttps://docs.aws.amazon.com/waf/latest/developerguide/web-acl.html", "answer_choice": "B"}, "400": {"q_num": 400, "question": "기상 스타트업 회사는 사용자에게 날씨 데이터를 온라인으로 판매하는 맞춤형 웹 \n애플리케이션을 보유하고 있습니다. 이 회사는 Amazon DynamoDB 를 사용하여 데이터를 \n저장하고 새로운 날씨 이벤트가 기록될 때마다 4 개의 내부 팀 관리자에게 경고를 보내는 \n새로운 서비스를 구축하려고 합니다. 회사는 이 새로운 서비스가 현재 애플리케이션의 \n성능에 영향을 미치는 것을 원하지 않습니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하려면 솔루션 설계자가 무엇을 해야 \n합니까? \nA. DynamoDB 트랜잭션을 사용하여 새 이벤트 데이터를 테이블에 씁니다. 내부 팀에 \n알리도록 트랜잭션을 구성합니다. \nB. 현재 애플리케이션이 4 개의 Amazon Simple Notification Service(Amazon SNS) 주제에 \n메시지를 게시하도록 합니다. 각 팀이 하나의 주제를 구독하도록 합니다. \nC. 테이블에서 Amazon DynamoDB 스트림을 활성화합니다. 트리거를 사용하여 팀이 \n구독할 수 있는 단일 Amazon Simple Notification Service(Amazon SNS) 주제에 씁니다. \nD. 각 레코드에 사용자 정의 속성을 추가하여 새 항목에 플래그를 지정합니다. 새 항목이 \n있는지 \n매분 \n테이블을 \n스캔하고 \n팀이 \n구독할 \n수 \n있는 \nAmazon \nSimple \nQueue \nService(Amazon SQS) 대기열에 알리는 cron 작업을 작성합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/102169-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 최상의 솔루션은 테이블에서 \nAmazon DynamoDB 스트림을 활성화하고 트리거를 사용하여 팀이 구독할 수 있는 단일 \nAmazon Simple Notification Service(Amazon SNS) 주제에 쓰는 것입니다. 이 솔루션에는 \n최소한의 구성 및 인프라 설정이 필요하며 Amazon DynamoDB Streams 는 DynamoDB \n테이블에 대한 변경 사항을 캡처하는 지연 시간이 짧은 방법을 제공합니다. 트리거는 \n자동으로 변경 사항을 캡처하고 이를 내부 팀에 알리는 SNS 주제에 게시합니다.", "answer_choice": "C"}, "401": {"q_num": 401, "question": "회사는 AWS 클라우드를 사용하여 기존 애플리케이션의 가용성과 탄력성을 높이려고 \n합니다. 애플리케이션의 현재 버전은 회사의 데이터 센터에 상주합니다. 예기치 않은 \n정전으로 인해 데이터베이스 서버가 충돌한 후 애플리케이션에서 최근 데이터 손실이 \n\n발생했습니다. \n회사는 단일 실패 지점을 방지하는 솔루션이 필요합니다. 솔루션은 애플리케이션에 사용자 \n요구에 맞게 확장할 수 있는 기능을 제공해야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 여러 가용 영역의 Auto Scaling 그룹에서 Amazon EC2 인스턴스를 사용하여 \n애플리케이션 서버를 배포합니다. 다중 AZ 구성에서 Amazon RDS DB 인스턴스를 \n사용합니다. \nB. 단일 가용 영역의 Auto Scaling 그룹에서 Amazon EC2 인스턴스를 사용하여 \n애플리케이션 서버를 배포합니다. EC2 인스턴스에 데이터베이스를 배포합니다. EC2 자동 \n복구를 활성화합니다. \nC. 여러 가용 영역의 Auto Scaling 그룹에서 Amazon EC2 인스턴스를 사용하여 \n애플리케이션 서버를 배포합니다. 단일 가용 영역에서 읽기 전용 복제본이 있는 Amazon \nRDS DB 인스턴스를 사용합니다. 기본 DB 인스턴스가 실패할 경우 읽기 전용 복제본을 \n승격하여 기본 DB 인스턴스를 교체하십시오. \nD. 여러 가용 영역의 Auto Scaling 그룹에서 Amazon EC2 인스턴스를 사용하여 \n애플리케이션 서버를 배포합니다. 여러 가용 영역에 걸쳐 EC2 인스턴스에 기본 및 보조 \n데이터베이스 서버를 배포합니다. Amazon Elastic Block Store(Amazon EBS) 다중 연결을 \n사용하여 인스턴스 간에 공유 스토리지를 생성합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/102170-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명1: \nA(O) : Amazon RDS 다중 AZ 배포에서 Amazon RDS 는 자동으로 프라이머리 데이터베이스 \nDB 인스턴스를 생성하고 동시에 다른 AZ 의 인스턴스에 데이터를 복제합니다. 장애를 \n감지하면 Amazon RDS 는 수동 개입 없이 자동으로 대기 인스턴스로 장애 조치합니다. \nhttps://aws.amazon.com/ko/rds/features/multi-az/ \nB(X) : Auto Scaling 을 단일 가용 영역에서 사용하므로 고가용성 조건 불충족. \nC(X) : 단일 가용 영역에서 읽기 전용 복제본이 있는 DB 인스턴스를 사용한다고 했으므로 \n고가용성 조건 불충족. \nD(X) : 공유 스토리지가 아니라 read replica 나 다중 AZ 가 더 합리적. \n \n설명2: \n여러 가용 영역의 Auto Scaling 그룹에서 Amazon EC2 인스턴스를 사용하여 애플리케이션 \n서버를 배포합니다. 다중 AZ 구성에서 Amazon RDS DB 인스턴스를 사용합니다. 단일 장애 \n지점을 피하고 사용자 요구에 맞게 애플리케이션을 확장할 수 있는 기능을 제공하면서 기존 \n\n애플리케이션의 가용성과 탄력성을 높이려면 최상의 솔루션은 Auto Scaling 그룹의 \nAmazon EC2 인스턴스를 사용하여 애플리케이션 서버를 여러 그룹에 배포하는 것입니다. \n가용 영역 및 다중 AZ 구성에서 Amazon RDS DB 인스턴스를 사용합니다. 다중 AZ \n구성에서 Amazon RDS DB 인스턴스를 사용하면 데이터베이스가 여러 가용 영역에 걸쳐 \n자동으로 복제되므로 데이터베이스의 가용성이 높고 단일 가용 영역의 장애를 견딜 수 \n있습니다. 이는 내결함성을 제공하고 단일 실패 지점을 방지합니다.", "answer_choice": "A"}, "402": {"q_num": 402, "question": "회사는 애플리케이션에서 생성하는 대량의 스트리밍 데이터를 수집하고 처리해야 합니다. \n이 애플리케이션은 Amazon EC2 인스턴스에서 실행되며 기본 설정으로 구성된 Amazon \nKinesis Data Streams 로 데이터를 전송합니다. 격일로 애플리케이션은 데이터를 소비하고 \n비즈니스 인텔리전스(BI) 처리를 위해 데이터를 Amazon S3 버킷에 기록합니다. 회사는 \nAmazon S3 가 애플리케이션이 Kinesis Data Streams 로 보내는 모든 데이터를 수신하지 \n못하는 것을 관찰합니다. \n솔루션 설계자는 이 문제를 해결하기 위해 무엇을 해야 합니까? \nA. 데이터 보존 기간을 수정하여 Kinesis Data Streams 기본 설정을 업데이트합니다. \nB. Kinesis Producer Library(KPL)를 사용하여 Kinesis Data Streams 로 데이터를 전송하도록 \n애플리케이션을 업데이트합니다. \nC. Kinesis Data Streams 로 전송되는 데이터의 처리량을 처리하도록 Kinesis 샤드 수를 \n업데이트합니다. \nD. S3 버킷 내에서 S3 버전 관리를 켜서 S3 버킷에 수집된 모든 객체의 모든 버전을 \n보존합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/102175-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nKinesis 데이터 스트림의 데이터 보존 기간은 레코드가 추가된 시점부터 더 이상 액세스할 \n수 없는 시점까지의 기간입니다. Kinesis 데이터 스트림의 기본 보존 기간은 24 시간이며 \n최대 8760 시간(365 일)까지 연장할 수 있습니다. 데이터 보존 기간은 AWS Management \nConsole, AWS CLI 또는 Kinesis Data Streams API 를 사용하여 업데이트할 수 있습니다. \n시나리오의 요구 사항을 충족하려면 솔루션 설계자가 데이터 보존 기간을 수정하여 Kinesis \nData Streams 기본 설정을 업데이트해야 합니다. 솔루션 설계자는 보존 기간을 데이터를 \n소비하고 S3 에 쓰는 빈도보다 크거나 같은 값으로 늘려야 합니다. 이렇게 하면 회사는 \n애플리케이션이 Kinesis Data Streams 로 보내는 모든 데이터를 S3 가 수신하도록 할 수 \n\n있습니다.", "answer_choice": "A"}, "403": {"q_num": 403, "question": "개발자에게는 AWS Lambda 함수를 사용하여 파일을 Amazon S3\n에 업로드하는 \n애플리케이션이 있으며 작업을 수행하는 데 필요한 권한이 필요합니다. 개발자에게는 이미 \nAmazon S3 에 필요한 유효한 IAM 자격 증명이 있는 IAM 사용자가 있습니다. \n권한을 부여하려면 솔루션 설계자가 무엇을 해야 합니까? \nA. Lambda 함수의 리소스 정책에 필요한 IAM 권한을 추가합니다. \nB. Lambda 함수에서 기존 IAM 자격 증명을 사용하여 서명된 요청을 생성합니다. \nC. 새 IAM 사용자를 생성하고 Lambda 함수에서 기존 IAM 자격 증명을 사용합니다. \nD. 필요한 권한이 있는 IAM 실행 역할을 생성하고 IAM 역할을 Lambda 함수에 \n연결합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/102178-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nAmazon S3 에 파일을 업로드하기 위해 AWS Lambda 함수에 필요한 권한을 부여하려면 \n솔루션 설계자는 필요한 권한이 있는 IAM 실행 역할을 생성하고 IAM 역할을 Lambda \n함수에 연결해야 합니다. 이 접근 방식은 최소 권한 원칙을 따르며 Lambda 함수가 특정 \n작업을 수행하는 데 필요한 리소스에만 액세스할 수 있도록 합니다.", "answer_choice": "D"}, "404": {"q_num": 404, "question": "회사는 새 문서가 Amazon S3 버킷에 업로드될 때 AWS Lambda 함수를 호출하는 서버리스 \n애플리케이션을 \n배포했습니다. \n애플리케이션은 \nLambda \n함수를 \n사용하여 \n문서를 \n처리합니다. 최근 마케팅 캠페인 후 회사는 애플리케이션이 많은 문서를 처리하지 않는다는 \n사실을 알게 되었습니다. \n솔루션 설계자는 이 애플리케이션의 아키텍처를 개선하기 위해 무엇을 해야 합니까? \nA. Lambda 함수의 런타임 제한 시간 값을 15 분으로 설정합니다. \nB. S3 버킷 복제 정책을 구성합니다. 나중에 처리할 수 있도록 S3 버킷에 문서를 \n준비합니다. \nC. 추가 Lambda 함수를 배포합니다. 두 Lambda 함수에서 문서 처리 부하를 분산합니다. \nD. Amazon Simple Queue Service(Amazon SQS) 대기열을 생성합니다. 대기열에 요청을 \n보냅니다. 대기열을 Lambda 에 대한 이벤트 소스로 구성합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/102180-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n이 애플리케이션의 아키텍처를 개선하기 위한 최상의 솔루션은 Amazon Simple Queue \nService(Amazon SQS)를 사용하여 요청을 버퍼링하고 Lambda 함수에서 S3 버킷을 \n분리하는 것입니다. 이렇게 하면 문서가 손실되지 않고 Lambda 함수를 사용할 수 없는 \n경우 나중에 처리할 수 있습니다. 이렇게 하면 문서가 손실되지 않고 Lambda 함수를 \n사용할 수 없는 경우 나중에 처리할 수 있습니다. Amazon SQS 를 사용하면 아키텍처가 \n분리되고 Lambda 함수가 확장 가능하고 내결함성 있는 방식으로 문서를 처리할 수 \n있습니다.", "answer_choice": "D"}, "405": {"q_num": 405, "question": "솔루션 설계자는 소프트웨어 데모 환경을 위한 아키텍처를 설계하고 있습니다. 환경은 \nApplication Load Balancer(ALB) 뒤에 있는 Auto Scaling 그룹의 Amazon EC2 인스턴스에서 \n실행됩니다. 시스템은 근무 시간 동안 트래픽이 크게 증가하지만 주말에는 작동하지 않아도 \n됩니다. \n수요에 맞게 시스템을 확장할 수 있도록 하기 위해 솔루션 설계자는 어떤 조치 조합을 \n취해야 합니까? (2 개 선택) \nA. AWS Auto Scaling 을 사용하여 요청 속도에 따라 ALB 용량을 조정하십시오. \nB. AWS Auto Scaling 을 사용하여 VPC 인터넷 게이트웨이의 용량을 확장합니다. \nC. 여러 AWS 지역에서 EC2 인스턴스를 시작하여 여러 지역에 로드를 분산합니다. \nD. 대상 추적 조정 정책을 사용하여 인스턴스 CPU 사용률을 기반으로 Auto Scaling 그룹을 \n조정합니다. \nE. 예약된 조정을 사용하여 Auto Scaling 그룹의 최소, 최대 및 원하는 용량을 주말 동안 \n0 으로 변경합니다. 주의 시작 시 기본값으로 되돌립니다.", "answer_block": "Answer: D, E \nhttps://www.examtopics.com/discussions/amazon/view/102181-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nhttps://docs.aws.amazon.com/ko_kr/autoscaling/ec2/userguide/as-scaling-target-tracki\nng.html#target-tracking-choose-metrics \n대상 추적 조정 정책은 지정된 메트릭과 대상 값을 기반으로 Auto Scaling 그룹의 용량을 \n\n조정하는 일종의 동적 조정 정책입니다. 대상 추적 조정 정책은 Auto Scaling 그룹에서 \n자동으로 확장 또는 축소하여 실제 지표 값을 대상 값 또는 그 근처에 유지할 수 있습니다. \n대상 추적 조정 정책은 근무 시간과 같이 애플리케이션에 대한 로드가 예측할 수 없이 자주 \n변경되는 시나리오에 적합합니다. \n시나리오의 요구 사항을 충족하기 위해 솔루션 설계자는 대상 추적 조정 정책을 사용하여 \n인스턴스 CPU 사용률에 따라 Auto Scaling 그룹을 조정해야 합니다. 인스턴스 CPU \n사용률은 애플리케이션에 대한 수요를 반영하는 일반적인 메트릭입니다. 솔루션 설계자는 \n애플리케이션의 이상적인 평균 CPU 사용률 수준(예: 50%)을 나타내는 목표 값을 지정해야 \n합니다. 그러면 Auto Scaling 그룹이 해당 수준의 CPU 사용률을 유지하기 위해 확장 또는 \n축소됩니다. \n예약된 조정은 날짜와 시간을 기준으로 조정 작업을 수행하는 일종의 조정 정책입니다. \n예약된 조정은 주말과 같이 애플리케이션의 부하가 주기적으로 예측 가능하게 변경되는 \n시나리오에 적합합니다. \n시나리오의 요구 사항을 충족하기 위해 솔루션 설계자는 예약된 조정을 사용하여 Auto \nScaling 그룹의 최소, 최대 및 원하는 용량을 주말 동안 0 으로 변경해야 합니다. \n이렇게 하면 Auto Scaling 그룹은 작동이 필요하지 않은 주말에 모든 인스턴스를 \n종료합니다. 솔루션 설계자는 Auto Scaling 그룹이 정상 작동을 재개할 수 있도록 주의 \n시작 시 기본값으로 되돌려야 합니다.", "answer_choice": "D"}, "406": {"q_num": 406, "question": "솔루션 설계자는 공용 서브넷과 데이터베이스 서브넷을 포함하는 2\n계층 아키텍처를 \n설계하고 있습니다. 퍼블릭 서브넷의 웹 서버는 포트 443 에서 인터넷에 열려 있어야 \n합니다. 데이터베이스 서브넷의 Amazon RDS for MySQL DB 인스턴스는 포트 3306 의 웹 \n서버에서만 액세스할 수 있어야 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 단계 조합을 수행해야 합니까? \n(2 개 선택) \nA. 퍼블릭 서브넷에 대한 네트워크 ACL 을 만듭니다. 포트 3306 에서 0.0.0.0/0 에 대한 \n아웃바운드 트래픽을 거부하는 규칙을 추가합니다. \nB. DB 인스턴스에 대한 보안 그룹을 생성합니다. 포트 3306 에서 퍼블릭 서브넷 CIDR \n블록의 트래픽을 허용하는 규칙을 추가합니다. \nC. 퍼블릭 서브넷의 웹 서버에 대한 보안 그룹을 생성합니다. 포트 443 에서 0.0.0.0/0 의 \n트래픽을 허용하는 규칙을 추가합니다. \nD. DB 인스턴스에 대한 보안 그룹을 생성합니다. 포트 3306 에서 웹 서버 보안 그룹의 \n트래픽을 허용하는 규칙을 추가합니다. \nE. DB 인스턴스에 대한 보안 그룹을 생성합니다. 포트 3306 에서 웹 서버 보안 그룹의 \n\n트래픽을 제외한 모든 트래픽을 거부하는 규칙을 추가합니다.", "answer_block": "Answer: C, D \nhttps://www.examtopics.com/discussions/amazon/view/102183-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "407": {"q_num": 407, "question": "회사는 AWS 클라우드에서 호스팅되는 게임 애플리케이션용 공유 스토리지 솔루션을 \n구현하고 있습니다. 회사는 Lustre 클라이언트를 사용하여 데이터에 액세스할 수 있는 \n기능이 필요합니다. 솔루션은 완전히 관리되어야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 탑재 가능한 파일 시스템으로 데이터를 공유하는 AWS DataSync 작업을 생성합니다. \n파일 시스템을 애플리케이션 서버에 마운트하십시오. \nB. AWS Storage Gateway 파일 게이트웨이를 생성합니다. 필요한 클라이언트 프로토콜을 \n사용하는 파일 공유를 만듭니다. 응용 프로그램 서버를 파일 공유에 연결합니다. \nC. Amazon Elastic File System(Amazon EFS) 파일 시스템을 만들고 Lustre 를 지원하도록 \n구성합니다. 원본 서버에 파일 시스템을 연결합니다. 애플리케이션 서버를 파일 시스템에 \n연결하십시오. \nD. Amazon FSx for Lustre 파일 시스템을 생성합니다. 원본 서버에 파일 시스템을 \n연결합니다. 애플리케이션 서버를 파일 시스템에 연결하십시오.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/102184-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "D"}, "408": {"q_num": 408, "question": "한 회사에서 UDP 를 사용하는 수천 개의 지리적으로 분산된 원격 장치로부터 데이터를 \n수신하는 애플리케이션을 실행합니다. 애플리케이션은 데이터를 즉시 처리하고 필요한 경우 \n장치로 다시 메시지를 보냅니다. 데이터가 저장되지 않습니다. \n회사는 장치에서 데이터 전송에 대한 대기 시간을 최소화하는 솔루션이 필요합니다. \n솔루션은 또한 다른 AWS 리전에 대한 빠른 장애 조치를 제공해야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Amazon Route 53 장애 조치 라우팅 정책을 구성합니다. 두 리전 각각에 NLB(Network \nLoad Balancer)를 생성합니다. 데이터를 처리하기 위해 AWS Lambda 함수를 호출하도록 \nNLB 를 구성합니다. \nB. AWS Global Accelerator 를 사용합니다. 두 리전 각각에 NLB(Network Load Balancer)를 \n\n엔드포인트로 \n생성합니다. \nFargate \n시작 \n유형으로 \nAmazon \nElastic \nContainer \nService(Amazon ECS) 클러스터를 생성합니다. 클러스터에서 ECS 서비스를 생성합니다. \nAmazon ECS 에서 데이터를 NLProcess 하기 위한 대상으로 ECS 서비스를 설정합니다. \nC. AWS Global Accelerator\n를 사용합니다. 두 리전 각각에 Application Load \nBalancer(ALB)를 엔드포인트로 생성합니다. Fargate 시작 유형으로 Amazon Elastic \nContainer Service(Amazon ECS) 클러스터를 생성합니다. 클러스터에서 ECS 서비스를 \n생성합니다. ECS 서비스를 ALB 의 대상으로 설정합니다. Amazon ECS 에서 데이터를 \n처리합니다. \nD. Amazon Route 53 장애 조치 라우팅 정책을 구성합니다. 두 리전 각각에 Application \nLoad Balancer(ALB)를 생성합니다. Fargate 시작 유형으로 Amazon Elastic Container \nService(Amazon ECS) 클러스터를 생성합니다. 클러스터에서 ECS 서비스를 생성합니다. \nECS 서비스를 ALB 의 대상으로 설정합니다. Amazon ECS 에서 데이터를 처리합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/102185-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n장치에서 데이터를 전송하는 지연 시간을 최소화하고 다른 AWS 영역으로 신속하게 \n페일오버해야 하는 요구 사항을 충족하기 위해 가장 좋은 솔루션은 네트워크 로드 \n밸런서(NLB) 및 Amazon Elastic Container Service(Amazon ECS)와 함께 AWS Global \nAccelerator 를 사용하는 것입니다. \nAWS Global Accelerator 는 정적 IP 주소(Anycast)를 사용하여 트래픽을 최적의 AWS \n끝점으로 라우팅하여 애플리케이션의 가용성과 성능을 향상시키는 서비스입니다. Global \nAccelerator 를 사용하면 트래픽을 여러 지역 및 끝점으로 유도하고 다른 AWS 지역으로 \n자동 페일오버를 제공할 수 있습니다.", "answer_choice": "B"}, "409": {"q_num": 409, "question": "솔루션 \n설계자는 \nWindows \n인터넷 \n정보 \n서비스(IIS) \n웹 \n애플리케이션을 \nAWS\n로 \n마이그레이션해야 \n합니다. \n애플리케이션은 \n현재 \n사용자의 \n온프레미스 \nNAS(Network-Attached Storage)에서 호스팅되는 파일 공유에 의존합니다. 솔루션 설계자는 \nIIS 웹 서버를 스토리지 솔루션에 연결된 여러 가용 영역의 Amazon EC2 인스턴스로 \n마이그레이션하고 인스턴스에 연결된 Elastic Load Balancer 를 구성할 것을 제안했습니다. \n온프레미스 파일 공유에 대한 어떤 대체가 가장 탄력적이고 내구성이 있습니까? \nA. 파일 공유를 Amazon RDS 로 마이그레이션합니다. \nB. 파일 공유를 AWS Storage Gateway 로 마이그레이션합니다. \n\nC. 파일 공유를 Amazon FSx for Windows File Server 로 마이그레이션합니다. \nD. 파일 공유를 Amazon Elastic File System(Amazon EFS)으로 마이그레이션합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/102186-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n이 대답은 Windows IIS 웹 서버와 호환되는 온-프레미스 파일 공유에 대한 탄력적이고 \n내구성 있는 대체를 제공하기 때문에 정확합니다. Amazon FSx for Windows File Server 는 \nWindows Server 에 구축된 공유 파일 스토리지를 제공하는 완전 관리형 서비스입니다. SMB \n프로토콜을 지원하고 Windows 기반 애플리케이션에 대한 원활한 액세스 및 인증을 \n가능하게 하는 Microsoft Active Directory 와 통합됩니다. Amazon FSx for Windows File \nServer 는 또한 다음과 같은 이점을 제공합니다. \n복원력: Amazon FSx for Windows File Server 는 고가용성 및 장애 조치 보호를 제공하는 \n여러 가용 영역에 배포할 수 있습니다. 또한 자동 백업 및 복원은 물론 문제를 감지하고 \n수정하는 자가 치유 기능도 지원합니다. \n내구성: Windows File Server 용 Amazon FSx 는 가용 영역 내외에서 데이터를 복제하고 \n내구성이 뛰어난 스토리지 장치에 데이터를 저장합니다. 또한 유휴 및 전송 중 암호화는 \n물론 파일 액세스 감사 및 데이터 중복 제거를 지원합니다. \n성능: Windows File Server 용 Amazon FSx 는 파일 작업을 위한 일관된 1 밀리초 미만의 \n지연 시간과 높은 처리량을 제공합니다. 또한 SSD 스토리지, 분산 파일 시스템(DFS) \n네임스페이스 및 복제와 같은 기본 Windows 기능, 사용자 중심 성능 확장을 지원합니다.", "answer_choice": "C"}, "410": {"q_num": 410, "question": "회사에서 Amazon EC2 인스턴스에 새 애플리케이션을 배포하고 있습니다. 애플리케이션은 \nAmazon Elastic Block Store(Amazon EBS) 볼륨에 데이터를 씁니다. 회사는 EBS 볼륨에 \n기록된 모든 데이터가 유휴 상태에서 암호화되도록 해야 합니다. \n이 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. EBS 암호화를 지정하는 IAM 역할을 생성합니다. 역할을 EC2 인스턴스에 연결합니다. \nB. EBS 볼륨을 암호화된 볼륨으로 생성합니다. EBS 볼륨을 EC2 인스턴스에 연결합니다. \nC. 키가 Encrypt 이고 값이 True 인 EC2 인스턴스 태그를 생성합니다. EBS 수준에서 \n암호화가 필요한 모든 인스턴스에 태그를 지정합니다. \nD. 계정에서 EBS 암호화를 시행하는 AWS Key Management Service(AWS KMS) 키 정책을 \n생성합니다. 키 정책이 활성 상태인지 확인하십시오.", "answer_block": "Answer: B \n\nhttps://www.examtopics.com/discussions/amazon/view/102187-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nEBS 볼륨에 기록되는 모든 데이터가 유휴 상태에서 암호화되도록 보장하는 요구 사항을 \n충족하는 솔루션은 B 입니다. EBS 볼륨을 암호화된 볼륨으로 생성하고 암호화된 EBS \n볼륨을 EC2 인스턴스에 연결합니다. EBS 볼륨을 생성할 때 볼륨 암호화 여부를 지정할 수 \n있습니다. 볼륨을 암호화하도록 선택한 경우 볼륨에 기록된 모든 데이터는 AWS 관리형 \n키를 사용하여 유휴 상태에서 자동으로 암호화됩니다. 또한 AWS KMS 에 저장된 고객 \n관리형 키(CMK)를 사용하여 EBS 볼륨을 암호화하고 보호할 수 있습니다. 암호화된 EBS \n볼륨을 생성하고 EC2 인스턴스에 연결하여 볼륨에 기록된 모든 데이터가 유휴 상태에서 \n암호화되도록 할 수 있습니다.", "answer_choice": "B"}, "411": {"q_num": 411, "question": "회사에 산발적인 사용 패턴을 가진 웹 애플리케이션이 있습니다. 매달 초에는 사용량이 \n많고, 매주 초에는 보통 사용량이 있으며, 주중에는 예측할 수 없는 사용량이 있습니다. 이 \n애플리케이션은 웹 서버와 데이터 센터 내에서 실행되는 MySQL 데이터베이스 서버로 \n구성됩니다. 이 회사는 애플리케이션을 AWS 클라우드로 이동하려고 하며 데이터베이스 \n수정이 필요하지 않은 비용 효율적인 데이터베이스 플랫폼을 선택해야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Amazon DynamoDB \nB. MySQL 용 Amazon RDS \nC. MySQL 호환 Amazon Aurora Serverless \nD. Auto Scaling 그룹의 Amazon EC2 에 배포된 MySQL", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/102188-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nAmazon RDS for MySQL 은 클라우드에서 MySQL 배포를 쉽게 설정, 운영 및 확장할 수 \n있는 완전관리형 관계형 데이터베이스 서비스입니다. Amazon Aurora Serverless 는 Amazon \nAurora(MySQL \n호환 \n버전)에 \n대한 \n온디맨드 \n자동 \n확장 \n구성으로, \n데이터베이스가 \n애플리케이션의 요구 사항에 따라 자동으로 시작, 종료 및 용량 확장 또는 축소됩니다. \n간헐적이거나 예측할 수 없는 워크로드를 위한 간단하고 비용 효율적인 옵션입니다.", "answer_choice": "C"}, "412": {"q_num": 412, "question": "이미지 호스팅 회사는 객체를 Amazon S3 버킷에 저장합니다. 회사는 S3 버킷의 개체가 \n대중에게 우발적으로 노출되는 것을 방지하려고 합니다. 전체 AWS 계정의 모든 S3 객체는 \n비공개로 유지되어야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Amazon GuardDuty 를 사용하여 S3 버킷 정책을 모니터링합니다. AWS Lambda 함수를 \n사용하여 객체를 공개하는 변경 사항을 수정하는 자동 수정 작업 규칙을 생성합니다. \nB. AWS Trusted Advisor 를 사용하여 공개적으로 액세스 가능한 S3 버킷을 찾습니다. 변경 \n사항이 감지되면 Trusted Advisor\n에서 이메일 알림을 구성합니다. 퍼블릭 액세스를 \n허용하는 경우 S3 버킷 정책을 수동으로 변경합니다. \nC. AWS Resource Access Manager 를 사용하여 공개적으로 액세스 가능한 S3 버킷을 \n찾습니다. 변경이 감지되면 Amazon Simple Notification Service(Amazon SNS)를 사용하여 \nAWS Lambda 함수를 호출합니다. 프로그래밍 방식으로 변경 사항을 수정하는 Lambda \n함수를 배포합니다. \nD. 계정 수준에서 S3 퍼블릭 액세스 차단 기능을 사용합니다. AWS Organizations 를 \n사용하여 IAM 사용자가 설정을 변경하지 못하도록 하는 서비스 제어 정책(SCP)을 \n생성합니다. 계정에 SCP 를 적용합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/102189-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nS3 퍼블릭 액세스 차단 기능을 사용하면 계정 내의 S3 버킷 및 객체에 대한 퍼블릭 \n액세스를 제한할 수 있습니다. 버킷 정책 설정에 관계없이 계정 수준에서 이 기능을 \n활성화하여 S3 버킷이 공개되지 않도록 할 수 있습니다. AWS Organizations 를 사용하여 \nIAM 사용자가 이 설정을 변경하지 못하도록 SCP(서비스 제어 정책)를 계정에 적용하여 \n모든 S3 객체가 비공개로 유지되도록 할 수 있습니다. 이는 최소한의 운영 오버헤드가 \n필요한 간단하고 효과적인 솔루션입니다.", "answer_choice": "D"}, "413": {"q_num": 413, "question": "한 전자상거래 회사에서 사용자 트래픽이 증가하고 있습니다. 회사의 스토어는 웹 계층과 \n별도의 데이터베이스 계층으로 구성된 2\n계층 웹 애플리케이션으로 Amazon EC2 \n인스턴스에 배포됩니다. 트래픽이 증가함에 따라 회사는 아키텍처로 인해 사용자에게 \n적시에 마케팅 및 주문 확인 이메일을 보내는 데 상당한 지연이 발생하고 있음을 알게 \n\n되었습니다. 이 회사는 복잡한 이메일 전송 문제를 해결하는 데 소요되는 시간을 줄이고 \n운영 오버헤드를 최소화하기를 원합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. 이메일 처리 전용 EC2 인스턴스를 사용하여 별도의 애플리케이션 계층을 만듭니다. \nB. Amazon Simple Email Service(Amazon SES)를 통해 이메일을 보내도록 웹 인스턴스를 \n구성합니다. \nC. Amazon Simple Notification Service(Amazon SNS)를 통해 이메일을 보내도록 웹 \n인스턴스를 구성합니다. \nD. 이메일 처리 전용 EC2 인스턴스를 사용하여 별도의 애플리케이션 계층을 생성합니다. \nAuto Scaling 그룹에 인스턴스를 배치합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/102190-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nAmazon SES 는 기업이 자체 이메일 주소와 도메인을 사용하여 이메일을 보내고 받을 수 \n있도록 하는 비용 효율적이고 확장 가능한 이메일 서비스입니다. Amazon SES 를 통해 \n이메일을 보내도록 웹 인스턴스를 구성하는 것은 복잡한 이메일 전송 문제를 해결하는 데 \n소요되는 \n시간을 \n줄이고 \n운영 \n오버헤드를 \n최소화할 \n수 \n있는 \n간단하고 \n효과적인 \n솔루션입니다.", "answer_choice": "B"}, "414": {"q_num": 414, "question": "회사에는 매일 수백 개의 보고서를 생성하는 비즈니스 시스템이 있습니다. 비즈니스 \n시스템은 보고서를 CSV 형식으로 네트워크 공유에 저장합니다. 회사는 분석을 위해 이 \n데이터를 거의 실시간으로 AWS 클라우드에 저장해야 합니다. \n최소한의 관리 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. AWS DataSync 를 사용하여 파일을 Amazon S3 로 전송합니다. 매일 끝날 때 실행되는 \n예약된 작업을 만듭니다. \nB. Amazon S3 파일 게이트웨이를 생성합니다. S3 파일 게이트웨이에서 새 네트워크 공유를 \n사용하도록 비즈니스 시스템을 업데이트합니다. \nC. AWS DataSync 를 사용하여 파일을 Amazon S3 로 전송합니다. 자동화 워크플로에서 \nDataSync API 를 사용하는 애플리케이션을 생성합니다. \nD. SFTP 용 AWS 전송 엔드포인트를 배포합니다. 네트워크 공유에서 새 파일을 확인하고 \nSFTP 를 사용하여 새 파일을 업로드하는 스크립트를 만듭니다.", "answer_block": "Answer: B \n\nhttps://www.examtopics.com/discussions/amazon/view/103452-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "415": {"q_num": 415, "question": "회사에서 Amazon S3 Standard\n에 페타바이트 규모의 데이터를 저장하고 있습니다. \n데이터는 여러 S3 버킷에 저장되며 다양한 빈도로 액세스됩니다. 회사는 모든 데이터에 \n대한 액세스 패턴을 알지 못합니다. 회사는 S3 사용 비용을 최적화하기 위해 각 S3 버킷에 \n대한 솔루션을 구현해야 합니다. \n이러한 요구 사항을 가장 효율적으로 충족하는 솔루션은 무엇입니까? \nA. S3 버킷의 객체를 S3 Intelligent-Tiering 으로 전환하는 규칙으로 S3 수명 주기 구성을 \n생성합니다. \nB. S3 스토리지 클래스 분석 도구를 사용하여 S3 버킷의 각 객체에 대한 올바른 계층을 \n결정합니다. 각 개체를 식별된 스토리지 계층으로 이동합니다. \nC. S3 버킷의 객체를 S3 Glacier Instant Retrieval 로 전환하는 규칙으로 S3 수명 주기 \n구성을 생성합니다. \nD. S3 버킷의 객체를 S3 One Zone-Infrequent Access(S3 One Zone-IA)로 전환하는 \n규칙으로 S3 수명 주기 구성을 생성합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/103404-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "416": {"q_num": 416, "question": "빠르게 성장하는 글로벌 전자상거래 회사는 AWS\n에서 웹 애플리케이션을 호스팅하고 \n있습니다. 웹 애플리케이션에는 정적 콘텐츠와 동적 콘텐츠가 포함됩니다. 웹사이트는 \nAmazon RDS 데이터베이스에 OLTP(온라인 거래 처리) 데이터를 저장합니다. 웹사이트 \n사용자의 페이지 로드 속도가 느립니다. \n이 문제를 해결하기 위해 솔루션 아키텍트가 취해야 할 조치 조합은 무엇입니까? (2 개 \n선택) \nA. Amazon Redshift 클러스터를 구성합니다. \nB. Amazon CloudFront 배포를 설정합니다. \nC. Amazon S3 에서 동적 웹 콘텐츠를 호스팅합니다. \nD. RDS DB 인스턴스에 대한 읽기 전용 복제본을 생성합니다. \nE. RDS DB 인스턴스에 대한 다중 AZ 배포를 구성합니다.", "answer_block": "Answer: B, D \n\nhttps://www.examtopics.com/discussions/amazon/view/103423-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nAWS 에서 호스팅되는 빠르게 성장하는 전자 상거래 웹 사이트의 느린 페이지 로드 문제를 \n해결하기 위해 솔루션 설계자는 다음 두 가지 조치를 취할 수 있습니다. \n1. Amazon CloudFront 배포 설정 \n2. RDS DB 인스턴스에 대한 읽기 전용 복제본 생성 \nAmazon Redshift 클러스터 구성은 Redshift 가 데이터 웨어하우징 서비스이고 일반적으로 \n대량 데이터의 분석 처리에 사용되기 때문에 이 문제와 관련이 없습니다. \nS3 는 웹 애플리케이션 서버가 아니라 객체 스토리지 서비스이기 때문에 Amazon S3 에서 \n동적 웹 콘텐츠를 호스팅해도 성능이 반드시 향상되는 것은 아닙니다. S3 는 정적 웹 \n콘텐츠를 호스팅하는 데 사용할 수 있지만 S3 는 서버 측 스크립팅 또는 처리를 지원하지 \n않기 때문에 동적 웹 콘텐츠를 호스팅하는 데 적합하지 않을 수 있습니다. \nRDS DB 인스턴스에 대해 다중 AZ 배포를 구성하면 고가용성이 향상되지만 반드시 성능이 \n향상되는 것은 아닙니다.", "answer_choice": "B"}, "417": {"q_num": 417, "question": "회사는 Amazon EC2 \n인스턴스와 AWS Lambda 함수를 사용하여 \n애플리케이션을 \n실행합니다. 이 회사는 AWS 계정에 퍼블릭 서브넷과 프라이빗 서브넷이 있는 VPC 가 \n있습니다. \nEC2 \n인스턴스는 \nVPC \n중 \n하나의 \n프라이빗 \n서브넷에서 \n실행됩니다. \n애플리케이션이 작동하려면 Lambda 함수가 EC2 인스턴스에 대한 직접적인 네트워크 \n액세스가 필요합니다. \n응용 프로그램은 최소 1 년 동안 실행됩니다. 회사는 해당 시간 동안 애플리케이션이 \n사용하는 Lambda 함수의 수가 증가할 것으로 예상합니다. 회사는 모든 애플리케이션 \n리소스에 대한 절감 효과를 극대화하고 서비스 간의 네트워크 대기 시간을 낮게 유지하려고 \n합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. EC2 Instance Savings Plan 구매 Lambda 함수의 지속 시간, 메모리 사용량 및 호출 \n수를 \n최적화합니다. \nEC2 \n인스턴스가 \n포함된 \n프라이빗 \n서브넷에 \nLambda \n함수를 \n연결합니다. \nB. EC2 Instance Savings Plan 구매 Lambda 함수의 기간 및 메모리 사용량, 호출 수 및 \n전송되는 데이터 양을 최적화합니다. EC2 인스턴스가 실행되는 동일한 VPC 의 퍼블릭 \n서브넷에 Lambda 함수를 연결합니다. \nC. Compute Savings Plan 을 구매합니다. Lambda 함수의 기간 및 메모리 사용량, 호출 수 \n\n및 전송되는 데이터 양을 최적화합니다. EC2 인스턴스가 포함된 프라이빗 서브넷에 \nLambda 함수를 연결합니다. \nD. Compute Savings Plan 을 구매합니다. Lambda 함수의 기간 및 메모리 사용량, 호출 수 \n및 전송되는 데이터 양을 최적화합니다. Lambda 서비스 VPC\n에 Lambda 함수를 \n유지합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/103598-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nCompute Savings Plan 을 구매함으로써 회사는 EC2 인스턴스와 Lambda 기능을 모두 \n실행하는 비용을 절약할 수 있습니다. Lambda 함수는 AWS 서비스용 VPC 엔드포인트 또는 \nVPC 피어링 연결을 통해 EC2 인스턴스가 포함된 프라이빗 서브넷에 연결할 수 있습니다. \n이렇게 하면 사설 네트워크 내에서 트래픽을 유지하면서 EC2 인스턴스에 대한 직접 \n네트워크 액세스를 제공하여 네트워크 대기 시간을 최소화하는 데 도움이 됩니다. Lambda \n함수의 지속 시간, 메모리 사용량, 호출 수 및 전송된 데이터 양을 최적화하면 비용을 \n추가로 최소화하고 성능을 개선하는 데 도움이 될 수 있습니다. 또한 프라이빗 서브넷을 \n사용하면 보안 모범 사례인 퍼블릭 인터넷에서 EC2 인스턴스에 직접 액세스할 수 없도록 \n하는 데 도움이 됩니다.", "answer_choice": "C"}, "418": {"q_num": 418, "question": "솔루션 아키텍트는 팀 구성원이 두 개의 다른 AWS 계정(개발 계정 및 프로덕션 계정)에서 \nAmazon S3 버킷에 액세스할 수 있도록 허용해야 합니다. 팀은 현재 계정에서 적절한 \n권한이 있는 IAM 그룹에 할당된 고유한 IAM 사용자를 사용하여 개발 계정의 S3 버킷에 \n액세스할 수 있습니다. \n솔루션 설계자는 프로덕션 계정에서 IAM 역할을 생성했습니다. 이 역할에는 프로덕션 \n계정의 S3 버킷에 대한 액세스 권한을 부여하는 정책이 있습니다. \n최소 권한 원칙을 준수하면서 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 관리자 액세스 정책을 개발 계정 사용자에게 연결합니다. \nB. 생산 계정에 있는 역할의 신뢰 정책에서 개발 계정을 주체로 추가합니다. \nC. 프로덕션 계정의 S3 버킷에서 S3 퍼블릭 액세스 차단 기능을 끕니다. \nD. 각 팀 구성원에 대해 고유한 자격 증명을 사용하여 프로덕션 계정에 사용자를 \n생성합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/103585-exam-aws-certified-sol\n\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "419": {"q_num": 419, "question": "회사는 모든 기능이 활성화된 AWS Organizations 를 사용하고 ap-southeast-2 리전에서 \n여러 Amazon EC2 워크로드를 실행합니다. 회사에는 다른 리전에서 리소스가 생성되지 \n않도록 하는 SCP(서비스 제어 정책)가 있습니다. 보안 정책에 따라 회사는 유휴 상태의 \n모든 데이터를 암호화해야 합니다. \n감사 결과 직원이 볼륨을 암호화하지 않고 EC2 인스턴스용 Amazon Elastic Block \nStore(Amazon EBS) 볼륨을 생성한 것으로 확인되었습니다. 회사는 암호화된 EBS 볼륨을 \n사용하기 위해 모든 IAM 사용자 또는 루트 사용자가 ap-southeast-2 에서 시작하는 모든 \n새 EC2 인스턴스를 원합니다. 회사는 EBS 볼륨을 생성하는 직원에게 최소한의 영향을 \n미치는 솔루션을 원합니다. \n이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (2 개 선택) \nA. Amazon EC2 콘솔에서 EBS 암호화 계정 속성을 선택하고 기본 암호화 키를 정의합니다. \nB. IAM 권한 경계를 생성합니다. 권한 경계를 루트 조직 단위(OU)에 연결합니다. \nec2:Encrypted 조건이 false\n인 경우 ec2:CreateVolume 작업을 거부하도록 경계를 \n정의합니다. \nC. SCP 를 생성합니다. 루트 조직 단위(OU)에 SCP 를 연결합니다. ec2:Encrypted 조건이 \nfalse 인 경우 ec2:CreateVolume 작업을 거부하도록 SCP 를 정의합니다. \nD. ec2:Encrypted 조건이 false 인 경우 ec2:CreateVolume 작업을 거부하도록 각 계정에 \n대한 IAM 정책을 업데이트합니다. \nE. 조직 관리 계정에서 기본 EBS 볼륨 암호화 설정을 지정합니다.", "answer_block": "Answer: C, E \nhttps://www.examtopics.com/discussions/amazon/view/109268-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n서비스 제어 정책(SCP)은 조직에서 권한을 관리하는 데 사용할 수 있는 정책 유형입니다. \nSCP 는 조직의 모든 계정에 대해 사용 가능한 최대 권한에 대한 중앙 제어를 제공하므로 \n계정이 조직의 액세스 제어 지침을 준수하도록 할 수 있습니다. \nec2:Encrypted 조건이 false 일 때 SCP 를 사용하여 ec2:CreateVolume 작업을 거부할 수 \n있습니다. 즉, 루트 OU 아래 계정의 모든 사용자 또는 역할은 암호화되지 않은 EBS \n볼륨을 생성할 수 없습니다. 이 솔루션은 필요에 따라 암호화된 볼륨을 계속 생성할 수 \n있으므로 EBS 볼륨을 생성하는 직원에게 최소한의 영향을 미칩니다. \n참조: \n\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps\n.html", "answer_choice": "C"}, "420": {"q_num": 420, "question": "회사에서 Amazon RDS for PostgreSQL DB 클러스터를 사용하여 프로덕션 데이터베이스 \n워크로드에 대한 시간 소모적인 데이터베이스 관리 작업을 단순화하려고 합니다. 회사는 \n데이터베이스의 고가용성을 보장하고 대부분의 시나리오에서 40 초 이내에 자동 장애 조치 \n지원을 제공할 것입니다. 회사는 기본 인스턴스에서 읽기를 오프로드하고 비용을 가능한 한 \n낮게 유지하려고 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Amazon RDS 다중 AZ DB 인스턴스 배포를 사용합니다. 하나의 읽기 복제본을 만들고 \n읽기 워크로드를 읽기 복제본으로 지정합니다. \nB. Amazon RDS 다중 AZ DB 더스터 배포 사용 2 개의 읽기 전용 복제본을 생성하고 읽기 \n워크로드를 읽기 전용 복제본으로 지정합니다. \nC. Amazon RDS 다중 AZ DB 인스턴스 배포를 사용합니다. 읽기 워크로드가 다중 AZ 쌍의 \n보조 인스턴스를 가리키도록 합니다. \nD. Amazon RDS 다중 AZ DB 클러스터 배포 사용 읽기 워크로드를 리더 엔드포인트로 \n지정합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/109269-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "D"}, "421": {"q_num": 421, "question": "회사에서 고가용성 SFTP 서비스를 실행합니다. SFTP 서비스는 탄력적 IP 주소로 실행되는 \n두 개의 Amazon EC2 Linux 인스턴스를 사용하여 인터넷에서 신뢰할 수 있는 IP 소스의 \n트래픽을 허용합니다. SFTP 서비스는 인스턴스에 연결된 공유 스토리지에서 지원합니다. \n사용자 계정은 SFTP 서버에서 Linux 사용자로 생성되고 관리됩니다. \n회사는 높은 IOPS 성능과 고도로 구성 가능한 보안을 제공하는 서버리스 옵션을 원합니다. \n회사는 또한 사용자 권한에 대한 제어를 유지하기를 원합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 암호화된 Amazon Elastic Block Store(Amazon EBS) 볼륨을 생성합니다. 신뢰할 수 있는 \nIP 주소만 허용하는 퍼블릭 엔드포인트로 AWS Transfer Family SFTP 서비스를 생성합니다. \nEBS 볼륨을 SFTP 서비스 엔드포인트에 연결합니다. 사용자에게 SFTP 서비스에 대한 \n액세스 권한을 부여합니다. \n\nB. 암호화된 Amazon Elastic File System(Amazon EFS) 볼륨을 생성합니다. 탄력적 IP \n주소와 인터넷 연결 액세스가 있는 VPC 엔드포인트를 사용하여 AWS Transfer Family SFTP \n서비스를 생성합니다. 신뢰할 수 있는 IP 주소만 허용하는 엔드포인트에 보안 그룹을 \n연결합니다. EFS 볼륨을 SFTP 서비스 엔드포인트에 연결합니다. 사용자에게 SFTP \n서비스에 대한 액세스 권한을 부여합니다. \nC. 기본 암호화가 활성화된 Amazon S3 버킷을 생성합니다. 신뢰할 수 있는 IP 주소만 \n허용하는 퍼블릭 엔드포인트로 AWS Transfer Family SFTP 서비스를 생성합니다. S3 버킷을 \nSFTP 서비스 엔드포인트에 연결합니다. 사용자에게 SFTP 서비스에 대한 액세스 권한을 \n부여합니다. \nD. 기본 암호화가 활성화된 Amazon S3 버킷을 생성합니다. 프라이빗 서브넷에서 내부 \n액세스 권한이 있는 VPC 엔드포인트로 AWS Transfer Family SFTP 서비스를 생성합니다. \n신뢰할 수 있는 IP 주소만 허용하는 보안 그룹을 연결합니다. S3 버킷을 SFTP 서비스 \n엔드포인트에 연결합니다. 사용자에게 SFTP 서비스에 대한 액세스 권한을 부여합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/109270-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "422": {"q_num": 422, "question": "한 회사가 AWS 에서 새로운 기계 학습(ML) 모델 솔루션을 개발하고 있습니다. 모델은 시작 \n시 Amazon S3\n에서 약 1GB 의 모델 데이터를 가져와 메모리에 로드하는 독립적인 \n마이크로서비스로 개발됩니다. 사용자는 비동기 API 를 통해 모델에 액세스합니다. 사용자는 \n요청 또는 요청 배치를 보내고 결과를 보낼 위치를 지정할 수 있습니다. \n회사는 수백 명의 사용자에게 모델을 제공합니다. 모델의 사용 패턴이 불규칙합니다. 일부 \n모델은 며칠 또는 몇 주 동안 사용하지 않을 수 있습니다. 다른 모델은 한 번에 수천 개의 \n요청 배치를 수신할 수 있습니다. \n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 디자인을 권장해야 합니까? \nA. API 의 요청을 Network Load Balancer(NLB)로 보냅니다. NLB 에서 호출하는 AWS \nLambda 함수로 모델을 배포합니다. \nB. API 의 요청을 Application Load Balancer(ALB)로 보냅니다. Amazon Simple Queue \nService(Amazon SQS) 대기열에서 읽는 Amazon Elastic Container Service(Amazon ECS) \n서비스로 모델을 배포합니다. AWS App Mesh 를 사용하여 SQS 대기열 크기에 따라 ECS \n클러스터의 인스턴스를 확장합니다. \nC. API 의 요청을 Amazon Simple Queue Service(Amazon SQS) 대기열로 보냅니다. SQS \n이벤트에 의해 호출되는 AWS Lambda 함수로 모델을 배포합니다. AWS Auto Scaling 을 \n사용하여 SQS 대기열 크기에 따라 Lambda 함수의 vCPU 수를 늘립니다. \n\nD. API 의 요청을 Amazon Simple Queue Service(Amazon SQS) 대기열로 보냅니다. \n대기열에서 읽는 Amazon Elastic Container Service(Amazon ECS) 서비스로 모델을 \n배포합니다. 대기열 크기에 따라 서비스의 클러스터와 복사본 모두에 대해 Amazon \nECS 에서 AWS Auto Scaling 을 활성화합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/109280-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명:・ \n이 대답은 불규칙하고 예측할 수 없는 사용 패턴을 처리할 수 있는 독립적인 마이크로 \n서비스로 ML 모델을 실행하기 위한 요구 사항을 충족하기 때문에 정확합니다. API 의 \n요청을 Amazon SQS 대기열로 보내면 회사는 모델 실행에서 요청 처리를 분리하고 수요 \n급증으로 인해 요청이 손실되지 않도록 할 수 있습니다. 대기열에서 읽는 Amazon ECS \n서비스로 모델을 배포함으로써 회사는 컨테이너를 활용하여 각 모델을 마이크로 서비스로 \n격리 및 패키징하고 시작 시 S3 에서 모델 데이터를 가져올 수 있습니다. 대기열 크기에 \n따라 서비스의 클러스터와 복사본 모두에 대해 Amazon ECS 에서 AWS Auto Scaling 을 \n활성화함으로써 회사는 클러스터의 EC2 인스턴스 수와 각 서비스의 작업 수를 성능을 \n요구하고 최적화합니다. \n \n참조: \nhttps://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/welc\nome.html \nhttps://docs.aws.amazon.com/AmazonECS/latest/developerguide/Welcome.html \nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/autoscaling-ecs.html", "answer_choice": "D"}, "423": {"q_num": 423, "question": "솔루션 설계자는 다음 JSON 텍스트를 자격 증명 기반 정책으로 사용하여 특정 권한을 \n부여하려고 합니다. \n\n \n솔루션 설계자가 이 정책을 연결할 수 있는 IAM 보안 주체는 무엇입니까? (2 개 선택) \nA. 역할(Role) \nB. 그룹(Group) \nC. 조직(Organization) \nD. Amazon Elastic Container Service(Amazon ECS) 리소스(resource) \nE. Amazon EC2 리소스(resource)", "answer_block": "Answer: A, B \nhttps://www.examtopics.com/discussions/amazon/view/109281-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "424": {"q_num": 424, "question": "회사는 Amazon EC2 온디맨드 인스턴스에서 사용자 지정 애플리케이션을 실행하고 \n있습니다. 애플리케이션에는 하루 24 시간, 주 7 일 실행해야 하는 프런트엔드 노드와 \n워크로드에 따라 짧은 시간 동안만 실행해야 하는 백엔드 노드가 있습니다. 백엔드 노드의 \n수는 하루 동안 다양합니다. \n회사는 워크로드에 따라 더 많은 인스턴스를 확장 및 확장해야 합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. 프런트엔드 노드에는 예약 인스턴스를 사용합니다. 백엔드 노드에 AWS Fargate 를 \n사용합니다. \nB. 프런트엔드 노드에 예약 인스턴스를 사용합니다. 백엔드 노드에 스팟 인스턴스를 \n사용합니다. \nC. 프런트엔드 노드에 스팟 인스턴스를 사용합니다. 백엔드 노드에 예약 인스턴스를 \n사용합니다. \nD. 프런트엔드 노드에 스팟 인스턴스를 사용합니다. 백엔드 노드에 AWS Fargate\n를 \n사용합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/109283-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "425": {"q_num": 425, "question": "회사는 높은 블록 스토리지 용량을 사용하여 온프레미스에서 워크로드를 실행합니다. \n회사의 일일 최대 입력 및 초당 출력 트랜잭션은 15,000 IOPS 를 넘지 않습니다. 이 회사는 \n워크로드를 Amazon EC2 로 마이그레이션하고 스토리지 용량과 독립적으로 디스크 성능을 \n프로비저닝하려고 합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 Amazon Elastic Block Store(Amazon \nEBS) 볼륨 유형은 무엇입니까? \nA. GP2 볼륨 유형 \nB. io2 볼륨 유형 \nC. GP3 볼륨 유형 \nD. io1 볼륨 유형", "answer_block": "Answer: C  \nhttps://www.examtopics.com/discussions/amazon/view/109282-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n이 답변은 기존 데이터를 AWS 로 안전하게 마이그레이션하는 요구 사항을 충족하고 새로운 \n규정을 충족하기 때문에 정답입니다. AWS DataSync 는 온프레미스 스토리지와 Amazon S3 \n간에 대량의 데이터를 온라인으로 쉽게 이동할 수 있게 해주는 서비스입니다. DataSync 는 \n전송 중인 데이터를 자동으로 암호화하고 전송 중에 데이터 무결성을 확인합니다. AWS \nCloudTrail 은 계정에 대한 AWS API 호출을 기록하고 로그 파일을 Amazon S3 에 전달하는 \n서비스입니다. CloudTrail 은 S3 객체 수준 API 활동과 같이 AWS 계정의 리소스에서 또는 \n리소스 내에서 수행된 리소스 작업을 보여주는 데이터 이벤트를 기록할 수 있습니다. \nCloudTrail 을 사용하여 데이터 이벤트를 기록하면 저장된 데이터의 모든 수준에서 액세스를 \n감사할 수 있습니다. \n \n참조: \nhttps://docs.aws.amazon.com/datasync/latest/userguide/what-is-datasync.html \nhttps://docs.aws.amazon.com/awscloudtrail/latest/userguide/logging-data-events-withcl\noudtrail.html", "answer_choice": "C"}, "426": {"q_num": 426, "question": "회사는 의료 애플리케이션의 데이터를 저장해야 합니다. 애플리케이션의 데이터는 자주 \n변경됩니다. 새로운 규정은 저장된 데이터의 모든 수준에서 감사 액세스를 요구합니다. \n회사는 스토리지 용량이 부족한 온프레미스 인프라에서 애플리케이션을 호스팅합니다. \n솔루션 \n설계자는 \n새로운 \n규정을 \n만족하면서 \n기존 \n데이터를 \nAWS\n로 \n안전하게 \n마이그레이션해야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. AWS DataSync 를 사용하여 기존 데이터를 Amazon S3 로 이동합니다. AWS CloudTrail 을 \n사용하여 데이터 이벤트를 기록합니다. \nB. AWS Snowcone 을 사용하여 기존 데이터를 Amazon S3 로 이동합니다. AWS CloudTrail 을 \n사용하여 관리 이벤트를 기록합니다. \nC. Amazon S3 Transfer Acceleration 을 사용하여 기존 데이터를 Amazon S3 로 이동합니다. \nAWS CloudTrail 을 사용하여 데이터 이벤트를 기록합니다. \nD. AWS Storage Gateway 를 사용하여 기존 데이터를 Amazon S3 로 이동합니다. AWS \nCloudTrail 을 사용하여 관리 이벤트를 기록합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/109278-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "427": {"q_num": 427, "question": "솔루션 아키텍트가 MySQL 데이터베이스로 복잡한 Java 애플리케이션을 구현하고 있습니다. \nJava 애플리케이션은 Apache Tomcat 에 배포되어야 하며 고가용성이어야 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. AWS Lambda 에 애플리케이션을 배포합니다. Lambda 함수와 연결하도록 Amazon API \nGateway API 를 구성합니다. \nB. AWS Elastic Beanstalk 를 사용하여 애플리케이션을 배포합니다. 부하 분산 환경 및 롤링 \n배포 정책을 구성합니다. \nC. 데이터베이스를 Amazon ElastiCache 로 마이그레이션합니다. 애플리케이션에서 액세스를 \n허용하도록 ElastiCache 보안 그룹을 구성합니다. \nD. Amazon EC2 인스턴스를 시작합니다. EC2 인스턴스에 MySQL 서버를 설치합니다. \n서버에서 애플리케이션을 구성합니다. AMI 를 생성합니다. AMI 를 사용하여 Auto Scaling \n그룹으로 시작 템플릿을 생성합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/109279-exam-aws-certified-sol\n\nutions-architect-associate-saa-c03/ \n \n설명:・ \nAWS Elastic Beanstalk 는 애플리케이션을 쉽고 빠르게 배포, 관리 및 확장할 수 있는 \n방법을 제공합니다. Java 및 Apache Tomcat 을 포함한 다양한 플랫폼을 지원합니다. 솔루션 \n설계자는 Elastic Beanstalk 를 사용하여 Java 애플리케이션을 업로드하고 Apache Tomcat 을 \n실행하도록 환경을 구성할 수 있습니다.", "answer_choice": "B"}, "428": {"q_num": 428, "question": "서버리스 애플리케이션은 Amazon API Gateway, AWS Lambda 및 Amazon DynamoDB 를 \n사용합니다. Lambda 함수에는 DynamoDB 테이블을 읽고 쓸 수 있는 권한이 필요합니다. \nDynamoDB 테이블에 대한 Lambda 함수 액세스를 가장 안전하게 제공하는 솔루션은 \n무엇입니까? \nA. Lambda 함수에 프로그래밍 방식으로 액세스할 수 있는 IAM 사용자를 생성합니다. \nDynamoDB 테이블에 대한 읽기 및 쓰기 액세스를 허용하는 정책을 사용자에게 연결합니다. \naccess_key_id 및 secret_access_key 파라미터를 Lambda 환경 변수의 일부로 저장합니다. \n다른 AWS 사용자에게 Lambda 함수 구성에 대한 읽기 및 쓰기 액세스 권한이 없는지 \n확인하십시오. \nB. Lambda 를 신뢰할 수 있는 서비스로 포함하는 IAM 역할을 생성합니다. DynamoDB \n테이블에 대한 읽기 및 쓰기 액세스를 허용하는 역할에 정책을 연결합니다. 새 역할을 실행 \n역할로 사용하도록 Lambda 함수의 구성을 업데이트합니다. \nC. Lambda 함수에 프로그래밍 방식으로 액세스할 수 있는 IAM 사용자를 생성합니다. \nDynamoDB 테이블에 대한 읽기 및 쓰기 액세스를 허용하는 정책을 사용자에게 연결합니다. \nAWS Systems Manager Parameter Store\n에 access_key_id 및 secret_access_key \n파라미터를 보안 문자열 파라미터로 저장합니다. DynamoDB 테이블에 연결하기 전에 보안 \n문자열 파라미터를 검색하도록 Lambda 함수 코드를 업데이트합니다. \nD. DynamoDB 를 신뢰할 수 있는 서비스로 포함하는 IAM 역할을 생성합니다. Lambda \n함수에서 읽기 및 쓰기 액세스를 허용하는 역할에 정책을 연결합니다. 새 역할에 실행 \n역할로 연결되도록 Lambda 함수의 코드를 업데이트합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/109285-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명:・ \n옵션 B\n는 Lambda\n를 신뢰할 수 있는 서비스로 포함하는 IAM 역할을 생성할 것을 \n\n제안합니다. 즉, 이 역할은 Lambda 함수용으로 특별히 설계되었습니다. 역할에는 \nDynamoDB 테이블에 대한 필수 읽기 및 쓰기 액세스 권한을 부여하는 정책이 연결되어 \n있어야 합니다.", "answer_choice": "B"}, "429": {"q_num": 429, "question": "다음 IAM 정책은 IAM 그룹에 연결됩니다. 이것은 그룹에 적용되는 유일한 정책입니다. \n \n그룹 구성원에 대한 이 정책의 유효 IAM 권한은 무엇입니까? \nA. 그룹 구성원은 us-east-1 지역 내 모든 Amazon EC2 작업이 허용됩니다. 허용 권한 \n이후의 문은 적용되지 않습니다. \nB. 그룹 구성원은 멀티 팩터 인증(MFA)으로 로그인하지 않는 한 us-east-1 리전에서 모든 \nAmazon EC2 권한이 거부됩니다. \nC. \n그룹 \n구성원은 \n멀티 \n팩터 \n인증(MFA)으로 \n로그인할 \n때 \n모든 \n리전에 \n대한 \nec2:StopInstances 및 ec2:TerminateInstances 권한이 허용됩니다. 그룹 구성원은 다른 \n\n모든 Amazon EC2 작업이 허용됩니다. \nD. 그룹 구성원은 멀티 팩터 인증(MFA)으로 로그인한 경우에만 us-east-1 리전에 대한 \nec2:StopInstances \n및 \nec2:TerminateInstances \n권한이 \n허용됩니다. \n그룹 \n구성원은 \nus-east-1 리전 내에서 다른 모든 Amazon EC2 작업이 허용됩니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/109286-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명:・ \n이 답변은 그룹 구성원에 대한 IAM 정책의 영향을 반영하기 때문에 정확합니다. 정책에는 \n두 개의 문이 있습니다. 하나는 허용 효과가 있고 다른 하나는 거부 효과가 있습니다. Allow \n문은 us-east-1 지역 내의 모든 리소스에 대해 EC2 작업을 수행할 수 있는 권한을 \n부여합니다. Deny 문은 Allow 문을 재정의하고 그룹 구성원이 MFA 로 로그인하지 않는 한 \nus-east-1 리전 내의 모든 리소스에 대해 ec2:StopInstances 및 ec2:TerminateInstances \n작업을 수행할 수 있는 권한을 거부합니다. 따라서 그룹 구성원은 모든 작업을 수행할 수 \n있습니다. MFA 를 사용하지 않는 한 us-east-1 리전에서 인스턴스 중지 또는 종료를 \n제외한 EC2 작업.", "answer_choice": "D"}, "430": {"q_num": 430, "question": "제조 회사에는 Amazon S3 버킷에 .csv 파일을 업로드하는 기계 센서가 있습니다. \n이러한 .csv 파일은 이미지로 변환되어야 하며 그래픽 보고서의 자동 생성을 위해 가능한 \n한 빨리 사용할 수 있어야 합니다. \n이미지는 1 개월이 지나면 관련이 없게 되지만 1 년에 두 번 기계 학습(ML) 모델을 \n훈련시키기 위해 .csv 파일을 보관해야 합니다. ML 교육 및 감사는 몇 주 전에 미리 \n계획됩니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 단계 조합은 무엇입니까? (2 개 선택) \nA. 매시간 .csv 파일을 다운로드하고 이미지 파일을 생성하며 이미지를 S3 버킷에 \n업로드하는 Amazon EC2 스팟 인스턴스를 시작합니다. \nB. .csv 파일을 이미지로 변환하고 이미지를 S3 버킷에 저장하는 AWS Lambda 함수를 \n설계합니다. .csv 파일이 업로드되면 Lambda 함수를 호출합니다. \nC. S3 버킷의 .csv 파일 및 이미지 파일에 대한 S3 수명 주기 규칙을 생성합니다. .csv \n파일을 업로드하고 1 일 후에 S3 Standard 에서 S3 Glacier 로 전환합니다. 30 일 후에 이미지 \n파일을 만료하십시오. \nD. S3 버킷의 .csv 파일 및 이미지 파일에 대한 S3 수명 주기 규칙을 생성합니다. 업로드 \n1 일 후 .csv 파일을 S3 Standard 에서 S3 One Zone-Infrequent Access(S3 One Zone-IA)로 \n\n전환합니다. 30 일 후에 이미지 파일을 만료하십시오. \nE. S3 버킷의 .csv 파일 및 이미지 파일에 대한 S3 수명 주기 규칙을 생성합니다. .csv \n파일을 업로드하고 1 일 후에 S3 Standard 에서 S3 Standard-Infrequent Access(S3 \nStandard-IA)로 전환합니다. RRS(Reduced Redundancy Storage)에 \n이미지 파일을 \n보관합니다.", "answer_block": "Answer: B, C \nhttps://www.examtopics.com/discussions/amazon/view/109288-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명:・ \n이러한 답변은 .csv 파일을 이미지로 변환하고 가능한 한 빨리 사용 가능하게 하며 \n스토리지 비용을 최소화하기 위한 요구 사항을 충족하므로 정확합니다. AWS Lambda 는 \n서버를 프로비저닝하거나 관리하지 않고 코드를 실행할 수 있는 서비스입니다. AWS \nLambda 를 사용하여 .csv 파일을 이미지로 변환하고 이미지를 S3 버킷에 저장하는 함수를 \n설계할 수 있습니다. \nS3 이벤트 알림을 사용하여 .csv 파일이 S3 버킷에 업로드될 때 Lambda 함수를 호출할 \n수 있습니다. 이렇게 하면 이미지가 생성되어 그래픽 보고서에 가능한 한 빨리 사용할 수 \n있습니다. S3 수명 주기는 개체가 수명 주기 동안 비용 효율적으로 저장되도록 개체를 \n관리할 수 있게 해주는 기능입니다. S3 버킷의 .csv 파일 및 이미지 파일에 대한 S3 수명 \n주기 규칙을 생성하여 비즈니스 요구 사항에 따라 다른 스토리지 클래스로 전환하거나 \n만료할 수 있습니다. .csv 파일은 몇 주 전에 계획된 ML 교육 및 감사에 1 년에 두 번만 \n필요하므로 업로드한 지 1 일 후에 S3 Standard 에서 S3 Glacier 로 전환할 수 있습니다. S3 \nGlacier 는 검색 시간이 몇 분에서 몇 시간에 이르는 안전하고 내구성이 있으며 매우 저렴한 \n스토리지를 제공하는 데이터 아카이빙용 스토리지 클래스입니다. \n이미지 파일은 1 개월이 지나면 관련성이 없어지므로 30 일 후에 만료될 수 있습니다. \n \n참조: \nhttps://docs.aws.amazon.com/lambda/latest/dg/welcome.html \nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/NotificationHowTo.html \nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lifecycle-mgmt.html \nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/storage-class-intro.html#sc-\nglacier", "answer_choice": "B"}, "431": {"q_num": 431, "question": "회사에서 웹 애플리케이션으로 새로운 비디오 게임을 개발했습니다. 애플리케이션은 \n\n데이터베이스 계층에 MySQL 용 Amazon RDS 가 있는 VPC 의 3 계층 아키텍처에 있습니다. \n여러 플레이어가 온라인에서 동시에 경쟁합니다. 게임 개발자는 거의 실시간으로 상위 \n10 개 점수판을 표시하고 현재 점수를 유지하면서 게임을 중지하고 복원할 수 있는 기능을 \n제공하고자 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. 웹 애플리케이션이 표시할 점수를 캐시하도록 Memcached 클러스터용 Amazon \nElastiCache 를 설정합니다. \nB. Redis 클러스터용 Amazon ElastiCache 를 설정하여 웹 애플리케이션이 표시할 점수를 \n계산하고 캐시합니다. \nC. 웹 애플리케이션 앞에 Amazon CloudFront 배포를 배치하여 애플리케이션 섹션의 \n점수판을 캐시합니다. \nD. MySQL 용 Amazon RDS 에서 읽기 전용 복제본을 생성하여 스코어보드를 계산하고 웹 \n애플리케이션에 읽기 트래픽을 제공하는 쿼리를 실행합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/109274-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명:・ \n이 답변은 거의 실시간으로 상위 10 개 점수판을 표시하고 현재 점수를 유지하면서 게임을 \n중지하고 복원할 수 있는 기능을 제공하는 요구 사항을 충족하므로 정확합니다. Redis 용 \nAmazon ElastiCache 는 인터넷 규모의 실시간 애플리케이션을 지원하기 위해 1 밀리초 \n미만의 지연 시간을 제공하는 초고속 인 메모리 데이터 스토어입니다. Redis 용 Amazon \nElastiCache 를 사용하여 Redis 용 ElastiCache 클러스터를 설정하여 웹 애플리케이션이 \n표시할 점수를 계산하고 캐시할 수 있습니다. 정렬된 세트 및 해시와 같은 Redis 데이터 \n구조를 사용하여 플레이어의 점수를 저장하고 순위를 매길 수 있으며 ZRANGE 및 ZADD 와 \n같은 Redis 명령을 사용하여 점수를 효율적으로 검색 및 업데이트할 수 있습니다. 또한 \n스냅샷 및 추가 전용 파일(AOF)과 같은 Redis 지속성 기능을 사용하여 데이터의 특정 시점 \n복구를 활성화할 수 있으므로 현재 점수를 유지하면서 게임을 중지하고 복원할 수 \n있습니다. \n \n참조: \nhttps://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/WhatIs.html \nhttps://redis.io/topics/data-types \nhttps://redis.io/topics/persistence", "answer_choice": "B"}, "432": {"q_num": 432, "question": "한 전자상거래 회사에서 기계 학습(ML) 알고리즘을 사용하여 모델을 구축하고 훈련하려고 \n합니다. 회사는 모델을 사용하여 복잡한 시나리오를 시각화하고 고객 데이터의 추세를 \n감지합니다. 아키텍처 팀은 ML 모델을 보고 플랫폼과 통합하여 증강 데이터를 분석하고 \n비즈니스 인텔리전스 대시보드에서 직접 데이터를 사용하려고 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. AWS Glue 를 사용하여 ML 변환을 생성하여 모델을 구축하고 교육합니다. Amazon \nOpenSearch Service 를 사용하여 데이터를 시각화합니다. \nB. Amazon SageMaker 를 사용하여 모델을 구축하고 교육합니다. Amazon QuickSight 를 \n사용하여 데이터를 시각화합니다. \nC. AWS Marketplace 에서 사전 구축된 ML Amazon 머신 이미지(AMI)를 사용하여 모델을 \n구축하고 교육합니다. Amazon OpenSearch Service 를 사용하여 데이터를 시각화합니다. \nD. Amazon QuickSight 를 사용하여 계산된 필드를 사용하여 모델을 구축하고 교육합니다. \nAmazon QuickSight 를 사용하여 데이터를 시각화합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/109291-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "433": {"q_num": 433, "question": "한 회사가 여러 AWS 계정에서 프로덕션 및 비프로덕션 환경 워크로드를 실행하고 \n있습니다. 계정은 AWS Organizations 의 조직에 있습니다. 회사는 비용 사용 태그의 수정을 \n방지하는 솔루션을 설계해야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 권한이 부여된 보안 주체 외에는 태그 수정을 방지하기 위해 사용자 지정 AWS Config \n규칙을 생성합니다. \nB. 태그 수정을 방지하기 위해 AWS CloudTrail 에서 사용자 지정 추적을 생성합니다. \nC. 인증된 주체 외에는 태그 수정을 방지하기 위해 서비스 제어 정책(SCP)을 생성합니다. \nD. 태그 수정을 방지하기 위해 사용자 지정 Amazon CloudWatch 로그를 생성합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/109384-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "434": {"q_num": 434, "question": "회사는 AWS 클라우드에서 애플리케이션을 호스팅합니다. 이 애플리케이션은 Amazon \n\nDynamoDB 테이블과 함께 Auto Scaling 그룹의 Elastic Load Balancer 뒤에 있는 Amazon \nEC2 인스턴스에서 실행됩니다. 회사는 다운타임을 최소화하면서 다른 AWS 리전에서 \n애플리케이션을 사용할 수 있기를 원합니다. \n가동 중지 시간을 최소화하면서 이러한 요구 사항을 충족하려면 솔루션 설계자가 무엇을 \n해야 합니까? \nA. 재해 복구 지역에 Auto Scaling 그룹과 로드 밸런서를 생성합니다. DynamoDB 테이블을 \n전역 테이블로 구성합니다. 새 재해 복구 리전의 로드 밸런서를 가리키도록 DNS 장애 \n조치를 구성합니다. \nB. 필요할 때 시작할 EC2 인스턴스, 로드 밸런서 및 DynamoDB 테이블을 생성하기 위해 \nAWS CloudFormation 템플릿을 생성합니다. 새 재해 복구 리전의 로드 밸런서를 \n가리키도록 DNS 장애 조치를 구성합니다. \nC. AWS CloudFormation 템플릿을 생성하여 EC2 인스턴스와 필요할 때 실행할 로드 \n밸런서를 생성합니다. DynamoDB 테이블을 전역 테이블로 구성합니다. 새 재해 복구 \n리전의 로드 밸런서를 가리키도록 DNS 장애 조치를 구성합니다. \nD. 재해 복구 지역에서 Auto Scaling 그룹 및 로드 밸런서를 생성합니다. DynamoDB \n테이블을 전역 테이블로 구성합니다. 재해 복구 로드 밸런서를 가리키는 Amazon Route \n53\n을 업데이트하는 AWS Lambda 함수를 트리거하는 Amazon CloudWatch 경보를 \n생성합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/109294-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n이 답변은 기존 데이터를 AWS 로 안전하게 마이그레이션하는 요구 사항을 충족하고 새로운 \n규정을 충족하기 때문에 정답입니다. AWS DataSync 는 온프레미스 스토리지와 Amazon S3 \n간에 대량의 데이터를 온라인으로 쉽게 이동할 수 있게 해주는 서비스입니다. DataSync 는 \n전송 중인 데이터를 자동으로 암호화하고 전송 중에 데이터 무결성을 확인합니다. AWS \nCloudTrail 은 계정에 대한 AWS API 호출을 기록하고 로그 파일을 Amazon S3 에 전달하는 \n서비스입니다. CloudTrail 은 S3 객체 수준 API 활동과 같이 AWS 계정의 리소스에서 또는 \n리소스 내에서 수행된 리소스 작업을 보여주는 데이터 이벤트를 기록할 수 있습니다. \nCloudTrail 을 사용하여 데이터 이벤트를 기록하면 저장된 데이터의 모든 수준에서 액세스를 \n감사할 수 있습니다. \n \n참조: \nhttps://docs.aws.amazon.com/datasync/latest/userguide/what-is-datasync.html \nhttps://docs.aws.amazon.com/awscloudtrail/latest/userguide/logging-data-events-withcl\n\noudtrail.html", "answer_choice": "A"}, "435": {"q_num": 435, "question": "회사는 2\n주 이내에 온프레미스 데이터 센터에서 AWS\n로 MySQL 데이터베이스를 \n마이그레이션해야 \n합니다. \n데이터베이스 \n크기는 \n20TB\n입니다. \n회사는 \n다운타임을 \n최소화하면서 마이그레이션을 완료하기를 원합니다. \n데이터베이스를 가장 비용 효율적으로 마이그레이션하는 솔루션은 무엇입니까? \nA. AWS Snowball Edge Storage Optimized 디바이스를 주문합니다. AWS Schema \nConversion Tool(AWS SCT)과 함께 AWS Database Migration Service(AWS DMS)를 \n사용하여 진행 중인 변경 사항을 복제하여 데이터베이스를 마이그레이션합니다. Snowball \nEdge 디바이스를 AWS 로 보내 마이그레이션을 완료하고 진행 중인 복제를 계속합니다. \nB. AWS Snowmobile 차량을 주문합니다. AWS Schema Conversion Tool(AWS SCT)과 함께 \nAWS Database Migration Service(AWS DMS)를 사용하여 지속적인 변경 사항이 있는 \n데이터베이스를 \n마이그레이션합니다. \nSnowmobile \n차량을 \n다시 \nAWS\n로 \n보내 \n마이그레이션을 완료하고 진행 중인 복제를 계속합니다. \nC. GPU 장치로 AWS Snowball Edge Compute Optimized 를 주문합니다. AWS Schema \nConversion Tool(AWS SCT)과 함께 AWS Database Migration Service(AWS DMS)를 \n사용하여 지속적인 변경 사항이 있는 데이터베이스를 마이그레이션합니다. Snowball \n디바이스를 AWS 로 보내 마이그레이션을 완료하고 진행 중인 복제를 계속합니다. \nD. 1GB 전용 AWS Direct Connect 연결을 주문하여 데이터 센터와의 연결을 설정합니다. \nAWS Schema Conversion Tool(AWS SCT)과 함께 AWS Database Migration Service(AWS \nDMS)를 사용하여 진행 중인 변경 사항을 복제하여 데이터베이스를 마이그레이션합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/109377-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n이 대답은 가동 중지 시간을 최소화하고 비용 효율적으로 2 주 이내에 20TB MySQL \n데이터베이스를 마이그레이션해야 하는 요구 사항을 충족하기 때문에 정답입니다. AWS \nSnowball Edge Storage Optimized 디바이스에는 최대 80TB 의 사용 가능한 스토리지 \n공간이 있으며 이는 데이터베이스에 적합합니다. AWS Database Migration Service(AWS \nDMS)는 소스에서 대상으로 변경 사항을 지속적으로 복제하여 다운타임을 최소화하면서 \nMySQL 에서 Amazon Aurora, Amazon RDS for MySQL 또는 Amazon EC2 의 MySQL 로 \n데이터를 마이그레이션할 수 있습니다. AWS Schema Conversion Tool(AWS SCT)은 소스 \n스키마와 코드를 대상 데이터베이스와 호환되는 형식으로 변환할 수 있습니다. 이러한 \n\n서비스를 함께 사용함으로써 회사는 가동 중지 시간과 비용을 최소화하면서 데이터베이스를 \nAWS 로 마이그레이션할 수 있습니다. \nSnowball \nEdge \n디바이스를 \n다시 \nAWS\n로 \n배송하여 \n마이그레이션을 \n완료하고 \n데이터베이스가 완전히 마이그레이션될 때까지 지속적인 복제를 계속할 수 있습니다. \n \n참조: \nhttps://docs.aws.amazon.com/snowball/latest/developer-guide/device-differences.html \nhttps://docs.aws.amazon.com/dms/latest/userguide/CHAP_Source.MySQL.html \nhttps://docs.aws.amazon.com/SchemaConversionTool/latest/userguide/CHAP_Source.My\nSQL.htm", "answer_choice": "A"}, "436": {"q_num": 436, "question": "회사에서 온프레미스 PostgreSQL 데이터베이스를 Amazon RDS for PostgreSQL DB \n인스턴스로 \n옮겼습니다. \n회사는 \n신제품을 \n성공적으로 \n출시했습니다. \n데이터베이스의 \n워크로드가 증가했습니다. 회사는 인프라를 추가하지 않고 더 큰 워크로드를 수용하려고 \n합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. 전체 워크로드에 대해 예약된 DB 인스턴스를 구매합니다. PostgreSQL DB 인스턴스용 \nAmazon RDS 를 더 크게 만듭니다. \nB. Amazon RDS for PostgreSQL DB 인스턴스를 다중 AZ DB 인스턴스로 만듭니다. \nC. GPU 장치로 AWS Snowball Edge Compute Optimized 를 주문합니다. AWS Schema \nConversion Tool(AWS SCT)과 함께 AWS Database Migration Service(AWS DMS)를 \n사용하여 지속적인 변경 사항이 있는 데이터베이스를 마이그레이션합니다. Snowball \n디바이스를 AWS 로 보내 마이그레이션을 완료하고 진행 중인 복제를 계속합니다. \nD. Amazon RDS for PostgreSQL DB 인스턴스를 온디맨드 DB 인스턴스로 만듭니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/109277-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명:・ \n이 대답은 인프라를 추가하지 않고 비용을 최소화하지 않고 더 큰 워크로드를 수용하는 \n요구 사항을 충족하기 때문에 맞습니다. 예약 DB 인스턴스는 계정에서 특정 온디맨드 DB \n인스턴스 사용에 적용되는 청구 할인입니다. 예약 DB 인스턴스는 온디맨드 DB 인스턴스 \n요금에 비해 상당한 할인을 제공합니다. 총 워크로드에 대해 예약된 DB 인스턴스를 \n구입하고 선결제 없음, 부분 선결제 또는 전체 선결제의 세 가지 결제 옵션 중에서 선택할 \n\n수 있습니다. 인스턴스 유형을 더 높은 성능 클래스로 수정하여 Amazon RDS for \nPostgreSQL DB 인스턴스를 더 크게 만들 수 있습니다. 이렇게 하면 DB 인스턴스의 CPU, \n메모리 및 네트워크 용량을 늘리고 늘어난 워크로드를 처리할 수 있습니다. \n \n참조: \nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithReserved\nDBInstances.html \nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.DBInstanceClass.\nhtml", "answer_choice": "A"}, "437": {"q_num": 437, "question": "회사는 Auto Scaling 그룹의 Application Load Balancer(ALB) 뒤에 있는 Amazon EC2 \n인스턴스에서 전자상거래 웹 사이트를 운영합니다. 사이트에서 IP 주소가 변경되는 불법 \n외부 시스템의 높은 요청 비율과 관련된 성능 문제가 발생하고 있습니다. 보안 팀은 웹 \n사이트에 대한 잠재적인 DDoS 공격에 대해 걱정하고 있습니다. 회사는 합법적인 \n사용자에게 최소한의 영향을 미치는 방식으로 불법적으로 들어오는 요청을 차단해야 \n합니다. \n솔루션 설계자는 무엇을 추천해야 합니까? \nA. Amazon Inspector 를 배포하고 ALB 와 연결합니다. \nB. AWS WAF 를 배포하고 ALB 와 연결하고 속도 제한 규칙을 구성합니다. \nC. 들어오는 트래픽을 차단하기 위해 ALB 와 연결된 네트워크 ACL 에 규칙을 배포합니다. \nD. Amazon GuardDuty\n를 배포하고 GuardDuty\n를 구성할 때 속도 제한 보호를 \n활성화합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/109378-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명:・ \n이 답변은 합법적인 사용자에게 최소한의 영향을 미치는 방식으로 불법적으로 들어오는 \n요청을 차단하는 요구 사항을 충족하기 때문에 정확합니다. AWS WAF 는 가용성에 영향을 \n미치거나 \n보안을 \n손상시키거나 \n과도한 \n리소스를 \n소비할 \n수 \n있는 \n일반적인 \n웹 \n익스플로잇으로부터 웹 애플리케이션 또는 API\n를 보호하는 데 도움이 되는 웹 \n애플리케이션 방화벽입니다. AWS WAF 는 SQL 삽입 또는 사이트 간 스크립팅과 같은 \n일반적인 공격 패턴을 차단하는 보안 규칙과 정의한 특정 트래픽 패턴을 필터링하는 규칙을 \n생성할 수 있도록 하여 트래픽이 애플리케이션에 도달하는 방식을 제어할 수 있습니다. \n\nAWS WAF 를 ALB 와 연결하여 악의적인 요청으로부터 웹 애플리케이션을 보호할 수 \n있습니다. 각 발신 IP 주소에 대한 요청 속도를 추적하고 5 분 이내에 특정 제한을 초과하는 \nIP 주소의 요청을 차단하도록 AWS WAF 에서 속도 제한 규칙을 구성할 수 있습니다. 이렇게 \n하면 잠재적인 DDoS 공격을 완화하고 웹 사이트의 성능을 향상시킬 수 있습니다. \n \n참조: \nhttps://docs.aws.amazon.com/waf/latest/developerguide/what-is-aws-waf.html \nhttps://docs.aws.amazon.com/waf/latest/developerguide/waf-rule-statement-type-rate-\nbased.html", "answer_choice": "B"}, "438": {"q_num": 438, "question": "회사에서 외부 감사인과 회계 데이터를 공유하려고 합니다. 데이터는 프라이빗 서브넷에 \n상주하는 Amazon RDS DB 인스턴스에 저장됩니다. 감사자는 자체 AWS 계정이 있으며 \n자체 데이터베이스 사본이 필요합니다. \n회사가 감사자와 데이터베이스를 공유하는 가장 안전한 방법은 무엇입니까? \nA. 데이터베이스의 읽기 전용 복제본을 생성합니다. 감사자 액세스 권한을 부여하도록 IAM \n표준 데이터베이스 인증을 구성합니다. \nB. 데이터베이스 내용을 텍스트 파일로 내보냅니다. 파일을 Amazon S3 버킷에 저장합니다. \n감사자를 위한 새 IAM 사용자를 생성합니다. 사용자에게 S3 버킷에 대한 액세스 권한을 \n부여합니다. \nC. 데이터베이스의 스냅샷을 Amazon S3 버킷에 복사합니다. IAM 사용자를 생성합니다. \n사용자의 키를 감사자와 공유하여 S3 버킷의 객체에 대한 액세스 권한을 부여합니다. \nD. 데이터베이스의 암호화된 스냅샷을 생성합니다. 감사자와 스냅샷을 공유합니다. AWS \nKey Management Service(AWS KMS) 암호화 키에 대한 액세스를 허용합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/109398-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명:・ \n이 대답은 안전한 방식으로 감사자와 데이터베이스를 공유하는 요구 사항을 충족하기 \n때문에 정확합니다. AWS Key Management Service(AWS KMS)를 사용하여 데이터베이스의 \n암호화된 스냅샷을 생성하여 고객 관리형 키로 스냅샷을 암호화할 수 있습니다. 스냅샷의 \n권한을 수정하고 감사자의 AWS 계정 ID\n를 지정하여 감사자와 스냅샷을 공유할 수 \n있습니다. 감사자의 계정에 권한을 부여하는 키 정책 설명을 추가하여 AWS KMS 암호화 \n키에 대한 액세스를 허용할 수도 있습니다. 이렇게 하면 감사자만 자신의 AWS 계정에서 \n\n스냅샷에 액세스하고 복원할 수 있습니다. \n \n참조: \nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ShareSnapshot.html \nhttps://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html#key-policy-\ndefaultallow-root-enable-iam", "answer_choice": "D"}, "439": {"q_num": 439, "question": "솔루션 설계자는 IP 주소 범위가 작은 VPC 를 구성했습니다. VPC 에 있는 Amazon EC2 \n인스턴스의 수가 증가하고 있으며 향후 워크로드를 위한 IP 주소의 수가 부족합니다. \n최소한의 운영 오버헤드로 이 문제를 해결하는 솔루션은 무엇입니까? \nA. 추가 IPv4 CIDR 블록을 추가하여 IP 주소 수를 늘리고 VPC 에 추가 서브넷을 만듭니다. \n새 CIDR 을 사용하여 새 서브넷에 새 리소스를 만듭니다. \nB. 추가 서브넷이 있는 두 번째 VPC 를 생성합니다. 피어링 연결을 사용하여 두 번째 \nVPC 를 첫 번째 VPC 와 연결 경로를 업데이트하고 두 번째 VPC 의 서브넷에서 새 리소스를 \n생성합니다. \nC. AWS Transit Gateway 를 사용하여 transit gateway 를 추가하고 첫 번째 VPUpdate 에 두 \n번째 VPC 를 연결하여 transit gateway 및 VPC 의 경로를 업데이트합니다. 두 번째 VPC 의 \n서브넷에 새 리소스를 만듭니다. \nD. 두 번째 VPC 를 생성합니다. Amazon EC2 및 가상 프라이빗 게이트웨이에서 VPN \n호스팅 솔루션을 사용하여 첫 번째 VPC 와 두 번째 VPC 간에 사이트 간 VPN 연결을 \n생성합니다. VPC 간 경로를 VPN 을 통한 트래픽으로 업데이트합니다. 두 번째 VPC 의 \n서브넷에 새 리소스를 만듭니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/109400-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "440": {"q_num": 440, "question": "한 회사에서 애플리케이션 테스트 중에 Amazon RDS for MySQL DB 인스턴스를 \n사용했습니다. 테스트 주기가 끝날 때 DB 인스턴스를 종료하기 전에 솔루션 설계자는 두 \n개의 \n백업을 \n생성했습니다. \n솔루션 \n설계자는 \n데이터베이스 \n덤프를 \n생성하기 \n위해 \nmysqldump 유틸리티를 사용하여 첫 번째 백업을 생성했습니다. 솔루션 설계자는 RDS \n종료 시 최종 DB 스냅샷 옵션을 활성화하여 두 번째 백업을 생성했습니다. \n회사는 이제 새로운 테스트 주기를 계획하고 있으며 가장 최근 백업에서 새 DB 인스턴스를 \n\n생성하려고 합니다. 이 회사는 DB 인스턴스를 호스팅하기 위해 Amazon Aurora 의 MySQL \n호환 에디션을 선택했습니다. \n어떤 솔루션이 새 DB 인스턴스를 생성합니까? (2 개 선택) \nA. RDS 스냅샷을 Aurora 로 직접 가져옵니다. \nB. RDS 스냅샷을 Amazon S3 에 업로드합니다. 그런 다음 RDS 스냅샷을 Aurora 로 \n가져옵니다. \nC. 데이터베이스 덤프를 Amazon S3 에 업로드합니다. 그런 다음 데이터베이스 덤프를 \nAurora 로 가져옵니다. \nD. AWS Database Migration Service(AWS DMS)를 사용하여 RDS 스냅샷을 Aurora 로 \n가져옵니다. \nE. 데이터베이스 덤프를 Amazon S3 에 업로드합니다. 그런 다음 AWS Database Migration \nService(AWS DMS)를 사용하여 데이터베이스 덤프를 Aurora 로 가져옵니다.", "answer_block": "Answer: A, C \nhttps://www.examtopics.com/discussions/amazon/view/109297-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명:・ \n이러한 답변은 최신 백업에서 새 DB 인스턴스를 생성하고 Amazon Aurora 의 MySQL 호환 \n에디션을 사용하여 DB 인스턴스를 호스팅해야 하는 요구 사항을 충족하기 때문에 \n정확합니다. MySQL DB 인스턴스와 Aurora DB 클러스터가 동일한 버전의 MySQL 을 실행 \n중인 경우 RDS 스냅샷을 Aurora 로 직접 가져올 수 있습니다. 예를 들어 MySQL 버전 5.6 \n스냅샷을 Aurora MySQL 버전 5.6 으로 직접 복원할 수 있지만 MySQL 버전 5.6 스냅샷을 \nAurora MySQL 버전 5.7 로 직접 복원할 수는 없습니다. 이 방법은 간단하고 가장 적은 수의 \n단계가 필요합니다. MySQL DB 인스턴스와 Aurora DB 클러스터가 다른 버전의 MySQL 을 \n실행 중인 경우 데이터베이스 덤프를 Amazon S3 에 업로드한 다음 Aurora 로 데이터베이스 \n덤프를 가져올 수 있습니다. 예를 들어 MySQL 버전 5.6 데이터베이스 덤프를 Aurora \nMySQL 버전 5.7 로 가져올 수 있지만 MySQL 버전 5.6 스냅샷을 Aurora MySQL 버전 \n5.7 로 직접 복원할 수는 없습니다. \n이 방법은 더 유연하며 다른 버전의 MySQL 간에 마이그레이션할 수 있습니다. \n \n참조: \nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Migrati\nng.RDSMySQL.Import.html \nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Migrati\nng.RDSMySQL.Dump.html", "answer_choice": "A"}, "441": {"q_num": 441, "question": "회사는 Application Load Balancer 뒤의 Amazon Linux Amazon EC2 인스턴스에서 다중 \n계층 웹 애플리케이션을 호스팅합니다. 인스턴스는 여러 가용 영역의 Auto Scaling \n그룹에서 실행됩니다. 이 회사는 애플리케이션의 최종 사용자가 대량의 정적 웹 콘텐츠에 \n액세스할 때 Auto Scaling 그룹이 더 많은 온디맨드 인스턴스를 시작하는 것을 관찰합니다. \n회사는 비용을 최적화하려고 합니다. \n애플리케이션을 가장 비용 효율적으로 재설계하기 위해 솔루션 설계자는 무엇을 해야 \n합니까? \nA. \n온디맨드 \n인스턴스 \n대신 \n예약 \n인스턴스를 \n사용하도록 \nAuto \nScaling \n그룹을 \n업데이트합니다. \nB. 온디맨드 인스턴스 대신 스팟 인스턴스를 시작하여 조정하도록 Auto Scaling 그룹을 \n업데이트합니다. \nC. Amazon S3 버킷에서 정적 웹 콘텐츠를 호스팅할 Amazon CloudFront 배포를 만듭니다. \nD. Amazon API Gateway API 뒤에 AWS Lambda 함수를 생성하여 정적 웹 사이트 콘텐츠를 \n호스팅합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/109423-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명:・ \n이 대답은 비용을 최적화하고 데이터베이스의 작업 부하를 줄이는 요구 사항을 충족하므로 \n정확합니다. Amazon CloudFront 는 .html, .css, .js 및 이미지 파일과 같은 정적 및 동적 웹 \n콘텐츠를 \n사용자에게 \n빠르게 \n배포하는 \n콘텐츠 \n전송 \n네트워크(CDN) \n서비스입니다. \nCloudFront 는 엣지 로케이션이라고 하는 전 세계 데이터 센터 네트워크를 통해 콘텐츠를 \n제공합니다. CloudFront 에서 제공하는 콘텐츠를 사용자가 요청하면 지연 시간(시간 지연)이 \n가장 짧은 엣지 로케이션으로 요청이 라우팅되므로 콘텐츠가 가능한 최상의 성능으로 \n제공됩니다. Amazon CloudFront 배포를 생성하여 CloudFront 에 대해 정의하는 오리진인 \nAmazon S3 버킷에서 정적 웹 콘텐츠를 호스팅할 수 있습니다. \n이렇게 하면 정적 웹 콘텐츠에 대한 요청을 EC2 인스턴스에서 CloudFront 로 오프로드할 \n수 있으므로 웹 사이트의 성능과 가용성을 개선하고 EC2 인스턴스 실행 비용을 줄일 수 \n있습니다. \n \n참조: \nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Introduction.ht\nml \n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/WebsiteHosting.html", "answer_choice": "C"}, "442": {"q_num": 442, "question": "한 회사가 여러 AWS 계정에 몇 페타바이트의 데이터를 저장합니다. 이 회사는 AWS Lake \nFormation\n을 사용하여 데이터 레이크를 관리합니다. 회사의 데이터 과학 팀은 분석 \n목적으로 회사의 엔지니어링 팀과 계정에서 선택한 데이터를 안전하게 공유하려고 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 필요한 데이터를 공통 계정에 복사하십시오. 해당 계정에서 IAM 액세스 역할을 \n생성합니다. 엔지니어링 팀 계정의 사용자를 신뢰할 수 있는 엔터티로 포함하는 권한 \n정책을 지정하여 액세스 권한을 부여합니다. \nB. 필요한 엔지니어링 팀 사용자가 데이터에 액세스할 수 있도록 데이터가 저장된 각 \n계정에서 Lake Formation 권한 부여 명령을 사용합니다. \nC. AWS Data Exchange 를 사용하여 필요한 데이터를 필요한 엔지니어링 팀 계정에 \n비공개로 게시합니다. \nD. Lake Formation 태그 기반 액세스 제어를 사용하여 엔지니어링 팀 계정에 필요한 \n데이터에 대한 교차 계정 권한을 승인하고 부여합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/109647-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "D"}, "443": {"q_num": 443, "question": "회사는 AWS 에서 확장 가능한 웹 애플리케이션을 호스팅하려고 합니다. 응용 프로그램은 \n전 세계 여러 지역의 사용자가 액세스할 수 있습니다. 애플리케이션 사용자는 최대 \n기가바이트 크기의 고유한 데이터를 다운로드하고 업로드할 수 있습니다. 개발 팀은 업로드 \n및 다운로드 대기 시간을 최소화하고 성능을 최대화할 수 있는 비용 효율적인 솔루션을 \n원합니다. \n이를 달성하기 위해 솔루션 설계자는 무엇을 해야 합니까? \nA. Transfer Acceleration 과 함께 Amazon S3 를 사용하여 애플리케이션을 호스팅합니다. \nB. CacheControl 헤더와 함께 Amazon S3 를 사용하여 애플리케이션을 호스팅합니다. \nC. Auto Scaling 및 Amazon CloudFront 와 함께 Amazon EC2 를 사용하여 애플리케이션을 \n호스팅합니다. \nD. Auto Scaling 및 Amazon ElastiCache 와 함께 Amazon EC2 를 사용하여 애플리케이션을 \n호스팅합니다.", "answer_block": "Answer: A \n\nhttps://www.examtopics.com/discussions/amazon/view/109424-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "444": {"q_num": 444, "question": "회사에서 \n응용 \n프로그램의 \n안정적인 \n아키텍처를 \n설계하기 \n위해 \n솔루션 \n설계자를 \n고용했습니다. 이 애플리케이션은 웹 서버를 실행하는 Amazon RDS DB 인스턴스 1 개와 \n수동으로 프로비저닝된 Amazon EC2 인스턴스 2 개로 구성됩니다. EC2 인스턴스는 단일 \n가용 영역에 있습니다. \n직원이 최근 DB 인스턴스를 삭제했고 그 결과 애플리케이션을 24 시간 동안 사용할 수 \n없었습니다. 회사는 환경의 전반적인 안정성에 관심이 있습니다. \n애플리케이션 인프라의 안정성을 극대화하기 위해 솔루션 설계자는 무엇을 해야 합니까? \nA. 하나의 EC2 인스턴스를 삭제하고 다른 EC2 인스턴스에서 종료 방지 기능을 \n활성화합니다. 다중 AZ 가 되도록 DB 인스턴스를 업데이트하고 삭제 방지를 활성화합니다. \nB. DB 인스턴스를 다중 AZ 로 업데이트하고 삭제 방지를 활성화합니다. Application Load \nBalancer 뒤에 EC2 인스턴스를 배치하고 여러 가용 영역에 걸쳐 EC2 Auto Scaling \n그룹에서 실행합니다. \nC. Amazon API Gateway 및 AWS Lambda 함수와 함께 추가 DB 인스턴스를 생성합니다. \nAPI Gateway 를 통해 Lambda 함수를 호출하도록 애플리케이션을 구성합니다. Lambda \n함수가 두 DB 인스턴스에 데이터를 쓰도록 합니다. \nD. 여러 가용 영역에 여러 서브넷이 있는 EC2 Auto Scaling 그룹에 EC2 인스턴스를 \n배치합니다. 온디맨드 인스턴스 대신 스팟 인스턴스를 사용하십시오. 인스턴스의 상태를 \n모니터링하도록 Amazon CloudWatch 경보를 설정합니다. DB 인스턴스를 다중 AZ 로 \n업데이트하고 삭제 방지를 활성화합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/109426-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명:・ \n이 대답은 응용 프로그램 인프라의 안정성을 최대화하기 위한 요구 사항을 충족하기 때문에 \n정확합니다. DB 인스턴스를 다중 AZ 로 업데이트할 수 있습니다. 즉, Amazon RDS 가 다른 \n가용 영역에서 동기식 대기 복제본을 자동으로 프로비저닝하고 유지합니다. 기본 DB \n인스턴스는 가용 영역 전체에서 대기 복제본으로 동기식으로 복제되어 데이터 중복성을 \n제공하고 시스템 백업 중에 지연 시간 급증을 최소화합니다. \n고가용성으로 DB 인스턴스를 실행하면 계획된 시스템 유지 관리 중에 가용성을 높일 수 \n있습니다. 또한 DB 인스턴스 장애 및 가용 영역 중단으로부터 데이터베이스를 보호하는 데 \n\n도움이 될 수 있습니다. 또한 DB 인스턴스에서 삭제 보호를 활성화하여 어떤 사용자도 DB \n인스턴스를 삭제하지 못하도록 할 수 있습니다. 여러 가용 영역에서 EC2 인스턴스와 같은 \n여러 대상에 수신 애플리케이션 트래픽을 분산하는 Application Load Balancer 뒤에 EC2 \n인스턴스를 배치할 수 있습니다. 이렇게 하면 애플리케이션의 가용성과 내결함성이 \n향상됩니다. \n여러 가용 영역의 EC2 Auto Scaling 그룹에서 EC2 인스턴스를 실행할 수 있으므로 \n애플리케이션 로드를 처리하는 데 사용할 수 있는 정확한 수의 EC2 인스턴스를 확보할 수 \n있습니다. 조정 정책을 사용하여 수요 변화에 따라 Auto Scaling 그룹의 인스턴스 수를 \n조정할 수 있습니다. \n \n참조: \nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZSingleStan\ndby.html \nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_DeleteInstance.html#\nUSER_DeleteInstance.DeletionProtection \nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html \nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/AutoScalingGroup.html", "answer_choice": "B"}, "445": {"q_num": 445, "question": "회사는 \n회사 \n데이터 \n센터의 \n대규모 \nNAS(Network-Attached \nStorage) \n시스템에 \n700 테라바이트의 데이터를 저장하고 있습니다. 이 회사는 10Gbps AWS Direct Connect \n연결을 사용하는 하이브리드 환경을 보유하고 있습니다. \n규제 기관의 감사 후 회사는 90 일 이내에 데이터를 클라우드로 옮길 수 있습니다. 회사는 \n데이터를 중단 없이 효율적으로 이동해야 합니다. 회사는 여전히 이전 기간 동안 데이터에 \n액세스하고 데이터를 업데이트할 수 있어야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 회사 데이터 센터에서 AWS DataSync 에이전트를 생성합니다. 데이터 전송 작업 생성 \nAmazon S3 버킷으로의 전송을 시작합니다. \nB. 데이터를 AWS Snowball Edge Storage Optimized 디바이스에 백업합니다. 디바이스를 \nAWS 데이터 센터로 배송합니다. 온프레미스 파일 시스템에 대상 Amazon S3 버킷을 \n탑재합니다. \nC. DataSync 를 사용하여 Direct Connect 연결을 통해 로컬 스토리지에서 지정된 Amazon \nS3 버킷으로 데이터를 직접 복사합니다. \nD. 테이프에 데이터를 백업합니다. 테이프를 AWS 데이터 센터로 배송합니다. 온프레미스 \n파일 시스템에 대상 Amazon S3 버킷을 탑재합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/109403-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명:・ \n이 답변은 중단 없이 데이터를 효율적으로 이동하고 전송 기간 동안 데이터에 계속 \n액세스하고 업데이트할 수 있어야 한다는 요구 사항을 충족하기 때문에 정답입니다. AWS \nDataSync 는 AWS 로의 데이터 마이그레이션을 간소화 및 가속화하고 온프레미스 스토리지, \n엣지 로케이션, 기타 클라우드 및 AWS 스토리지 간에 데이터를 빠르고 안전하게 이동할 수 \n있도록 지원하는 온라인 데이터 이동 및 검색 서비스입니다. 회사 데이터 센터에서 AWS \nDataSync 에이전트를 생성하여 Direct Connect 연결을 통해 NAS 시스템을 AWS 에 연결할 \n수 있습니다. 데이터 전송 작업을 생성하여 소스 위치, 대상 위치 및 데이터 전송 옵션을 \n지정할 수 있습니다. Amazon S3 버킷으로 전송을 시작하고 작업 진행 상황을 모니터링할 \n수 있습니다. \nDataSync\n는 전송 중인 데이터를 자동으로 암호화하고 전송 중에 데이터 무결성을 \n확인합니다. DataSync 는 증분 전송도 지원합니다. 즉, 마지막 전송 이후 변경된 파일만 \n복사됩니다. 이렇게 하면 NAS 시스템과 S3 버킷 간에 데이터가 동기화되었는지 확인할 수 \n있으며 전송 기간 동안 데이터에 액세스하고 데이터를 업데이트할 수 있습니다. \n \n참조: \nhttps://docs.aws.amazon.com/datasync/latest/userguide/what-is-datasync.html \nhttps://docs.aws.amazon.com/datasync/latest/userguide/how-datasync-works.html", "answer_choice": "A"}, "446": {"q_num": 446, "question": "회사는 데이터를 Amazon S3 버킷에 PDF 형식으로 저장합니다. 회사는 모든 신규 및 기존 \n데이터를 Amazon S3 에 7 년 동안 보관해야 한다는 법적 요구 사항을 따라야 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. S3 버킷에 대한 S3 버전 관리 기능을 켭니다. 7 년 후 데이터를 삭제하도록 S3 수명 \n주기를 구성합니다. 모든 S3 객체에 대한 MFA(Multi-Factor Authentication) 삭제를 \n구성합니다. \nB. S3 버킷에 대한 거버넌스 보존 모드로 S3 객체 잠금을 켭니다. 7 년 후에 만료되도록 \n보존 기간을 설정합니다. 모든 기존 개체를 다시 복사하여 기존 데이터를 준수하도록 \n합니다. \nC. S3 버킷에 대해 규정 준수 보존 모드로 S3 객체 잠금을 켭니다. 7 년 후에 만료되도록 \n보존 기간을 설정합니다. 모든 기존 개체를 다시 복사하여 기존 데이터를 준수하도록 \n\n합니다. \nD. S3 버킷에 대해 규정 준수 보존 모드로 S3 객체 잠금을 켭니다. 7 년 후에 만료되도록 \n보존 기간을 설정합니다. S3 배치 작업을 사용하여 기존 데이터를 규정에 맞게 가져옵니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/109404-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "D"}, "447": {"q_num": 447, "question": "회사에는 Amazon API Gateway 에서 호출하는 AWS Lambda 함수에서 실행되는 상태 \n비저장 웹 애플리케이션이 있습니다. 회사는 지역 장애 조치 기능을 제공하기 위해 여러 \nAWS 지역에 애플리케이션을 배포하려고 합니다. \n트래픽을 여러 지역으로 라우팅하려면 솔루션 설계자가 무엇을 해야 합니까? \nA. 각 지역에 대해 Amazon Route 53 상태 확인을 생성합니다. 활성-활성 장애 조치 \n구성을 사용합니다. \nB. 각 리전의 오리진을 사용하여 Amazon CloudFront 배포를 생성합니다. CloudFront 상태 \n확인을 사용하여 트래픽을 라우팅합니다. \nC. 전송 게이트웨이를 생성합니다. Transit Gateway 를 각 리전의 API Gateway 엔드포인트에 \n연결합니다. 요청을 라우팅하도록 전송 게이트웨이를 구성합니다. \nD. 기본 지역에서 Application Load Balancer 를 생성합니다. 각 리전의 API 게이트웨이 \n엔드포인트 호스트 이름을 가리키도록 대상 그룹을 설정합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/109405-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "448": {"q_num": 448, "question": "회사에는 Management 및 Production 이라는 두 개의 VPC 가 있습니다. 관리 VPC 는 고객 \n게이트웨이를 통해 VPN 을 사용하여 데이터 센터의 단일 디바이스에 연결합니다. 프로덕션 \nVPC 는 2 개의 연결된 AWS Direct Connect 연결이 있는 가상 프라이빗 게이트웨이를 \n사용합니다. 관리 및 프로덕션 VPC\n는 모두 단일 VPC 피어링 연결을 사용하여 \n애플리케이션 간의 통신을 허용합니다. \n솔루션 아키텍트는 이 아키텍처에서 단일 실패 지점을 완화하기 위해 무엇을 해야 합니까? \nA. 관리 VPC 와 프로덕션 VPC 사이에 VPN 세트를 추가하십시오. \nB. 두 번째 가상 프라이빗 게이트웨이를 추가하고 관리 VPC 에 연결합니다. \nC. 두 번째 고객 게이트웨이 디바이스에서 관리 VPC 에 두 번째 VPN 세트를 추가합니다. \n\nD. 관리 VPC 와 프로덕션 VPC 간에 두 번째 VPC 피어링 연결을 추가합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/109499-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명:・ \n이 답변은 관리 VPC\n와 데이터 센터 간의 VPN 연결에 중복성을 제공하기 때문에 \n정답입니다. 하나의 고객 게이트웨이 디바이스 또는 하나의 VPN 터널을 사용할 수 없게 \n되더라도 트래픽은 여전히 두 번째 고객 게이트웨이 디바이스와 두 번째 VPN 터널을 통해 \n흐를 수 있습니다. 이렇게 하면 VPN 연결의 단일 실패 지점이 완화됩니다. \n \n참조: \nhttps://docs.aws.amazon.com/vpn/latest/s2svpn/vpn-redundant-connection.html \nhttps://www.trendmicro.com/cloudoneconformity/knowledge-base/aws/VPC/vpn-tunnelr\nedundancy.html", "answer_choice": "C"}, "449": {"q_num": 449, "question": "회사는 Oracle 데이터베이스에서 애플리케이션을 실행합니다. 이 회사는 데이터베이스, \n백업 관리 및 데이터 센터 유지 관리를 위한 제한된 리소스로 인해 AWS 로 신속하게 \n마이그레이션할 \n계획입니다. \n응용 \n프로그램은 \n권한 \n있는 \n액세스가 \n필요한 \n타사 \n데이터베이스 기능을 사용합니다. \n회사가 비용 효율적으로 데이터베이스를 AWS MOST 로 마이그레이션하는 데 도움이 되는 \n솔루션은 무엇입니까? \nA. 데이터베이스를 Oracle 용 Amazon RDS 로 마이그레이션합니다. 타사 기능을 클라우드 \n서비스로 대체합니다. \nB. 데이터베이스를 Amazon RDS Custom for Oracle 로 마이그레이션합니다. 타사 기능을 \n지원하도록 데이터베이스 설정을 사용자 지정합니다. \nC. \n데이터베이스를 \nOracle\n용 \nAmazon \nEC2 \nAmazon \n머신 \n이미지(AMI)로 \n마이그레이션합니다. 타사 기능을 지원하도록 데이터베이스 설정을 사용자 지정합니다. \nD. Oracle APEX\n에 대한 종속성을 제거하도록 애플리케이션 코드를 다시 작성하여 \nPostgreSQL 용 Amazon RDS 로 데이터베이스를 마이그레이션합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/109432-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "450": {"q_num": 450, "question": "회사에는 단일 서버에 있는 3 계층 웹 응용 프로그램이 있습니다. 회사는 애플리케이션을 \nAWS \n클라우드로 \n마이그레이션하려고 \n합니다. \n또한 \n회사는 \n애플리케이션이 \nAWS \nWell-Architected 프레임워크와 일치하고 보안, 확장성 및 복원력에 대한 AWS 권장 모범 \n사례와 일치하기를 원합니다. \n이러한 요구 사항을 충족하는 솔루션 조합은 무엇입니까? (3 개 선택) \nA. 애플리케이션의 기존 아키텍처를 사용하여 두 가용 영역에 걸쳐 VPC 를 생성합니다. \nEC2 Auto Scaling 그룹이 있는 각 가용 영역의 프라이빗 서브넷에 있는 Amazon EC2 \n인스턴스의 기존 아키텍처로 애플리케이션을 호스팅합니다. 보안 그룹 및 네트워크 액세스 \n제어 목록(네트워크 ACL)을 사용하여 EC2 인스턴스를 보호합니다. \nB. 보안 그룹 및 네트워크 액세스 제어 목록(네트워크 ACL)을 설정하여 데이터베이스 \n계층에 대한 액세스를 제어합니다. 프라이빗 서브넷에 단일 Amazon RDS 데이터베이스를 \n설정합니다. \nC. 두 가용 영역에 걸쳐 VPC 를 생성합니다. 웹 계층, 애플리케이션 계층 및 데이터베이스 \n계층을 호스팅하도록 애플리케이션을 리팩터링합니다. 웹 계층 및 애플리케이션 계층에 \n대한 Auto Scaling 그룹을 사용하여 자체 프라이빗 서브넷에서 각 계층을 호스팅합니다. \nD. 단일 Amazon RDS 데이터베이스를 사용합니다. 애플리케이션 계층 보안 그룹에서만 \n데이터베이스 액세스를 허용합니다. \nE. 웹 티어 앞에서 Elastic Load Balancer 를 사용합니다. 각 계층의 보안 그룹에 대한 \n참조를 포함하는 보안 그룹을 사용하여 액세스를 제어합니다. \nF. 프라이빗 서브넷에서 Amazon RDS 데이터베이스 다중 AZ 클러스터 배포를 사용합니다. \n애플리케이션 계층 보안 그룹에서만 데이터베이스 액세스를 허용합니다.", "answer_block": "Answer: C, E, F \nhttps://www.examtopics.com/discussions/amazon/view/109406-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "451": {"q_num": 451, "question": "회사에서 애플리케이션과 데이터베이스를 AWS 클라우드로 마이그레이션하고 있습니다. 이 \n회사는 Amazon Elastic Container Service(Amazon ECS), AWS Direct Connect 및 Amazon \nRDS 를 사용합니다. \n회사의 운영 팀에서 어떤 활동을 관리합니까? (3 개 선택) \nA. Amazon RDS 인프라 계층, 운영 체제 및 플랫폼 관리 \nB. Amazon RDS DB 인스턴스 생성 및 예약된 유지 관리 기간 구성 \nC. 모니터링, 패치 관리, 로그 관리 및 호스트 침입 탐지를 위한 Amazon ECS 의 추가 \n\n소프트웨어 구성 요소 구성 \nD. Amazon RDS 의 모든 마이너 및 메이저 데이터베이스 버전에 대한 패치 설치 \nE. 데이터 센터에서 Amazon RDS 인프라의 물리적 보안 보장 \nF. Direct Connect 를 통해 이동하는 데이터의 암호화", "answer_block": "Answer: B, C, F \nhttps://www.examtopics.com/discussions/amazon/view/109408-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "452": {"q_num": 452, "question": "회사는 Amazon EC2 인스턴스에서 Java 기반 작업을 실행합니다. 작업은 매시간 실행되며 \n실행하는 데 10\n초가 걸립니다. 작업은 예약된 간격으로 실행되며 1GB\n의 메모리를 \n사용합니다. 작업이 사용 가능한 최대 CPU 를 사용하는 짧은 순간을 제외하고 인스턴스의 \nCPU 사용률은 낮습니다. 회사는 작업 실행 비용을 최적화하려고 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. AWS App2Container(A2C)를 사용하여 작업을 컨테이너화합니다. 0.5 vCPU(가상 CPU) 및 \n1GB 메모리를 사용하여 AWS Fargate 에서 Amazon Elastic Container Service(Amazon ECS) \n작업으로 작업을 실행합니다. \nB. 메모리가 1GB 인 AWS Lambda 함수에 코드를 복사합니다. Amazon EventBridge 예약 \n규칙을 생성하여 매시간 코드를 실행합니다. \nC. AWS App2Container(A2C)를 사용하여 작업을 컨테이너화합니다. 기존 Amazon Machine \nImage(AMI)에 컨테이너를 설치합니다. 태스크가 완료되면 스케줄이 컨테이너를 중지하는지 \n확인하십시오. \nD. 작업 완료 시 EC2 인스턴스를 중지하고 다음 작업이 시작될 때 EC2 인스턴스를 다시 \n시작하도록 기존 일정을 구성합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/109521-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "453": {"q_num": 453, "question": "회사에서 Amazon EC2 데이터 및 여러 Amazon S3 버킷에 대한 백업 전략을 구현하려고 \n합니다. 규정 요구 사항으로 인해 회사는 특정 기간 동안 백업 파일을 보존해야 합니다. \n회사는 보유기간 동안 파일을 변조해서는 안됩니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. AWS Backup 을 사용하여 거버넌스 모드에서 볼트 잠금이 있는 백업 볼트를 생성합니다. \n\n필요한 백업 계획을 생성합니다. \nB. Amazon Data Lifecycle Manager 를 사용하여 필요한 자동 스냅샷 정책을 생성합니다. \nC. Amazon S3 파일 게이트웨이를 사용하여 백업을 생성합니다. 적절한 S3 수명 주기 \n관리를 구성합니다. \nD. AWS Backup 을 사용하여 규정 준수 모드에서 볼트 잠금이 있는 백업 볼트를 생성합니다. \n필요한 백업 계획을 생성합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/109410-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nAWS Backup 은 컴퓨팅, 스토리지 및 데이터베이스 전반에서 AWS 서비스의 데이터 보호를 \n중앙 집중화하고 자동화할 수 있는 완전 관리형 서비스입니다. AWS Backup Vault Lock 은 \n백업 볼트에 대한 보안 및 제어를 강화하는 데 도움이 되는 백업 볼트의 선택적 기능입니다. \n규정 준수 모드에서 잠금이 활성화되고 유예 시간이 끝나면 고객, 계정/데이터 소유자 또는 \nAWS 가 볼트 구성을 변경하거나 삭제할 수 없습니다. 이렇게 하면 보존 기간이 만료되고 \n규정 요구 사항을 충족할 때까지 백업을 사용할 수 있습니다. \n \n참조: \nhttps://docs.aws.amazon.com/aws-backup/latest/devguide/vaultlock.html", "answer_choice": "D"}, "454": {"q_num": 454, "question": "회사는 여러 AWS 리전 및 계정에 걸쳐 리소스를 보유하고 있습니다. 새로 고용된 솔루션 \n설계자는 이전 직원이 리소스 인벤토리에 대한 세부 정보를 제공하지 않은 것을 \n발견했습니다. 솔루션 설계자는 모든 계정에서 다양한 워크로드의 관계 세부 정보를 \n구축하고 매핑해야 합니다. \n운영상 가장 효율적인 방식으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. AWS Systems Manager Inventory\n를 사용하여 상세 보기 보고서에서 맵 보기를 \n생성합니다. \nB. AWS Step Functions\n를 사용하여 워크로드 세부 정보를 수집합니다. 워크로드의 \n아키텍처 다이어그램을 수동으로 작성합니다. \nC. Workload Discovery on AWS 를 사용하여 워크로드의 아키텍처 다이어그램을 생성합니다. \nD. AWS X-Ray 를 사용하여 워크로드 세부 정보를 봅니다. 관계를 사용하여 아키텍처 \n다이어그램을 구축합니다.", "answer_block": "Answer: C \n\nhttps://www.examtopics.com/discussions/amazon/view/109433-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nWorkload Discovery on AWS(이전에는 AWS Perspective\n라고 함)는 AWS 클라우드 \n워크로드를 시각화하는 도구입니다. 계정과 리전 전체에서 AWS 리소스의 인벤토리를 \n유지하고 이들 간의 관계를 매핑하고 웹 UI 에 표시합니다. 또한 AWS 비용 및 사용 보고서 \n쿼리, 리소스 검색, 아키텍처 다이어그램 저장 및 내보내기 등을 수행할 수 있습니다. \n솔루션은 AWS\n에서 Workload Discovery\n를 사용하여 최소한의 운영 노력으로 모든 \n계정에서 다양한 워크로드의 관계 세부 정보를 구축하고 매핑할 수 있습니다. \n1. AWS Systems Manager Inventory 를 사용하여 상세 보기 보고서에서 지도 보기를 \n생성합니다. AWS Systems Manager Inventory\n는 관리형 인스턴스에서 메타데이터를 \n수집하여 중앙 Amazon S3 버킷에 저장하는 기능이므로 이 솔루션은 모든 계정에서 다양한 \n워크로드의 관계 세부 정보를 구축하고 매핑해야 하는 요구 사항을 충족하지 않습니다. \n워크로드의 맵 보기 또는 아키텍처 다이어그램을 제공하지 않습니다. \n2. AWS Step Functions 를 사용하여 워크로드 세부 정보를 수집합니다. 워크로드의 아키텍처 \n다이어그램을 \n수동으로 \n구축합니다. \n이 \n솔루션은 \n워크로드 \n세부 \n정보 \n수집을 \n오케스트레이션하고 아키텍처 다이어그램을 수동으로 구축하기 위해 상태 시스템을 생성 및 \n관리해야 하므로 최소한의 운영 노력 요구 사항을 충족하지 않습니다. \n3. AWS X-Ray 를 사용하여 워크로드 세부 정보 보기 관계가 있는 아키텍처 다이어그램을 \n구축합니다. 이 솔루션은 워크로드 세부 정보를 수집하고 아키텍처 다이어그램을 수동으로 \n구축하기 위해 X-Ray SDK 로 애플리케이션을 구성해야 하므로 최소한의 운영 노력 요구 \n사항을 충족하지 않습니다. \n \n참조: \nhttps://aws.amazon.com/solutions/implementations/workload-discovery-on-aws/", "answer_choice": "C"}, "455": {"q_num": 455, "question": "회사에서 AWS Organizations 를 사용합니다. 회사는 다른 예산으로 일부 AWS 계정을 \n운영하려고 합니다. 회사는 특정 기간 동안 할당된 예산 임계값에 도달하면 알림을 받고 \nAWS 계정에 추가 리소스 프로비저닝을 자동으로 방지하려고 합니다. \n이러한 요구 사항을 충족하는 솔루션 조합은 무엇입니까? (3 개 선택) \nA. AWS 예산을 사용하여 예산을 생성합니다. 필요한 AWS 계정의 비용 및 사용 보고서 \n섹션에서 예산 금액을 설정합니다. \nB. AWS 예산을 사용하여 예산을 생성합니다. 필요한 AWS 계정의 결제 대시보드에서 예산 \n\n금액을 설정합니다. \nC. 필요한 권한으로 예산 작업을 실행하기 위해 AWS 예산에 대한 IAM 사용자를 \n생성합니다. \nD. 필요한 권한으로 예산 작업을 실행하기 위해 AWS 예산에 대한 IAM 역할을 생성합니다. \nE. 각 계정이 예산 임계값을 충족할 때 회사에 알리는 경고를 추가합니다. 추가 리소스의 \n프로비저닝을 방지하기 위해 적절한 구성 규칙으로 생성된 IAM 자격 증명을 선택하는 예산 \n작업을 추가합니다. \nF. 각 계정이 예산 임계값을 충족할 때 회사에 알리는 경고를 추가합니다. 추가 리소스의 \n프로비저닝을 방지하기 위해 적절한 SCP(서비스 제어 정책)로 생성된 IAM 자격 증명을 \n선택하는 예산 작업을 추가합니다.", "answer_block": "Answer: B, D, F \nhttps://www.examtopics.com/discussions/amazon/view/109522-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "456": {"q_num": 456, "question": "한 회사가 한 AWS 리전의 Amazon EC2 인스턴스에서 애플리케이션을 실행합니다. 회사는 \nEC2 인스턴스를 두 번째 리전에 백업하려고 합니다. 또한 회사는 두 번째 리전에서 EC2 \n리소스를 프로비저닝하고 하나의 AWS 계정에서 중앙에서 EC2 인스턴스를 관리하기를 \n원합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. 두 번째 지역에 비슷한 수의 EC2 인스턴스가 있는 재해 복구(DR) 계획을 만듭니다. \n데이터 복제를 구성합니다. \nB. EC2 인스턴스의 특정 시점 Amazon Elastic Block Store(Amazon EBS) 스냅샷을 \n생성합니다. 주기적으로 스냅샷을 두 번째 리전에 복사합니다. \nC. AWS Backup 을 사용하여 백업 계획을 생성합니다. EC2 인스턴스의 두 번째 리전에 대한 \n교차 리전 백업을 구성합니다. \nD. 두 번째 리전에 비슷한 수의 EC2 인스턴스를 배포합니다. AWS DataSync 를 사용하여 \n원본 리전에서 두 번째 리전으로 데이터를 전송합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/109523-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "457": {"q_num": 457, "question": "AWS 를 사용하는 회사는 제품 제조업체에 데이터를 전송하는 애플리케이션을 구축하고 \n\n있습니다. 회사에는 자체 ID 공급자(IdP)가 있습니다. 회사는 사용자가 애플리케이션을 \n사용하여 데이터를 전송하는 동안 IdP 가 애플리케이션 사용자를 인증하기를 원합니다. \n회사는 AS2(Applicability Statement 2) 프로토콜을 사용해야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. AWS DataSync 를 사용하여 데이터를 전송하십시오. IdP 인증을 위한 AWS Lambda \n함수를 생성합니다. \nB. Amazon AppFlow 흐름을 사용하여 데이터를 전송합니다. IdP 인증을 위한 Amazon \nElastic Container Service(Amazon ECS) 작업을 생성합니다. \nC. AWS Transfer Family 를 사용하여 데이터를 전송합니다. IdP 인증을 위한 AWS Lambda \n함수를 생성합니다. \nD. AWS Storage Gateway 를 사용하여 데이터를 전송합니다. IdP 인증을 위한 Amazon \nCognito 자격 증명 풀을 생성합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/109524-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "458": {"q_num": 458, "question": "솔루션 설계자는 현금 회수 서비스를 위해 Amazon API Gateway 에서 RESTAPI 를 설계하고 \n있습니다. 응용 프로그램에는 컴퓨팅 리소스를 위해 1GB 의 메모리와 2GB 의 스토리지가 \n필요합니다. 애플리케이션은 데이터가 관계형 형식이어야 합니다. \n최소한의 관리 노력으로 이러한 요구 사항을 충족하는 추가 AWS 서비스 조합은 \n무엇입니까? (2 개 선택) \nA. Amazon EC2 \nB. AWS Lambda \nC. Amazon RDS \nD. Amazon DynamoDB \nE. Amazon Elastic Kubernetes Services (Amazon EKS)", "answer_block": "Answer: B, C \nhttps://www.examtopics.com/discussions/amazon/view/109435-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "459": {"q_num": 459, "question": "회사는 AWS Organizations 를 사용하여 여러 AWS 계정 내에서 워크로드를 실행합니다. \n태깅 정책은 회사에서 태그를 생성할 때 부서 태그를 AWS 리소스에 추가합니다. \n\n회계 팀은 Amazon EC2 소비에 대한 지출을 결정해야 합니다. 회계팀은 AWS 계정과 \n관계없이 비용을 담당하는 부서를 결정해야 합니다. 회계 팀은 조직 내 모든 AWS 계정에 \n대해 AWS Cost Explorer 에 액세스할 수 있으며 Cost Explorer 의 모든 보고서에 액세스해야 \n합니다. \n운영상 가장 효율적인 방식으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 조직 관리 계정 청구 콘솔에서 부서라는 사용자 정의 비용 할당 태그를 활성화합니다. \n비용 탐색기에서 태그 이름별로 그룹화하여 하나의 비용 보고서를 생성하고 EC2 별로 \n필터링합니다. \nB. Organizations 마스터 계정 결제 콘솔에서 부서라는 AWS 정의 비용 할당 태그를 \n활성화합니다. 비용 탐색기에서 태그 이름별로 그룹화하여 하나의 비용 보고서를 생성하고 \nEC2 별로 필터링합니다. \nC. 조직 회원 계정 청구 콘솔에서 부서라는 사용자 정의 비용 할당 태그를 활성화합니다. \n비용 탐색기에서 태그 이름별로 그룹화하여 하나의 비용 보고서를 생성하고 EC2 별로 \n필터링합니다. \nD. Organizations 회원 계정 결제 콘솔에서 부서라는 AWS 정의 비용 할당 태그를 \n활성화합니다. 비용 탐색기에서 태그 이름별로 그룹화하여 하나의 비용 보고서를 생성하고 \nEC2 별로 필터링합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/109440-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "460": {"q_num": 460, "question": "회사는 SaaS(Software as a Service) 애플리케이션 Salesforce 계정과 Amazon S3 간에 \n데이터를 안전하게 교환하려고 합니다. 회사는 AWS Key Management Service(AWS KMS) \n고객 관리형 키(CMK)를 사용하여 저장된 데이터를 암호화해야 합니다. 또한 회사는 전송 \n중인 데이터를 암호화해야 합니다. 회사에서 Salesforce 계정에 대한 API 액세스를 \n활성화했습니다. \nA. Salesforce 에서 Amazon S3 로 안전하게 데이터를 전송하는 AWS Lambda 함수를 \n생성합니다. \nB. AWS Step Functions 워크플로를 생성합니다. Salesforce 에서 Amazon S3 로 안전하게 \n데이터를 전송하는 작업을 정의합니다. \nC. Amazon AppFlow 흐름을 생성하여 Salesforce 에서 Amazon S3 로 데이터를 안전하게 \n전송합니다. \nD. Salesforce 용 사용자 지정 커넥터를 만들어 Salesforce 에서 Amazon S3 로 데이터를 \n안전하게 전송합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/109525-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nAmazon AppFlow 는 사용자가 SaaS 애플리케이션과 AWS 서비스 간에 안전하게 데이터를 \n전송할 수 있도록 하는 완전관리형 통합 서비스입니다. Salesforce 를 소스로, Amazon S3 를 \n대상으로 지원합니다. 또한 AWS KMS CMK\n를 사용하여 유휴 데이터 암호화 및 \nSSL/TLS1 을 사용하여 전송 중인 데이터 암호화를 지원합니다. Amazon AppFlow 를 \n사용하면 솔루션이 최소한의 개발 노력으로 요구 사항을 충족할 수 있습니다. \n1. 데이터를 Salesforce 에서 Amazon S3 로 안전하게 전송하는 AWS Lambda 함수를 \n생성합니다. 이 솔루션은 Salesforce 및 Amazon S3 API 와 상호 작용하고 인증, 암호화, \n오류 처리 및 모니터링을 처리하기 위한 사용자 지정 코드 작성을 포함하므로 최소한의 \n개발 노력 요구 사항을 충족하지 않습니다. \n2. AWS Step Functions 워크플로 생성 Salesforce 에서 Amazon S3 로 데이터를 안전하게 \n전송하는 작업을 정의합니다. 이 솔루션은 데이터 전송 작업을 오케스트레이션하기 위한 \n상태 시스템 정의를 생성하고 실제 데이터 전송을 수행하기 위해 Lambda 함수 또는 기타 \n서비스를 호출하기 때문에 최소한의 개발 노력 요구 사항을 충족하지 않습니다. \n3. Salesforce 용 사용자 지정 커넥터를 생성하여 Salesforce 에서 Amazon S3 로 데이터를 \n안전하게 전송합니다. 이 솔루션은 Amazon AppFlow 사용자 지정 커넥터 SDK 를 사용하여 \nSalesforce 용 사용자 지정 커넥터를 구축하고 배포하므로 추가 구성 및 관리가 필요하므로 \n최소한의 개발 노력 요구 사항을 충족하지 않습니다. \n \n참조: https://aws.amazon.com/appflow/", "answer_choice": "C"}, "461": {"q_num": 461, "question": "회사가 단일 AWS 리전에서 모바일 게임 앱을 개발하고 있습니다. 앱은 Auto Scaling \n그룹의 여러 Amazon EC2 인스턴스에서 실행됩니다. 회사는 앱 데이터를 Amazon \nDynamoDB\n에 저장합니다. 앱은 사용자와 서버 간에 TCP 트래픽과 UDP 트래픽을 \n사용하여 통신합니다. 응용 프로그램은 전 세계적으로 사용됩니다. 회사는 모든 사용자에게 \n가능한 가장 낮은 대기 시간을 보장하고자 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. AWS Global Accelerator 를 사용하여 가속기를 생성합니다. Global Accelerator 통합을 \n사용하고 TCP 및 UDP 포트에서 수신 대기하는 가속기 엔드포인트 뒤에 Application Load \nBalancer(ALB)를 생성합니다. Auto Scaling 그룹을 업데이트하여 ALB\n에 인스턴스를 \n\n등록합니다. \nB. AWS Global Accelerator 를 사용하여 가속기를 생성합니다. Global Accelerator 통합을 \n사용하고 TCP 및 UDP 포트에서 수신 대기하는 가속기 엔드포인트 뒤에 NLB(Network \nLoad Balancer)를 생성합니다. Auto Scaling 그룹을 업데이트하여 NLB 에 인스턴스를 \n등록합니다. \nC. Amazon CloudFront 콘텐츠 전송 네트워크(CDN) 엔드포인트를 생성합니다. 엔드포인트 \n뒤에 NLB(Network Load Balancer)를 생성하고 TCP 및 UDP 포트에서 수신 대기합니다. \nAuto Scaling 그룹을 업데이트하여 NLB 에 인스턴스를 등록합니다. NLB 를 오리진으로 \n사용하도록 CloudFront 를 업데이트합니다. \nD. Amazon CloudFront 콘텐츠 전송 네트워크(CDN) 엔드포인트를 생성합니다. 엔드포인트 \n뒤에 Application Load Balancer(ALB)를 생성하고 TCP 및 UDP 포트에서 수신 대기합니다. \nAuto Scaling 그룹을 업데이트하여 ALB 에 인스턴스를 등록합니다. ALB 를 오리진으로 \n사용하도록 CloudFront 를 업데이트합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/109446-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nAWS Global Accelerator\n는 글로벌 사용자를 위해 애플리케이션의 성능과 가용성을 \n향상시키는 네트워킹 서비스입니다. AWS 글로벌 네트워크를 사용하여 사용자 트래픽을 \n성능 및 상태에 따라 최적의 엔드포인트로 라우팅합니다. 또한 애플리케이션에 대한 고정 \n진입점 역할을 하고 TCP 및 UDP 프로토콜을 모두 지원하는 고정 IP 주소를 제공합니다. \n솔루션은 AWS Global Accelerator 를 사용하여 모든 사용자에게 가능한 최저 지연 시간을 \n보장할 수 있습니다. \n1. AWS Global Accelerator 를 사용하여 가속기를 생성합니다. Global Accelerator 통합을 \n사용하고 TCP 및 UDP 포트에서 수신 대기하는 가속기 엔드포인트 뒤에 Application Load \nBalancer(ALB)를 생성합니다. Auto Scaling 그룹을 업데이트하여 ALB\n에 인스턴스를 \n등록합니다. ALB 는 UDP 프로토콜을 지원하지 않으므로 이 솔루션은 작동하지 않습니다. \n2. Amazon CloudFront 콘텐츠 전송 네트워크(CDN) 엔드포인트를 생성합니다. 엔드포인트 \n뒤에 NLB(Network Load Balancer)를 생성하고 TCP 및 UDP 포트에서 수신 대기합니다. \nAuto Scaling 그룹을 업데이트하여 NLB 에 인스턴스를 등록합니다. NLB 를 오리진으로 \n사용하도록 CloudFront\n를 업데이트합니다. CloudFront\n는 UDP 프로토콜을 지원하지 \n않으므로 이 솔루션은 작동하지 않습니다. \n3. Amazon CloudFront 콘텐츠 전송 네트워크(CDN) 엔드포인트를 생성합니다. 엔드포인트 \n뒤에 Application Load Balancer(ALB)를 생성하고 TCP 및 UDP 포트에서 수신 대기합니다. \nAuto Scaling 그룹을 업데이트하여 ALB 에 인스턴스를 등록합니다. ALB 를 오리진으로 \n\n사용하도록 CloudFront\n를 업데이트합니다. CloudFront 및 ALB\n는 UDP 프로토콜을 \n지원하지 않으므로 이 솔루션은 작동하지 않습니다. \n \n참조: https://aws.amazon.com/global-accelerator/", "answer_choice": "B"}, "462": {"q_num": 462, "question": "회사에 고객 주문을 처리하는 애플리케이션이 있습니다. 회사는 주문을 Amazon Aurora \n데이터베이스에 저장하는 Amazon EC2 인스턴스에서 애플리케이션을 호스팅합니다. 때때로 \n트래픽이 높을 때 워크로드가 주문을 충분히 빠르게 처리하지 못합니다. \n가능한 한 빨리 데이터베이스에 주문을 안정적으로 기록하려면 솔루션 설계자가 무엇을 \n해야 합니까? \nA. 트래픽이 많을 때 EC2 인스턴스의 인스턴스 크기를 늘립니다. Amazon Simple \nNotification Service(Amazon SNS)에 주문을 작성합니다. SNS 주제에 데이터베이스 \n엔드포인트를 구독합니다. \nB. Amazon Simple Queue Service(Amazon SQS) 대기열에 주문을 씁니다. Application Load \nBalancer 뒤의 Auto Scaling 그룹에서 EC2 인스턴스를 사용하여 SQS 대기열에서 읽고 \n주문을 데이터베이스로 처리합니다. \nC. Amazon Simple Notification Service(Amazon SNS)에 주문을 작성합니다. SNS 주제에 \n데이터베이스 엔드포인트를 구독합니다. Application Load Balancer 뒤의 Auto Scaling \n그룹에서 EC2 인스턴스를 사용하여 SNS 주제에서 읽습니다. \nD. EC2 인스턴스가 CPU 임계값 제한에 도달하면 Amazon Simple Queue Service(Amazon \nSQS) 대기열에 주문을 씁니다. Application Load Balancer 뒤의 Auto Scaling 그룹에서 EC2 \n인스턴스의 예약된 조정을 사용하여 SQS 대기열에서 읽고 데이터베이스로 주문을 \n처리합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/109653-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nAmazon SQS 는 마이크로서비스, 분산 시스템 및 서버리스 애플리케이션을 분리하고 확장할 \n수 있는 완전관리형 메시지 대기열 서비스입니다. 애플리케이션은 SQS 대기열에 주문을 \n기록함으로써 주문 손실 없이 트래픽 급증을 처리할 수 있습니다. Auto Scaling 그룹의 EC2 \n인스턴스는 SQS 대기열에서 읽고 꾸준한 속도로 데이터베이스로 주문을 처리할 수 \n있습니다. Application Load Balancer 는 EC2 인스턴스에 부하를 분산하고 상태 확인을 \n제공할 수 있습니다. 이 솔루션은 질문의 모든 요구 사항을 충족하지만 다른 옵션은 그렇지 \n\n않습니다. \n참조: \nhttps://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/welcome.html \nhttps://aws.amazon.com/architecture/serverless/ \nhttps://aws.amazon.com/sqs/", "answer_choice": "B"}, "463": {"q_num": 463, "question": "IoT 회사는 사용자의 수면에 대한 데이터를 수집하는 센서가 있는 매트리스를 출시하고 \n있습니다. 센서는 데이터를 Amazon S3 버킷으로 보냅니다. 센서는 각 매트리스에 대해 \n매일 밤 약 2MB 의 데이터를 수집합니다. 회사는 각 매트리스에 대한 데이터를 처리하고 \n요약해야 합니다. 결과는 가능한 한 빨리 제공되어야 합니다. 데이터 처리에는 1GB 의 \n메모리가 필요하며 30 초 이내에 완료됩니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. Scala 작업에 AWS Glue 사용 \nB. Apache Spark 스크립트와 함께 Amazon EMR 사용 \nC. Python 스크립트와 함께 AWS Lambda 사용 \nD. PySpark 작업과 함께 AWS Glue 사용", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/109501-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "464": {"q_num": 464, "question": "회사는 PostgreSQL 단일 AZ DB 인스턴스용 Amazon RDS 에 모든 주문을 저장하는 온라인 \n쇼핑 애플리케이션을 호스팅합니다. 경영진은 단일 실패 지점을 제거하기를 원하며 솔루션 \n설계자에게 애플리케이션 코드를 변경하지 않고도 데이터베이스 다운타임을 최소화할 수 \n있는 접근 방식을 권장하도록 요청했습니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 데이터베이스 인스턴스를 수정하고 다중 AZ 옵션을 지정하여 기존 데이터베이스 \n인스턴스를 다중 AZ 배포로 변환합니다. \nB. 새로운 RDS 다중 AZ 배포를 생성합니다. 현재 RDS 인스턴스의 스냅샷을 만들고 \n스냅샷으로 새 다중 AZ 배포를 복원합니다. \nC. 다른 가용 영역에서 PostgreSQL 데이터베이스의 읽기 전용 복제본을 생성합니다. \nAmazon Route 53 가중 레코드 세트를 사용하여 데이터베이스 전체에 요청을 분산합니다. \nD. 최소 그룹 크기가 2 인 Amazon EC2 Auto Scaling 그룹에 RDS for PostgreSQL \n\n데이터베이스를 배치합니다. Amazon Route 53 가중 레코드 세트를 사용하여 인스턴스 간에 \n요청을 분산합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/109449-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n기존 단일 AZ DB 인스턴스를 다중 AZ 배포로 변환하려면 AWS Management Console 에서 \nDB 인스턴스에 해당하는 \"수정\" 옵션을 사용하십시오. \n \n참고: \nhttps://aws.amazon.com/rds/features/multi-az/", "answer_choice": "A"}, "465": {"q_num": 465, "question": "회사에서 고객 요구를 지원하기 위해 애플리케이션을 개발하고 있습니다. 회사는 동일한 \n가용 영역 내의 여러 Amazon EC2 Nitro 기반 인스턴스에 애플리케이션을 배포하려고 \n합니다. 또한 이 회사는 더 높은 애플리케이션 가용성을 달성하기 위해 여러 EC2 Nitro \n기반 인스턴스의 여러 블록 스토리지 볼륨에 동시에 쓸 수 있는 기능을 애플리케이션에 \n제공하고자 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Amazon Elastic Block Store(Amazon EBS) 다중 연결에 범용 SSD(gp3) EBS 볼륨 사용 \nB. Amazon Elastic Block Store(Amazon EBS) 다중 연결과 함께 처리량 최적화 HDD(st1) \nEBS 볼륨 사용 \nC. Amazon Elastic Block Store(Amazon EBS) 다중 연결과 함께 프로비저닝된 IOPS SSD(io2) \nEBS 볼륨 사용 \nD. Amazon Elastic Block Store(Amazon EBS) 다중 연결에 범용 SSD(gp2) EBS 볼륨 사용", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/109655-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "466": {"q_num": 466, "question": "한 회사에서 단일 가용 영역과 Amazon RDS 다중 AZ DB 인스턴스에서 Amazon EC2 를 \n사용하는 상태 비저장 2\n계층 애플리케이션을 설계했습니다. 새로운 회사 경영진은 \n애플리케이션의 가용성을 높이려고 합니다. \n\n솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. 다중 AZ EC2 Auto Scaling 을 사용하도록 애플리케이션을 구성하고 Application Load \nBalancer 를 생성합니다. \nB. EC2 인스턴스의 스냅샷을 찍어 다른 AWS 리전으로 보내도록 애플리케이션을 \n구성합니다. \nC. Amazon Route 53 대기 시간 기반 라우팅을 사용하여 애플리케이션에 요청을 제공하도록 \n애플리케이션을 구성합니다. \nD. 들어오는 요청을 처리하고 다중 AZ 애플리케이션 로드 밸런서를 생성하도록 Amazon \nRoute 53 규칙을 구성합니다.", "answer_block": "Answer: \nA \nhttps://www.examtopics.com/discussions/amazon/view/109450-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n참고: \nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/as-add-availability-zone.html", "answer_choice": "A"}, "467": {"q_num": 467, "question": "회사에서 AWS Organizations 를 사용합니다. 멤버 계정이 Compute Savings Plan 을 \n구입했습니다. 멤버 계정 내부의 워크로드 변경으로 인해 해당 계정은 더 이상 Compute \nSavings Plan 약정의 전체 혜택을 받지 못합니다. 이 회사는 구매한 컴퓨팅 성능의 50% \n미만을 사용합니다. \nA. Compute Savings Plan 을 구매한 멤버 계정의 계정 콘솔에 있는 청구 기본 설정 \n섹션에서 할인 공유를 켭니다. \nB. 회사의 조직 관리 계정에 있는 계정 콘솔의 청구 기본 설정 섹션에서 할인 공유를 \n켭니다. \nC. 다른 AWS 계정에서 Compute Savings Plan 이 있는 계정으로 추가 컴퓨팅 워크로드를 \n마이그레이션합니다. \nD. 예약 인스턴스 마켓플레이스에서 초과된 Savings Plan 약정을 판매합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/109485-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "468": {"q_num": 468, "question": "회사에서 고객을 위한 검색 카탈로그를 제공할 마이크로서비스 애플리케이션을 개발하고 \n\n있습니다. 회사는 REST API 를 사용하여 애플리케이션의 프런트엔드를 사용자에게 제시해야 \n합니다. REST API 는 회사가 프라이빗 VPC 서브넷의 컨테이너에서 호스팅하는 백엔드 \n서비스에 액세스해야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Amazon API Gateway 를 사용하여 WebSocket API 를 설계합니다. 프라이빗 서브넷의 \nAmazon Elastic Container Service(Amazon ECS)에서 애플리케이션을 호스팅합니다. \nAmazon ECS 에 액세스하기 위해 API Gateway 용 프라이빗 VPC 링크를 생성합니다. \nB. Amazon API Gateway 를 사용하여 REST API 를 설계합니다. 프라이빗 서브넷의 Amazon \nElastic Container Service(Amazon ECS)에서 애플리케이션을 호스팅합니다. Amazon ECS 에 \n액세스하기 위해 API Gateway 용 프라이빗 VPC 링크를 생성합니다. \nC. Amazon API Gateway 를 사용하여 WebSocket API 를 설계합니다. 프라이빗 서브넷의 \nAmazon Elastic Container Service(Amazon ECS)에서 애플리케이션을 호스팅합니다. \nAmazon ECS 에 액세스하기 위해 API Gateway 에 대한 보안 그룹을 생성합니다. \nD. Amazon API Gateway 를 사용하여 REST API 를 설계합니다. 프라이빗 서브넷의 Amazon \nElastic Container Service(Amazon ECS)에서 애플리케이션을 호스팅합니다. Amazon ECS 에 \n액세스하기 위해 API Gateway 에 대한 보안 그룹을 생성합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/109451-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "469": {"q_num": 469, "question": "회사는 수집된 원시 데이터를 Amazon S3 버킷에 저장합니다. 이 데이터는 회사 고객을 \n대신하여 여러 유형의 분석에 사용됩니다. 요청된 분석 유형에 따라 S3 객체에 대한 \n액세스 패턴이 결정됩니다. \n회사는 접속 패턴을 예측하거나 통제할 수 없습니다. 회사는 S3 비용을 줄이고자 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. S3 복제를 사용하여 자주 액세스하지 않는 개체를 S3 Standard-Infrequent Access(S3 \nStandard-IA)로 전환합니다. \nB. S3 수명 주기 규칙을 사용하여 객체를 S3 Standard 에서 Standard-Infrequent Access 로 \n전환(S3 Standard-IA) \nC. S3 수명 주기 규칙을 사용하여 객체를 S3 Standard 에서 S3 Intelligent-Tiering 으로 전환 \nD. S3 Inventory 를 사용하여 S3 Standard 에서 S3 Intelligent-Tiering 으로 액세스하지 않은 \n객체를 식별하고 전환", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/109452-exam-aws-certified-sol\n\nutions-architect-associate-saa-c03/ \n \n설명: \nS3 Intelligent-Tiering 은 액세스 빈도에 따라 가장 비용 효율적인 액세스 계층으로 데이터를 \n이동하여 스토리지 비용을 자동으로 줄이는 스토리지 클래스입니다. 여기에는 빈번한 \n액세스와 드문 액세스의 두 가지 액세스 계층이 있습니다. 데이터는 기본적으로 빈번한 \n액세스 계층에 저장되며 연속 30 일 동안 액세스가 없으면 빈번하지 않은 액세스 계층으로 \n이동됩니다. 데이터에 다시 액세스하면 자주 액세스하는 tier1 로 다시 이동됩니다. S3 수명 \n주기 규칙을 사용하여 개체를 S3 Standard 에서 S3 Intelligent-Tiering 으로 전환함으로써 \n솔루션은 액세스 패턴을 알 수 없거나 변경하는 데이터에 대한 S3 비용을 줄일 수 \n있습니다. \n1. S3 복제를 사용하여 자주 액세스하지 않는 객체를 S3 Standard-Infrequent Access(S3 \nStandard-IA)로 전환합니다. 이 솔루션은 액세스 패턴을 알 수 없거나 변경하는 데이터에 \n대한 S3 비용 절감 요구 사항을 충족하지 않습니다. S3 복제는 중복성 또는 규정 준수를 \n위해 버킷 또는 리전 간에 개체를 복사하는 기능이기 때문입니다. 액세스 빈도에 따라 \n개체를 다른 스토리지 클래스로 자동으로 이동하지 않습니다. \n2. S3 수명 주기 규칙을 사용하여 객체를 S3 Standard 에서 Standard-Infrequent Access(S3 \nStandard-IA)로 전환합니다. 이 솔루션은 액세스 패턴을 알 수 없거나 변경하는 데이터에 \n대한 S3 비용 절감 요구 사항을 충족하지 않습니다. S3 Standard-IA 는 S3 Standard 보다 \n낮은 스토리지 비용을 제공하지만 데이터 액세스에 대한 검색 요금을 부과하는 스토리지 \n클래스이기 때문입니다. 액세스 패턴이 변화하는 데이터가 아니라 수명이 길고 자주 \n액세스하지 않는 데이터에 적합합니다. \n3. S3 Inventory 를 사용하여 S3 Standard 에서 S3 Intelligent-Tiering 으로 액세스하지 않은 \n객체를 식별하고 전환합니다. 이 솔루션은 액세스 패턴을 알 수 없거나 변경하는 데이터에 \n대한 S3 비용 절감 요구 사항을 충족하지 않습니다. S3 Inventory 는 버킷의 객체 및 해당 \n메타데이터에 대한 보고서를 매일 또는 매주 제공하는 기능이기 때문입니다. 액세스 빈도에 \n따라 개체를 다른 스토리지 클래스로 자동으로 이동하지 않습니다. \n참조 URL: https://aws.amazon.com/s3/storage-classes/intelligent-tiering/ \nS3 지능형 계층화 \n액세스 패턴을 예측할 수 없거나 변경될 때 S3 비용을 줄이기 위한 최상의 솔루션입니다. \nS3 Intelligent-Tiering 은 성능에 미치는 영향이나 검색 비용 없이 액세스 빈도를 기준으로 \n두 \n액세스 \n계층(빈번함 \n및 \n비빈번함) \n간에 \n객체를 \n자동으로 \n이동합니다. \nS3 \nIntelligent-Tiering\n에는 거의 액세스하지 않는 개체에 대한 선택적 아카이브 계층도 \n있습니다. \nS3 \n수명 \n주기 \n규칙을 \n사용하여 \n객체를 \nS3 \nStandard\n에서 \nS3 \nIntelligent-Tiering 으로 전환할 수 있습니다. \n참조 URL: \n\n1 https://aws.amazon.com/s3/storage-classes/intelligent-tiering/ \n2 https://docs.aws.amazon.com/AmazonS3/latest/userguide/using-intelligent-tiering.html \n3 \nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/intelligent-tiering-overview.ht\nml", "answer_choice": "C"}, "470": {"q_num": 470, "question": "한 회사에 IPv6 주소를 사용하여 Amazon EC2 인스턴스에서 호스팅되는 애플리케이션이 \n있습니다. 애플리케이션은 인터넷을 사용하여 다른 외부 애플리케이션과의 통신을 시작해야 \n합니다. 그러나 회사의 보안 정책에 따르면 외부 서비스는 EC2 인스턴스에 대한 연결을 \n시작할 수 없습니다. \n솔루션 설계자는 이 문제를 해결하기 위해 무엇을 권장해야 합니까? \nA. NAT 게이트웨이를 생성하고 이를 서브넷 라우팅 테이블의 대상으로 만듭니다. \nB. 인터넷 게이트웨이를 만들고 이를 서브넷의 라우팅 테이블 대상으로 만듭니다. \nC. 가상 프라이빗 게이트웨이를 만들고 이를 서브넷의 라우팅 테이블 대상으로 만듭니다. \nD. 외부 전용 인터넷 게이트웨이를 만들고 이를 서브넷 라우팅 테이블의 대상으로 \n만듭니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/109334-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n외부 전용 인터넷 게이트웨이는 VPC 의 인스턴스에서 인터넷으로 IPv6 을 통한 아웃바운드 \n통신을 허용하고 인터넷이 인스턴스와의 IPv6 연결을 시작하지 못하도록 하는 VPC 구성 \n요소입니다. 이것은 회사의 보안 정책 및 요구 사항을 충족합니다. 외부 전용 인터넷 \n게이트웨이를 사용하려면 IPv6 인터넷 트래픽(::/0)을 외부 전용 인터넷 게이트웨이로 \n라우팅하는 경로를 서브넷의 라우팅 테이블에 추가해야 합니다. \n참조 URL: \n1 https://docs.aws.amazon.com/vpc/latest/userguide/egress-only-internet-gateway.html \n2 https://dev.to/aws-builders/what-is-an-egress-only-internet-gateways-in-aws-7gp \n3 https://docs.aws.amazon.com/vpc/latest/userguide/route-table-options.html", "answer_choice": "D"}, "471": {"q_num": 471, "question": "회사에서 VPC 의 컨테이너에서 실행되는 애플리케이션을 만들고 있습니다. 애플리케이션은 \n\nAmazon S3 버킷에 데이터를 저장하고 액세스합니다. 개발 단계에서 애플리케이션은 매일 \nAmazon S3 에 1TB 의 데이터를 저장하고 액세스합니다. 회사는 비용을 최소화하고 가능한 \n한 트래픽이 인터넷을 통과하지 못하도록 막고자 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. S3 버킷에 대해 S3 Intelligent-Tiering 을 활성화합니다. \nB. S3 버킷에 대해 S3 Transfer Acceleration 을 활성화합니다. \nC. Amazon S3 용 게이트웨이 VPC 엔드포인트를 생성합니다. 이 엔드포인트를 VPC 의 모든 \n라우팅 테이블과 연결합니다. \nD. VPC 에서 Amazon S3 에 대한 인터페이스 엔드포인트를 생성합니다. 이 엔드포인트를 \nVPC 의 모든 라우팅 테이블과 연결합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/109453-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nAmazon S3\n용 게이트웨이 VPC 엔드포인트는 인터넷 게이트웨이나 NAT 디바이스가 \n필요하지 않은 VPC 와 Amazon S3 간의 프라이빗 연결을 가능하게 합니다. 이렇게 하면 \n비용이 최소화되고 트래픽이 인터넷을 통과하는 것을 방지할 수 있습니다. 게이트웨이 VPC \n엔드포인트는 트래픽을 비공개로 Amazon S31 로 라우팅하기 위해 접두사 목록을 VPC \n라우팅 테이블의 라우팅 대상으로 사용합니다. 엔드포인트를 VPC 의 모든 라우팅 테이블과 \n연결하면 모든 서브넷이 엔드포인트를 통해 Amazon S3 에 액세스할 수 있습니다. \n \n옵션 A 는 S3 Intelligent-Tiering 이 변화하는 액세스 패턴을 기반으로 두 액세스 계층 간에 \n객체를 자동으로 이동하여 스토리지 비용을 최적화하는 스토리지 클래스이기 때문에 \n올바르지 않습니다. VPC 와 Amazon S3 간의 네트워크 트래픽에는 영향을 미치지 않습니다. \n \n옵션 B 는 올바르지 않습니다. S3 Transfer Acceleration 은 클라이언트와 S3 버킷 간에 \n장거리에서 파일을 빠르고 쉽고 안전하게 전송할 수 있는 기능이기 때문입니다. 트래픽이 \n인터넷을 통과하는 것을 막지는 않습니다. \n \n옵션 D 는 Amazon S3 용 인터페이스 VPC 엔드포인트는 각 서브넷에 프라이빗 IP 주소가 \n있는 탄력적 네트워크 인터페이스(ENI)가 필요한 AWS PrivateLink 에 의해 구동되기 때문에 \n올바르지 않습니다. 이것은 솔루션에 복잡성과 비용을 추가합니다. 또한 인터페이스 VPC \n엔드포인트는 Amazon S3 에 대한 교차 리전 액세스를 지원하지 않습니다. \n참조 URL: \nhttps://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints-s3.html  \n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/storage-class-intro.html#sc-\ndynamicdata-access \nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/transfer-acceleration.html \nhttps://aws.amazon.com/blogs/architecture/choosing-your-vpc-endpoint-strategy-for-a\nmazon-s3/", "answer_choice": "C"}, "472": {"q_num": 472, "question": "회사에 Amazon DynamoDB 기반 데이터 저장소가 있는 모바일 채팅 애플리케이션이 \n있습니다. 사용자는 가능한 한 짧은 대기 시간으로 새 메시지를 읽기를 원합니다. 솔루션 \n설계자는 최소한의 애플리케이션 변경이 필요한 최적의 솔루션을 설계해야 합니다. \n솔루션 설계자는 어떤 방법을 선택해야 합니까? \nA. 새 메시지 테이블에 대해 Amazon DynamoDB Accelerator(DAX)를 구성합니다. DAX \n끝점을 사용하도록 코드를 업데이트합니다. \nB. 증가된 읽기 로드를 처리하기 위해 DynamoDB 읽기 복제본을 추가합니다. 읽기 전용 \n복제본의 읽기 엔드포인트를 가리키도록 애플리케이션을 업데이트합니다. \nC. DynamoDB 의 새 메시지 테이블에 대한 읽기 용량 단위 수를 두 배로 늘립니다. 기존 \nDynamoDB 엔드포인트를 계속 사용합니다. \nD. Redis 캐시용 Amazon ElastiCache 를 애플리케이션 스택에 추가합니다. DynamoDB 대신 \nRedis 캐시 엔드포인트를 가리키도록 애플리케이션을 업데이트합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/109454-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nhttps://aws.amazon.com/premiumsupport/knowledge-center/dynamodb-high-latency/ \nAmazon DynamoDB Accelerator(DAX)는 DynamoDB 를 위한 완전 관리형 인 메모리 캐시로, \nDynamoDB 테이블의 성능을 최대 10 배까지 향상시키고 모든 규모에서 마이크로초 수준의 \n응답 시간을 제공합니다. DynamoDB API 작업과 호환되며 use1 에 대한 최소한의 코드 \n변경이 필요합니다. 새 메시지 테이블에 대해 DAX 를 구성함으로써 솔루션은 최소한의 \n애플리케이션 변경으로 새 메시지를 읽는 대기 시간을 줄일 수 있습니다. \n1. 증가된 읽기 로드를 처리하기 위해 DynamoDB 읽기 replicas 를 추가합니다. 읽기 전용 \n복제본의 읽기 엔드포인트를 가리키도록 애플리케이션을 업데이트합니다. DynamoDB 는 \n읽기 전용 복제본을 기능으로 지원하지 않으므로 이 솔루션은 작동하지 않습니다. 읽기 \n전용 복제본은 DynamoDB 가 아닌 Amazon RDS 에서 사용할 수 있습니다. \n2. DynamoDB 의 새 메시지 테이블에 대한 읽기 용량 단위 수를 두 배로 늘립니다. 기존 \n\nDynamoDB 엔드포인트를 계속 사용합니다. 읽기 용량 단위를 늘리면 성능이나 지연 \n시간이 아니라 DynamoDB 의 처리량만 증가하므로 이 솔루션은 가능한 한 적은 지연 \n시간으로 새 메시지를 읽어야 한다는 요구 사항을 충족하지 않습니다. \n3. Redis 용 Amazon ElastiCache 캐시를 애플리케이션 스택에 추가합니다. DynamoDB 대신 \nRedis \n캐시 \n엔드포인트를 \n가리키도록 \n애플리케이션을 \n업데이트합니다. \nRedis\n용 \nElastiCache 를 추가하려면 먼저 캐시 쿼리, DynamoDB 에 쓴 후 캐시 업데이트, 필요할 때 \n캐시 무효화와 같은 캐싱 로직을 구현하기 위해 상당한 코드 변경이 필요하므로 이 \n솔루션은 최소한의 애플리케이션 변경 요구 사항을 충족하지 않습니다. \n \n참조: https://aws.amazon.com/dynamodb/dax/", "answer_choice": "A"}, "473": {"q_num": 473, "question": "회사는 Application Load Balancer(ALB) 뒤에 있는 Amazon EC2 인스턴스에서 웹 사이트를 \n호스팅합니다. 웹 사이트는 정적 콘텐츠를 제공합니다. 웹 사이트 트래픽이 증가하고 \n있으며 회사는 잠재적인 비용 증가에 대해 우려하고 있습니다. \nA. Amazon CloudFront 배포를 생성하여 엣지 로케이션에서 상태 파일을 캐싱합니다. \nB. Amazon ElastiCache 클러스터를 생성합니다. ALB 를 ElastiCache 클러스터에 연결하여 \n캐싱된 파일을 제공합니다. \nC. AWS WAF 웹 ACL 을 생성하고 ALB 와 연결합니다. 웹 ACL 에 규칙을 추가하여 정적 \n파일을 캐시합니다. \nD. 대체 AWS 리전에서 두 번째 ALB\n를 생성합니다. 사용자 트래픽을 가장 가까운 \n리전으로 라우팅하여 데이터 전송 비용을 최소화합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/109455-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "474": {"q_num": 474, "question": "회사는 다른 리전의 워크로드와 격리된 워크로드를 지원하고 실행하기 위해 AWS 리전에 \n여러 VPC 를 보유하고 있습니다. 최근 애플리케이션 시작 요구 사항으로 인해 회사의 \nVPC 는 모든 지역의 다른 모든 VPC 와 통신해야 합니다. \n최소한의 관리 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. VPC 피어링을 사용하여 단일 리전에서 VPC 통신을 관리합니다. 리전 간 VPC 피어링을 \n사용하여 VPC 통신을 관리합니다. \nB. 모든 지역에서 AWS Direct Connect 게이트웨이를 사용하여 여러 지역에서 VPC 를 \n\n연결하고 VPC 통신을 관리합니다. \nC. AWS Transit Gateway 를 사용하여 단일 지역에서 VPC 통신을 관리하고 지역 간 Transit \nGateway 피어링을 사용하여 VPC 통신을 관리합니다. \nD. 모든 지역에서 AWS PrivateLink 를 사용하여 여러 지역에서 VPC 를 연결하고 VPC \n통신을 관리합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/109659-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "475": {"q_num": 475, "question": "회사에서 Amazon Elastic Container Service(Amazon ECS)를 사용할 컨테이너화된 \n애플리케이션을 설계하고 있습니다. 애플리케이션은 내구성이 뛰어나고 RPO(복구 지점 \n목표)가 8\n시간인 다른 AWS 리전에 데이터를 복구할 수 있는 공유 파일 시스템에 \n액세스해야 합니다. 파일 시스템은 리전 내의 각 가용 영역에 탑재 대상을 제공해야 \n합니다. \n솔루션 설계자는 AWS Backup 을 사용하여 다른 리전에 대한 복제를 관리하려고 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 다중 AZ 배포가 있는 Windows 파일 서버용 Amazon FSx \nB. 다중 AZ 배포가 있는 NetApp ONTAP 용 Amazon FSx \nC. 표준 스토리지 클래스가 있는 Amazon Elastic File System(Amazon EFS) \nD. OpenZFS 용 Amazon FSx", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/109456-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "476": {"q_num": 476, "question": "회사는 가까운 장래에 급속한 성장을 기대하고 있습니다. 솔루션 설계자는 기존 사용자를 \n구성하고 AWS 에서 새 사용자에게 권한을 부여해야 합니다. 솔루션 설계자는 IAM 그룹을 \n만들기로 결정했습니다. 솔루션 설계자는 부서를 기반으로 IAM 그룹에 새 사용자를 \n추가합니다. \n새 사용자에게 권한을 부여하는 가장 안전한 추가 작업은 무엇입니까? \nA. 서비스 제어 정책(SCP)을 적용하여 액세스 권한을 관리합니다. \nB. 최소 권한이 있는 IAM 역할을 생성합니다. 역할을 IAM 그룹에 연결합니다. \n\nC. 최소 권한을 부여하는 IAM 정책을 생성합니다. 정책을 IAM 그룹에 연결합니다. \nD. IAM 역할을 생성합니다. 최대 권한을 정의하는 권한 경계와 역할을 연결합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/109458-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nIAM 정책은 IAM 자격 증명(예: 사용자, 그룹 또는 역할)에 대한 권한을 정의하는 \n문서입니다. IAM 정책을 사용하여 부서에 따라 기존 사용자 및 그룹에 권한을 부여할 수 \n있습니다. 최소 권한 권한을 부여하는 IAM 정책을 생성할 수 있습니다. 즉, 사용자가 \n작업을 수행하는 데 필요한 최소한의 권한만 부여한다는 의미입니다. 그런 다음 정책을 \nIAM 그룹에 연결하면 해당 그룹의 모든 사용자에게 정책이 적용됩니다. 이 솔루션은 운영 \n비용을 줄이고 권한 구성 및 관리를 단순화합니다. \n참조: \nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html", "answer_choice": "C"}, "477": {"q_num": 477, "question": "그룹에는 Amazon S3 버킷을 나열하고 해당 버킷에서 객체를 삭제할 수 있는 권한이 \n필요합니다. 관리자는 버킷에 대한 액세스 권한을 제공하기 위해 다음 IAM 정책을 \n생성하고 해당 정책을 그룹에 적용했습니다. 그룹은 버킷의 객체를 삭제할 수 없습니다. \n회사는 최소 권한 액세스 규칙을 따릅니다. \n \n\n버킷 액세스를 수정하기 위해 솔루션 설계자가 정책에 추가해야 하는 설명은 무엇입니까? \nA. \n \nB. \n \nC. \n \nD.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/109459-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "D"}, "478": {"q_num": 478, "question": "로펌은 대중과 정보를 공유해야 합니다. 이 정보에는 공개적으로 읽을 수 있어야 하는 수백 \n개의 파일이 포함됩니다. 지정된 미래 날짜 이전에 누구든지 파일을 수정하거나 삭제하는 \n것은 금지됩니다. \n가장 안전한 방식으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 정적 웹 사이트 호스팅용으로 구성된 Amazon S3 버킷에 모든 파일을 업로드합니다. \n지정된 날짜까지 S3 버킷에 액세스하는 모든 AWS 보안 주체에게 읽기 전용 IAM 권한을 \n부여합니다. \nB. S3 버전 관리가 활성화된 새 Amazon S3 버킷을 생성합니다. 지정된 날짜에 따라 보존 \n기간이 있는 S3 Object Lock 을 사용하십시오. 정적 웹 사이트 호스팅을 위해 S3 버킷을 \n구성합니다. 객체에 대한 읽기 전용 액세스를 허용하도록 S3 버킷 정책을 설정합니다. \nC. S3 버전 관리가 활성화된 새 Amazon S3 버킷을 생성합니다. 객체 수정 또는 삭제 시 \nAWS Lambda 함수를 실행하도록 이벤트 트리거를 구성합니다. 개체를 프라이빗 S3 버킷의 \n원래 버전으로 바꾸도록 Lambda 함수를 구성합니다. \nD. 정적 웹 사이트 호스팅용으로 구성된 Amazon S3 버킷에 모든 파일을 업로드합니다. \n파일이 포함된 폴더를 선택합니다. 지정된 날짜에 따라 보존 기간이 있는 S3 Object Lock 을 \n사용하십시오. S3 버킷에 액세스하는 모든 AWS 보안 주체에게 읽기 전용 IAM 권한을 \n부여합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/109725-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "479": {"q_num": 479, "question": "회사에서 필요한 인프라를 수동으로 프로비저닝하여 새 웹 사이트의 인프라 프로토타입을 \n만들고 있습니다. 이 인프라에는 Auto Scaling 그룹, Application Load Balancer 및 Amazon \nRDS 데이터베이스가 포함됩니다. 구성이 철저히 검증된 후 회사는 자동화된 방식으로 두 \n가용 영역에서 개발 및 프로덕션 사용을 위한 인프라를 즉시 배포할 수 있는 기능을 \n원합니다. \n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까? \nA. AWS Systems Manager 를 사용하여 2 개의 가용 영역에서 프로토타입 인프라를 복제하고 \n프로비저닝합니다. \nB. 프로토타입 인프라를 가이드로 사용하여 인프라를 템플릿으로 정의합니다. AWS \nCloudFormation 으로 인프라를 배포하십시오. \nC. AWS Config 를 사용하여 프로토타입 인프라에서 사용되는 리소스 인벤토리를 기록합니다. \nAWS Config 를 사용하여 프로토타입 인프라를 두 개의 가용 영역에 배포합니다. \nD. AWS Elastic Beanstalk 를 사용하고 프로토타입 인프라에 대한 자동 참조를 사용하도록 \n\n구성하여 2 개의 가용 영역에 새 환경을 자동으로 배포합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/109461-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nAWS CloudFormation 은 Auto Scaling 그룹, 로드 밸런서, 데이터베이스 등 원하는 모든 \n리소스를 설명하는 템플릿을 사용하여 AWS 리소스를 모델링하고 설정할 수 있도록 \n도와주는 서비스입니다. AWS CloudFormation\n을 사용하여 여러 환경과 리전에서 \n자동화되고 일관된 방식으로 인프라를 배포할 수 있습니다. 또한 AWS CloudFormation 을 \n사용하여 인프라를 단일 단위로 업데이트하거나 삭제할 수 있습니다. \n참조 URL: \n1 https://aws.amazon.com/cloudformation/ \n2 https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/Welcome.html \n3 \nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-whatis-concep\nts.html", "answer_choice": "B"}, "480": {"q_num": 480, "question": "비즈니스 애플리케이션은 Amazon EC2 에서 호스팅되며 암호화된 객체 스토리지에 Amazon \nS3 를 사용합니다. 최고 정보 보안 책임자는 두 서비스 간의 애플리케이션 트래픽이 공용 \n인터넷을 통과해서는 안 된다고 지시했습니다. \n규정 준수 요구 사항을 충족하기 위해 솔루션 설계자가 사용해야 하는 기능은 무엇입니까? \nA. AWS 키 관리 서비스(AWS KMS) \nB. VPC 엔드포인트 \nC. 사설 서브넷 \nD. 가상 프라이빗 게이트웨이", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/109663-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n참고: \nhttps://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints.html", "answer_choice": "B"}, "481": {"q_num": 481, "question": "회사는 AWS 클라우드에서 3\n계층 웹 애플리케이션을 호스팅합니다. MySQL\n용 다중 \nAZAmazon RDS 서버는 데이터베이스 계층을 형성합니다. Amazon ElastiCache 는 캐시 \n계층을 형성합니다. 회사는 고객이 데이터베이스에 항목을 추가할 때 캐시의 데이터를 \n추가하거나 업데이트하는 캐싱 전략을 원합니다. 캐시의 데이터는 항상 데이터베이스의 \n데이터와 일치해야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 지연 로딩 캐싱 전략 구현 \nB. write-through 캐싱 전략 구현 \nC. 추가 TTL 캐싱 전략 구현 \nD. AWS AppConfig 캐싱 전략 구현", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/109462-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "482": {"q_num": 482, "question": "회사는 \n온프레미스 \n위치에서 \nAmazon \nS3 \n버킷으로 \n100GB\n의 \n기록 \n데이터를 \n마이그레이션하려고 합니다. 이 회사는 온프레미스에 100Mbps 인터넷 연결이 있습니다. \n회사는 S3 버킷으로 전송되는 데이터를 암호화해야 합니다. 회사는 새로운 데이터를 \nAmazon S3 에 직접 저장합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. AWS CLI 에서 s3 sync 명령을 사용하여 데이터를 S3 버킷으로 직접 이동합니다. \nB. \nAWS \nDataSync\n를 \n사용하여 \n온프레미스 \n위치에서 \nS3 \n버킷으로 \n데이터를 \n마이그레이션합니다. \nC. AWS Snowball 을 사용하여 데이터를 S3 버킷으로 이동합니다. \nD. 온프레미스 위치에서 AWS 로 IPsec VPN 을 설정합니다. AWS CLI 에서 s3 cp 명령을 \n사용하여 데이터를 S3 버킷으로 직접 이동합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/109490-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nAWS DataSync 는 인터넷 또는 AWS Direct Connect 를 통해 온프레미스 스토리지와 AWS \n스토리지 서비스 간에 대량의 데이터를 온라인으로 쉽게 이동할 수 있게 해주는 데이터 \n전송 서비스입니다. DataSync 는 TLS 암호화를 사용하여 전송 중인 데이터를 자동으로 \n\n암호화하고 체크섬을 사용하여 전송하는 동안 데이터 무결성을 확인합니다. DataSync 는 \n오픈 소스 도구보다 최대 10 배 빠르게 데이터를 전송할 수 있으며 전송 예약, 모니터링 및 \n재개와 같은 작업을 단순화하고 자동화하여 운영 오버헤드를 줄입니다. \n참조: \nhttps://aws.amazon.com/datasync/", "answer_choice": "B"}, "483": {"q_num": 483, "question": "회사에서 Windows 컨테이너 아래의 .NET 6 Framework 에서 실행되는 Windows 작업을 \n컨테이너화했습니다. 회사는 AWS 클라우드에서 이 작업을 실행하려고 합니다. 작업은 \n10 분마다 실행됩니다. 작업의 실행 시간은 1 분에서 3 분 사이입니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. 작업의 컨테이너 이미지를 기반으로 AWS Lambda 함수를 생성합니다. 10 분마다 함수를 \n호출하도록 Amazon EventBridge 를 구성합니다. \nB. AWS Batch 를 사용하여 AWS Fargate 리소스를 사용하는 작업을 생성합니다. 10 분마다 \n실행되도록 작업 일정을 구성합니다. \nC. AWS Fargate 에서 Amazon Elastic Container Service(Amazon ECS)를 사용하여 작업을 \n실행합니다. 10 분마다 실행할 작업의 컨테이너 이미지를 기반으로 예약된 작업을 만듭니다. \nD. AWS Fargate 에서 Amazon Elastic Container Service(Amazon ECS)를 사용하여 작업을 \n실행합니다. 작업의 컨테이너 이미지를 기반으로 독립 실행형 작업을 생성합니다. Windows \n작업 스케줄러를 사용하여 10 분마다 작업을 실행합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/109463-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "484": {"q_num": 484, "question": "한 회사가 많은 독립 실행형 AWS 계정에서 통합된 다중 계정 아키텍처로 이동하려고 \n합니다. 이 회사는 다양한 사업부에 대해 많은 새 AWS 계정을 생성할 계획입니다. 회사는 \n중앙 집중식 회사 디렉터리 서비스를 사용하여 이러한 AWS 계정에 대한 액세스를 \n인증해야 합니다. \n이러한 요구 사항을 충족하기 위해 솔루션 설계자가 권장해야 하는 작업 조합은 무엇입니까? \n(2 개 선택) \nA. 모든 기능을 켠 상태에서 AWS Organizations 에 새 조직을 만듭니다. 조직에서 새 AWS \n계정을 생성합니다. \nB. Amazon Cognito 자격 증명 풀을 설정합니다. Amazon Cognito 인증을 수락하도록 AWS \n\nIAM Identity Center(AWS Single Sign-On)를 구성합니다. \nC. AWS 계정을 관리하기 위해 서비스 제어 정책(SCP)을 구성합니다. AWS IAM Identity \nCenter(AWS Single Sign-On)를 AWS Directory Service 에 추가합니다. \nD. AWS Organizations\n에서 새 조직을 생성합니다. AWS Directory Service\n를 직접 \n사용하도록 조직의 인증 메커니즘을 구성합니다. \nE. 조직에서 AWS IAM Identity Center(AWS Single Sign-On)를 설정합니다. IAM Identity \nCenter 를 구성하고 회사의 회사 디렉터리 서비스와 통합합니다.", "answer_block": "Answer: A, E \nhttps://www.examtopics.com/discussions/amazon/view/109467-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nAWS Organizations 는 사용자가 여러 AWS 계정을 중앙에서 관리하고 제어할 수 있도록 \n도와주는 서비스입니다. 이를 통해 사용자는 비즈니스 요구 사항 또는 기타 기준에 따라 \n계정을 그룹화하는 조직 단위(OU)를 만들 수 있습니다. 또한 사용자는 서비스 제어 \n정책(SCP)을 정의하고 OU 또는 계정에 연결하여 계정에서 수행할 수 있는 작업을 제한할 \n수 있습니다. 모든 기능을 켠 상태에서 AWS Organizations 에 새 조직을 생성하면 이 \n솔루션은 서로 다른 비즈니스 단위의 새 AWS 계정을 통합하고 관리할 수 있습니다. AWS \nIAM Identity Center(이전에는 AWS Single Sign-On 이라고 함)는 모든 AWS 계정 및 \n클라우드 애플리케이션에 대한 Single Sign-On 액세스를 제공하는 서비스입니다. AWS \nDirectory Service 를 통해 Microsoft Active Directory 와 연결하여 해당 디렉터리의 사용자가 \n기존 Active Directory 사용자 이름과 암호를 사용하여 맞춤형 AWS 액세스 포털에 로그인할 \n수 있도록 합니다. AWS 액세스 포털에서 사용자는 권한이 있는 모든 AWS 계정 및 \n클라우드 애플리케이션에 액세스할 수 있습니다2. 조직에 IAM Identity Center 를 설정하고 \n회사의 회사 디렉터리 서비스와 통합함으로써 솔루션은 중앙 집중식 회사 디렉터리 \n서비스를 사용하여 이러한 AWS 계정에 대한 액세스를 인증할 수 있습니다. \n1. Amazon Cognito 자격 증명 풀을 설정합니다. Amazon Cognito 인증을 수락하도록 AWS \nIAM Identity Center(AWS Single Sign-On)를 구성합니다. 이 솔루션은 중앙 집중식 기업 \n디렉터리 서비스를 사용하여 이러한 AWS 계정에 대한 액세스 인증 요구 사항을 충족하지 \n않습니다. Amazon Cognito 는 웹 및 모바일 애플리케이션에 대한 사용자 가입, 로그인 및 \n액세스 제어를 제공하는 서비스이기 때문입니다. 기업 디렉토리 서비스. \n2. 서비스 제어 정책(SCP)을 구성하여 AWS 계정을 관리합니다. AWS IAM Identity \nCenter(AWS Single Sign-On)를 AWS Directory Service 에 추가합니다. SCP 는 계정 자체를 \n관리하는 것이 아니라 조직의 계정이 수행할 수 있는 작업을 제한하는 데 사용되기 때문에 \n이 솔루션은 작동하지 않습니다1. 또한 IAM Identity Center 는 AWS Directory Service 를 \n통해 Microsoft Active Directory 와 연결하는 별도의 서비스이므로 AWS Directory Service 에 \n\n추가할 수 없습니다. \n3. AWS Organizations\n에서 새 조직을 생성합니다. AWS Directory Service\n를 직접 \n사용하도록 조직의 인증 메커니즘을 구성합니다. AWS Organizations 에는 AWS Directory \nService 를 직접 사용할 수 있는 인증 메커니즘이 없기 때문에 이 솔루션은 작동하지 \n않습니다. AWS Organizations 는 IAM Identity Center 를 사용하여 조직의 계정에 대한 Single \nSign-On 액세스를 제공합니다. \n \n참조: \nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_integrate_services.htm\nl", "answer_choice": "A"}, "485": {"q_num": 485, "question": "회사는 오래된 뉴스 영상에서 AWS 에 비디오 아카이브를 저장할 수 있는 솔루션을 찾고 \n있습니다. 회사는 비용을 최소화해야 하며 이러한 파일을 복원할 필요가 거의 없습니다. \n파일이 필요할 때 최대 5 분 내에 사용할 수 있어야 합니다. \n가장 비용 효율적인 솔루션은 무엇입니까? \nA. 비디오 아카이브를 Amazon S3 Glacier 에 저장하고 긴급 검색을 사용합니다. \nB. 비디오 아카이브를 Amazon S3 Glacier 에 저장하고 표준 검색을 사용합니다. \nC. 비디오 아카이브를 Amazon S3 Standard-Infrequent Access(S3 Standard-IA)에 \n저장합니다. \nD. 비디오 아카이브를 Amazon S3 One Zone-Infrequent Access(S3 One Zone-IA)에 \n저장합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/109470-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "486": {"q_num": 486, "question": "한 회사가 AWS 에서 3 계층 애플리케이션을 구축하고 있습니다. 프레젠테이션 계층은 정적 \n웹 사이트를 제공합니다. 논리 계층은 컨테이너화된 애플리케이션입니다. 이 응용 \n프로그램은 관계형 데이터베이스에 데이터를 저장합니다. 이 회사는 배포를 단순화하고 \n운영 비용을 절감하기를 원합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Amazon S3\n를 사용하여 정적 콘텐츠를 호스팅합니다. 컴퓨팅 성능을 위해 AWS \nFargate\n와 함께 Amazon Elastic Container Service(Amazon ECS)를 사용합니다. \n\n데이터베이스에 대해 관리형 Amazon RDS 클러스터를 사용합니다. \nB. Amazon CloudFront 를 사용하여 정적 콘텐츠를 호스팅합니다. 컴퓨팅 성능을 위해 \nAmazon EC2 와 함께 Amazon Elastic Container Service(Amazon ECS)를 사용합니다. \n데이터베이스에 대해 관리형 Amazon RDS 클러스터를 사용합니다. \nC. Amazon S3\n를 사용하여 정적 콘텐츠를 호스팅합니다. 컴퓨팅 성능을 위해 AWS \nFargate\n와 함께 Amazon Elastic Kubernetes Service(Amazon EKS)를 사용합니다. \n데이터베이스에 대해 관리형 Amazon RDS 클러스터를 사용합니다. \nD. Amazon EC2 예약 인스턴스를 사용하여 정적 콘텐츠를 호스팅합니다. 컴퓨팅 성능을 \n위해 Amazon EC2 와 함께 Amazon Elastic Kubernetes Service(Amazon EKS)를 사용합니다. \n데이터베이스에 대해 관리형 Amazon RDS 클러스터를 사용합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/109664-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nAmazon S3 는 업계 최고의 확장성, 데이터 가용성, 보안 및 성능을 제공하는 객체 스토리지 \n서비스입니다. Amazon S3 를 사용하여 HTML 파일, 이미지, 비디오 등과 같은 웹 사이트용 \n정적 콘텐츠를 호스팅할 수 있습니다. Amazon Elastic Container Service(Amazon ECS)는 \nAWS 에서 컨테이너화된 애플리케이션을 실행하고 확장할 수 있는 완전 관리형 컨테이너 \n오케스트레이션 서비스입니다. . \nAWS Fargate 는 Amazon ECS 및 Amazon EKS 모두에서 작동하는 컨테이너용 서버리스 \n컴퓨팅 엔진입니다. Fargate 를 사용하면 서버를 프로비저닝하고 관리할 필요가 없으므로 \n애플리케이션 구축에 쉽게 집중할 수 있습니다. 컨테이너화된 애플리케이션 논리 계층의 \n컴퓨팅 성능을 위해 AWS Fargate 와 함께 Amazon ECS 를 사용할 수 있습니다. Amazon \nRDS 는 클라우드에서 관계형 데이터베이스를 쉽게 설정, 운영 및 확장할 수 있게 해주는 \n관리형 관계형 데이터베이스 서비스입니다. 애플리케이션의 데이터베이스 계층에 대해 \n관리형 Amazon RDS 클러스터를 사용할 수 있습니다. 이 솔루션은 배포를 단순화하고 \n3 계층 애플리케이션의 운영 비용을 줄여줍니다. \n참조: \nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/WebsiteHosting.html \nhttps://docs.aws.amazon.com/AmazonECS/latest/developerguide/Welcome.html \nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Welcome.html", "answer_choice": "A"}, "487": {"q_num": 487, "question": "회사에서 해당 애플리케이션을 위한 스토리지 솔루션을 찾고 있습니다. 솔루션은 가용성과 \n\n확장성이 높아야 합니다. 또한 솔루션은 기본 프로토콜을 통해 AWS 및 온프레미스의 여러 \nLinux 인스턴스에 의해 마운트될 수 있고 최소 크기 요구 사항이 없는 파일 시스템으로 \n작동해야 합니다. 회사는 온프레미스 네트워크에서 VPC 로 액세스하기 위해 사이트 간 \nVPN 을 설정했습니다. \n이러한 요구 사항을 충족하는 스토리지 솔루션은 무엇입니까? \nA. Amazon FSx 다중 AZ 배포 \nB. Amazon Elastic Block Store(Amazon EBS) 다중 연결 볼륨 \nC. 탑재 대상이 여러 개인 Amazon Elastic File System(Amazon EFS) \nD. 단일 탑재 대상 및 여러 액세스 지점이 있는 Amazon Elastic File System(Amazon EFS)", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/109665-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "488": {"q_num": 488, "question": "4 년 차 미디어 회사는 AWS 계정을 구성하기 위해 AWS Organizations 모든 기능 기능 \n세트를 사용하고 있습니다. 회사의 재무 팀에 따르면 회원 계정의 청구 정보는 회원 계정의 \n루트 사용자를 포함하여 누구도 액세스할 수 없어야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 모든 재무 팀 사용자를 IAM 그룹에 추가합니다. Billing 이라는 AWS 관리형 정책을 \n그룹에 연결합니다. \nB. 루트 사용자를 포함한 모든 사용자의 청구 정보에 대한 액세스를 거부하는 자격 증명 \n기반 정책을 첨부합니다. \nC. 청구 정보에 대한 액세스를 거부하는 서비스 제어 정책(SCP)을 만듭니다. 루트 조직 \n단위(OU)에 SCP 를 연결합니다. \nD. 조직의 모든 기능 기능 집합에서 조직 통합 결제 기능 집합으로 변환합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/109509-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명:・ \n서비스 제어 정책(SCP): SCP 는 AWS Organizations 의 필수적인 부분이며 이를 통해 AWS \nOrganization 내 조직 단위(OU)에 대한 세분화된 권한을 설정할 수 있습니다. SCP 는 루트 \n사용자를 포함하여 멤버 계정에 부여할 수 있는 최대 권한에 대한 중앙 제어를 제공합니다. \n청구 정보에 대한 액세스 거부: SCP 를 만들어 루트 OU 에 연결하면 조직 내 모든 계정의 \n청구 정보에 대한 액세스를 명시적으로 거부할 수 있습니다. SCP 는 청구 관련 서비스를 \n\n포함하여 다양한 AWS 서비스 및 작업에 대한 액세스를 제한하는 데 사용할 수 있습니다. \n세분화된 제어: SCP 를 사용하면 조직 단위 수준에서 특정 권한 및 제한을 정의할 수 \n있습니다. 루트 OU 에서 청구 정보에 대한 액세스를 거부하면 루트 사용자를 포함한 어떤 \n멤버 계정도 청구 정보에 액세스할 수 없습니다.", "answer_choice": "C"}, "489": {"q_num": 489, "question": "전자상거래 \n회사는 \n온프레미스 \n웨어하우스 \n솔루션과 \n통합된 \nAWS \n클라우드에서 \n애플리케이션을 실행합니다. 이 회사는 Amazon Simple Notification Service(Amazon SNS)를 \n사용하여 주문 메시지를 온프레미스 HTTPS 엔드포인트로 보내 창고 애플리케이션이 \n주문을 처리할 수 있도록 합니다. 로컬 데이터 센터 팀에서 일부 주문 메시지가 수신되지 \n않은 것을 감지했습니다. \n솔루션 설계자는 전달되지 않은 메시지를 보관하고 최대 14 일 동안 메시지를 분석해야 \n합니다. \n최소한의 개발 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 보존 기간이 14 일인 Amazon Kinesis Data Stream 대상이 있는 Amazon SNS 배달 못한 \n편지 대기열을 구성합니다. \nB. 애플리케이션과 Amazon SNS 사이에 보존 기간이 14 일인 Amazon Simple Queue \nService(Amazon SQS) 대기열을 추가합니다. \nC. 보존 기간이 14 일인 Amazon Simple Queue Service(Amazon SQS) 대상이 있는 Amazon \nSNS 데드 레터 대기열을 구성합니다. \nD. 보존 기간이 14\n일로 설정된 TTL 속성이 있는 Amazon DynamoDB 대상이 있는 \nAmazon SNS 데드 레터 대기열을 구성합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/109637-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "490": {"q_num": 490, "question": "게임 회사는 Amazon DynamoDB 를 사용하여 지리적 위치, 플레이어 데이터 및 순위표와 \n같은 사용자 정보를 저장합니다. 회사는 최소한의 코딩으로 Amazon S3 버킷에 대한 \n지속적인 백업을 구성해야 합니다. 백업은 애플리케이션의 가용성에 영향을 미치지 않아야 \n하며 테이블에 대해 정의된 읽기 용량 단위(RCU)에 영향을 주지 않아야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. Amazon EMR 클러스터를 사용하십시오. Apache Hive 작업을 생성하여 Amazon S3 에 \n데이터를 백업합니다. \n\nB. 연속 백업을 통해 DynamoDB 에서 Amazon S3 로 직접 데이터를 내보냅니다. 테이블에 \n대해 지정 시간 복구를 설정합니다. \nC. Amazon DynamoDB 스트림을 구성합니다. 스트림을 사용하고 데이터를 Amazon S3 \n버킷으로 내보내는 AWS Lambda 함수를 생성합니다. \nD. 정기적으로 데이터베이스 테이블에서 Amazon S3 로 데이터를 내보내는 AWS Lambda \n함수를 생성합니다. 테이블에 대해 지정 시간 복구를 설정합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/109577-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n참고: \nhttps://aws.amazon.com/ko/blogs/database/dynamodb-streams-use-cases-and-design\n-patterns/ \nhttps://repost.aws/ko/knowledge-center/back-up-dynamodb-s3", "answer_choice": "B"}, "491": {"q_num": 491, "question": "솔루션 설계자는 은행에 대한 신용 카드 데이터 유효성 검사 요청을 처리하기 위해 \n비동기식 애플리케이션을 설계하고 있습니다. 애플리케이션은 안전해야 하며 각 요청을 한 \n번 이상 처리할 수 있어야 합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. AWS Lambda 이벤트 소스 매핑을 사용하십시오. Amazon Simple Queue Service(Amazon \nSQS) 표준 대기열을 이벤트 소스로 설정합니다. 암호화에 AWS Key Management \nService(SSE-KMS)를 \n사용합니다. Lambda \n실행 역할에 대한 kms:Decrypt \n권한을 \n추가합니다. \nB. AWS Lambda 이벤트 소스 매핑을 사용합니다. Amazon Simple Queue Service(Amazon \nSQS) \nFIFO \n대기열을 \n이벤트 \n소스로 \n사용합니다. \n암호화에 \nSQS \n관리형 \n암호화 \n키(SSE-SQS)를 사용합니다. Lambda 함수에 대한 암호화 키 호출 권한을 추가합니다. \nC. AWS Lambda 이벤트 소스 매핑을 사용합니다. Amazon Simple Queue Service(Amazon \nSQS) FIFO 대기열을 이벤트 소스로 설정합니다. AWS KMS 키(SSE-KMS)를 사용합니다. \nLambda 실행 역할에 대한 kms:Decrypt 권한을 추가합니다. \nD. AWS Lambda 이벤트 소스 매핑을 사용합니다. Amazon Simple Queue Service(Amazon \nSQS) 표준 대기열을 이벤트 소스로 설정합니다. 암호화에 AWS KMS 키(SSE-KMS)를 \n사용합니다. Lambda 함수에 대한 암호화 키 호출 권한을 추가합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/109513-exam-aws-certified-sol\n\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "492": {"q_num": 492, "question": "회사에 개발 작업을 위한 여러 AWS 계정이 있습니다. 일부 직원은 지속적으로 대형 \nAmazon EC2 인스턴스를 사용하므로 회사가 개발 계정에 대한 연간 예산을 초과하게 \n됩니다. 회사는 이러한 계정에서 AWS 리소스 생성을 중앙에서 제한하려고 합니다. \n최소한의 개발 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 승인된 EC2 생성 프로세스를 사용하는 AWS Systems Manager 템플릿을 개발합니다. \n승인된 Systems Manager 템플릿을 사용하여 EC2 인스턴스를 프로비저닝합니다. \nB. AWS Organizations 를 사용하여 계정을 조직 단위(OU)로 구성합니다. 서비스 제어 \n정책(SCP)을 정의하고 연결하여 EC2 인스턴스 유형의 사용을 제어합니다. \nC. EC2 인스턴스가 생성될 때 AWS Lambda 함수를 호출하는 Amazon EventBridge 규칙을 \n구성합니다. 허용되지 않는 EC2 인스턴스 유형을 중지합니다. \nD. 직원이 허용되는 EC2 인스턴스 유형을 생성할 수 있도록 AWS Service Catalog 제품을 \n설정합니다. 직원이 서비스 카탈로그 제품을 사용해야만 EC2 인스턴스를 배포할 수 있는지 \n확인하십시오.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/109638-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n동적 조정은 수요 또는 부하에 따라 Auto Scaling 그룹의 EC2 인스턴스 수를 자동으로 \n조정하는 일종의 자동 조정입니다. 지정된 지표가 임계값을 초과하면 CloudWatch 경보를 \n사용하여 조정 작업을 트리거합니다. 필요에 따라 확장(인스턴스 추가) 또는 축소(인스턴스 \n제거)할 수 있습니다1. 솔루션은 동적 확장을 사용하여 갑작스러운 트래픽 증가 중에 가장 \n비용 효율적으로 애플리케이션 성능을 유지할 수 있습니다. \n1. 수동 조정을 사용하여 Auto Scaling 그룹의 크기를 변경합니다. 수동 확장은 사용자가 \nCLI 또는 콘솔을 통해 인스턴스 수를 수동으로 늘리거나 줄여야 하므로 이 솔루션은 \n트래픽이 갑자기 증가하는 동안 애플리케이션 성능을 유지해야 하는 요구 사항을 충족하지 \n않습니다. 수요나 부하의 변화에 자동으로 반응하지 않습니다. \n2. 예측 조정을 사용하여 Auto Scaling 그룹의 크기를 변경합니다. 이 솔루션은 예측 \n확장이 기계 학습 및 인공 지능 도구를 사용하여 트래픽 부하를 평가하고 더 많거나 적은 \n리소스가 필요할 때를 예상하므로 대부분의 비용 효율성 요구 사항을 충족하지 않습니다. \n주어진 시간에 실제 수요 또는 로드와 일치하지 않을 수 있는 예측을 기반으로 예약된 조정 \n작업을 수행합니다. 예측 조정은 예측 가능한 트래픽 패턴이 있거나 트래픽 부하의 알려진 \n\n변경 사항이 있는 시나리오에 더 적합합니다. \n3. 일정 조정을 사용하여 Auto Scaling 그룹의 크기를 변경합니다. 일정 조정은 사용자가 \n예약한 특정 시간에 조정 작업을 수행하므로 이 솔루션은 트래픽이 갑자기 증가하는 동안 \n애플리케이션 성능을 유지해야 하는 요구 사항을 충족하지 않습니다. 수요나 부하의 변화에 \n자동으로 반응하지 않습니다. 일정 조정은 하루 중 특정 시간에 예측 가능한 트래픽 감소 \n또는 급증이 있는 시나리오에 더 적합합니다. \n \n참조: \nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scale-based-ondemand.ht\nml", "answer_choice": "B"}, "493": {"q_num": 493, "question": "한 회사에서 AI(인공 지능)를 사용하여 고객 서비스 통화 품질을 확인하려고 합니다. 회사는 \n현재 영어를 포함하여 4 개 언어로 통화를 관리합니다. 회사는 앞으로 새로운 언어를 \n제공할 것입니다. 회사는 기계 학습(ML) 모델을 정기적으로 유지 관리할 리소스가 \n없습니다. \n회사는 고객 서비스 통화 녹음에서 서면 감정 분석 보고서를 작성해야 합니다. 고객 서비스 \n통화 녹음 텍스트는 영어로 번역되어야 합니다. \n이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (3 개 선택) \nA. Amazon Comprehend 를 사용하여 오디오 녹음을 영어로 번역하십시오. \nB. Amazon Lex 를 사용하여 작성된 감정 분석 보고서를 생성합니다. \nC. Amazon Polly 를 사용하여 오디오 녹음을 텍스트로 변환합니다. \nD. Amazon Transcribe 를 사용하여 모든 언어의 오디오 녹음을 텍스트로 변환합니다. \nE. Amazon Translate 를 사용하여 모든 언어의 텍스트를 영어로 번역합니다. \nF. Amazon Comprehend 를 사용하여 감정 분석 보고서를 생성합니다.", "answer_block": "Answer: D, E, F \nhttps://www.examtopics.com/discussions/amazon/view/109639-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명:・ \n이러한 답변은 모든 언어로 된 고객 서비스 통화 녹음에서 서면 감정 분석 보고서를 \n작성하고 이를 영어로 번역하는 요구 사항을 충족하므로 정확합니다. Amazon Transcribe 는 \n고급 기계 학습 기술을 사용하여 오디오 파일의 음성을 인식하고 텍스트로 변환하는 \n서비스입니다. Amazon Transcribe\n를 사용하여 모든 언어의 오디오 녹음을 텍스트로 \n변환하고 소스 오디오의 언어 코드를 지정할 수 있습니다. Amazon Translate 는 빠르고 \n\n고품질의 저렴한 언어 번역을 제공하는 신경망 기계 번역 서비스입니다. Amazon \nTranslate 를 사용하여 모든 언어의 텍스트를 영어로 번역하고 소스 및 대상 언어 코드를 \n지정할 수 있습니다. Amazon Comprehend 는 기계 학습을 사용하여 텍스트에서 통찰력과 \n관계를 찾는 자연어 처리(NLP) 서비스입니다. Amazon Comprehend 를 사용하여 텍스트가 \n긍정적인지, 부정적인지, 중립적인지 또는 혼합되어 있는지 판단하는 감정 분석 보고서를 \n생성할 수 있습니다. \n \n참조: \nhttps://docs.aws.amazon.com/transcribe/latest/dg/what-is-transcribe.html \nhttps://docs.aws.amazon.com/translate/latest/dg/what-is.html \nhttps://docs.aws.amazon.com/comprehend/latest/dg/how-sentiment.html", "answer_choice": "D"}, "494": {"q_num": 494, "question": "회사는 Amazon EC2 인스턴스를 사용하여 내부 시스템을 호스팅합니다. 배포 작업의 \n일부로 관리자는 AWS CLI\n를 사용하여 EC2 인스턴스를 종료하려고 합니다. 그러나 \n관리자는 403(액세스 거부) 오류 메시지를 받습니다. \n관리자는 다음 IAM 정책이 연결된 IAM 역할을 사용하고 있습니다. \n\n \n실패한 요청의 원인은 무엇입니까? \nA. EC2 인스턴스에는 Deny 문이 포함된 리소스 기반 정책이 있습니다. \nB. 정책 설명에 주체가 지정되지 않았습니다. \nC. \"Action\" 필드는 EC2 인스턴스를 종료하는 데 필요한 조치를 부여하지 않습니다. \nD. EC2 인스턴스 종료 요청은 CIDR 블록 192.0.2.0/24 또는 203.0.113.0/24 에서 시작되지 \n않습니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/109727-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "D"}, "495": {"q_num": 495, "question": "회사에서 내부 감사를 실시하고 있습니다. 회사는 회사의 AWS Lake Formation 데이터 \n레이크와 연결된 Amazon S3 버킷의 데이터에 민감한 고객 또는 직원 데이터가 포함되지 \n\n않도록 하려고 합니다. 회사는 개인 식별 정보(PII) 또는 여권 번호 및 신용 카드 번호를 \n포함한 금융 정보를 검색하려고 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 계정에서 AWS Audit Manager 를 구성합니다. 감사를 위해 PCI DSS(Payment Card \nIndustry Data Security Standards)를 선택합니다. \nB. S3 버킷에서 Amazon S3 인벤토리 구성 인벤토리를 쿼리하도록 Amazon Athena 를 \n구성합니다. \nC. 필요한 데이터 유형에 대해 관리형 식별자를 사용하는 데이터 검색 작업을 실행하도록 \nAmazon Macie 를 구성합니다. \nD. Amazon S3 Select 를 사용하여 S3 버킷에서 보고서를 실행합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/109666-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nAmazon Macie 는 기계 학습 및 패턴 일치를 사용하여 AWS 에서 중요한 데이터를 검색하고 \n보호하는 완전 관리형 데이터 보안 및 데이터 개인 정보 보호 서비스입니다. Macie 는 \n다양한 유형의 PII 또는 금융 정보(예: 여권 번호 및 신용 카드 번호)에 대해 관리형 \n식별자를 사용하는 데이터 검색 작업을 실행할 수 있습니다. Macie 는 또한 데이터의 \n잠재적인 문제나 위험을 경고하는 결과를 생성할 수 있습니다. \n참조: \nhttps://docs.aws.amazon.com/macie/latest/userguide/macie-identifiers.html", "answer_choice": "C"}, "496": {"q_num": 496, "question": "회사는 온프레미스 서버를 사용하여 애플리케이션을 호스팅합니다. 회사의 저장 용량이 \n부족합니다. 애플리케이션은 블록 스토리지와 NFS 스토리지를 모두 사용합니다. 회사는 \n기존 애플리케이션을 재설계하지 않고 로컬 캐싱을 지원하는 고성능 솔루션이 필요합니다. \n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 작업 조합을 수행해야 합니까? \n(2 개 선택) \nA. Amazon S3 를 온프레미스 서버에 파일 시스템으로 탑재합니다. \nB. NFS 스토리지를 대체할 AWS Storage Gateway 파일 게이트웨이를 배포합니다. \nC. AWS Snowball Edge 를 배포하여 온프레미스 서버에 NFS 마운트를 프로비저닝합니다. \nD. 블록 스토리지를 대체할 AWS Storage Gateway 볼륨 게이트웨이를 배포합니다. \nE. Amazon Elastic File System(Amazon EFS) 볼륨을 배포하고 온프레미스 서버에 \n탑재합니다.", "answer_block": "Answer: B, D \nhttps://www.examtopics.com/discussions/amazon/view/109552-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명:・ \nhttps://aws.amazon.com/storagegateway/file/ \n파일 게이트웨이는 애플리케이션 데이터 파일과 백업 이미지를 Amazon S3 클라우드 \n스토리지에 내구성 있는 개체로 저장하기 위해 클라우드에 원활하게 연결할 수 있는 방법을 \n제공합니다. 파일 게이트웨이는 로컬 캐싱을 통해 Amazon S3 의 데이터에 대한 SMB 또는 \nNFS 기반 액세스를 제공합니다. 온프레미스 애플리케이션과 S3 객체 스토리지에 대한 파일 \n프로토콜 액세스가 필요한 Amazon EC2 기반 애플리케이션에 사용할 수 있습니다. \nhttps://aws.amazon.com/storagegateway/volume/ \n볼륨 게이트웨이는 온프레미스 애플리케이션에 클라우드 지원 iSCSI 블록 스토리지 볼륨을 \n제공합니다. \n볼륨 게이트웨이는 사용자를 대신하여 Amazon S3\n에 온프레미스 데이터를 저장하고 \n관리하며 캐시 모드 또는 저장 모드에서 작동합니다. 캐싱된 볼륨 게이트웨이 모드에서 \n기본 데이터는 Amazon S3 에 저장되는 반면 자주 액세스하는 데이터는 짧은 지연 시간 \n액세스를 위해 캐시에 로컬로 유지됩니다.", "answer_choice": "B"}, "497": {"q_num": 497, "question": "회사에는 동일한 AWS 리전의 Amazon S3 버킷에서 대량의 데이터를 읽고 쓰는 서비스가 \n있습니다. 이 서비스는 VPC 의 프라이빗 서브넷 내 Amazon EC2 인스턴스에 배포됩니다. \n이 서비스는 퍼블릭 서브넷의 NAT 게이트웨이를 통해 Amazon S3 와 통신합니다. 그러나 \n회사는 데이터 출력 비용을 줄일 수 있는 솔루션을 원합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. 퍼블릭 서브넷에서 전용 EC2 NAT 인스턴스를 프로비저닝합니다. 이 인스턴스의 탄력적 \n네트워크 인터페이스를 모든 S3 트래픽의 대상으로 사용하도록 프라이빗 서브넷에 대한 \n라우팅 테이블을 구성합니다. \nB. 프라이빗 서브넷에서 전용 EC2 NAT 인스턴스를 프로비저닝합니다. 이 인스턴스의 \n탄력적 네트워크 인터페이스를 모든 S3 트래픽의 대상으로 사용하도록 퍼블릭 서브넷에 \n대한 라우팅 테이블을 구성합니다. \nC. VPC 게이트웨이 엔드포인트를 프로비저닝합니다. 게이트웨이 엔드포인트를 모든 S3 \n트래픽의 경로로 사용하도록 프라이빗 서브넷에 대한 경로 테이블을 구성합니다. \nD. 두 번째 NAT 게이트웨이를 프로비저닝합니다. 이 NAT 게이트웨이를 모든 S3 트래픽의 \n대상으로 사용하도록 프라이빗 서브넷에 대한 라우팅 테이블을 구성합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/109667-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n이를 통해 회사는 VPC 의 Amazon EC2 인스턴스에서 Amazon S3 에 액세스하기 위한 \n데이터 \n출력 \n비용을 \n줄일 \n수 \n있습니다. \n회사는 \nVPC \n게이트웨이 \n엔드포인트를 \n프로비저닝함으로써 VPC 와 S3 간의 프라이빗 연결을 활성화할 수 있습니다. 게이트웨이 \n엔드포인트를 모든 S3 트래픽의 경로로 사용하도록 프라이빗 서브넷의 라우팅 테이블을 \n구성함으로써 회사는 데이터 처리 및 데이터 전송 비용을 청구하는 NAT 게이트웨이 사용을 \n피할 수 있습니다.", "answer_choice": "C"}, "498": {"q_num": 498, "question": "회사는 Amazon S3 를 사용하여 고해상도 사진을 S3 버킷에 저장합니다. 애플리케이션 \n변경을 최소화하기 위해 회사는 사진을 S3 개체의 최신 버전으로 저장합니다. 회사는 \n사진의 가장 최근 버전 두 개만 유지하면 됩니다. \n회사는 비용을 줄이고 싶어합니다. 회사는 S3 버킷을 큰 비용으로 식별했습니다. \n최소한의 운영 오버헤드로 S3 비용을 줄이는 솔루션은 무엇입니까? \nA. S3 수명 주기를 사용하여 만료된 객체 버전을 삭제하고 가장 최근 버전 2\n개를 \n유지합니다. \nB. AWS Lambda 함수를 사용하여 이전 버전을 확인하고 가장 최근 버전 2 개를 제외한 \n모든 버전을 삭제합니다. \nC. S3 배치 작업을 사용하여 최신이 아닌 객체 버전을 삭제하고 가장 최근 버전 2 개만 \n유지합니다. \nD. S3 버킷에서 버전 관리를 비활성화하고 가장 최근 버전 2 개를 유지합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/109668-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "499": {"q_num": 499, "question": "회사는 1Gbps AWS Direct Connect 연결 비용을 최소화해야 합니다. 회사의 평균 연결 \n사용률은 10% 미만입니다. 솔루션 설계자는 보안을 손상시키지 않으면서 비용을 절감할 \n솔루션을 추천해야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \n\nA. 새로운 1Gbps Direct Connect 연결을 설정합니다. 다른 AWS 계정과 연결을 \n공유합니다. \nB. AWS Management Console 에서 새로운 200Mbps Direct Connect 연결을 설정합니다. \nC. 1Gbps 연결을 주문하려면 AWS Direct Connect 파트너에게 문의하십시오. 다른 AWS \n계정과 연결을 공유합니다. \nD. 기존 AWS 계정에 대한 200Mbps 호스팅 연결을 주문하려면 AWS Direct Connect \n파트너에게 문의하십시오.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/109515-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명 \n회사는 더 저렴한 연결(200M)을 설정해야 하지만 호스트 연결로 더 많은 유연성을 위해 1, \n10 또는 100Gbps 의 포트 속도만 주문할 수 있기 때문에 B 는 올바르지 않습니다. \n50Mbps 에서 10Gbps 사이의 포트 속도를 주문할 수 있습니다. \nhttps://docs.aws.amazon.com/whitepapers/latest/aws-vpc-connectivity-options/aws-dir\nectconnect.html", "answer_choice": "D"}, "500": {"q_num": 500, "question": "회사에는 온프레미스에 여러 Windows 파일 서버가 있습니다. 이 회사는 파일을 Windows \nFile Server 파일 시스템용 Amazon FSx 로 마이그레이션하고 통합하려고 합니다. 액세스 \n권한이 변경되지 않도록 하려면 파일 권한을 보존해야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? (2 개 선택) \nA. 온프레미스에 AWS DataSync 에이전트를 배포합니다. 데이터를 FSx for Windows 파일 \n서버 파일 시스템으로 전송하도록 DataSync 작업을 예약합니다. \nB. AWS CLI 를 사용하여 각 파일 서버의 공유를 Amazon S3 버킷에 복사합니다. 데이터를 \nFSx for Windows File Server 파일 시스템으로 전송하도록 AWS DataSync 작업을 \n예약합니다. \nC. 각 파일 서버에서 드라이브를 제거합니다. Amazon S3 로 가져오기 위해 드라이브를 \nAWS 로 배송합니다. 데이터를 FSx for Windows File Server 파일 시스템으로 전송하도록 \nAWS DataSync 작업을 예약합니다. \nD. AWS Snowcone 디바이스를 주문합니다. 장치를 온프레미스 네트워크에 연결합니다. \n디바이스에서 AWS DataSync 에이전트를 시작합니다. 데이터를 FSx for Windows 파일 서버 \n파일 시스템으로 전송하도록 DataSync 작업을 예약합니다. \nE. AWS Snowball Edge Storage Optimized 디바이스를 주문합니다. 장치를 온프레미스 \n\n네트워크에 연결합니다. AWS CLI 를 사용하여 디바이스에 데이터를 복사합니다. Amazon \nS3 로 가져오기 위해 디바이스를 AWS 로 반송합니다. 데이터를 FSx for Windows File Server \n파일 시스템으로 전송하도록 AWS DataSync 작업을 예약합니다.", "answer_block": "Answer: A, D \nhttps://www.examtopics.com/discussions/amazon/view/109689-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명:・ \nA 이 옵션에는 온프레미스 파일 서버에 DataSync 에이전트를 배포하고 DataSync\n를 \n사용하여 데이터를 FSx for Windows File Server 로 직접 전송하는 작업이 포함됩니다. \nDataSync 는 마이그레이션 프로세스 중에 파일 권한이 보존되도록 합니다. \nD 이 옵션에는 휴대용 데이터 전송 장치인 AWS Snowcone 장치 사용이 포함됩니다. \nSnowcone \n디바이스를 \n온프레미스 \n네트워크에 \n연결하고 \n디바이스에서 \nDataSync \n에이전트를 시작하고 DataSync 작업을 예약하여 데이터를 FSx for Windows File Server 로 \n전송합니다. \nDataSync 는 파일 권한을 유지하면서 마이그레이션 프로세스를 처리합니다.", "answer_choice": "A"}, "501": {"q_num": 501, "question": "회사는 고객 결제 데이터를 Amazon S3 의 회사 데이터 레이크로 수집하려고 합니다. \n회사는 평균적으로 1 분마다 결제 데이터를 수신합니다. 회사는 결제 데이터를 실시간으로 \n분석하기를 원합니다. 그런 다음 회사는 데이터를 데이터 레이크로 수집하려고 합니다. \n이러한 요구 사항을 가장 효율적으로 충족하는 솔루션은 무엇입니까? \nA. Amazon Kinesis Data Streams 를 사용하여 데이터를 수집하십시오. AWS Lambda 를 \n사용하여 실시간으로 데이터를 분석합니다. \nB. AWS Glue 를 사용하여 데이터를 수집합니다. Amazon Kinesis Data Analytics 를 사용하여 \n데이터를 실시간으로 분석하십시오. \nC. Amazon Kinesis Data Firehose 를 사용하여 데이터를 수집합니다. Amazon Kinesis Data \nAnalytics 를 사용하여 데이터를 실시간으로 분석하십시오. \nD. Amazon API Gateway 를 사용하여 데이터를 수집합니다. AWS Lambda 를 사용하여 \n실시간으로 데이터를 분석합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/109421-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "502": {"q_num": 502, "question": "회사는 Amazon EC2 에서 콘텐츠 관리 시스템(CMS)을 사용하는 웹 사이트를 운영합니다. \nCMS 는 단일 EC2 인스턴스에서 실행되며 데이터 계층에 Amazon Aurora MySQL 다중 AZ \nDB 인스턴스를 사용합니다. 웹 사이트 이미지는 EC2 인스턴스 내부에 탑재된 Amazon \nElastic Block Store(Amazon EBS) 볼륨에 저장됩니다. \n웹 사이트의 성능과 복원력을 개선하기 위해 솔루션 설계자가 취해야 하는 작업 조합은 \n무엇입니까? (2 개 선택) \nA. 웹 사이트 이미지를 모든 EC2 인스턴스에 탑재된 Amazon S3 버킷으로 이동합니다. \nB. 기본 EC2 인스턴스의 NFS 공유를 사용하여 웹사이트 이미지를 공유합니다. 이 공유를 \n다른 EC2 인스턴스에 마운트합니다. \nC. 모든 EC2 인스턴스에 탑재된 Amazon Elastic File System(Amazon EFS) 파일 \n시스템으로 웹 사이트 이미지를 이동합니다. \nD. 기존 EC2 인스턴스에서 Amazon 머신 이미지(AMI)를 생성합니다. AMI 를 사용하여 Auto \nScaling 그룹의 일부로 Application Load Balancer 뒤에 새 인스턴스를 프로비저닝합니다. \n최소 2 개의 인스턴스를 유지하도록 Auto Scaling 그룹을 구성합니다. 웹 사이트에 대한 \nAWS Global Accelerator 에서 액셀러레이터를 구성합니다. \nE. 기존 EC2 인스턴스에서 Amazon 머신 이미지(AMI)를 생성합니다. AMI 를 사용하여 Auto \nScaling 그룹의 일부로 Application Load Balancer 뒤에 새 인스턴스를 프로비저닝합니다. \n최소 2 개의 인스턴스를 유지하도록 Auto Scaling 그룹을 구성합니다. 웹 사이트에 대한 \nAmazon CloudFront 배포를 구성합니다.", "answer_block": "Answer: C, E \nhttps://www.examtopics.com/discussions/amazon/view/109420-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명 \n옵션 C 는 웹 사이트 이미지를 모든 EC2 인스턴스에 탑재된 Amazon EFS 파일 시스템으로 \n이동하는 기능을 제공합니다. Amazon EFS 는 여러 EC2 인스턴스에서 동시에 액세스할 수 \n있는 확장 가능하고 완벽하게 관리되는 파일 스토리지 솔루션을 제공합니다. 이렇게 하면 \n모든 인스턴스에서 웹 사이트 이미지에 효율적이고 일관되게 액세스할 수 있으므로 옵션 \nE 에서 성능이 향상됩니다. Auto Scaling 그룹은 최소 2 개의 인스턴스를 유지 관리하여 \n비정상 인스턴스를 자동으로 교체하여 복원력을 보장합니다. \n또한 웹 사이트에 대해 Amazon CloudFront 배포를 구성하면 최종 사용자에게 더 가까운 \n엣지 위치에서 콘텐츠를 캐싱하여 지연 시간을 줄이고 콘텐츠 전송을 개선하여 성능을 더욱 \n향상시킵니다. \n따라서 이러한 작업을 결합하면 효율적인 이미지 저장 및 콘텐츠 전달을 통해 웹 사이트의 \n성능이 향상됩니다.", "answer_choice": "C"}, "503": {"q_num": 503, "question": "회사에서 인프라 모니터링 서비스를 실행합니다. 이 회사는 서비스가 고객 AWS 계정의 \n데이터를 모니터링할 수 있는 새로운 기능을 구축하고 있습니다. 새로운 기능은 고객 \n계정에서 AWS API 를 호출하여 Amazon EC2 인스턴스를 설명하고 Amazon CloudWatch \n지표를 읽습니다. \n회사는 가장 안전한 방법으로 고객 계정에 대한 액세스 권한을 얻기 위해 무엇을 해야 \n합니까? \nA. 고객이 회사 계정에 대한 읽기 전용 EC2 및 CloudWatch 권한과 신뢰 정책을 사용하여 \n계정에 IAM 역할을 생성하는지 확인합니다. \nB. 토큰 판매기를 구현하는 서버리스 API 를 생성하여 읽기 전용 EC2 및 CloudWatch \n권한이 있는 역할에 대한 임시 AWS 자격 증명을 제공합니다. \nC. 고객이 자신의 계정에서 읽기 전용 EC2 및 CloudWatch 권한을 가진 IAM 사용자를 \n생성하는지 확인합니다. 비밀 관리 시스템에서 고객 액세스 및 비밀 키를 암호화하고 \n저장합니다. \nD. 고객이 자신의 계정에 Amazon Cognito 사용자를 생성하여 읽기 전용 EC2 및 \nCloudWatch 권한이 있는 IAM 역할을 사용하는지 확인합니다. 암호 관리 시스템에서 \nAmazon Cognito 사용자 및 암호를 암호화하고 저장합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/109595-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명 \n고객이 자신의 계정에서 필요한 권한이 있는 IAM 역할을 생성하도록 함으로써 회사는 AWS \nIdentity and Access Management(IAM)를 사용하여 교차 계정 액세스를 설정할 수 있습니다. \n신뢰 정책은 회사의 AWS 계정이 일시적으로 고객의 IAM 역할을 맡도록 허용하여 고객 \n계정 내의 지정된 리소스(EC2 인스턴스 및 CloudWatch 지표)에 대한 액세스 권한을 \n부여합니다. 이 접근 방식은 회사가 필요한 권한만 요청하고 고객의 장기 액세스 키나 \n사용자 자격 증명을 요구하지 않기 때문에 최소 권한 원칙을 따릅니다.", "answer_choice": "A"}, "504": {"q_num": 504, "question": "회사는 수백 개의 AWS 계정에 걸쳐 있는 us-east-1 리전의 여러 VPC 를 연결해야 합니다. \n회사의 네트워킹 팀에는 클라우드 네트워크를 관리하기 위한 자체 AWS 계정이 있습니다. \nVPC 를 연결하기 위한 운영상 가장 효율적인 솔루션은 무엇입니까? \n\nA. 각 VPC 간에 VPC 피어링 연결을 설정합니다. 연결된 각 서브넷의 경로 테이블을 \n업데이트합니다. \nB. 인터넷을 통해 각 VPC\n를 연결하도록 각 VPC\n에서 NAT 게이트웨이와 인터넷 \n게이트웨이를 구성합니다. \nC. 네트워킹 팀의 AWS 계정에서 AWS Transit Gateway 를 생성합니다. 각 VPC 에서 정적 \n경로를 구성합니다. \nD. 각 VPC 에 VPN 게이트웨이를 배포합니다. 네트워킹 팀의 AWS 계정에 전송 VPC 를 \n생성하여 각 VPC 에 연결합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/109690-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명 \nAWS Transit Gateway 는 여러 VPC, 온프레미스 네트워크 및 원격 네트워크를 연결하기 \n위한 확장성이 뛰어난 중앙 집중식 허브입니다. 단일 진입점을 제공하고 필요한 연결 수를 \n줄임으로써 네트워크 연결을 단순화합니다. 이 시나리오에서 네트워킹 팀의 AWS 계정에 \nAWS Transit Gateway 를 배포하면 여러 VPC 에서 네트워크 연결을 효율적으로 관리하고 \n제어할 수 있습니다.", "answer_choice": "C"}, "505": {"q_num": 505, "question": "한 회사에 야간 배치 작업을 실행하여 데이터를 처리하는 Amazon EC2 인스턴스가 \n있습니다. EC2 인스턴스는 온디맨드 결제를 사용하는 Auto Scaling 그룹에서 실행됩니다. \n한 인스턴스에서 작업이 실패하면 다른 인스턴스가 작업을 다시 처리합니다. 배치 작업은 \n현지 시간으로 매일 오전 12 시에서 오전 6 시 사이에 실행됩니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 EC2 인스턴스를 제공하는 솔루션은 \n무엇입니까? \nA. 배치 작업이 사용하는 Auto Scaling 그룹의 인스턴스 제품군을 포함하는 Amazon EC2 용 \n1 년 절약 플랜을 구매합니다. \nB. 배치 작업이 사용하는 Auto Scaling 그룹에 있는 인스턴스의 특정 인스턴스 유형 및 \n운영 체제에 대해 1 년 예약 인스턴스를 구매합니다. \nC. Auto Scaling 그룹에 대한 새 시작 템플릿을 생성합니다. 인스턴스를 스팟 인스턴스로 \n설정합니다. CPU 사용량에 따라 확장하도록 정책을 설정합니다. \nD. Auto Scaling 그룹에 대한 새 시작 템플릿을 생성합니다. 인스턴스 크기를 늘립니다. \nCPU 사용량에 따라 확장하도록 정책을 설정합니다.", "answer_block": "Answer: C \n\nhttps://www.examtopics.com/discussions/amazon/view/109691-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "506": {"q_num": 506, "question": "소셜 미디어 회사는 웹사이트용 기능을 구축하고 있습니다. 이 기능을 통해 사용자는 \n사진을 업로드할 수 있습니다. 회사는 대규모 이벤트 기간 동안 수요가 크게 증가할 것으로 \n예상하고 웹사이트가 사용자의 업로드 트래픽을 처리할 수 있는지 확인해야 합니다. \nMOST 확장성으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 사용자의 브라우저에서 응용 프로그램 서버로 파일을 업로드합니다. 파일을 Amazon S3 \n버킷으로 전송합니다. \nB. AWS Storage Gateway 파일 게이트웨이를 프로비저닝합니다. 사용자의 브라우저에서 \n파일 게이트웨이로 직접 파일을 업로드합니다. \nC. 애플리케이션에서 Amazon S3 미리 서명된 URL 을 생성합니다. 사용자 브라우저에서 S3 \n버킷으로 직접 파일을 업로드합니다. \nD. Amazon Elastic File System(Amazon EFS) 파일 시스템을 프로비저닝합니다. 사용자의 \n브라우저에서 파일 시스템으로 직접 파일을 업로드합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/109692-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "507": {"q_num": 507, "question": "회사에 여행 발권을 위한 웹 애플리케이션이 있습니다. 이 애플리케이션은 북미 지역의 \n단일 데이터 센터에서 실행되는 데이터베이스를 기반으로 합니다. 회사는 글로벌 사용자 \n기반에 \n서비스를 \n제공하기 \n위해 \n응용 \n프로그램을 \n확장하려고 \n합니다. \n회사는 \n애플리케이션을 여러 AWS 리전에 배포해야 합니다. 예약 데이터베이스 업데이트 시 평균 \n대기 시간은 1 초 미만이어야 합니다. \n이 회사는 여러 지역에 걸쳐 웹 플랫폼을 별도로 배포하려고 합니다. 그러나 회사는 전 \n세계적으로 일관된 단일 기본 예약 데이터베이스를 유지해야 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 솔루션을 권장해야 합니까? \nA. Amazon DynamoDB 를 사용하도록 애플리케이션을 변환합니다. 중앙 예약 테이블에 전역 \n테이블을 사용합니다. 각 지역 배포에서 올바른 지역 엔드포인트를 사용합니다. \nB. 데이터베이스를 Amazon Aurora MySQL 데이터베이스로 마이그레이션합니다. 각 지역에 \nAurora 읽기 전용 복제본을 배포합니다. 데이터베이스에 액세스하려면 각 지역 배포에서 \n올바른 지역 엔드포인트를 사용하세요. \n\nC. 데이터베이스를 Amazon RDS for MySQL 데이터베이스로 마이그레이션합니다. 각 리전에 \nMySQL 읽기 전용 복제본을 배포합니다. 데이터베이스에 액세스하려면 각 지역 배포에서 \n올바른 지역 엔드포인트를 사용하세요. \nD. 애플리케이션을 Amazon Aurora Serverless 데이터베이스로 마이그레이션합니다. 각 \n지역에 데이터베이스 인스턴스를 배포합니다. 각 지역 배포에서 올바른 지역 엔드포인트를 \n사용하여 데이터베이스에 액세스합니다. AWS Lambda 함수를 사용하여 각 리전에서 이벤트 \n스트림을 처리하여 데이터베이스를 동기화합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/109608-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "508": {"q_num": 508, "question": "한 회사에서 여러 Microsoft Windows Server 워크로드를 us-west-1 리전에서 실행되는 \nAmazon EC2 인스턴스로 마이그레이션했습니다. 회사는 필요에 따라 이미지를 생성하기 \n위해 워크로드를 수동으로 백업합니다. \nus-west-1 리전에서 자연 재해가 발생한 경우 회사는 us-west-2 리전에서 워크로드를 \n신속하게 복구하기를 원합니다. 회사는 EC2 인스턴스에서 24 시간 이상의 데이터 손실을 \n원하지 않습니다. 회사는 또한 EC2 인스턴스의 모든 백업을 자동화하려고 합니다. \n최소한의 관리 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? (2 개 선택) \nA. Amazon EC2 지원 Amazon 머신 이미지(AMI) 수명 주기 정책을 생성하여 태그 기반 \n백업을 생성합니다. 하루에 두 번 실행되도록 백업을 예약합니다. 필요에 따라 이미지를 \n복사합니다. \nB. Amazon EC2 지원 Amazon 머신 이미지(AMI) 수명 주기 정책을 생성하여 태그 기반 \n백업을 생성합니다. 하루에 두 번 실행되도록 백업을 예약합니다. us-west-2 리전에 대한 \n복사본을 구성합니다. \nC. AWS Backup 을 사용하여 us-west-1 및 us-west-2 에 백업 볼트를 생성합니다. 태그 \n값을 기반으로 EC2 인스턴스에 대한 백업 계획을 생성합니다. 백업 데이터를 us-west-2 에 \n복사하기 위해 예약된 작업으로 실행할 AWS Lambda 함수를 생성합니다. \nD. AWS Backup 을 사용하여 백업 볼트를 생성합니다. AWS Backup 을 사용하여 태그 값을 \n기반으로 EC2 인스턴스에 대한 백업 계획을 생성합니다. 사본의 대상을 us-west-2 로 \n정의합니다. 하루에 두 번 실행할 백업 일정을 지정합니다. \nE. AWS Backup 을 사용하여 백업 볼트를 생성합니다. AWS Backup 을 사용하여 태그 값을 \n기반으로 EC2 인스턴스에 대한 백업 계획을 생성합니다. 하루에 두 번 실행할 백업 일정을 \n지정합니다. 요청 시 us-west-2 에 복사합니다.", "answer_block": "Answer: B, D \n\nhttps://www.examtopics.com/discussions/amazon/view/109530-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명:・ \n옵션 B\n는 EC2 지원 Amazon 머신 이미지(AMI) 수명 주기 정책을 사용하여 백업 \n프로세스를 자동화할 것을 제안합니다. 하루에 두 번 실행되도록 정책을 구성하고 \nuswest-2 리전에 대한 복사본을 지정함으로써 회사는 정기적인 백업이 생성되고 대체 \n리전에 복사되도록 할 수 있습니다. \n옵션 D 는 중앙 집중식 백업 관리 솔루션을 제공하는 AWS Backup 사용을 제안합니다. \n태그 값을 기반으로 백업 볼트 및 백업 계획을 생성함으로써 회사는 EC2 인스턴스에 대한 \n백업 프로세스를 자동화할 수 있습니다. \n백업 일정은 하루에 두 번 실행되도록 설정할 수 있으며 복사 대상은 us-west-2 리전으로 \n정의할 수 있습니다. \n두 옵션 모두 백업 프로세스를 자동화하고 백업을 us-west-2 리전에 복사하는 것을 \n포함하여 재해 발생 시 데이터 복원력을 보장합니다. 이러한 솔루션은 AWS 서비스에서 \n제공하는 자동화된 백업 및 복사 메커니즘을 활용하여 관리 작업을 최소화합니다.", "answer_choice": "B"}, "509": {"q_num": 509, "question": "회사에서 이미지 처리를 위한 2 계층 애플리케이션을 운영하고 있습니다. 애플리케이션은 \n각각 1\n개의 퍼블릭 서브넷과 1\n개의 프라이빗 서브넷이 있는 2\n개의 가용 영역을 \n사용합니다. 웹 계층용 ALB(Application Load Balancer)는 퍼블릭 서브넷을 사용합니다. \n애플리케이션 계층의 Amazon EC2 인스턴스는 프라이빗 서브넷을 사용합니다. \n사용자는 응용 프로그램이 예상보다 느리게 실행되고 있다고 보고합니다. 웹 서버 로그 \n파일의 보안 감사 결과 애플리케이션이 소수의 IP 주소로부터 수백만 건의 불법 요청을 \n받고 있는 것으로 나타났습니다. 솔루션 설계자는 회사가 보다 영구적인 솔루션을 조사하는 \n동안 즉각적인 성능 문제를 해결해야 합니다. \n이 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까? \nA. 웹 계층에 대한 인바운드 보안 그룹을 수정합니다. 리소스를 소비하는 IP 주소에 대한 \n거부 규칙을 추가합니다. \nB. 웹 계층 서브넷에 대한 네트워크 ACL 을 수정합니다. 리소스를 소비하는 IP 주소에 대한 \n인바운드 거부 규칙을 추가합니다. \nC. 애플리케이션 계층에 대한 인바운드 보안 그룹을 수정합니다. 리소스를 소비하는 IP \n주소에 대한 거부 규칙을 추가합니다. \nD. 애플리케이션 계층 서브넷에 대한 네트워크 ACL 을 수정합니다. 리소스를 소비하는 IP \n주소에 대한 인바운드 거부 규칙을 추가합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/109531-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명 \n퍼블릭 서브넷의 첫 번째 항목에서 요청을 거부하고 프라이빗 서브넷에 도달하는 것을 \n허용하지 마십시오. \n이 시나리오에서 보안 감사는 애플리케이션이 소수의 IP 주소로부터 수백만 건의 불법 \n요청을 수신하고 있음을 보여줍니다. 이 문제를 해결하려면 웹 계층 서브넷에 대한 \n네트워크 ACL(액세스 제어 목록)을 수정하는 것이 좋습니다. 리소스를 소비하는 IP 주소를 \n특별히 대상으로 하는 인바운드 거부 규칙을 추가함으로써 네트워크 ACL 은 불법 트래픽이 \n웹 서버에 도달하기 전에 서브넷 수준에서 차단할 수 있습니다. 이는 웹 계층의 과도한 \n로드를 완화하고 애플리케이션의 성능을 향상시키는 데 도움이 됩니다.", "answer_choice": "B"}, "510": {"q_num": 510, "question": "글로벌 마케팅 회사에는 ap-southeast-2 지역 및 eu-west-1 지역에서 실행되는 \n애플리케이션이 \n있습니다. \neu-west-1\n의 \nVPC\n에서 \n실행되는 \n애플리케이션은 \nap-southeast-2 의 VPC 에서 실행되는 데이터베이스와 안전하게 통신해야 합니다. \n이러한 요구 사항을 충족하는 네트워크 설계는 무엇입니까? \nA. eu-west-1 VPC\n와 ap-southeast-2 VPC 간에 VPC 피어링 연결을 생성합니다. \nap-southeast-2 보안 그룹의 데이터베이스 서버 IP 주소에서 오는 트래픽을 허용하는 \n인바운드 규칙을 eu-west-1 애플리케이션 보안 그룹에 생성합니다. \nB. ap-southeast-2 VPC 와 eu-west-1 VPC 간에 VPC 피어링 연결을 구성합니다. 서브넷 \n경로 테이블을 업데이트합니다. eu-west-1 에 있는 애플리케이션 서버의 보안 그룹 ID 를 \n참조하는 ap-southeast-2 데이터베이스 보안 그룹에서 인바운드 규칙을 생성합니다. \nC. ap-southeast-2 VPC 와 eu-west-1 VPUpdate 서브넷 라우팅 테이블 간에 VPC 피어링 \n연결을 구성합니다. ap-southeast-2 데이터베이스 보안 그룹에서 eu-west-1 애플리케이션 \n서버 IP 주소의 트래픽을 허용하는 인바운드 규칙을 생성합니다. \nD. eu-west-1 VPC 와 ap-southeast-2 VPC 간에 피어링 연결이 있는 전송 게이트웨이를 \n생성합니다. 전송 게이트웨이가 올바르게 피어링되고 라우팅이 구성되면 eu-west-1 에 \n있는 애플리케이션 서버의 보안 그룹 ID 를 참조하는 데이터베이스 보안 그룹에 인바운드 \n규칙을 생성합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/109708-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n\n \n설명 \n다른 리전에 있는 피어 VPC 의 보안 그룹을 참조할 수 없습니다. 대신 피어 VPC 의 CIDR \n블록을 사용하십시오. \nhttps://docs.aws.amazon.com/vpc/latest/peering/vpc-peering-securitygroups.html", "answer_choice": "C"}, "511": {"q_num": 511, "question": "회사에서 PostgreSQL 데이터베이스 스키마를 사용하는 소프트웨어를 개발하고 있습니다. \n회사는 회사 개발자를 위해 여러 개발 환경과 데이터베이스를 구성해야 합니다. 평균적으로 \n각 개발 환경은 8 시간 근무 시간의 절반을 사용합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. 자체 Amazon Aurora PostgreSQL 데이터베이스로 각 개발 환경 구성 \nB. 자체 Amazon RDS for PostgreSQL 단일 AZ DB 인스턴스로 각 개발 환경 구성 \nC. 자체 Amazon Aurora 온디맨드 PostgreSQL 호환 데이터베이스로 각 개발 환경 구성 \nD. Amazon S3 Object Select 를 사용하여 자체 Amazon S3 버킷으로 각 개발 환경 구성", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/109532-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "512": {"q_num": 512, "question": "회사는 계정으로 태그가 지정된 리소스와 함께 AWS Organizations 를 사용합니다. 이 \n회사는 또한 AWS Backup 을 사용하여 AWS 인프라 리소스를 백업합니다. 회사는 모든 \nAWS 리소스를 백업해야 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 태그가 지정되지 않은 모든 리소스를 식별하려면 AWS Config\n를 사용하십시오. \n프로그래밍 \n방식으로 \n식별된 \n리소스에 \n태그를 \n지정합니다. \n백업 \n계획에서 \n태그를 \n사용합니다. \nB. AWS Config 를 사용하여 실행 중이 아닌 모든 리소스를 식별합니다. 해당 리소스를 백업 \n볼트에 추가합니다. \nC. 모든 AWS 계정 소유자가 리소스를 검토하여 백업해야 하는 리소스를 식별하도록 \n요구합니다. \nD. Amazon Inspector 를 사용하여 규정을 준수하지 않는 모든 리소스를 식별합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/109709-exam-aws-certified-sol\n\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "513": {"q_num": 513, "question": "소셜 미디어 회사는 사용자가 AWS 클라우드에서 호스팅되는 애플리케이션에 이미지를 \n업로드할 수 있도록 허용하려고 합니다. 회사는 이미지가 여러 장치 유형에 표시될 수 \n있도록 이미지 크기를 자동으로 조정하는 솔루션이 필요합니다. 애플리케이션은 하루 종일 \n예측할 수 없는 트래픽 패턴을 경험합니다. 회사는 확장성을 극대화하는 고가용성 솔루션을 \n찾고 있습니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. 이미지 크기를 조정하고 이미지를 Amazon S3 버킷에 저장하기 위해 AWS Lambda \n함수를 호출하는 Amazon S3 에서 호스팅되는 정적 웹 사이트를 생성합니다. \nB. AWS Step Functions 를 호출하여 이미지 크기를 조정하고 Amazon RDS 데이터베이스에 \n이미지를 저장하는 Amazon CloudFront 에서 호스팅되는 정적 웹 사이트를 생성합니다. \nC. Amazon EC2 인스턴스에서 실행되는 웹 서버에서 호스팅되는 동적 웹 사이트를 \n만듭니다. EC2 인스턴스에서 실행되는 프로세스를 구성하여 이미지 크기를 조정하고 \nAmazon S3 버킷에 이미지를 저장합니다. \nD. Amazon Simple Queue Service(Amazon SQS)에서 크기 조정 작업을 생성하는 자동 확장 \nAmazon Elastic Container Service(Amazon ECS) 클러스터에서 호스팅되는 동적 웹 \n사이트를 생성합니다. 크기 조정 작업을 처리하기 위해 Amazon EC2 인스턴스에서 \n실행되는 이미지 크기 조정 프로그램을 설정합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/109713-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명 \nAmazon S3 와 AWS Lambda 를 함께 사용하면 확장성과 가용성이 뛰어난 이미지 크기 조정 \n기능을 제공하는 서버리스 아키텍처를 생성할 수 있습니다. \n솔루션이 작동하는 방식은 다음과 같습니다. \n사용자가 업로드한 원본 이미지를 저장하도록 Amazon S3 버킷을 설정합니다. \n새 이미지가 업로드될 때마다 AWS Lambda 함수를 호출하도록 S3 버킷에서 이벤트 \n트리거를 구성합니다. \nLambda 함수는 업로드된 이미지를 검색하고, 장치 요구 사항에 따라 필요한 크기 조정 \n작업을 수행하고, 크기 조정된 이미지를 S3 버킷 또는 크기 조정된 이미지용으로 지정된 \n다른 버킷에 다시 저장하도록 설계할 수 있습니다. \n사용자에게 제공하기 위해 크기 조정된 이미지에 공개적으로 액세스할 수 있도록 Amazon \n\nS3 버킷을 구성합니다.", "answer_choice": "A"}, "514": {"q_num": 514, "question": "회사는 Amazon EC2 인스턴스에서 마이크로서비스 애플리케이션을 실행하고 있습니다. 이 \n회사는 확장성을 위해 애플리케이션을 Amazon Elastic Kubernetes Service(Amazon EKS) \n클러스터로 \n마이그레이션하려고 \n합니다. \n회사는 \n보안 \n규정 \n준수를 \n유지하기 \n위해 \n엔드포인트 프라이빗 액세스를 true 로 설정하고 엔드포인트 퍼블릭 액세스를 false 로 \n설정하여 Amazon EKS 제어 플레인을 구성해야 합니다. 회사는 또한 사설 서브넷에 데이터 \n플레인을 배치해야 합니다. 그러나 회사는 노드가 클러스터에 가입할 수 없기 때문에 오류 \n알림을 받았습니다. \n노드가 클러스터에 가입하도록 허용하는 솔루션은 무엇입니까? \nA. AWS Identity and Access Management(IAM)에서 필요한 권한을 AmazonEKSNodeRole \nIAM 역할에 부여합니다. \nB. 노드가 컨트롤 플레인에 액세스할 수 있도록 인터페이스 VPC 엔드포인트를 생성합니다. \nC. 퍼블릭 서브넷에서 노드를 재생성합니다. EC2 노드에 대한 보안 그룹을 제한합니다. \nD. 노드의 보안 그룹에서 아웃바운드 트래픽을 허용합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/109534-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명 \n클러스터의 VPC 내 Kubernetes API 요청(예: 노드와 컨트롤 플레인 통신)은 프라이빗 VPC \n엔드포인트를 사용합니다. \nhttps://docs.aws.amazon.com/eks/latest/userguide/cluster-endpoint.html", "answer_choice": "B"}, "515": {"q_num": 515, "question": "회사에서 온프레미스 애플리케이션을 AWS 로 마이그레이션하고 있습니다. 회사는 Amazon \nRedshift 를 솔루션으로 사용하려고 합니다. \n이 시나리오에서 Amazon Redshift 에 적합한 사용 사례는 무엇입니까? (3 개 선택) \nA. 기존의 컨테이너화된 이벤트 기반 애플리케이션으로 데이터에 액세스하기 위한 데이터 \nAPI 지원 \nB. 클라이언트 측 및 서버 측 암호화 지원 \nC. 지정된 시간 동안 애플리케이션이 활성 상태가 아닐 때 분석 워크로드 구축 \nD. 백엔드 데이터베이스에 대한 부담을 줄이기 위한 데이터 캐싱 \n\nE. 페타바이트 규모의 데이터와 분당 수천만 건의 요청을 지원하도록 전 세계적으로 확장 \nF. AWS Management Console 을 사용하여 클러스터의 보조 복제본 생성", "answer_block": "Answer: B, C, E \nhttps://www.examtopics.com/discussions/amazon/view/109535-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "516": {"q_num": 516, "question": "회사는 고객이 재무 정보를 검색할 수 있도록 고객에게 API 인터페이스를 제공합니다. \n회사는 연중 최대 사용 시간에 더 많은 수의 요청을 예상합니다. \n회사는 API\n가 고객 만족을 보장하기 위해 낮은 대기 시간으로 일관되게 응답하도록 \n요구합니다. 회사는 API 에 컴퓨팅 호스트를 제공해야 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Application Load Balancer 및 Amazon Elastic Container Service(Amazon ECS)를 \n사용합니다. \nB. 프로비저닝된 동시성과 함께 Amazon API Gateway 및 AWS Lambda 함수를 사용합니다. \nC. Application Load Balancer 및 Amazon Elastic Kubernetes Service(Amazon EKS) \n클러스터를 사용합니다. \nD. 예약된 동시성과 함께 Amazon API Gateway 및 AWS Lambda 함수를 사용합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/109719-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nAmazon API Gateway 는 개발자가 모든 규모에서 API 를 쉽게 생성, 게시, 유지 관리, \n모니터링 및 보호할 수 있게 해주는 완전관리형 서비스입니다. AWS Lambda 는 서버를 \n프로비저닝하거나 관리하지 않고도 코드를 실행할 수 있는 서버리스 컴퓨팅 서비스입니다. \nLambda 는 들어오는 요청에 따라 자동으로 확장되지만 수요가 갑자기 증가하면 함수의 새 \n인스턴스를 초기화하는 데 시간이 걸릴 수 있습니다. 이로 인해 API 에 대한 긴 대기 시간 \n또는 콜드 스타트가 발생할 수 있습니다. 이를 방지하기 위해 함수가 초기화되고 언제든지 \n응답할 준비가 되도록 프로비저닝된 동시성을 사용할 수 있습니다. 프로비저닝된 동시성은 \n또한 확장이 성능에 미치는 영향을 줄임으로써 API 의 지연 시간을 일관되게 줄이는 데 \n도움이 됩니다. \n참조: \nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/http-api-develop-integr\nationslambda.html \n\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-concurrency.html", "answer_choice": "B"}, "517": {"q_num": 517, "question": "한 회사에서 보관 목적으로 모든 AWS Systems Manager Session Manager 로그를 Amazon \nS3 버킷으로 보내려고 합니다. \n어떤 솔루션이 가장 운영 효율성이 높은 이 요구 사항을 충족합니까? \nA. Systems Manager 콘솔에서 S3 로깅을 활성화합니다. 세션 데이터를 보낼 S3 버킷을 \n선택합니다. \nB. Amazon CloudWatch 에이전트를 설치합니다. 모든 로그를 CloudWatch 로그 그룹에 \n푸시합니다. 보관 목적으로 그룹에서 S3 버킷으로 로그를 내보냅니다. \nC. 모든 서버 로그를 중앙 S3 버킷에 업로드할 Systems Manager 문서를 생성합니다. \nAmazon EventBridge 를 사용하여 매일 계정에 있는 모든 서버에 대해 Systems Manager \n문서를 실행하십시오. \nD. Amazon CloudWatch 에이전트를 설치합니다. 모든 로그를 CloudWatch 로그 그룹에 \n푸시합니다. 수신 로그 이벤트를 Amazon Kinesis Data Firehose 전송 스트림으로 푸시하는 \nCloudWatch 로그 구독을 생성합니다. Amazon S3 를 대상으로 설정합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/109536-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "518": {"q_num": 518, "question": "애플리케이션은 Amazon RDS MySQL DB 인스턴스를 사용합니다. RDS 데이터베이스의 \n디스크 공간이 부족해지고 있습니다. 솔루션 설계자는 다운타임 없이 디스크 공간을 늘리고 \n싶어합니다. \n최소한의 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. RDS 에서 스토리지 자동 확장 활성화 \nB. RDS 데이터베이스 인스턴스 크기 늘리기 \nC. RDS 데이터베이스 인스턴스 스토리지 유형을 프로비저닝된 IOPS 로 변경 \nD. RDS 데이터베이스 백업, 저장 용량 증가, 데이터베이스 복원 및 이전 인스턴스 중지", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/109721-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "519": {"q_num": 519, "question": "컨설팅 회사는 전 세계 고객에게 전문 서비스를 제공합니다. 이 회사는 고객이 AWS 에서 \n데이터를 신속하게 수집하고 분석할 수 있는 솔루션과 도구를 제공합니다. 회사는 고객이 \n셀프 서비스 목적으로 사용할 공통 솔루션 및 도구 집합을 중앙에서 관리하고 배포해야 \n합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 고객을 위한 AWS CloudFormation 템플릿을 생성합니다. \nB. 고객을 위한 AWS Service Catalog 제품을 만듭니다. \nC. 고객을 위한 AWS Systems Manager 템플릿을 생성합니다. \nD. 고객을 위한 AWS Config 항목을 생성합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/109722-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "520": {"q_num": 520, "question": "한 회사에서 Amazon EC2 인스턴스에서 실행할 새 웹 애플리케이션을 설계하고 있습니다. \n애플리케이션은 \n백엔드 \n데이터 \n스토리지에 \nAmazon \nDynamoDB\n를 \n사용합니다. \n애플리케이션 트래픽은 예측할 수 없습니다. 회사는 데이터베이스에 대한 응용 프로그램 \n읽기 및 쓰기 처리량이 보통에서 높을 것으로 예상합니다. 회사는 애플리케이션 트래픽에 \n대응하여 확장해야 합니다. \n이러한 \n요구 \n사항을 \n가장 \n비용 \n효율적으로 \n충족하는 \nDynamoDB \n테이블 \n구성은 \n무엇입니까? \nA. DynamoDB 표준 테이블 클래스를 사용하여 프로비저닝된 읽기 및 쓰기로 DynamoDB 를 \n구성합니다. DynamoDB Auto Scaling 을 정의된 최대 용량으로 설정합니다. \nB. DynamoDB Standard 테이블 클래스를 사용하여 온디맨드 모드에서 DynamoDB 를 \n구성합니다. \nC. DynamoDB Standard Infrequent Access(DynamoDB Standard-IA) 테이블 클래스를 \n사용하여 프로비저닝된 읽기 및 쓰기로 DynamoDB\n를 구성합니다. DynamoDB Auto \nScaling 을 정의된 최대 용량으로 설정합니다. \nD. DynamoDB Standard Infrequent Access(DynamoDB Standard-IA) 테이블 클래스를 \n사용하여 온디맨드 모드에서 DynamoDB 를 구성합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/109539-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n\n설명: \n웹 애플리케이션을 위한 가장 비용 효율적인 DynamoDB 테이블 구성은 DynamoDB \nStandard 테이블 클래스를 사용하여 온디맨드 모드에서 DynamoDB 를 구성하는 것입니다. \n이 구성을 사용하면 회사는 애플리케이션 트래픽에 따라 확장하고 애플리케이션이 \n테이블에서 수행하는 읽기 및 쓰기 요청에 대해서만 비용을 지불할 수 있습니다. \n온디맨드 모드는 용량 계획 없이 초당 수천 개의 요청을 처리할 수 있는 유연한 청구 \n옵션입니다. 온디맨드 모드는 들어오는 트래픽을 기준으로 테이블 용량을 자동으로 \n조정하고 실제로 수행된 읽기 및 쓰기 요청에 대해서만 요금을 청구합니다. 온디맨드 \n모드는 예측할 수 없거나 가변적인 워크로드가 있는 애플리케이션 또는 사용한 만큼만 \n비용을 지불하는 용이성을 선호하는 애플리케이션에 적합합니다. \nDynamoDB 표준 테이블 클래스는 대부분의 워크로드에 대한 기본이자 권장 테이블 \n클래스입니다. DynamoDB Standard 테이블 클래스는 DynamoDB Standard-Infrequent \nAccess(DynamoDB Standard-IA) 테이블 클래스보다 낮은 처리량 비용을 제공하며 \n처리량이 주요 비용인 테이블에 대해 더 비용 효율적입니다. DynamoDB Standard 테이블 \n클래스는 DynamoDB Standard-IA 테이블 클래스와 동일한 성능, 내구성 및 가용성을 \n제공합니다. \n다른 옵션은 비용 효율적이지 않거나 사용 사례에 적합하지 않기 때문에 올바르지 않습니다. \nDynamoDB 표준 테이블 클래스를 사용하여 프로비저닝된 읽기 및 쓰기로 DynamoDB 를 \n구성하고 DynamoDB Auto Scaling 을 정의된 최대 용량으로 설정하는 것은 올바르지 \n않습니다. 이 구성에는 테이블 용량을 수동으로 예측하고 관리해야 하므로 솔루션에 \n복잡성과 비용이 추가되기 때문입니다. \n프로비저닝 모드는 사용자가 테이블에 대한 읽기 및 쓰기 용량 단위의 양을 지정하고 \n사용량에 관계없이 예약된 용량에 대해 비용을 청구하도록 요구하는 청구 옵션입니다. \n프로비저닝 모드는 예측 가능하거나 안정적인 워크로드가 있는 애플리케이션이나 용량 \n설정을 보다 세밀하게 제어해야 하는 애플리케이션에 적합합니다. \nDynamoDB Standard-Infrequent Access(DynamoDB Standard-IA) 테이블 클래스를 \n사용하여 DynamoDB\n를 프로비저닝된 읽기 및 쓰기로 구성하고 DynamoDB 자동 \n스케일링을 정의된 최대 용량으로 설정하는 것은 중간에서 높은 처리량의 테이블에서는 \n비용 효율적이지 않기 때문에 올바르지 않습니다. \nDynamoDB Standard-IA 테이블 클래스는 DynamoDB Standard 테이블 클래스보다 \n스토리지 비용은 낮지만 처리량 비용은 더 높습니다. DynamoDB Standard-IA 테이블 \n클래스는 자주 액세스하지 않는 데이터를 저장하는 테이블과 같이 스토리지 비용이 가장 큰 \n테이블에 최적화되어 있습니다. DynamoDB Standard-Infrequent Access(DynamoDB \nStandard-IA) 테이블 클래스를 사용하여 온디맨드 모드에서 DynamoDB 를 구성하는 것은 \n올바르지 않습니다. 왜냐하면 이 구성은 중간에서 높은 처리량을 가진 테이블에 대해서는 \n비용 효율적이지 않기 때문입니다. 위에서 언급한 것처럼 DynamoDB Standard-IA 테이블 \n\n클래스는 DynamoDB Standard 테이블 클래스보다 처리량 비용이 높기 때문에 스토리지 \n비용 절감으로 인한 절감 효과를 상쇄할 수 있습니다.", "answer_choice": "B"}, "521": {"q_num": 521, "question": "소매 회사에는 여러 비즈니스가 있습니다. 각 비즈니스의 IT 팀은 자체 AWS 계정을 \n관리합니다. 각 팀 계정은 AWS Organizations 에서 조직의 일부입니다. 각 팀은 팀 자체 \nAWS 계정의 Amazon DynamoDB 테이블에서 제품 재고 수준을 모니터링합니다. \n회사는 \n공유 \nAWS \n계정에 \n중앙 \n재고 \n보고 \n애플리케이션을 \n배포하고 \n있습니다. \n애플리케이션은 모든 팀의 DynamoDB 테이블에서 항목을 읽을 수 있어야 합니다. \n이러한 요구 사항을 가장 안전하게 충족하는 인증 옵션은 무엇입니까? \nA. 인벤토리 애플리케이션 계정에서 DynamoDB 를 AWS Secrets Manager 와 통합합니다. \nSecrets Manager\n의 올바른 암호를 사용하여 DynamoDB 테이블을 인증하고 읽도록 \n애플리케이션을 구성합니다. 30 일마다 비밀 순환을 예약합니다. \nB. 모든 비즈니스 계정에서 프로그래밍 방식 액세스 권한이 있는 IAM 사용자를 생성합니다. \n올바른 IAM 사용자 액세스 키 ID 와 보안 액세스 키를 사용하여 DynamoDB 테이블을 \n인증하고 읽도록 애플리케이션을 구성합니다. 30\n일마다 IAM 액세스 키를 수동으로 \n교체합니다. \nC. 모든 비즈니스 계정에서 DynamoDB 테이블에 대한 역할 액세스 권한을 부여하는 \n정책과 인벤토리 애플리케이션 계정의 특정 역할을 신뢰하는 신뢰 정책을 사용하여 \nBU_ROLE 이라는 IAM 역할을 생성합니다. 인벤토리 계정에서 STS AssumeRole API 작업에 \n대한 액세스를 허용하는 APP_ROLE 이라는 역할을 생성합니다. APP_ROLE 을 사용하도록 \n애플리케이션을 구성하고 DynamoDB 테이블을 읽기 위해 교차 계정 역할 BU_ROLE 을 \n수임합니다. \nD. DynamoDB 를 AWS Certificate Manager(ACM)와 통합합니다. DynamoDB 를 인증하기 \n위해 ID 인증서를 생성합니다. 올바른 인증서를 사용하여 DynamoDB 테이블을 인증하고 \n읽도록 애플리케이션을 구성합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/109703-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "522": {"q_num": 522, "question": "회사는 \nAmazon \nElastic \nKubernetes \nService(Amazon \nEKS)를 \n사용하여 \n컨테이너 \n애플리케이션을 실행합니다. 회사의 작업량은 하루 종일 일정하지 않습니다. 회사는 \nAmazon EKS 가 워크로드에 따라 확장 및 축소되기를 원합니다. \n\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (2 개 \n선택) \nA. AWS Lambda 함수를 사용하여 EKS 클러스터의 크기를 조정합니다. \nB. Kubernetes Metrics Server 를 사용하여 수평적 포드 자동 확장을 활성화합니다. \nC. Kubernetes Cluster Autoscaler 를 사용하여 클러스터의 노드 수를 관리합니다. \nD. Amazon API Gateway 를 사용하여 Amazon EKS 에 연결합니다. \nE. AWS App Mesh 를 사용하여 네트워크 활동을 관찰합니다.", "answer_block": "Answer: B, C \nhttps://www.examtopics.com/discussions/amazon/view/109702-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nhttps://docs.aws.amazon.com/eks/latest/userguide/horizontal-pod-autoscaler.html \nhttps://docs.aws.amazon.com/eks/latest/userguide/autoscaling.html \n수평적 포드 자동 확장은 해당 리소스의 CPU 사용률을 기반으로 배포, 복제 컨트롤러 또는 \n복제 세트의 포드 수를 자동으로 확장하는 Kubernetes\n의 기능입니다. CPU 사용량 \n데이터를 제공하려면 Kubernetes Metrics Server\n와 같은 메트릭 소스가 필요합니다. \n클러스터 자동 크기 조정은 Pod 가 실패하거나 다른 노드로 다시 예약될 때 클러스터의 \n노드 수를 자동으로 조정하는 Kubernetes 의 기능입니다. 클러스터2 에 가입하는 EC2 \n인스턴스를 관리하려면 AWS Auto Scaling 그룹과의 통합이 필요합니다. 이 솔루션은 \n수평적 포드 자동 확장과 클러스터 자동 확장을 모두 사용하여 Amazon EKS 가 워크로드에 \n따라 확장 및 축소되도록 할 수 있습니다.", "answer_choice": "B"}, "523": {"q_num": 523, "question": "회사에서 마이크로서비스 기반 서버리스 웹 애플리케이션을 실행합니다. 애플리케이션은 \n여러 Amazon DynamoDB 테이블에서 데이터를 검색할 수 있어야 합니다. 솔루션 설계자는 \n애플리케이션의 기본 성능에 영향을 주지 않고 데이터를 검색할 수 있는 기능을 \n애플리케이션에 제공해야 합니다. \n운영상 가장 효율적인 방식으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. AWS AppSync 파이프라인 해석기 \nB. Lambda@Edge 기능이 있는 Amazon CloudFront \nC. AWS Lambda 함수를 사용하는 엣지 최적화 Amazon API Gateway \nD. DynamoDB 커넥터를 사용한 Amazon Athena Federated Query", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/109701-exam-aws-certified-sol\n\nutions-architect-associate-saa-c03/ \nB??", "answer_choice": "D"}, "524": {"q_num": 524, "question": "회사에서 IAM 권한과 관련된 액세스 거부 오류 및 무단 오류를 분석하고 문제를 \n해결하려고 합니다. 회사에서 AWS CloudTrail 을 켰습니다. \n최소한의 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. AWS Glue 를 사용하고 사용자 지정 스크립트를 작성하여 오류에 대한 CloudTrail 로그를 \n쿼리합니다. \nB. AWS Batch 를 사용하고 사용자 지정 스크립트를 작성하여 오류에 대한 CloudTrail \n로그를 쿼리합니다. \nC. Amazon Athena 쿼리로 CloudTrail 로그를 검색하여 오류를 식별합니다. \nD. Amazon QuickSight 로 CloudTrail 로그를 검색합니다. 오류를 식별하는 대시보드를 \n만듭니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/111425-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \nD??", "answer_choice": "C"}, "525": {"q_num": 525, "question": "회사에서 기존 AWS 사용 비용을 운영 비용 대시보드에 추가하려고 합니다. 솔루션 \n설계자는 회사가 프로그래밍 방식으로 사용 비용에 액세스할 수 있는 솔루션을 추천해야 \n합니다. 회사는 현재 연도의 비용 데이터에 액세스하고 향후 12 개월의 비용을 예측할 수 \n있어야 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 페이지 매김과 함께 AWS Cost Explorer API 를 사용하여 사용 비용 관련 데이터에 \n액세스합니다. \nB. 다운로드 가능한 AWS Cost Explorer 보고서 .csv 파일을 사용하여 사용 비용 관련 \n데이터에 액세스합니다. \nC. FTP 를 통해 회사에 사용 비용 데이터를 전송하도록 AWS 예산 작업을 구성합니다. \nD. 사용 비용 데이터에 대한 AWS 예산 보고서를 생성합니다. SMTP\n를 통해 회사에 \n데이터를 보냅니다.", "answer_block": "Answer: A \n\nhttps://www.examtopics.com/discussions/amazon/view/111278-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "526": {"q_num": 526, "question": "솔루션 설계자가 애플리케이션의 복원력을 검토하고 있습니다. 솔루션 설계자는 최근에 \n데이터베이스 관리자가 확장 연습의 일부로 애플리케이션의 Amazon Aurora PostgreSQL \n데이터베이스 작성자 인스턴스를 장애 조치했음을 확인했습니다. 장애 조치로 인해 \n애플리케이션에 3 분의 다운타임이 발생했습니다. \n최소한의 운영 오버헤드로 확장 연습의 중단 시간을 줄이는 솔루션은 무엇입니까? \nA. 장애 조치 중 로드를 처리하기 위해 클러스터에서 더 많은 Aurora PostgreSQL 읽기 \n전용 복제본을 생성합니다. \nB. 동일한 AWS 리전에서 보조 Aurora PostgreSQL 클러스터를 설정합니다. 장애 조치 중에 \n보조 클러스터의 작성자 엔드포인트를 사용하도록 애플리케이션을 업데이트합니다. \nC. 장애 조치 중 로드를 처리할 Amazon ElastiCache for Memcached 클러스터를 \n생성합니다. \nD. 데이터베이스에 대한 Amazon RDS 프록시를 설정합니다. 프록시 엔드포인트를 \n사용하도록 애플리케이션을 업데이트합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/111245-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "D"}, "527": {"q_num": 527, "question": "한 회사에 단일 AWS 리전에서 실행되는 리전 구독 기반 스트리밍 서비스가 있습니다. \n아키텍처는 Amazon EC2 인스턴스의 웹 서버와 애플리케이션 서버로 구성됩니다. EC2 \n인스턴스는 Elastic Load Balancer 뒤의 Auto Scaling 그룹에 있습니다. 아키텍처에는 여러 \n가용 영역에 걸쳐 확장되는 Amazon Aurora 글로벌 데이터베이스 클러스터가 포함됩니다. \n이 회사는 전 세계적으로 확장하고 응용 프로그램의 가동 중지 시간을 최소화하기를 \n원합니다. \n어떤 솔루션이 가장 내결함성을 제공합니까? \nA. 웹 계층 및 애플리케이션 계층에 대한 Auto Scaling 그룹을 확장하여 두 번째 리전의 \n가용 영역에 인스턴스를 배포합니다. Aurora 글로벌 데이터베이스를 사용하여 기본 리전과 \n두 번째 리전에 데이터베이스를 배포합니다. 두 번째 리전에 대한 장애 조치 라우팅 정책과 \n함께 Amazon Route 53 상태 확인을 사용합니다. \nB. 웹 계층과 애플리케이션 계층을 두 번째 리전에 배포합니다. 두 번째 리전에 Aurora \n\nPostgreSQL 교차 리전 Aurora 복제본을 추가합니다. 두 번째 리전에 대한 장애 조치 \n라우팅 정책과 함께 Amazon Route 53 상태 확인을 사용합니다. 필요에 따라 보조를 \n기본으로 승격합니다. \nC. 웹 계층과 애플리케이션 계층을 두 번째 리전에 배포합니다. 두 번째 리전에서 Aurora \nPostgreSQL 데이터베이스를 생성합니다. AWS Database Migration Service(AWS DMS)를 \n사용하여 기본 데이터베이스를 두 번째 리전에 복제합니다. 두 번째 리전에 대한 장애 조치 \n라우팅 정책과 함께 Amazon Route 53 상태 확인을 사용합니다. \nD. 웹 계층과 애플리케이션 계층을 두 번째 지역에 배포합니다. Amazon Aurora 글로벌 \n데이터베이스를 사용하여 기본 리전과 두 번째 리전에 데이터베이스를 배포합니다. 두 번째 \n리전에 대한 장애 조치 라우팅 정책과 함께 Amazon Route 53 상태 확인을 사용합니다. \n필요에 따라 보조를 기본으로 승격합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/111428-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n이 옵션은 애플리케이션에 고가용성과 중복성을 제공하는 두 번째 리전에 웹 계층과 \n애플리케이션 \n계층을 \n배포하기 \n때문에 \n가장 \n효율적입니다. \n또한 \n단일 \nAurora \n데이터베이스가 여러 AWS 지역에 걸쳐 있을 수 있도록 하는 기능인 Amazon Aurora \n글로벌 데이터베이스를 사용합니다. 또한 기본 지역과 두 번째 지역에 데이터베이스를 \n배포하여 지연 시간이 짧은 글로벌 읽기 및 지역 중단 시 빠른 복구를 제공합니다. 또한 두 \n번째 리전에 대한 장애 조치 라우팅 정책과 함께 Amazon Route 53 상태 확인을 사용하여 \n다른 리전의 정상적인 엔드포인트로 트래픽을 라우팅하여 데이터 보호를 제공합니다. 또한 \n필요에 따라 보조를 기본으로 승격하여 한 번에 리전 중 하나에서 쓰기 작업을 허용하여 \n데이터 일관성을 제공합니다. 이 솔루션은 전 세계적으로 확장하고 해당 애플리케이션의 \n다운타임을 최소화해야 한다는 요구 사항을 충족합니다. \n \n옵션 A 는 웹 계층 및 애플리케이션 계층에 대한 Auto Scaling 그룹을 확장하여 두 번째 \n리전의 가용 영역에 인스턴스를 배포하기 때문에 효율성이 떨어집니다. 이렇게 하면 별도로 \n배포하는 것보다 더 높은 비용과 복잡성이 발생할 수 있습니다. 또한 Aurora 글로벌 \n데이터베이스를 사용하여 기본 리전과 두 번째 리전에 데이터베이스를 배포합니다. 이는 \n맞습니다. 그러나 두 번째 리전에 대한 장애 조치 라우팅 정책과 함께 Amazon Route 53 \n상태 확인을 사용하지 않으므로 트래픽이 비정상 엔드포인트로 라우팅될 수 있습니다. \n \n옵션 B\n는 웹 계층과 애플리케이션 계층을 올바른 두 번째 리전에 배포하기 때문에 \n효율성이 떨어집니다. 또한 두 번째 리전에 Aurora PostgreSQL 교차 리전 Aurora 복제본을 \n\n추가하여 리전 간 읽기 확장성을 제공합니다. 그러나 리전 간 복제본보다 더 빠른 복제 및 \n복구를 제공하는 Aurora 글로벌 데이터베이스를 사용하지 않습니다. 또한 올바른 두 번째 \n리전에 대한 장애 조치 라우팅 정책과 함께 Amazon Route 53 상태 확인을 사용합니다. \n그러나 필요에 따라 보조를 기본으로 승격하지 않으므로 데이터 불일치 또는 손실이 발생할 \n수 있습니다. \n \n옵션 C\n는 웹 계층과 애플리케이션 계층을 올바른 두 번째 리전에 배포하기 때문에 \n효율성이 떨어집니다. \n또한 두 번째 리전에 Aurora PostgreSQL 데이터베이스를 생성하여 리전 간 데이터 \n중복성을 제공합니다. 그러나 별도의 데이터베이스를 생성하는 것보다 더 빠른 복제 및 \n복구를 제공하는 Aurora 글로벌 데이터베이스 또는 리전 간 복제본을 사용하지 않습니다. \n또한 AWS DMS(AWS Database Migration Service)를 사용하여 기본 데이터베이스를 두 번째 \n리전에 복제하여 서로 다른 소스와 대상 간에 데이터 마이그레이션을 제공합니다. 그러나 \nAWS DMS\n를 사용하는 것보다 더 빠른 복제 및 복구를 제공하는 Aurora 글로벌 \n데이터베이스 또는 리전 간 복제본을 사용하지 않습니다. 또한 올바른 두 번째 리전에 대한 \n장애 조치 라우팅 정책과 함께 Amazon Route 53 상태 확인을 사용합니다.", "answer_choice": "D"}, "528": {"q_num": 528, "question": "데이터 분석 회사에서 일괄 처리 시스템을 AWS 로 마이그레이션하려고 합니다. 회사는 \nFTP 를 통해 하루 동안 주기적으로 수천 개의 작은 데이터 파일을 받습니다. 온프레미스 \n배치 작업은 밤새 데이터 파일을 처리합니다. 그러나 배치 작업 실행을 완료하는 데 몇 \n시간이 걸립니다. \n회사는 AWS 솔루션이 파일을 전송하는 FTP 클라이언트에 대한 변경을 최소화하면서 \n가능한 한 빨리 수신 데이터 파일을 처리하기를 원합니다. 파일이 성공적으로 처리된 후 \n솔루션은 수신 데이터 파일을 삭제해야 합니다. 각 파일을 처리하는 데 3~8\n분이 \n소요됩니다. \n운영상 가장 효율적인 방식으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. FTP 서버를 실행하는 Amazon EC2 인스턴스를 사용하여 수신 파일을 Amazon S3 \nGlacier Flexible Retrieval 의 객체로 저장합니다. AWS Batch 에서 작업 대기열을 구성합니다. \nAmazon EventBridge 규칙을 사용하여 S3 Glacier Flexible Retrieval 에서 야간에 객체를 \n처리하는 작업을 호출합니다. 작업이 개체를 처리한 후 개체를 삭제합니다. \nB. FTP 서버를 실행하는 Amazon EC2 인스턴스를 사용하여 수신 파일을 Amazon Elastic \nBlock Store(Amazon EBS) 볼륨에 저장합니다. AWS Batch 에서 작업 대기열을 구성합니다. \nAmazon EventBridge 규칙을 사용하여 EBS 볼륨에서 야간에 파일을 처리하는 작업을 \n호출합니다. 작업이 파일을 처리한 후 파일을 삭제합니다. \n\nC. AWS Transfer Family 를 사용하여 들어오는 파일을 Amazon Elastic Block Store(Amazon \nEBS) 볼륨에 저장할 FTP 서버를 생성합니다. AWS Batch 에서 작업 대기열을 구성합니다. \n각 파일이 도착하면 Amazon S3 이벤트 알림을 사용하여 AWS Batch\n에서 작업을 \n호출합니다. 작업이 파일을 처리한 후 파일을 삭제합니다. \nD. AWS Transfer Family 를 사용하여 Amazon S3 Standard 에 수신 파일을 저장할 FTP \n서버를 생성합니다. 파일을 처리하고 처리 후 파일을 삭제하는 AWS Lambda 함수를 \n생성합니다. 파일이 도착하면 S3 이벤트 알림을 사용하여 Lambda 함수를 호출합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/111317-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n이 옵션은 AWS Transfer Family 를 사용하여 저비용 고가용성 스토리지 서비스인 Amazon \nS3 Standard 에 수신 파일을 저장할 수 있는 FTP 서버를 생성하기 때문에 운영상 가장 \n효율적입니다. 또한 AWS Lambda 를 사용하여 파일을 처리하고 처리 후 삭제합니다. 이는 \n배치 스케줄링이나 인프라 관리가 필요하지 않은 확장 가능한 서버리스 솔루션입니다. 또한 \nS3 이벤트 알림을 사용하여 파일이 도착하면 Lambda 함수를 호출하여 수신 데이터 파일을 \n거의 실시간으로 처리할 수 있습니다. \n \n옵션 A 는 Amazon S3 Standard 보다 검색 비용이 높고 검색 시간이 긴 콜드 스토리지 \n클래스인 Amazon S3 Glacier Flexible Retrieval 을 사용하기 때문에 효율성이 떨어집니다. \n또한 EventBridge 규칙을 사용하여 야간에 작업을 호출하므로 들어오는 데이터 파일을 \n가능한 한 빨리 처리해야 한다는 요구 사항을 충족하지 않습니다. \n \n옵션 B 는 EBS 볼륨을 사용하여 수신 파일을 저장하기 때문에 효율성이 떨어집니다. 이는 \nAmazon S3\n보다 비용이 높고 내구성이 낮은 블록 스토리지 서비스입니다. 또한 \nEventBridge 규칙을 사용하여 야간에 작업을 호출하므로 들어오는 데이터 파일을 가능한 \n한 빨리 처리해야 한다는 요구 사항을 충족하지 않습니다. \n \n옵션 C 는 EBS 볼륨을 사용하여 수신 파일을 저장하기 때문에 효율성이 떨어집니다. 이는 \nAmazon S3 보다 비용이 높고 내구성이 낮은 블록 스토리지 서비스입니다. 또한 AWS \nBatch 를 사용하여 파일을 처리하므로 컴퓨팅 리소스와 작업 대기열을 관리해야 합니다.", "answer_choice": "C"}, "529": {"q_num": 529, "question": "회사에서 워크로드를 AWS 로 마이그레이션하고 있습니다. 회사는 데이터베이스에 거래 및 \n\n민감한 데이터를 가지고 있습니다. 이 회사는 AWS 클라우드 솔루션을 사용하여 보안을 \n강화하고 데이터베이스의 운영 오버헤드를 줄이려고 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 데이터베이스를 Amazon EC2 로 마이그레이션합니다. 암호화에 AWS Key Management \nService(AWS KMS) AWS 관리형 키를 사용합니다. \nB. 데이터베이스를 Amazon RDS 로 마이그레이션 유휴 암호화 구성. \nC. 데이터를 Amazon S3 로 마이그레이션합니다. 데이터 보안 및 보호를 위해 Amazon \nMacie 를 사용합니다. \nD. 데이터베이스를 Amazon RDS 로 마이그레이션합니다. 데이터 보안 및 보호를 위해 \nAmazon CloudWatch Logs 를 사용하십시오.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/111246-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "530": {"q_num": 530, "question": "회사에 TCP 및 UDP 멀티플레이어 게임 기능이 있는 온라인 게임 응용 프로그램이 \n있습니다. 이 회사는 Amazon Route 53 을 사용하여 애플리케이션 트래픽이 서로 다른 AWS \n리전에 있는 여러 NLB(Network Load Balancer)를 가리키도록 합니다. 회사는 사용자 \n증가에 대비하여 애플리케이션 성능을 개선하고 온라인 게임의 지연 시간을 줄여야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. NLB 앞에 Amazon CloudFront 배포를 추가합니다. Cache-Control max-age 매개변수를 \n늘리십시오. \nB. NLB\n를 ALB(Application Load Balancer)로 교체합니다. 지연 시간 기반 라우팅을 \n사용하도록 Route 53 을 구성합니다. \nC. NLB 앞에 AWS Global Accelerator 를 추가합니다. 올바른 수신기 포트를 사용하도록 \nGlobal Accelerator 끝점을 구성합니다. \nD. NLB 뒤에 Amazon API Gateway 엔드포인트를 추가합니다. API 캐싱을 활성화합니다. \n다른 단계에 대한 메서드 캐싱을 재정의합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/111271-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "531": {"q_num": 531, "question": "회사는 타사 데이터 피드와 통합해야 합니다. 데이터 피드는 웹후크를 보내 새 데이터를 \n\n사용할 준비가 되면 외부 서비스에 알립니다. 개발자는 회사에서 웹후크 콜백을 수신할 때 \n데이터를 검색하는 AWS Lambda 함수를 작성했습니다. 개발자는 제3 자가 호출할 수 \n있도록 Lambda 함수를 제공해야 합니다. \n이러한 요구 사항을 가장 효율적으로 충족하는 솔루션은 무엇입니까? \nA. Lambda 함수에 대한 함수 URL 을 생성합니다. Webhook 에 대한 Lambda 함수 URL 을 \n타사에 제공합니다. \nB. Lambda 함수 앞에 ALB(Application Load Balancer)를 배포합니다. Webhook 에 대한 \nALB URL 을 타사에 제공합니다. \nC. Amazon Simple Notification Service(Amazon SNS) 주제를 생성합니다. Lambda 함수에 \n주제를 연결합니다. Webhook 에 대한 제3 자에게 SNS 주제의 공개 호스트 이름을 \n제공합니다. \nD. Amazon Simple Queue Service(Amazon SQS) 대기열을 생성합니다. 대기열을 Lambda \n함수에 연결합니다. Webhook\n에 대해 타사에 SQS 대기열의 공개 호스트 이름을 \n제공합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/111430-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n함수 URL 은 HTTPS 를 통해 함수를 호출하는 데 사용할 수 있는 Lambda 함수의 고유 \n식별자입니다. 함수가 배포된 AWS 리전의 API 엔드포인트와 function1\n의 이름 또는 \nARN 으로 구성됩니다. Lambda 함수에 대한 함수 URL 을 생성함으로써 솔루션은 제3 자가 \nLambda 함수를 가장 효율적으로 호출할 수 있도록 할 수 있습니다. \n1. Lambda 함수 앞에 Application Load Balancer(ALB)를 배포합니다. Webhook 에 대한 \nALB URL 을 타사에 제공합니다. 이 솔루션은 HTTPS 를 통해 Lambda 함수를 호출하는 데 \n필요하지 않은 추가 리소스(ALB)를 생성하고 관리하기 때문에 최고의 운영 효율성 요구 \n사항을 충족하지 않습니다. \n2. Amazon Simple Notification Service(Amazon SNS) 주제를 생성합니다. Lambda 함수에 \n주제를 연결합니다. Webhook 에 대한 제3 자에게 SNS 주제의 공개 호스트 이름을 \n제공합니다. Amazon SNS 주제에는 웹훅으로 사용할 수 있는 공개 호스트 이름이 없기 \n때문에 이 솔루션은 작동하지 않습니다. SNS 주제는 외부 소스로부터 메시지를 받는 것이 \n아니라 구독자에게 메시지를 게시하는 데 사용됩니다. \n3. Amazon Simple Queue Service(Amazon SQS) 대기열을 생성합니다. 대기열을 Lambda \n함수에 연결합니다. Webhook\n에 대해 타사에 SQS 대기열의 공개 호스트 이름을 \n제공합니다. Amazon SQS 대기열에는 웹훅으로 사용할 수 있는 공개 호스트 이름이 없기 \n때문에 이 솔루션은 작동하지 않습니다. SQS 대기열은 외부 소스에서 메시지를 수신하는 \n\n것이 아니라 AWS 서비스 간에 메시지를 전송, 저장 및 수신하는 데 사용됩니다. \n참조 URL: \nhttps://docs.aws.amazon.com/lambda/latest/dg/lambda-api-permissions-ref.html", "answer_choice": "A"}, "532": {"q_num": 532, "question": "회사는 AWS 리전에 워크로드가 있습니다. 고객은 Amazon API Gateway REST API 를 \n사용하여 워크로드에 연결하고 액세스합니다. 이 회사는 Amazon Route 53\n을 DNS \n공급자로 사용합니다. 회사는 모든 고객에게 개별적이고 안전한 URL 을 제공하고자 합니다. \n가장 높은 운영 효율성으로 이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (3 개 \n선택) \nA. 등록기관에 필요한 도메인을 등록합니다. Route 53 호스팅 영역에서 와일드카드 사용자 \n지정 도메인 이름을 생성하고 API 게이트웨이 엔드포인트를 가리키는 영역에 기록합니다. \nB. 다른 리전에 있는 AWS Certificate Manager(ACM)의 도메인과 일치하는 와일드카드 \n인증서를 요청합니다. \nC. Route 53 에서 필요에 따라 각 고객에 대한 호스팅 영역을 생성합니다. API 게이트웨이 \n엔드포인트를 가리키는 영역 레코드를 생성합니다. \nD. 동일한 리전의 AWS Certificate Manager(ACM)에서 사용자 지정 도메인 이름과 일치하는 \n와일드카드 인증서를 요청합니다. \nE. API Gateway 에서 각 고객에 대해 여러 API 끝점을 만듭니다. \nF. API Gateway 에서 REST API 용 사용자 정의 도메인 이름을 생성합니다. AWS Certificate \nManager(ACM)에서 인증서를 가져옵니다.", "answer_block": "Answer: A, D, F \nhttps://www.examtopics.com/discussions/amazon/view/111382-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nAPI Gateway REST API 를 사용하는 모든 고객에게 개별 보안 URL 을 제공하려면 다음 \n단계를 수행해야 합니다. \n \na) 등록 기관에 필요한 도메인을 등록합니다. Route 53 호스팅 영역에서 와일드카드 사용자 \n지정 도메인 이름을 생성하고 API 게이트웨이 엔드포인트를 가리키는 영역에 기록합니다. \n이 단계를 통해 API Gateway 에서 생성한 기본 도메인 이름 대신 API 에 대한 사용자 지정 \n도메인 이름을 사용할 수 있습니다. 와일드카드 사용자 지정 도메인 이름은 도메인 이름 \n아래의 모든 하위 도메인(예: customer1.example.com 또는 customer2.example.com)을 \n사용하여 API 에 액세스할 수 있음을 의미합니다. 도메인 이름을 등록 대행자(예: Route 53 \n\n또는 타사 등록 대행자)에 등록하고 도메인 이름에 대해 Route 53 에 호스팅 영역을 \n생성해야 합니다. 또한 별칭 레코드를 사용하여 API Gateway 엔드포인트를 가리키는 \n호스팅 영역에 레코드를 생성해야 합니다. \n \nd) 동일한 리전의 AWS Certificate Manager(ACM)에서 사용자 지정 도메인 이름과 일치하는 \n와일드카드 인증서를 요청합니다. 이 단계에서는 ACM 에서 발급한 인증서를 사용하여 \nHTTPS 로 API 를 보호할 수 있습니다. 와일드카드 인증서는 도메인 이름 아래의 모든 하위 \n도메인(예: *.example.com)과 일치할 수 있음을 의미합니다. 사용자 지정 도메인 이름과 \n일치하는 ACM 에서 인증서를 요청하거나 가져와 도메인 이름을 소유하고 있는지 확인해야 \n합니다. 또한 API 와 동일한 리전에서 인증서를 요청해야 합니다. \n \nf) API Gateway 에서 REST API 용 사용자 지정 도메인 이름을 생성합니다. AWS Certificate \nManager(ACM)에서 인증서를 가져옵니다. 이 단계에서는 사용자 지정 도메인 이름을 API 와 \n연결하고 ACM 의 인증서를 사용하여 HTTPS 를 활성화할 수 있습니다. API Gateway 에서 \nREST API 용 사용자 지정 도메인 이름을 생성하고 ACM 에서 인증서 ARN 을 지정해야 \n합니다. 또한 사용자 지정 도메인 이름에서 API 단계로 경로를 매핑하는 기본 경로 매핑을 \n생성해야 합니다.", "answer_choice": "A"}, "533": {"q_num": 533, "question": "회사는 Amazon S3\n에 데이터를 저장합니다. 규정에 따르면 데이터에는 개인 식별 \n정보(PII)가 포함되어서는 안 됩니다. 이 회사는 최근 S3 버킷에 PII 가 포함된 일부 개체가 \n있음을 발견했습니다. 회사는 S3 버킷에서 PII 를 자동으로 감지하고 회사의 보안 팀에 \n알려야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Amazon Macie 를 사용하십시오. Amazon EventBridge 규칙을 생성하여 Macie 결과에서 \nSensitiveData \n이벤트 \n유형을 필터링하고 보안 팀에 Amazon Simple Notification \nService(Amazon SNS) 알림을 보냅니다. \nB. Amazon GuardDuty\n를 사용합니다. GuardDuty 결과에서 중요한 이벤트 유형을 \n필터링하고 보안 팀에 Amazon Simple Notification Service(Amazon SNS) 알림을 보내는 \nAmazon EventBridge 규칙을 생성합니다. \nC. Amazon Macie 를 사용합니다. Amazon EventBridge 규칙을 생성하여 Macie 결과에서 \nSensitiveData:S3Object/Personal 이벤트 유형을 필터링하고 보안 팀에 Amazon Simple \nQueue Service(Amazon SQS) 알림을 보냅니다. \nD. Amazon GuardDuty\n를 사용합니다. GuardDuty 결과에서 중요한 이벤트 유형을 \n필터링하고 보안 팀에 Amazon Simple Queue Service(Amazon SQS) 알림을 보내는 \n\nAmazon EventBridge 규칙을 생성합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/111432-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nAmazon Macie 는 또한 다양한 소스의 데이터를 사용하여 애플리케이션을 쉽게 연결할 수 \n있게 해주는 서버리스 이벤트 버스인 Amazon EventBridge 로 결과를 보낼 수 있습니다. \nMacie 결과에서 SensitiveData 이벤트 유형을 필터링하고 보안 팀에 Amazon SNS 알림을 \n보내는 EventBridge 규칙을 생성할 수 있습니다. Amazon SNS\n는 구독자 또는 다른 \n애플리케이션에 메시지를 보낼 수 있는 완전 관리형 메시징 서비스입니다. \n참조: \nhttps://docs.aws.amazon.com/macie/latest/userguide/macie-findings.html#macie-findin\ngseventbridge", "answer_choice": "A"}, "534": {"q_num": 534, "question": "회사에서 여러 AWS 계정에 대한 로깅 솔루션을 구축하려고 합니다. 회사는 현재 모든 \n계정의 로그를 중앙 집중식 계정에 저장합니다. 회사는 VPC 흐름 로그와 AWS CloudTrail \n로그를 저장하기 위해 중앙 집중식 계정에 Amazon S3 버킷을 생성했습니다. 모든 로그는 \n빈번한 분석을 위해 30 일 동안 가용성이 높아야 하며, 백업 목적으로 추가 60 일 동안 \n유지되고 생성 후 90 일 후에 삭제되어야 합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. 생성 후 30 일이 지나면 객체를 S3 Standard 스토리지 클래스로 전환합니다. 90 일 후에 \n객체를 삭제하도록 Amazon S3 에 지시하는 만료 작업을 작성합니다. \nB. 생성 후 30 일이 지나면 객체를 S3 Standard-Infrequent Access(S3 Standard-IA) \n스토리지 클래스로 전환합니다. 90 일 후에 모든 객체를 S3 Glacier Flexible Retrieval \n스토리지 클래스로 이동합니다. 90 일 후에 객체를 삭제하도록 Amazon S3 에 지시하는 만료 \n작업을 작성합니다. \nC. 생성 후 30 일이 지나면 객체를 S3 Glacier Flexible Retrieval 스토리지 클래스로 \n전환합니다. 90\n일 후에 객체를 삭제하도록 Amazon S3\n에 지시하는 만료 작업을 \n작성합니다. \nD. 생성 후 30 일이 지나면 객체를 S3 One Zone-Infrequent Access(S3 One Zone-IA) \n스토리지 클래스로 전환합니다. 90 일 후에 모든 객체를 S3 Glacier Flexible Retrieval \n스토리지 클래스로 이동합니다. 90 일 후에 객체를 삭제하도록 Amazon S3 에 지시하는 만료 \n작업을 작성합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/111434-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "535": {"q_num": 535, "question": "회사에서 워크로드를 위해 Amazon Elastic Kubernetes Service(Amazon EKS) 클러스터를 \n구축하고 있습니다. Amazon EKS\n에 저장되는 모든 암호는 Kubernetes etcd 키-값 \n저장소에서 암호화되어야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 새 AWS Key Management Service(AWS KMS) 키를 생성합니다. AWS Secrets Manager 를 \n사용하여 Amazon EKS 에서 모든 비밀을 관리, 교체 및 저장하십시오. \nB. 새 AWS Key Management Service(AWS KMS) 키를 생성합니다. Amazon EKS \n클러스터에서 Amazon EKS KMS 비밀 암호화를 활성화합니다. \nC. \n기본 옵션으로 \nAmazon EKS \n클러스터를 생성합니다. Amazon Elastic Block \nStore(Amazon \nEBS) \nCSI(Container \nStorage \nInterface) \n드라이버를 \n추가 \n기능으로 \n사용합니다. \nD. alias/aws/ebs 별칭으로 새 AWS Key Management Service(AWS KMS) 키를 생성합니다. \n계정에 대해 기본 Amazon Elastic Block Store(Amazon EBS) 볼륨 암호화를 활성화합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/111385-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "536": {"q_num": 536, "question": "회사에서 PostgreSQL 데이터베이스용 Amazon RDS 프로덕션에 대한 거의 실시간에 \n가까운 읽기 전용 액세스 권한을 데이터 과학자에게 제공하려고 합니다. 데이터베이스는 \n현재 \n단일 \nAZ \n데이터베이스로 \n구성되어 \n있습니다. \n데이터 \n과학자는 \n프로덕션 \n데이터베이스에 영향을 미치지 않는 복잡한 쿼리를 사용합니다. 회사는 가용성이 높은 \n솔루션이 필요합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. 유지 관리 기간에 기존 프로덕션 데이터베이스를 확장하여 데이터 과학자에게 충분한 \n성능을 제공합니다. \nB. 단일 AZ 에서 더 큰 보조 대기 인스턴스가 있는 다중 AZ 인스턴스 배포로 설정을 \n변경합니다. 데이터 과학자에게 보조 인스턴스에 대한 액세스 권한을 제공합니다. \nC. 단일 AZ 에서 다중 AZ 인스턴스 배포로 설정을 변경합니다. 데이터 과학자를 위한 두 \n\n개의 추가 읽기 복제본을 제공합니다. \nD. 단일 AZ 에서 2 개의 읽기 가능한 대기 인스턴스가 있는 다중 AZ 클러스터 배포로 \n설정을 변경합니다. 데이터 과학자에게 읽기 엔드포인트를 제공합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/111435-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "D"}, "537": {"q_num": 537, "question": "한 회사가 3 개의 가용 영역에서 작동하는 AWS 클라우드에서 3 계층 웹 애플리케이션을 \n실행합니다. 애플리케이션 아키텍처에는 Application Load Balancer, 사용자 세션 상태를 \n호스팅하는 Amazon EC2 웹 서버, EC2 인스턴스에서 실행되는 MySQL 데이터베이스가 \n있습니다. 회사는 애플리케이션 트래픽이 갑자기 증가할 것으로 예상합니다. 이 회사는 \n미래의 애플리케이션 용량 수요를 충족하고 3\n개의 가용 영역 모두에서 고가용성을 \n보장하기 위해 확장할 수 있기를 원합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 다중 AZ DB 클러스터 배포를 통해 MySQL 데이터베이스를 MySQL 용 Amazon RDS 로 \n마이그레이션합니다. 고가용성 Redis 용 Amazon ElastiCache 를 사용하여 세션 데이터를 \n저장하고 읽기를 캐시하십시오. 세 개의 가용 영역에 있는 Auto Scaling 그룹으로 웹 \n서버를 마이그레이션합니다. \nB. 다중 AZ DB 클러스터 배포를 통해 MySQL 데이터베이스를 MySQL 용 Amazon RDS 로 \n마이그레이션합니다. 고가용성 Memcached 용 Amazon ElastiCache 를 사용하여 세션 \n데이터를 저장하고 읽기를 캐시하십시오. 세 개의 가용 영역에 있는 Auto Scaling 그룹으로 \n웹 서버를 마이그레이션합니다. \nC. \nMySQL \n데이터베이스를 \nAmazon \nDynamoDB\n로 \n마이그레이션 \nDynamoDB \nAccelerator(DAX)를 사용하여 읽기를 캐시합니다. DynamoDB 에 세션 데이터를 저장합니다. \n세 개의 가용 영역에 있는 Auto Scaling 그룹으로 웹 서버를 마이그레이션합니다. \nD. \n단일 \n가용 \n영역에서 \nMySQL \n데이터베이스를 \nMySQL\n용 \nAmazon \nRDS\n로 \n마이그레이션합니다. 고가용성 Redis 용 Amazon ElastiCache 를 사용하여 세션 데이터를 \n저장하고 읽기를 캐시하십시오. 세 개의 가용 영역에 있는 Auto Scaling 그룹으로 웹 \n서버를 마이그레이션합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/111386-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n\n이 답변은 향후 애플리케이션 용량 요구 사항을 충족하기 위한 확장 요구 사항을 충족하고 \n세 가용 영역 모두에서 고가용성을 보장하기 때문에 정답입니다. 다중 AZ DB 클러스터 \n배포를 사용하여 MySQL 데이터베이스를 MySQL 용 Amazon RDS 로 마이그레이션함으로써 \n회사는 여러 가용 영역에서 데이터베이스의 자동 장애 조치, 백업 및 패치 적용의 이점을 \n누릴 수 있습니다. 고가용성 Redis 용 Amazon ElastiCache 를 사용하여 회사는 가용 영역 \n전체에서 장애 조치할 수 있는 빠른 인 메모리 데이터 저장소에 세션 데이터 및 캐시 \n읽기를 저장할 수 있습니다. 3 개의 가용 영역에 있는 Auto Scaling 그룹으로 웹 서버를 \n마이그레이션함으로써 회사는 수요 및 트래픽 패턴에 따라 웹 서버 용량을 자동으로 확장할 \n수 있습니다. \n \n참조: \nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html \nhttps://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/AutoFailover.html \nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/what-is-amazon-ec2-auto-sc\naling.html", "answer_choice": "A"}, "538": {"q_num": 538, "question": "글로벌 비디오 스트리밍 회사는 Amazon CloudFront 를 콘텐츠 배포 네트워크(CDN)로 \n사용합니다. 회사는 여러 국가에 단계적으로 콘텐츠를 배포하려고 합니다. 회사는 회사가 \n콘텐츠를 배포하는 국가 밖에 있는 시청자가 콘텐츠를 볼 수 없도록 해야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 허용 목록을 사용하여 CloudFront 의 콘텐츠에 지리적 제한을 추가합니다. 사용자 지정 \n오류 메시지를 설정합니다. \nB. 제한된 콘텐츠에 대한 새로운 URL 을 설정합니다. 서명된 URL 및 쿠키를 사용하여 \n액세스 권한을 부여합니다. 사용자 지정 오류 메시지를 설정합니다. \nC. 회사가 배포하는 콘텐츠에 대한 데이터를 암호화합니다. 사용자 지정 오류 메시지를 \n설정합니다. \nD. 제한된 콘텐츠에 대한 새 URL 을 만듭니다. 서명된 URL 에 대한 시간 제한 액세스 \n정책을 설정합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/111387-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "539": {"q_num": 539, "question": "회사에서 AWS 클라우드를 사용하여 온프레미스 DR(재해 복구) 구성을 개선하려고 합니다. \n회사의 핵심 프로덕션 비즈니스 애플리케이션은 가상 머신(VM)에서 실행되는 Microsoft \nSQL Server Standard\n를 사용합니다. 애플리케이션의 RPO(복구 시점 목표)는 30\n초 \n이하이고 RTO(복구 시간 목표)는 60 분입니다. DR 솔루션은 가능한 한 비용을 최소화해야 \n합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Always On 가용성 그룹과 함께 Microsoft SQL Server Enterprise 를 사용하여 온프레미스 \n서버와 AWS 간에 다중 사이트 활성/활성 설정을 구성합니다. \nB. AWS 에서 SQL Server 데이터베이스용 웜 대기 Amazon RDS 를 구성합니다. 변경 데이터 \n캡처(CDC)를 사용하도록 AWS DMS(AWS Database Migration Service)를 구성합니다. \nC. 디스크 변경 사항을 AWS 에 파일럿 라이트로 복제하도록 구성된 AWS Elastic Disaster \nRecovery 를 사용합니다. \nD. 타사 백업 소프트웨어를 사용하여 매일 밤 백업을 캡처합니다. Amazon S3 에 보조 백업 \n세트를 저장합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/111301-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "540": {"q_num": 540, "question": "회사에는 Oracle 데이터베이스를 사용하여 고객 정보를 처리하고 저장하는 온프레미스 \n서버가 있습니다. 이 회사는 AWS 데이터베이스 서비스를 사용하여 더 높은 가용성을 \n달성하고 애플리케이션 성능을 개선하고자 합니다. 회사는 또한 기본 데이터베이스 \n시스템에서 보고를 오프로드하려고 합니다. \n운영상 가장 효율적인 방식으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. AWS Database Migration Service(AWS DMS)를 사용하여 여러 AWS 리전에서 Amazon \nRDS DB 인스턴스를 생성합니다. 보고 기능은 기본 DB 인스턴스와 별도의 DB 인스턴스를 \n가리킵니다. \nB. 단일 AZ 배포에서 Amazon RDS 를 사용하여 Oracle 데이터베이스를 생성합니다. 기본 \nDB 인스턴스와 동일한 영역에 읽기 전용 복제본을 생성합니다. 보고 기능을 읽기 전용 \n복제본으로 지정합니다. \nC. 다중 AZ 클러스터 배포에 배포된 Amazon RDS 를 사용하여 Oracle 데이터베이스를 \n생성합니다. 클러스터 배포에서 리더 인스턴스를 사용하도록 보고 기능에 지시합니다. \nD. 다중 AZ 인스턴스 배포에 배포된 Amazon RDS\n를 사용하여 Amazon Aurora \n데이터베이스를 생성합니다. 보고 기능을 판독기 인스턴스에 지시합니다.", "answer_block": "Answer: D \n\nhttps://www.examtopics.com/discussions/amazon/view/111439-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nAmazon \nAurora\n는 \nMySQL \n및 \nPostgreSQL\n과 \n호환되는 \n완전관리형 \n관계형 \n데이터베이스입니다. MySQL 보다 최대 5 배, PostgreSQL 보다 최대 3 배 뛰어난 성능을 \n제공합니다. 또한 여러 가용 영역에 걸쳐 데이터를 복제하고 데이터를 Amazon S31 에 \n지속적으로 백업하여 고가용성과 내구성을 제공합니다. 다중 AZ 인스턴스 배포에 배포된 \nAmazon RDS 를 사용하여 Amazon Aurora 데이터베이스를 생성함으로써 솔루션은 더 높은 \n가용성을 달성하고 애플리케이션 성능을 개선할 수 있습니다. \nAmazon Aurora 는 기본 인스턴스와 동일한 기본 스토리지를 공유하는 별도의 인스턴스인 \n읽기 전용 복제본을 지원합니다. 읽기 전용 복제본을 사용하여 기본 인스턴스에서 읽기 \n전용 쿼리를 오프로드하고 성능을 향상할 수 있습니다. 읽기 전용 복제본은 보고 기능에도 \n사용할 수 있습니다. \n보고 기능을 판독기 인스턴스로 지정함으로써 솔루션은 기본 데이터베이스 시스템에서 \n보고를 오프로드할 수 있습니다. \n1. AWS Database Migration Service(AWS DMS)를 사용하여 여러 AWS 리전에서 Amazon \nRDS DB 인스턴스 생성 보고 기능이 기본 DB 인스턴스와 별도의 DB 인스턴스를 \n가리키도록 합니다. 이 솔루션은 AWS 데이터베이스 서비스 사용 요구 사항을 충족하지 \n않습니다. AWS DMS 는 데이터베이스 서비스 자체가 아니라 사용자가 데이터베이스를 \nAWS\n로 마이그레이션하는 데 도움을 주는 서비스이기 때문입니다. 또한 서로 다른 \n리전에서 여러 DB 인스턴스를 생성해야 하므로 복잡성과 비용이 증가할 수 있습니다. \n2. 단일 AZ 배포에서 Amazon RDS 를 사용하여 Oracle 데이터베이스 생성 기본 DB \n인스턴스와 동일한 영역에 읽기 전용 복제본을 생성합니다. 보고 기능을 읽기 전용 \n복제본으로 지정합니다. 단일 AZ 배포는 가용 영역 중단 시 장애 조치 보호를 제공하지 \n않으므로 이 솔루션은 고가용성 달성 요구 사항을 충족하지 않습니다. 또한 Oracle 을 \n데이터베이스 엔진으로 사용하므로 Aurora보다 더 나은 성능을 제공하지 못할 수 있습니다. \n3. 다중 AZ 클러스터 배포에 배포된 Amazon RDS 를 사용하여 Oracle 데이터베이스 생성 \n클러스터 배포에서 리더 인스턴스를 사용하도록 보고 기능에 지시합니다. Oracle\n이 \nAurora 보다 더 나은 성능을 제공하지 않을 수 있으므로 이 솔루션은 애플리케이션 성능 \n향상 요구 사항을 충족하지 않습니다. 또한 Oracle\n이 아닌 Aurora\n에서만 지원되는 \n클러스터 배포를 사용합니다. \n \n참조:  \nhttps://aws.amazon.com/rds/aurora/", "answer_choice": "D"}, "541": {"q_num": 541, "question": "회사에서 AWS 에서 웹 애플리케이션을 구축하려고 합니다. 웹 사이트에 대한 클라이언트 \n액세스 요청은 예측할 수 없으며 오랫동안 유휴 상태일 수 있습니다. 가입비를 지불한 \n고객만이 웹 애플리케이션에 로그인하고 사용할 수 있습니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 단계 조합은 무엇입니까? (3 개 선택) \nA. Amazon DynamoDB 에서 사용자 정보를 검색하는 AWS Lambda 함수를 생성합니다. \nRESTful API 를 수락할 Amazon API Gateway 엔드포인트를 생성합니다. API 호출을 Lambda \n함수로 보냅니다. \nB. Application Load Balancer 뒤에 Amazon Elastic Container Service(Amazon ECS) \n서비스를 생성하여 Amazon RDS 에서 사용자 정보를 검색합니다. RESTful API 를 수락할 \nAmazon API Gateway 엔드포인트를 생성합니다. API 호출을 Lambda 함수로 보냅니다. \nC. 사용자를 인증하기 위해 Amazon Cognito 사용자 풀을 생성합니다. \nD. 사용자를 인증하기 위해 Amazon Cognito 자격 증명 풀을 생성합니다. \nE. AWS Amplify를 사용하여 HTML, CSS 및 JS로 프런트엔드 웹 콘텐츠를 제공합니다. 통합 \nAmazon CloudFront 구성을 사용합니다. \nF. PHP, CSS 및 JS\n와 함께 Amazon S3 정적 웹 호스팅을 사용합니다. Amazon \nCloudFront 를 사용하여 프런트엔드 웹 콘텐츠를 제공합니다.", "answer_block": "Answer: A, C, E \nhttps://www.examtopics.com/discussions/amazon/view/111440-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n참고 \nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/WebsiteHosting.html", "answer_choice": "A"}, "542": {"q_num": 542, "question": "미디어 회사는 Amazon CloudFront 배포를 사용하여 인터넷을 통해 콘텐츠를 제공합니다. \n회사는 프리미엄 고객만 미디어 스트림과 파일 콘텐츠에 액세스할 수 있기를 원합니다. \n회사는 모든 콘텐츠를 Amazon S3 버킷에 저장합니다. 회사는 또한 영화 대여나 음악 \n다운로드와 같은 특정 목적을 위해 주문형 콘텐츠를 고객에게 제공합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. S3 서명 쿠키를 생성하여 프리미엄 고객에게 제공합니다. \nB. 프리미엄 고객에게 CloudFront 서명 URL 을 생성하고 제공합니다. \nC. 원본 액세스 제어(OAC)를 사용하여 비프리미엄 고객의 액세스를 제한합니다. \nD. 비프리미엄 고객을 차단하기 위해 필드 수준 암호화를 생성하고 활성화합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/111441-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "543": {"q_num": 543, "question": "회사는 개별적으로 블리딩된 여러 AWS 계정에서 Amazon EC2 인스턴스를 실행합니다. 이 \n회사는 최근 저축 피안을 구입했습니다. 회사의 비즈니스 요구 사항 변경으로 인해 회사는 \n많은 수의 EC2 인스턴스를 폐기했습니다. 회사는 다른 AWS 계정에서 Savings Plan 할인을 \n사용하려고 합니다. \n이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (2 개 선택) \nA. 마스터 계정의 AWS 계정 관리 콘솔에서 결제 기본 설정 섹션의 할인 공유를 켭니다. \nB. 기존 Savings Plan 을 구매한 계정의 AWS 계정 관리 콘솔에서 결제 기본 설정 섹션의 \n할인 공유를 켭니다. 모든 계정을 포함합니다. \nC. AWS Organizations 마스터 계정에서 AWS Resource Access Manager(AWS RAM)를 \n사용하여 다른 계정과 Savings Plan 을 공유합니다. \nD. 새 지급인 계정의 AWS Organizations 에서 조직을 생성합니다. 다른 AWS 계정을 \n초대하여 마스터 계정에서 조직에 가입합니다. \nE. 기존 EC2 인스턴스 및 Savings Plan\n을 사용하여 기존 AWS 계정의 AWS \nOrganizations 에 조직을 생성합니다. 다른 AWS 계정을 초대하여 마스터 계정에서 조직에 \n가입합니다.", "answer_block": "Answer: A, E \nhttps://www.examtopics.com/discussions/amazon/view/111442-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "544": {"q_num": 544, "question": "소매 회사는 퍼블릭 REST API 에 지역 Amazon API Gateway API 를 사용합니다. API \nGateway 엔드포인트는 Amazon Route 53 별칭 레코드를 가리키는 사용자 지정 도메인 \n이름입니다. \n솔루션 \n아키텍트는 \n고객에게 \n최소한의 \n영향을 \n미치고 \n데이터 \n손실을 \n최소화하는 솔루션을 생성하여 새 버전의 API 를 릴리스해야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. API 게이트웨이에 대한 카나리아 릴리스 배포 단계를 생성합니다. 최신 API 버전을 \n배포합니다. 트래픽의 적절한 비율을 카나리아 단계로 지정합니다. API 검증 후 카나리아 \n단계를 프로덕션 단계로 승격합니다. \nB. OpenAPI YAML 파일 형식의 새 API 버전으로 새 API 게이트웨이 엔드포인트를 \n\n생성합니다. API Gateway 의 API 에 병합 모드에서 가져오기-업데이트 작업을 사용합니다. \nAPI 의 새 버전을 프로덕션 단계에 배포합니다. \nC. OpenAPI JSON 파일 형식의 새 API 버전으로 새 API 게이트웨이 엔드포인트를 \n생성합니다. 덮어쓰기 모드에서 업데이트로 가져오기 작업을 API Gateway\n의 API\n에 \n사용합니다. API 의 새 버전을 프로덕션 단계에 배포합니다. \nD. API 정의의 새 버전으로 새 API 게이트웨이 엔드포인트를 생성합니다. 새 API Gateway \nAPI 에 대한 사용자 지정 도메인 이름을 생성합니다. Route 53 별칭 레코드가 새 API \nGateway API 사용자 지정 도메인 이름을 가리키도록 합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/111450-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n설명:・ \n이 답변은 고객에게 미치는 영향을 최소화하고 데이터 손실을 최소화하면서 API 의 새 \n버전을 릴리스하기 위한 요구 사항을 충족하므로 정확합니다. 카나리아 릴리스 배포는 \n테스트 목적으로 API 의 새 버전을 배포하고 기본 버전은 동일한 단계에서 일반 작업을 \n위해 프로덕션 릴리스로 배포된 상태로 유지하는 소프트웨어 개발 전략입니다. 카나리아 \n릴리스 배포에서 총 API 트래픽은 미리 구성된 비율로 프로덕션 릴리스와 카나리아 \n릴리스로 무작위로 분리됩니다. 일반적으로 카나리아 릴리스는 API 트래픽의 작은 비율을 \n수신하고 프로덕션 릴리스가 나머지를 차지합니다. 업데이트된 API 기능은 카나리아를 통한 \nAPI 트래픽에만 표시됩니다. 카나리아 트래픽 비율을 조정하여 테스트 범위 또는 성능을 \n최적화할 수 있습니다. 카나리아 트래픽을 작게 유지하고 선택을 무작위로 유지함으로써 \n대부분의 사용자는 새 버전의 잠재적인 버그로 인해 언제든지 악영향을 받지 않으며 단일 \n사용자도 항상 악영향을 받지 않습니다. 테스트 메트릭이 요구 사항을 통과한 후 canary \n릴리스를 프로덕션 릴리스로 승격하고 배포에서 canary 를 비활성화할 수 있습니다. 이렇게 \n하면 생산 단계에서 새로운 기능을 사용할 수 있습니다. \n \n참조: \nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/canary-release.html", "answer_choice": "A"}, "545": {"q_num": 545, "question": "회사는 회사의 기본 웹 사이트를 사용할 수 없는 경우 사용자를 백업 정적 오류 페이지로 \n안내하려고 합니다. 기본 웹 사이트의 DNS 레코드는 Amazon Route 53 에서 호스팅됩니다. \n도메인은 Application Load Balancer(ALB)를 가리킵니다. 회사는 변경 및 인프라 \n오버헤드를 최소화하는 솔루션이 필요합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \n\nA. 지연 시간 라우팅 정책을 사용하도록 Route 53 레코드를 업데이트합니다. 트래픽이 가장 \n반응이 빠른 엔드포인트로 전송되도록 Amazon S3 버킷에서 호스팅되는 정적 오류 \n페이지를 레코드에 추가합니다. \nB. Route 53 활성-수동 장애 조치 구성을 설정합니다. Route 53 상태 확인에서 ALB \n엔드포인트가 비정상이라고 판단하면 Amazon S3 버킷에서 호스팅되는 정적 오류 페이지로 \n트래픽을 보냅니다. \nC. 정적 오류 페이지를 엔드포인트로 호스팅하는 Amazon EC2 인스턴스와 ALB 를 사용하여 \nRoute 53 활성-활성 구성을 설정합니다. ALB\n에 대한 상태 확인이 실패한 경우에만 \n인스턴스에 요청을 보내도록 Route 53 을 구성합니다. \nD. 다중값 응답 라우팅 정책을 사용하도록 Route 53 레코드를 업데이트합니다. 상태 확인을 \n만듭니다. 상태 확인이 통과되면 트래픽을 웹사이트로 안내합니다. 상태 확인을 통과하지 \n못한 경우 Amazon S3 에서 호스팅되는 정적 오류 페이지로 트래픽을 보냅니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/116974-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명1: \nRoute 53 상태 확인을 사용하여 활성-활성 및 활성-수동 장애 조치 구성을 구성할 수 \n있습니다. 능동-수동 장애 조치 : 기본 리소스 또는 리소스 그룹을 대부분의 시간 동안 \n사용할 수 있도록 하고 모든 기본 리소스를 사용할 수 없는 경우에 대비하여 보조 리소스 \n또는 리소스 그룹을 대기 상태로 유지하려는 경우 활성-수동 장애 조치 구성을 사용합니다. \n쿼리에 응답할 때 Route 53 에는 정상적인 기본 리소스만 포함됩니다. 모든 기본 리소스가 \n비정상인 경우 Route 53 은 DNS 쿼리에 대한 응답으로 정상적인 보조 리소스만 포함하기 \n시작합니다. \nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-types.html \n \n설명2: \n이 솔루션은 기본 웹 사이트를 사용할 수 없는 경우 사용자를 백업 정적 오류 페이지로 \n안내하여 변경 및 인프라 오버헤드를 최소화하는 요구 사항을 충족합니다. Route 53 \n활성-수동 장애 조치 구성은 정상인 경우 기본 리소스로, 기본 리소스가 비정상인 경우 \n보조 리소스로 트래픽을 라우팅할 수 있습니다. Route 53 상태 확인은 ALB 엔드포인트의 \n상태를 모니터링하고 필요할 때 장애 조치를 트리거할 수 있습니다. 정적 오류 페이지는 \n웹사이트로 구성된 S3 버킷에서 호스팅할 수 있으며 이는 정적 콘텐츠를 제공하는 \n간단하고 비용 효율적인 방법입니다. \n대기 시간 라우팅 정책을 사용하면 사용자에 대한 가장 낮은 네트워크 대기 시간을 \n기반으로 트래픽을 라우팅할 수 있지만 장애 조치 기능을 제공하지 않기 때문에 옵션 A 는 \n\n올바르지 않습니다. \nALB 및 EC2 인스턴스와 함께 활성-활성 구성을 사용하면 인프라 오버헤드와 복잡성이 \n증가할 수 있고 EC2 인스턴스가 항상 정상 상태임을 보장하지 않기 때문에 옵션 C 는 \n올바르지 않습니다. \n다중값 응답 라우팅 정책을 사용하면 쿼리에 대해 여러 값을 반환할 수 있지만 장애 조치 \n기능을 제공하지 않기 때문에 옵션 D 는 올바르지 않습니다. \n \n참조: \nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-failover.ht\nml \nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover.html \nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/WebsiteHosting.html", "answer_choice": "B"}, "546": {"q_num": 546, "question": "회사의 IT 비용에 대한 최근 분석에서는 백업 비용을 줄여야 할 필요성이 강조되었습니다. \n회사의 CIO 는 온프레미스 백업 인프라를 단순화하고 물리적 백업 테이프 사용을 제거하여 \n비용을 절감하고자 합니다. 회사는 온프레미스 백업 애플리케이션 및 워크플로우에 대한 \n기존 투자를 보존해야 합니다. \n솔루션 설계자는 무엇을 추천해야 합니까? \nA. NFS 인터페이스를 사용하여 백업 애플리케이션과 연결하도록 AWS Storage Gateway 를 \n설정합니다. \nB. NFS 인터페이스를 사용하여 백업 애플리케이션과 연결하는 Amazon EFS 파일 시스템을 \n설정합니다. \nC. iSCSI 인터페이스를 사용하여 백업 애플리케이션과 연결하는 Amazon EFS 파일 \n시스템을 설정합니다. \nD. iSCSI-가상 테이프 라이브러리(VTL) 인터페이스를 사용하여 백업 애플리케이션과 \n연결하도록 AWS Storage Gateway 를 설정합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/116975-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n이를 통해 회사는 온프레미스 백업 인프라를 단순화하고 물리적 백업 테이프의 사용을 \n제거하여 비용을 절감할 수 있습니다. iSCSI-가상 테이프 라이브러리(VTL) 인터페이스를 \n사용하여 백업 애플리케이션과 연결하도록 AWS Storage Gateway 를 설정함으로써 회사는 \n\nS3 또는 Glacier 의 가상 테이프에 백업 데이터를 저장할 수 있습니다. 이를 통해 AWS \n스토리지 서비스를 활용하는 동시에 온프레미스 백업 애플리케이션 및 워크플로에 대한 \n기존 투자를 보존합니다.", "answer_choice": "D"}, "547": {"q_num": 547, "question": "회사는 서로 다른 위치에 데이터 수집 센서를 가지고 있습니다. 데이터 수집 센서는 대량의 \n데이터를 회사로 스트리밍합니다. 이 회사는 대용량 스트리밍 데이터를 수집하고 처리하기 \n위해 AWS\n에서 플랫폼을 설계하려고 합니다. 솔루션은 확장 가능해야 하며 거의 \n실시간으로 데이터 수집을 지원해야 합니다. 회사는 향후 보고를 위해 데이터를 Amazon \nS3 에 저장해야 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Amazon Kinesis Data Firehose를 사용하여 스트리밍 데이터를 Amazon S3에 전달합니다. \nB. AWS Glue 를 사용하여 스트리밍 데이터를 Amazon S3 에 전달합니다. \nC. AWS Lambda 를 사용하여 스트리밍 데이터를 전달하고 데이터를 Amazon S3 에 \n저장합니다. \nD. AWS DMS(AWS Database Migration Service)를 사용하여 스트리밍 데이터를 Amazon \nS3 에 전달합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/116976-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n최소한의 운영 오버헤드로 대용량 스트리밍 데이터를 수집하고 처리하려면 Amazon Kinesis \nData Firehose 가 적합한 솔루션입니다. Amazon Kinesis Data Firehose 는 스트리밍 데이터를 \n캡처, 변환하여 Amazon S3 또는 기타 대상으로 전달할 수 있습니다. Amazon Kinesis Data \nFirehose 는 데이터 처리량에 맞춰 자동으로 확장하고 모든 양의 데이터를 처리할 수 \n있습니다. Amazon Kinesis Data Firehose 는 프로비저닝이나 관리를 위해 서버가 필요하지 \n않은 완전관리형 서비스이기도 합니다.", "answer_choice": "A"}, "548": {"q_num": 548, "question": "회사에는 재무, 데이터 분석 및 개발 부서를 위한 별도의 AWS 계정이 있습니다. 비용 및 \n보안 문제 때문에 회사는 각 AWS 계정이 사용할 수 있는 서비스를 제어하려고 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. AWS Systems Manager 템플릿을 사용하여 각 부서에서 사용할 수 있는 AWS 서비스를 \n\n제어합니다. \nB. AWS Organizations 의 각 부서에 대한 조직 단위(OU)를 생성합니다. 서비스 제어 \n정책(SCP)을 OU 에 연결합니다. \nC. AWS CloudFormation 을 사용하여 각 부서에서 사용할 수 있는 AWS 서비스만 자동으로 \n프로비저닝합니다. \nD. 특정 AWS 서비스의 사용을 관리 및 제어하기 위해 AWS 계정의 AWS Service \nCatalog 에 제품 목록을 설정합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/116977-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "549": {"q_num": 549, "question": "회사에서 \n전자상거래 \n웹 \n사이트를 \n위한 \n다중 \n계층 \n애플리케이션을 \n만들었습니다. \n웹사이트는 퍼블릭 서브넷에 상주하는 Application Load Balancer, 퍼블릭 서브넷의 웹 계층, \n프라이빗 서브넷의 Amazon EC2 인스턴스에서 호스팅되는 MySQL 클러스터를 사용합니다. \nMySQL 데이터베이스는 타사 공급자가 인터넷에서 호스팅하는 제품 카탈로그 및 가격 \n정보를 검색해야 합니다. 솔루션 설계자는 운영 오버헤드를 늘리지 않고 보안을 극대화하는 \n전략을 고안해야 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. VPC 에 NAT 인스턴스를 배포합니다. NAT 인스턴스를 통해 모든 인터넷 기반 트래픽을 \n라우팅합니다. \nB. 퍼블릭 서브넷에 NAT 게이트웨이를 배포합니다. 인터넷 바인딩된 모든 트래픽을 NAT \n게이트웨이로 보내도록 프라이빗 서브넷 라우팅 테이블을 수정합니다. \nC. 인터넷 게이트웨이를 구성하고 VPModify 프라이빗 서브넷 라우팅 테이블에 연결하여 \n인터넷 바인딩 트래픽을 인터넷 게이트웨이로 보냅니다. \nD. 가상 프라이빗 게이트웨이를 구성하고 VPC 에 연결합니다. 인터넷 바인딩 트래픽을 가상 \n프라이빗 게이트웨이로 보내도록 프라이빗 서브넷 라우팅 테이블을 수정합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/116978-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n프라이빗 서브넷의 MySQL 데이터베이스가 공개적으로 노출되지 않고 인터넷에 액세스할 \n수 있도록 하려면 NAT 게이트웨이가 적합한 솔루션입니다. NAT 게이트웨이를 사용하면 \n프라이빗 서브넷의 인스턴스가 인터넷이나 다른 AWS 서비스에 연결할 수 있지만 인터넷이 \n\n해당 인스턴스와 연결을 시작하는 것은 방지됩니다. NAT 게이트웨이는 퍼블릭 서브넷에 \n상주하며 짧은 대기 시간으로 높은 트래픽 처리량을 처리할 수 있습니다. NAT 게이트웨이는 \n운영 오버헤드가 필요하지 않은 관리형 서비스이기도 합니다.", "answer_choice": "B"}, "550": {"q_num": 550, "question": "회사에서 AWS Key Management Service(AWS KMS) 키를 사용하여 AWS Lambda 환경 \n변수를 암호화하고 있습니다. 솔루션 설계자는 환경 변수를 해독하고 사용하는 데 필요한 \n권한이 있는지 확인해야 합니다. \n올바른 권한을 구현하기 위해 솔루션 설계자가 수행해야 하는 단계는 무엇입니까? (2 개 \n선택) \nA. Lambda 리소스 정책에 AWS KMS 권한을 추가합니다. \nB. Lambda 실행 역할에 AWS KMS 권한을 추가합니다. \nC. Lambda 함수 정책에 AWS KMS 권한을 추가합니다. \nD. AWS KMS 키 정책에서 Lambda 실행 역할을 허용합니다. \nE. AWS KMS 키 정책에서 Lambda 리소스 정책을 허용합니다.", "answer_block": "Answer: B, D \nhttps://www.examtopics.com/discussions/amazon/view/116979-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nB 와 D 는 정답입니다. Lambda 실행 역할에 환경 변수를 해독하고 사용할 수 있는 권한이 \n있고 AWS KMS 키 정책에 따라 Lambda 실행 역할이 키를 사용할 수 있도록 허용하기 \n때문입니다. Lambda 실행 역할은 AWS KMS 와 같은 AWS 리소스에 액세스할 수 있는 \n권한을 Lambda 함수에 부여하는 IAM 역할입니다. AWS KMS 키 정책은 키에 대한 \n액세스를 제어하는 리소스 기반 정책입니다. Lambda 실행 역할에 AWS KMS 권한을 \n추가하고 AWS KMS 키 정책에서 Lambda 실행 역할을 허용함으로써 솔루션 아키텍트는 \n환경 변수를 암호화하고 해독하기 위한 올바른 권한을 구현할 수 있습니다.", "answer_choice": "B"}, "551": {"q_num": 551, "question": "회사에 보고서를 생성하는 재무 응용 프로그램이 있습니다. 보고서 크기는 평균 50KB 이며 \nAmazon S3 에 저장됩니다. 보고서는 생산 후 첫 주 동안 자주 액세스되며 몇 년 동안 \n저장해야 합니다. 보고서는 6 시간 이내에 검색할 수 있어야 합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. S3 Standard 를 사용합니다. S3 수명 주기 규칙을 사용하여 7 일 후에 보고서를 S3 \n\nGlacier 로 전환합니다. \nB. S3 Standard 를 사용합니다. S3 수명 주기 규칙을 사용하여 7 일 후에 보고서를 S3 \nStandard-Infrequent Access(S3 Standard-IA)로 전환합니다. \nC. S3 Intelligent-Tiering 을 사용합니다. 보고서를 S3 Standard-Infrequent Access(S3 \nStandard-IA) 및 S3 Glacier 로 전환하도록 S3 Intelligent-Tiering 을 구성합니다. \nD. S3 Standard 를 사용합니다. S3 수명 주기 규칙을 사용하여 7 일 후에 보고서를 S3 \nGlacier Deep Archive 로 전환합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/116896-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n첫 주 동안 자주 액세스하고 수년간 보관해야 하는 보고서를 저장하고 검색하려면 S3 \nStandard 와 S3 Glacier 가 적합한 솔루션입니다. S3 Standard 는 자주 액세스하는 데이터에 \n대해 높은 내구성, 가용성 및 성능을 제공합니다. S3 Glacier 는 저렴한 비용으로 장기 \n데이터 보관을 위한 안전하고 내구성 있는 스토리지를 제공합니다. S3 수명 주기 규칙을 \n사용하면 7 일 후에 보고서를 S3 Standard 에서 S3 Glacier 로 전환할 수 있으므로 스토리지 \n비용을 줄일 수 있습니다. S3 Glacier 는 6 시간 이내 검색도 지원합니다.", "answer_choice": "A"}, "552": {"q_num": 552, "question": "회사는 Amazon EC2 인스턴스의 비용을 최적화해야 합니다. 회사는 또한 2~3 개월마다 \nEC2 인스턴스의 유형과 제품군을 변경해야 합니다. \n이러한 요구 사항을 충족하기 위해 회사는 무엇을 해야 합니까? \nA. 3 년 기간 동안 부분 선결제 예약 인스턴스를 구매합니다. \nB. 1 년 기간 동안 선결제 없는 컴퓨팅 절감 플랜을 구매합니다. \nC. 1 년 기간 동안 모든 선결제 예약 인스턴스를 구매합니다. \nD. 1 년 기간 동안 All Upfront EC2 Instance Savings Plan 을 구매합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/116897-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "553": {"q_num": 553, "question": "솔루션 설계자는 회사의 Amazon S3 버킷을 검토하여 개인 식별 정보(PII)를 검색해야 \n합니다. 회사는 us-east-1 지역 및 us-west-2 지역에 PII 데이터를 저장합니다. \n\n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 각 리전에서 Amazon Macie 를 구성합니다. Amazon S3 에 있는 데이터를 분석하는 \n작업을 생성합니다. \nB. 모든 지역에 대해 AWS Security Hub 를 구성합니다. Amazon S3 에 있는 데이터를 \n분석하는 AWS Config 규칙을 생성합니다. \nC. Amazon S3 에 있는 데이터를 분석하도록 Amazon Inspector 를 구성합니다. \nD. Amazon S3 에 있는 데이터를 분석하도록 Amazon GuardDuty 를 구성합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/117206-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "554": {"q_num": 554, "question": "회사의 SAP 애플리케이션에는 온프레미스 환경에 백엔드 SQL Server 데이터베이스가 \n있습니다. \n이 \n회사는 \n온프레미스 \n애플리케이션과 \n데이터베이스 \n서버를 \nAWS\n로 \n마이그레이션하려고 합니다. 회사는 SAP 데이터베이스의 높은 요구 사항을 충족하는 \n인스턴스 유형이 필요합니다. 온프레미스 성능 데이터에 따르면 SAP 애플리케이션과 \n데이터베이스 모두 메모리 사용률이 높습니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 애플리케이션에 최적화된 컴퓨팅 인스턴스 제품군을 사용하십시오. 데이터베이스에 \n메모리 최적화 인스턴스 제품군을 사용하십시오. \nB. 애플리케이션과 데이터베이스 모두에 스토리지 최적화 인스턴스 제품군을 사용하십시오. \nC. \n애플리케이션과 \n데이터베이스 \n모두에 \n대해 \n메모리 \n최적화 \n인스턴스 \n제품군을 \n사용하십시오. \nD. \n애플리케이션에 \n고성능 \n컴퓨팅(HPC) \n최적화 \n인스턴스 \n제품군을 \n사용합니다. \n데이터베이스에 메모리 최적화 인스턴스 제품군을 사용하십시오.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/117442-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "555": {"q_num": 555, "question": "회사는 퍼블릭 및 프라이빗 서브넷이 있는 VPC 에서 애플리케이션을 실행합니다. VPC 는 \n여러 가용 영역에 걸쳐 확장됩니다. 애플리케이션은 프라이빗 서브넷의 Amazon EC2 \n인스턴스에서 실행됩니다. 애플리케이션은 Amazon Simple Queue Service(Amazon SQS) \n대기열을 사용합니다. \n\n솔루션 설계자는 EC2 인스턴스와 SQS 대기열 간의 연결을 설정하기 위한 보안 솔루션을 \n설계해야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Amazon SQS\n용 인터페이스 VPC 엔드포인트를 구현합니다. 프라이빗 서브넷을 \n사용하도록 엔드포인트를 구성합니다. 프라이빗 서브넷에 있는 EC2 인스턴스의 트래픽을 \n허용하는 인바운드 액세스 규칙이 있는 보안 그룹을 엔드포인트에 추가합니다. \nB. Amazon SQS 용 인터페이스 VPC 엔드포인트를 구현합니다. 퍼블릭 서브넷을 사용하도록 \n엔드포인트를 구성합니다. 프라이빗 서브넷에 있는 EC2 인스턴스의 액세스를 허용하는 \nVPC 엔드포인트 정책을 인터페이스 엔드포인트에 연결합니다. \nC. Amazon SQS 용 인터페이스 VPC 엔드포인트를 구현합니다. 퍼블릭 서브넷을 사용하도록 \n엔드포인트를 구성합니다. 지정된 VPC 엔드포인트의 요청만 허용하는 인터페이스 VPC \n엔드포인트에 Amazon SQS 액세스 정책을 연결합니다. \nD. Amazon SQS\n용 게이트웨이 엔드포인트를 구현합니다. 프라이빗 서브넷에 NAT \n게이트웨이를 추가합니다. SQS 대기열에 대한 액세스를 허용하는 EC2 인스턴스에 IAM \n역할을 연결합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/116983-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "556": {"q_num": 556, "question": "솔루션 설계자는 AWS CloudFormation 템플릿을 사용하여 3\n계층 웹 애플리케이션을 \n배포합니다. 웹 애플리케이션은 웹 계층과 Amazon DynamoDB 테이블에서 사용자 \n데이터를 저장하고 검색하는 애플리케이션 계층으로 구성됩니다. 웹 및 애플리케이션 \n계층은 Amazon EC2 인스턴스에서 호스팅되며 데이터베이스 계층은 공개적으로 액세스할 \n수 없습니다. 애플리케이션 EC2 인스턴스는 템플릿에서 API 자격 증명을 노출하지 않고 \nDynamoDB 테이블에 액세스해야 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. DynamoDB 테이블을 읽을 IAM 역할을 생성합니다. 인스턴스 프로필을 참조하여 역할을 \n애플리케이션 인스턴스와 연결합니다. \nB. DynamoDB 테이블에서 읽고 쓰는 데 필요한 권한이 있는 IAM 역할을 생성합니다. EC2 \n인스턴스 \n프로필에 \n역할을 \n추가하고 \n인스턴스 \n프로필을 \n애플리케이션 \n인스턴스와 \n연결합니다. \nC. AWS CloudFormation 템플릿의 파라미터 섹션을 사용하여 사용자가 DynamoDB \n테이블에서 읽고 쓰는 데 필요한 권한이 있는 이미 생성된 IAM 사용자의 액세스 및 비밀 \n키를 입력하도록 합니다. \n\nD. DynamoDB 테이블에서 읽고 쓰는 데 필요한 권한이 있는 AWS CloudFormation \n템플릿에서 IAM 사용자를 생성합니다. GetAtt 기능을 사용하여 액세스 및 비밀 키를 \n검색하고 사용자 데이터를 통해 애플리케이션 인스턴스에 전달합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/117434-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n이를 통해 애플리케이션 EC2 인스턴스는 템플릿에 API 자격 증명을 노출하지 않고도 \nDynamoDB 테이블에 액세스할 수 있습니다. DynamoDB 테이블에서 읽고 쓰는 데 필요한 \n권한이 있는 IAM 역할을 생성하고 이를 EC2 인스턴스 프로필에 추가하면 애플리케이션 \n인스턴스는 AWS 에서 자동으로 교체하는 임시 보안 자격 증명을 사용할 수 있습니다. 이는 \nEC2 인스턴스에서 AWS 리소스에 대한 액세스 권한을 부여하는 안전한 모범 사례 \n방법입니다.", "answer_choice": "B"}, "557": {"q_num": 557, "question": "솔루션 설계자는 분석 애플리케이션을 관리합니다. 애플리케이션은 Amazon S3 버킷에 \n대량의 반구조화된 데이터를 저장합니다. 솔루션 설계자는 병렬 데이터 처리를 사용하여 \n데이터를 더 빠르게 처리하려고 합니다. 또한 솔루션 설계자는 Amazon Redshift \n데이터베이스에 저장된 정보를 사용하여 데이터를 보강하려고 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Amazon Athena 를 사용하여 S3 데이터를 처리합니다. Amazon Redshift 데이터와 함께 \nAWS Glue 를 사용하여 S3 데이터를 보강합니다. \nB. Amazon EMR 을 사용하여 S3 데이터를 처리합니다. Amazon Redshift 데이터와 함께 \nAmazon EMR 을 사용하여 S3 데이터를 보강합니다. \nC. Amazon EMR 을 사용하여 S3 데이터를 처리합니다. 데이터를 보강할 수 있도록 Amazon \nKinesis Data Streams 를 사용하여 S3 데이터를 Amazon Redshift 로 이동합니다. \nD. AWS Glue 를 사용하여 S3 데이터를 처리합니다. Amazon Redshift 데이터와 함께 AWS \nLake Formation 을 사용하여 S3 데이터를 보강합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/117344-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "558": {"q_num": 558, "question": "회사에는 동일한 AWS 계정 내의 us-west-2 리전에 위치한 두 개의 VPC 가 있습니다. \n회사는 이러한 VPC 간의 네트워크 트래픽을 허용해야 합니다. 매월 VPC 간에 약 \n500GB 의 데이터 전송이 발생합니다. \n이러한 VPC 를 연결하는 가장 비용 효율적인 솔루션은 무엇입니까? \nA. AWS Transit Gateway 를 구현하여 VPC 를 연결합니다. VPC 간 통신에 전송 게이트웨이를 \n사용하도록 각 VPC 의 라우팅 테이블을 업데이트합니다. \nB. VPC 간에 AWS Site-to-Site VPN 터널을 구현합니다. VPC 간 통신에 VPN 터널을 \n사용하도록 각 VPC 의 라우팅 테이블을 업데이트합니다. \nC. VPC 간에 VPC 피어링 연결을 설정합니다. VPC 간 통신에 VPC 피어링 연결을 \n사용하도록 각 VPC 의 라우팅 테이블을 업데이트합니다. \nD. VPC 간에 1GB AWS Direct Connect 연결을 설정합니다. VPC 간 통신에 Direct Connect \n연결을 사용하도록 각 VPC 의 라우팅 테이블을 업데이트합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/117053-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n동일한 AWS 계정 내 동일한 리전에 있는 두 개의 VPC 를 연결하려면 VPC 피어링이 가장 \n비용 효과적인 솔루션입니다. VPC 피어링을 사용하면 게이트웨이, VPN 연결 또는 AWS \nTransit Gateway 없이도 VPC 간의 직접 네트워크 트래픽을 허용할 수 있습니다. 또한 VPC \n피어링은 VPC 간 데이터 전송에 대한 추가 요금을 발생시키지 않습니다.", "answer_choice": "C"}, "559": {"q_num": 559, "question": "회사는 서로 다른 제품군에 대해 AWS\n에서 여러 애플리케이션을 호스팅합니다. \n애플리케이션은 Amazon EC2 인스턴스 및 Application Load Balancer 를 비롯한 다양한 \n컴퓨팅 리소스를 사용합니다. 애플리케이션은 여러 AWS 리전의 AWS Organizations 에서 \n동일한 조직의 다른 AWS 계정에서 실행됩니다. 각 제품군의 팀은 개별 계정의 각 컴퓨팅 \n리소스에 태그를 지정했습니다. \n회사는 조직의 통합 청구 기능에서 각 제품군의 비용에 대한 자세한 정보를 원합니다. \n이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (2 개 선택) \nA. AWS 결제 콘솔에서 특정 AWS 생성 태그를 선택합니다. \nB. AWS 결제 콘솔에서 특정 사용자 정의 태그를 선택합니다. \nC. AWS 리소스 그룹 콘솔에서 특정 사용자 정의 태그를 선택합니다. \nD. 각 AWS 계정에서 선택한 태그를 활성화합니다. \nE. 조직 마스터 계정에서 선택한 태그를 활성화합니다.", "answer_block": "Answer: B, E \nhttps://www.examtopics.com/discussions/amazon/view/117403-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n사용자 정의 태그는 AWS 리소스에 적용하여 분류하고 추적할 수 있는 키-값 쌍입니다. \n사용자 정의 태그를 사용하여 비용을 할당하고 AWS 결제 콘솔에서 세부 결제 보고서를 \n생성할 수도 있습니다. 비용 할당을 위해 사용자 정의 태그를 사용하려면 조직의 모든 회원 \n계정에 대한 모든 권한을 갖는 루트 계정인 조직 마스터 계정에서 태그를 활성화해야 \n합니다. 활성화되면 사용자 정의 태그가 비용 할당 보고서의 열로 표시되며 제품 라인별로 \n비용을 필터링하고 그룹화하는 데 사용할 수 있습니다. 이 솔루션은 기존 태깅 전략을 \n활용하고 코드 개발이나 수동 개입이 필요하지 않으므로 최소한의 운영 오버헤드로 요구 \n사항을 충족합니다.", "answer_choice": "B"}, "560": {"q_num": 560, "question": "회사의 솔루션 아키텍트가 AWS Organizations 를 사용하는 AWS 다중 계정 솔루션을 \n설계하고 있습니다. 솔루션 설계자는 회사의 계정을 OU(조직 단위)로 구성했습니다. \n솔루션 설계자는 OU 계층 구조에 대한 모든 변경 사항을 식별할 솔루션이 필요합니다. \n솔루션은 또한 회사의 운영 팀에 변경 사항을 알려야 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. AWS Control Tower 를 사용하여 AWS 계정을 프로비저닝합니다. 계정 드리프트 알림을 \n사용하여 OU 계층 구조의 변경 사항을 식별합니다. \nB. AWS Control Tower 를 사용하여 AWS 계정을 프로비저닝합니다. AWS Config 집계 \n규칙을 사용하여 OU 계층 구조의 변경 사항을 식별합니다. \nC. AWS Service Catalog 를 사용하여 조직에서 계정을 생성합니다. AWS CloudTrail 조직 \n추적을 사용하여 OU 계층 구조의 변경 사항을 식별합니다. \nD. AWS CloudFormation 템플릿을 사용하여 조직에서 계정을 생성합니다. 스택에서 \n드리프트 감지 작업을 사용하여 OU 계층 구조에 대한 변경 사항을 식별합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/117021-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "561": {"q_num": 561, "question": "회사의 웹 사이트는 매일 수백만 건의 요청을 처리하며 요청 수는 계속 증가하고 있습니다. \n\n솔루션 설계자는 웹 애플리케이션의 응답 시간을 개선해야 합니다. 솔루션 설계자는 \n애플리케이션이 Amazon DynamoDB 테이블에서 제품 세부 정보를 검색할 때 지연 시간을 \n줄여야 한다고 결정합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. DynamoDB Accelerator(DAX) 클러스터를 설정합니다. DAX 를 통해 모든 읽기 요청을 \n라우팅합니다. \nB. DynamoDB 테이블과 웹 애플리케이션 사이에 Redis\n용 Amazon ElastiCache\n를 \n설정합니다. Redis 를 통해 모든 읽기 요청을 라우팅합니다. \nC. DynamoDB 테이블과 웹 애플리케이션 사이에 Amazon ElastiCache for Memcached 를 \n설정합니다. Memcached 를 통해 모든 읽기 요청을 라우팅합니다. \nD. 테이블에 Amazon DynamoDB 스트림을 설정하고 AWS Lambda 가 테이블에서 읽고 \nAmazon ElastiCache\n를 채우도록 합니다. ElastiCache\n를 통해 모든 읽기 요청을 \n라우팅합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/117022-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n이를 통해 회사는 Amazon DynamoDB 테이블에서 제품 세부 정보를 검색할 때 웹 \n애플리케이션의 응답 시간을 개선하고 지연 시간을 줄일 수 있습니다. DynamoDB \nAccelerator(DAX) 클러스터를 설정함으로써 회사는 최대 10 배의 성능 향상을 제공하는 \nDynamoDB 용 완전 관리형 고가용성 인 메모리 캐시를 사용할 수 있습니다. 모든 읽기 \n요청을 DAX 를 통해 라우팅함으로써 회사는 DynamoDB 테이블에 대한 읽기 작업 수를 \n줄이고 사용자 경험을 향상시킬 수 있습니다.", "answer_choice": "A"}, "562": {"q_num": 562, "question": "솔루션 설계자는 VPC 의 Amazon EC2 인스턴스에서 Amazon DynamoDB 에 대한 API \n호출이 인터넷을 통해 이동하지 않도록 해야 합니다. \n솔루션 설계자는 이 요구 사항을 충족하기 위해 어떤 단계 조합을 수행해야 합니까? (2 개 \n선택) \nA. 엔드포인트에 대한 라우팅 테이블 항목을 생성합니다. \nB. DynamoDB 용 게이트웨이 엔드포인트를 생성합니다. \nC. Amazon EC2 용 인터페이스 엔드포인트를 생성합니다. \nD. VPC 의 각 서브넷에서 끝점에 대한 탄력적 네트워크 인터페이스를 만듭니다. \nE. 엔드포인트의 보안 그룹에 보안 그룹 항목을 생성하여 액세스를 제공합니다.", "answer_block": "Answer: A, B \nhttps://www.examtopics.com/discussions/amazon/view/117251-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "563": {"q_num": 563, "question": "회사는 Amazon Elastic Kubernetes Service(Amazon EKS) 클러스터와 온프레미스 \nKubernetes 클러스터 모두에서 애플리케이션을 실행합니다. 회사는 중앙 위치에서 모든 \n클러스터와 워크로드를 보기를 원합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Amazon CloudWatch Container Insights\n를 사용하여 클러스터 정보를 수집하고 \n그룹화합니다. \nB. Amazon EKS 커넥터를 사용하여 모든 Kubernetes 클러스터를 등록하고 연결합니다. \nC. AWS Systems Manager 를 사용하여 클러스터 정보를 수집하고 봅니다. \nD. Amazon EKS Anywhere 를 기본 클러스터로 사용하여 기본 Kubernetes 명령으로 다른 \n클러스터를 봅니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/117023-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "564": {"q_num": 564, "question": "회사에서 전자상거래 애플리케이션을 구축 중이며 중요한 고객 정보를 저장해야 합니다. \n회사는 고객이 웹사이트에서 구매 거래를 완료할 수 있는 기능을 제공해야 합니다. 회사는 \n또한 민감한 고객 데이터를 데이터베이스 관리자로부터 보호해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. Amazon Elastic Block Store(Amazon EBS) 볼륨에 민감한 데이터를 저장합니다. EBS \n암호화를 사용하여 데이터를 암호화합니다. IAM 인스턴스 역할을 사용하여 액세스를 \n제한합니다. \nB. MySQL 용 Amazon RDS 에 민감한 데이터를 저장합니다. AWS Key Management \nService(AWS KMS) 클라이언트 측 암호화를 사용하여 데이터를 암호화합니다. \nC. 민감한 데이터를 Amazon S3 에 저장합니다. AWS Key Management Service(AWS KMS) \n서버 측 암호화를 사용하여 데이터를 암호화합니다. S3 버킷 정책을 사용하여 액세스를 \n제한하십시오. \nD. 민감한 데이터를 Windows Server 용 Amazon FSx 에 저장합니다. 응용 프로그램 서버에 \n파일 공유를 탑재합니다. Windows 파일 권한을 사용하여 액세스를 제한하십시오.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/117024-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n이를 통해 회사는 중요한 고객 정보를 관리형 AWS 서비스에 저장하고 고객이 웹 \n사이트에서 구매 거래를 완료할 수 있는 기능을 제공할 수 있습니다. AWS Key Management \nService(AWS KMS) 클라이언트 측 암호화를 사용하여 회사는 데이터를 MySQL 용 Amazon \nRDS 로 보내기 전에 암호화할 수 있습니다. 애플리케이션만이 암호화 키에 액세스할 수 \n있으므로 이를 통해 데이터베이스 관리자로부터도 민감한 고객 데이터가 보호됩니다.", "answer_choice": "B"}, "565": {"q_num": 565, "question": "회사에는 트랜잭션 데이터를 처리하는 온프레미스 MySQL 데이터베이스가 있습니다. \n회사는 데이터베이스를 AWS 클라우드로 마이그레이션하고 있습니다. 마이그레이션된 \n데이터베이스는 데이터베이스를 사용하는 회사의 애플리케이션과 호환성을 유지해야 합니다. \n마이그레이션된 데이터베이스는 또한 수요가 증가하는 기간 동안 자동으로 확장되어야 \n합니다. \n이러한 요구 사항을 충족하는 마이그레이션 솔루션은 무엇입니까? \nA. \n기본 MySQL 도구를 사용하여 데이터베이스를 MySQL\n용 Amazon RDS\n로 \n마이그레이션합니다. 탄력적 스토리지 확장을 구성합니다. \nB. \nmysqldump \n유틸리티를 \n사용하여 \n데이터베이스를 \nAmazon \nRedshift\n로 \n마이그레이션합니다. Amazon Redshift 클러스터에 대해 Auto Scaling 을 켭니다. \nC. AWS Database Migration Service(AWS DMS)를 사용하여 데이터베이스를 Amazon \nAurora 로 마이그레이션합니다. Aurora Auto Scaling 을 켭니다. \nD. AWS Database Migration Service(AWS DMS)를 사용하여 데이터베이스를 Amazon \nDynamoDB 로 마이그레이션합니다. Auto Scaling 정책을 구성합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/117025-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n호환성과 확장성을 갖춘 MySQL 데이터베이스를 AWS\n로 마이그레이션하려면 Amazon \nAurora 가 적합한 옵션입니다. Aurora 는 MySQL 과 호환되며 Aurora Auto Scaling 을 통해 \n자동으로 확장할 수 있습니다. AWS Database Migration Service(AWS DMS)를 사용하면 가동 \n중지 시간을 최소화하면서 온프레미스에서 Aurora 로 데이터베이스를 마이그레이션할 수 \n\n있습니다.", "answer_choice": "C"}, "566": {"q_num": 566, "question": "회사는 2 개의 가용 영역에 걸쳐 VPC 에서 여러 Amazon EC2 Linux 인스턴스를 실행합니다. \n인스턴스는 \n계층적 \n디렉터리 \n구조를 \n사용하는 \n애플리케이션을 \n호스팅합니다. \n애플리케이션은 공유 스토리지에서 동시에 빠르게 읽고 쓸 수 있어야 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. Amazon S3 버킷을 생성합니다. VPC 의 모든 EC2 인스턴스에서 액세스를 허용합니다. \nB. Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성합니다. 각 EC2 \n인스턴스에서 EFS 파일 시스템을 탑재합니다. \nC. 프로비저닝된 IOPS SSD(io2) Amazon Elastic Block Store(Amazon EBS) 볼륨에 파일 \n시스템을 생성합니다. EBS 볼륨을 모든 EC2 인스턴스에 연결합니다. \nD. 각 EC2 인스턴스에 연결된 Amazon Elastic Block Store(Amazon EBS) 볼륨에 파일 \n시스템을 만듭니다. 여러 EC2 인스턴스 간에 EBS 볼륨을 동기화합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/116902-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n이를 통해 EC2 인스턴스는 두 가용 영역에 걸쳐 공유 스토리지에 동시에 빠르게 읽고 쓸 \n수 있습니다. Amazon EFS 는 여러 EC2 인스턴스에서 탑재할 수 있는 확장 가능하고 \n탄력적이며 가용성이 높은 파일 시스템을 제공합니다. Amazon EFS\n는 높은 수준의 \n처리량과 IOPS, 일관되게 낮은 지연 시간을 지원합니다. Amazon EFS 는 또한 높은 수준의 \n동시성을 지원하는 NFSv4 잠금 업그레이드 및 다운그레이드를 지원합니다.", "answer_choice": "B"}, "567": {"q_num": 567, "question": "솔루션 설계자는 건물 내 비즈니스 테넌트의 시간당 에너지 소비량을 저장할 워크로드를 \n설계하고 \n있습니다. \n센서는 \n각 \n테넌트의 \n사용량을 \n합산하는 \nHTTP \n요청을 \n통해 \n데이터베이스에 공급합니다. 솔루션 설계자는 가능한 경우 관리 서비스를 사용해야 합니다. \n워크로드는 솔루션 설계자가 독립적인 구성 요소를 추가함에 따라 향후 더 많은 기능을 \n받게 됩니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. AWS Lambda 함수와 함께 Amazon API Gateway 를 사용하여 센서에서 데이터를 \n수신하고, 데이터를 처리하고, Amazon DynamoDB 테이블에 데이터를 저장합니다. \n\nB. Amazon EC2 인스턴스의 Auto Scaling 그룹에서 지원하는 Elastic Load Balancer 를 \n사용하여 센서에서 데이터를 수신하고 처리합니다. Amazon S3 버킷을 사용하여 처리된 \n데이터를 저장합니다. \nC. AWS Lambda 함수와 함께 Amazon API Gateway 를 사용하여 센서에서 데이터를 \n수신하고, 데이터를 처리하고, Amazon EC2 인스턴스의 Microsoft SQL Server Express \n데이터베이스에 데이터를 저장합니다. \nD. Amazon EC2 인스턴스의 Auto Scaling 그룹에서 지원하는 Elastic Load Balancer 를 \n사용하여 센서에서 데이터를 수신하고 처리합니다. Amazon Elastic File System(Amazon EFS) \n공유 파일 시스템을 사용하여 처리된 데이터를 저장합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/117026-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nAWS Lambda 에서 이벤트 기반 프로그래밍 모델을 사용하고 운영 오버헤드를 줄이려면 \nAmazon API Gateway 와 Amazon DynamoDB 가 적합한 솔루션입니다. Amazon API \nGateway 는 센서로부터 데이터를 수신하고 AWS Lambda 함수를 호출하여 데이터를 처리할 \n수 있습니다. AWS Lambda 는 서버를 프로비저닝하거나 관리하지 않고도 코드를 실행하고 \n수신 요청에 따라 자동으로 확장할 수 있습니다. Amazon DynamoDB 는 일관된 성능으로 \n모든 양의 데이터를 처리할 수 있는 빠르고 유연한 NoSQL 데이터베이스에 데이터를 \n저장할 수 있습니다.", "answer_choice": "A"}, "568": {"q_num": 568, "question": "솔루션 설계자는 엔지니어링 도면을 저장하고 보는 데 사용되는 새 웹 애플리케이션의 \n스토리지 아키텍처를 설계하고 있습니다. 모든 애플리케이션 구성 요소는 AWS 인프라에 \n배포됩니다. \n응용 프로그램 디자인은 사용자가 엔지니어링 도면이 로드될 때까지 기다리는 시간을 \n최소화하기 위해 캐싱을 지원해야 합니다. 애플리케이션은 페타바이트의 데이터를 저장할 \n수 있어야 합니다. \n솔루션 설계자는 어떤 스토리지 및 캐싱 조합을 사용해야 합니까? \nA. Amazon CloudFront 를 사용하는 Amazon S3 \nB. Amazon ElastiCache 를 사용하는 Amazon S3 Glacier \nC. Amazon CloudFront 를 사용하는 Amazon Elastic Block Store(Amazon EBS) 볼륨 \nD. Amazon ElastiCache 를 사용하는 AWS Storage Gateway", "answer_block": "Answer: A \n\nhttps://www.examtopics.com/discussions/amazon/view/117027-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n캐싱 지원을 통해 엔지니어링 도면을 저장하고 보려면 Amazon S3 및 Amazon \nCloudFront 가 적합한 솔루션입니다. Amazon S3 는 높은 내구성, 가용성 및 성능으로 모든 \n양의 데이터를 저장할 수 있습니다. Amazon CloudFront 는 엔지니어링 도면을 사용자에게 \n더 가까운 엣지 로케이션에 배포하여 지연 시간을 줄이고 사용자 경험을 향상시킬 수 \n있습니다. Amazon CloudFront 는 엔지니어링 도면을 엣지 로케이션에 캐시할 수도 있으므로 \n사용자가 도면이 로드될 때까지 기다리는 시간을 최소화할 수 있습니다.", "answer_choice": "A"}, "569": {"q_num": 569, "question": "Amazon EventBridge 규칙은 타사 API 를 대상으로 합니다. 타사 API 가 수신 트래픽을 \n수신하지 않았습니다. 솔루션 설계자는 규칙 조건이 충족되고 있는지 여부와 규칙의 대상이 \n호출되고 있는지 확인해야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. AWS/Events 의 네임스페이스에서 Amazon CloudWatch 의 지표를 확인하십시오. \nB. Amazon Simple Queue Service(Amazon SQS) 데드 레터 대기열의 이벤트를 검토합니다. \nC. Amazon CloudWatch Logs 에서 이벤트를 확인합니다. \nD. EventBridge 이벤트에 대한 AWS CloudTrail 의 추적을 확인합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/117377-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "570": {"q_num": 570, "question": "회사에는 \n매주 \n금요일 \n저녁에 \n실행되는 \n대규모 \n워크로드가 \n있습니다. \n워크로드는 \nus-east-1 리전의 두 가용 영역에 있는 Amazon EC2 인스턴스에서 실행됩니다. \n일반적으로 회사는 항상 두 개 이상의 인스턴스를 실행하지 않아야 합니다. 그러나 회사는 \n정기적으로 반복되는 증가된 워크로드를 처리하기 위해 금요일마다 최대 6 개의 인스턴스로 \n확장하려고 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Amazon EventBridge 에서 미리 알림을 생성하여 인스턴스를 확장하십시오. \nB. 예약된 작업이 있는 Auto Scaling 그룹을 생성합니다. \nC. 수동 조정을 사용하는 Auto Scaling 그룹을 생성합니다. \n\nD. 자동 조정을 사용하는 Auto Scaling 그룹을 생성합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/116903-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nAuto Scaling 그룹은 유사한 특성을 공유하고 수요에 따라 자동으로 확장 또는 축소될 수 \n있는 EC2 인스턴스 모음입니다. Auto Scaling 그룹에는 특정 시간에 특정 크기로 \n확장하도록 그룹에 지시하는 구성인 예약된 작업이 있을 수 있습니다. 이러한 방식으로 \n회사는 매주 금요일 저녁 최대 6 개의 인스턴스로 확장하여 증가된 워크로드를 처리하고, \n다른 시간에는 2 개의 인스턴스로 축소하여 비용을 절감할 수 있습니다. 이 솔루션은 수동 \n개입이나 사용자 지정 스크립트가 필요하지 않으므로 최소한의 운영 오버헤드로 요구 \n사항을 충족합니다.", "answer_choice": "B"}, "571": {"q_num": 571, "question": "회사에서 REST API 를 만들고 있습니다. 회사에는 TLS 사용에 대한 엄격한 요구 사항이 \n있습니다. 회사는 API 엔드포인트에 TLSv1.3 을 요구합니다. 또한 회사는 TLS 인증서에 \n서명하기 위해 특정 공개 타사 인증 기관(CA)을 요구합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 로컬 시스템을 사용하여 타사 CI 가 서명한 인증서를 생성하고 인증서를 AWS Certificate \nManager(ACM)로 가져옵니다. 사용자 지정 도메인을 사용하여 Amazon API Gateway 에서 \nHTTP API 를 생성합니다. 인증서를 사용하도록 사용자 지정 도메인을 구성합니다. \nB. 타사 CA 가 서명한 AWS Certificate Manager(ACM)에서 인증서를 생성합니다. 사용자 \n지정 도메인을 사용하여 Amazon API Gateway 에서 HTTP API 를 생성합니다. 인증서를 \n사용하도록 사용자 지정 도메인을 구성합니다. \nC. AWS Certificate Manager(ACM)를 사용하여 타사 CA 에서 서명한 인증서를 생성합니다. \n인증서를 AWS Certificate Manager(ACM)로 가져옵니다. Lambda 함수 URL 을 사용하여 \nAWS Lambda 함수를 생성합니다. 인증서를 사용하도록 Lambda 함수 URL 을 구성합니다. \nD. 타사 CA 에서 서명한 AWS Certificate Manager(ACM)에서 인증서를 생성합니다. Lambda \n함수 URL 을 사용하여 AWS Lambda 함수를 생성합니다. 인증서를 사용하도록 Lambda \n함수 URL 을 구성합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/116904-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \nA??", "answer_choice": "B"}, "572": {"q_num": 572, "question": "회사는 AWS 에서 애플리케이션을 실행합니다. 애플리케이션이 일관되지 않은 사용량을 \n수신합니다. 애플리케이션은 AWS Direct Connect 를 사용하여 온프레미스 MySQL 호환 \n데이터베이스에 연결합니다. 온프레미스 데이터베이스는 지속적으로 최소 2GiB 의 메모리를 \n사용합니다. \n회사는 온프레미스 데이터베이스를 관리형 AWS 서비스로 마이그레이션하려고 합니다. \n회사는 자동 확장 기능을 사용하여 예기치 않은 작업 부하 증가를 관리하려고 합니다. \n최소한의 관리 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. \n기본 \n읽기 \n및 \n쓰기 \n용량 \n설정으로 \nAmazon \nDynamoDB \n데이터베이스를 \n프로비저닝합니다. \nB. \n최소 \n용량이 \n1 \nAurora \n용량 \n단위(ACU)인 \nAmazon \nAurora \n데이터베이스를 \n프로비저닝합니다. \nC. 최소 용량이 1 Aurora 용량 단위(ACU)인 Amazon Aurora Serverless v2 데이터베이스를 \n프로비저닝합니다. \nD. 2GiB 의 메모리로 Amazon RDS for MySQL 데이터베이스를 프로비저닝합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/117029-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n이를 통해 회사는 온프레미스 데이터베이스를 Auto Scaling 기능을 지원하고 관리 \n오버헤드가 가장 적은 관리형 AWS 서비스로 마이그레이션할 수 있습니다. Amazon Aurora \nServerless v2 는 워크로드 수요에 따라 컴퓨팅 용량을 자동으로 확장하는 Amazon Aurora 의 \n구성입니다. 단 몇 초 만에 수백 건에서 수십만 건의 트랜잭션을 확장할 수 있습니다. \nAmazon Aurora Serverless v2 는 MySQL 호환 데이터베이스와 AWS Direct Connect 연결도 \n지원합니다.", "answer_choice": "C"}, "573": {"q_num": 573, "question": "회사에서 AWS Lambda 와 함께 이벤트 기반 프로그래밍 모델을 사용하려고 합니다. 회사는 \nJava 11\n에서 실행되는 Lambda 함수의 시작 지연 시간을 줄이려고 합니다. 회사는 \n애플리케이션에 대한 엄격한 지연 시간 요구 사항이 없습니다. 이 회사는 함수가 확장될 때 \n콜드 스타트와 이상치 대기 시간을 줄이려고 합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \n\nA. Lambda 프로비저닝된 동시성을 구성합니다. \nB. Lambda 함수의 제한 시간을 늘립니다. \nC. Lambda 함수의 메모리를 늘립니다. \nD. Lambda SnapStart 를 구성합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/116925-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nJava 11\n에서 실행되는 Lambda 함수의 시작 지연 시간을 줄이기 위해 Lambda \nSnapStart 가 적합한 솔루션입니다. Lambda SnapStart 는 Java 11 기능에 대한 더 빠른 콜드 \n스타트와 더 낮은 이상치 지연 시간을 지원하는 기능입니다. Lambda SnapStart 는 사전 \n초기화된 JVM(Java Virtual Machine)을 사용하여 기능을 실행하므로 초기화 시간과 메모리 \n공간이 줄어듭니다. Lambda SnapStart 에는 추가 비용이 발생하지 않습니다.", "answer_choice": "D"}, "574": {"q_num": 574, "question": "금융 \n서비스 \n회사는 \nAmazon \nRDS \nfor \nMySQL \n데이터베이스를 \n사용하는 \n새로운 \n애플리케이션을 출시했습니다. 회사는 응용 프로그램을 사용하여 주식 시장 추세를 \n추적합니다. 회사는 매주 말 2\n시간 동안만 애플리케이션을 작동하면 됩니다. 회사는 \n데이터베이스 실행 비용을 최적화해야 합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. 기존 RDS for MySQL 데이터베이스를 Aurora Serverless v2 MySQL 데이터베이스 \n클러스터로 마이그레이션합니다. \nB. 기존 RDS for MySQL 데이터베이스를 Aurora MySQL 데이터베이스 클러스터로 \n마이그레이션합니다. \nC. 기존 RDS for MySQL 데이터베이스를 MySQL 을 실행하는 Amazon EC2 인스턴스로 \n마이그레이션합니다. EC2 인스턴스에 대한 인스턴스 예약을 구매합니다. \nD. 기존 RDS for MySQL 데이터베이스를 MySQL 컨테이너 이미지를 사용하여 작업을 \n실행하는 Amazon Elastic Container Service(Amazon ECS) 클러스터로 마이그레이션합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/117272-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "575": {"q_num": 575, "question": "회사는 AWS 리전의 Application Load Balancer 뒤에 있는 Amazon Elastic Kubernetes \nService(Amazon \nEKS)에 \n애플리케이션을 \n배포합니다. \n애플리케이션은 \nPostgreSQL \n데이터베이스 엔진에 데이터를 저장해야 합니다. 회사는 데이터베이스의 데이터가 가용성이 \n높기를 원합니다. 회사는 또한 읽기 워크로드를 위한 증가된 용량이 필요합니다. \n이러한 요구 사항을 가장 효율적으로 충족하는 솔루션은 무엇입니까? \nA. 전역 테이블로 구성된 Amazon DynamoDB 데이터베이스 테이블을 생성합니다. \nB. 다중 AZ 배포로 Amazon RDS 데이터베이스를 생성합니다. \nC. 다중 AZ DB 클러스터 배포로 Amazon RDS 데이터베이스를 생성합니다. \nD. 리전 간 읽기 전용 복제본으로 구성된 Amazon RDS 데이터베이스를 생성합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/116969-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "576": {"q_num": 576, "question": "회사는 Amazon API Gateway 및 AWS Lambda 를 사용하여 AWS 에서 RESTful 서버리스 웹 \n애플리케이션을 구축하고 있습니다. 이 웹 애플리케이션의 사용자는 지리적으로 분산되며 \n회사는 이러한 사용자에 대한 API 요청 대기 시간을 줄이려고 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 유형의 엔드포인트를 사용해야 \n합니까? \nA. 프라이빗 엔드포인트 \nB. 지역 엔드포인트 \nC. 인터페이스 VPC 엔드포인트 \nD. 엣지 최적화 엔드포인트", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/116906-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n엣지 최적화 API 엔드포인트는 API 요청을 가장 가까운 CloudFront POP(Point of \nPresence)로 라우팅하므로 지리적으로 분산된 클라이언트에 가장 적합합니다. 이렇게 하면 \n대기 시간이 줄어들고 API 성능이 향상됩니다. 엣지 최적화 엔드포인트는 API Gateway \nREST API 의 기본 유형입니다. \n지역 API 엔드포인트는 API와 동일한 지역에 있는 클라이언트를 위한 것이며 CloudFront를 \n사용하여 요청을 라우팅하지 않습니다. 프라이빗 API 엔드포인트는 인터페이스 VPC \n엔드포인트를 사용하여 VPC 에서만 액세스할 수 있는 API 엔드포인트입니다. 지역 또는 \n\n개인 끝점은 지리적으로 분산된 사용자의 대기 시간을 줄이는 요구 사항을 충족하지 \n않습니다.", "answer_choice": "D"}, "577": {"q_num": 577, "question": "회사는 Amazon CloudFront 배포를 사용하여 웹 사이트의 콘텐츠 페이지를 제공합니다. \n회사는 고객이 회사 웹 사이트에 액세스할 때 TLS 인증서를 사용하도록 해야 합니다. \n회사는 TLS 인증서의 생성 및 갱신을 자동화하려고 합니다. \n이러한 요구 사항을 가장 효율적으로 충족하는 솔루션은 무엇입니까? \nA. CloudFront 보안 정책을 사용하여 인증서를 생성합니다. \nB. CloudFront 원본 액세스 제어(OAC)를 사용하여 인증서를 생성합니다. \nC. AWS Certificate Manager(ACM)를 사용하여 인증서를 생성합니다. 도메인에 대해 DNS \n검증을 사용하십시오. \nD. AWS Certificate Manager(ACM)를 사용하여 인증서를 생성합니다. 도메인에 대한 이메일 \n유효성 검사를 사용합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/117037-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "578": {"q_num": 578, "question": "한 \n회사에서 \nAmazon \nDynamoDB\n를 \n데이터베이스 \n계층으로 \n사용하는 \n서버리스 \n애플리케이션을 배포했습니다. 응용 프로그램의 사용자가 크게 증가했습니다. 이 회사는 \n데이터베이스 응답 시간을 밀리초에서 마이크로초로 개선하고 데이터베이스에 대한 요청을 \n캐시하기를 원합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. DynamoDB 가속기(DAX)를 사용합니다. \nB. 데이터베이스를 Amazon Redshift 로 마이그레이션합니다. \nC. 데이터베이스를 Amazon RDS 로 마이그레이션합니다. \nD. Redis 용 Amazon ElastiCache 를 사용합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/117038-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "579": {"q_num": 579, "question": "회사에서 PostgreSQL\n용 Amazon RDS\n를 사용하는 애플리케이션을 실행합니다. \n애플리케이션은 평일 업무 시간에만 트래픽을 수신합니다. 회사는 이 사용량을 기반으로 \n비용을 최적화하고 운영 오버헤드를 줄이려고 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. AWS 의 인스턴스 스케줄러를 사용하여 시작 및 중지 일정을 구성하십시오. \nB. 자동 백업을 끕니다. 데이터베이스의 매주 수동 스냅샷을 생성합니다. \nC. 최소 CPU 사용률을 기준으로 데이터베이스를 시작하고 중지하는 사용자 지정 AWS \nLambda 함수를 생성합니다. \nD. 모든 Upfront 예약 DB 인스턴스를 구매합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/116924-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nAWS 솔루션의 인스턴스 스케줄러는 Amazon Elastic Compute Cloud(Amazon EC2) 및 \nAmazon Relational Database Service(Amazon RDS) \n인스턴스의 시작 및 중지를 \n자동화합니다. 이 솔루션은 사용하지 않는 리소스를 중지하고 필요할 때 시작하여 운영 \n비용을 절감하는 데 도움이 됩니다1. 이 솔루션을 사용하면 명령줄 인터페이스(CLI) 또는 \nSSM 유지 관리 기간을 사용하여 맞춤형 일정과 기간을 정의할 수 있습니다. 선결제 없음, \n부분 선결제, 전체 선결제 등 예약 DB 인스턴스에 대한 다양한 결제 옵션 중에서 선택할 \n수도 있습니다. \n \n참고: \nhttps://aws.amazon.com/ko/solutions/implementations/instance-scheduler-on-aws/?nc1\n=h_ls", "answer_choice": "A"}, "580": {"q_num": 580, "question": "회사는 \n로컬로 \n연결된 \n스토리지를 \n사용하여 \n온프레미스에서 \n대기 \n시간에 \n민감한 \n애플리케이션을 실행합니다. 이 회사는 애플리케이션을 AWS 클라우드로 옮기기 위해 \n리프트 앤 시프트 방식을 사용하고 있습니다. 회사는 애플리케이션 아키텍처를 변경하기를 \n원하지 않습니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. Amazon EC2 인스턴스로 Auto Scaling 그룹을 구성합니다. Amazon FSx for Lustre 파일 \n시스템을 사용하여 애플리케이션을 실행합니다. \nB. Amazon EC2 인스턴스에서 애플리케이션을 호스팅합니다. Amazon Elastic Block \n\nStore(Amazon EBS) GP2 볼륨을 사용하여 애플리케이션을 실행합니다. \nC. Amazon EC2 인스턴스로 Auto Scaling 그룹을 구성합니다. OpenZFS 파일 시스템용 \nAmazon FSx 를 사용하여 애플리케이션을 실행합니다. \nD. Amazon EC2 인스턴스에서 애플리케이션을 호스팅합니다. Amazon Elastic Block \nStore(Amazon EBS) GP3 볼륨을 사용하여 애플리케이션을 실행합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/117663-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "D"}, "581": {"q_num": 581, "question": "회사는 Amazon EC2 인스턴스에서 상태 저장 프로덕션 애플리케이션을 실행합니다. \n애플리케이션을 항상 실행하려면 최소 2 개의 EC2 인스턴스가 필요합니다. \n솔루션 설계자는 응용 프로그램을 위한 고가용성 및 내결함성 아키텍처를 설계해야 합니다. \n솔루션 설계자는 EC2 인스턴스의 Auto Scaling 그룹을 생성합니다. \n이러한 요구 사항을 충족하기 위해 솔루션 설계자가 수행해야 하는 추가 단계는 \n무엇입니까? \nA. Auto Scaling 그룹의 최소 용량을 2 로 설정합니다. 하나의 가용 영역에 하나의 온디맨드 \n인스턴스를 배포하고 두 번째 가용 영역에 하나의 온디맨드 인스턴스를 배포합니다. \nB. Auto Scaling 그룹의 최소 용량을 4 개로 설정합니다. 하나의 가용 영역에 2 개의 \n온디맨드 인스턴스를 배포하고 두 번째 가용 영역에 2\n개의 온디맨드 인스턴스를 \n배포합니다. \nC. Auto Scaling 그룹의 최소 용량을 2 로 설정합니다. 하나의 가용 영역에 4 개의 스팟 \n인스턴스를 배포합니다. \nD. Auto Scaling 그룹의 최소 용량을 4 로 설정합니다. 하나의 가용 영역에 2 개의 온디맨드 \n인스턴스를 배포하고 두 번째 가용 영역에 2 개의 스팟 인스턴스를 배포합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/116968-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "582": {"q_num": 582, "question": "전자상거래 회사는 Amazon Route 53 을 DNS 공급자로 사용합니다. 이 회사는 온프레미스 \n및 AWS 클라우드에서 웹 사이트를 호스팅합니다. 회사의 온프레미스 데이터 센터는 \nus-west-1 지역 근처에 있습니다. 회사는 eu-central-1 지역을 사용하여 웹사이트를 \n호스팅합니다. 회사는 웹사이트 로딩 시간을 최대한 최소화하고자 합니다. \n\n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 지리적 위치 라우팅 정책을 설정합니다. us-west-1 근처에 있는 트래픽을 온프레미스 \n데이터 센터로 보냅니다. eu-central-1 근처에 있는 트래픽을 eu-central-1 로 보냅니다. \nB. eu-central-1 근처에 있는 모든 트래픽을 eu-central-1\n로 라우팅하고 온프레미스 \n데이터 센터 근처에 있는 모든 트래픽을 온프레미스 데이터 센터로 라우팅하는 간단한 \n라우팅 정책을 설정합니다. \nC. 레이턴시 라우팅 정책을 설정합니다. 정책을 us-west-1 과 연결합니다. \nD. 가중치 기반 라우팅 정책을 설정합니다. eu-central-1 과 온프레미스 데이터 센터 간에 \n트래픽을 균등하게 분할합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/118597-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "583": {"q_num": 583, "question": "회사는 물리적 테이프에 5PB 의 아카이빙된 데이터를 가지고 있습니다. 회사는 규정 준수를 \n위해 테이프의 데이터를 10 년 더 보존해야 합니다. 회사는 향후 6 개월 내에 AWS 로 \n마이그레이션하기를 원합니다. 테이프를 저장하는 데이터 센터에는 1Gbps 업링크 인터넷 \n연결이 있습니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. \n온프레미스에서 \n테이프의 \n데이터를 \n읽습니다. \n로컬 \nNFS \n스토리지에 \n데이터를 \n준비합니다. AWS DataSync 를 사용하여 데이터를 Amazon S3 Glacier Flexible Retrieval 로 \n마이그레이션합니다. \nB. 온프레미스 백업 애플리케이션을 사용하여 테이프에서 데이터를 읽고 Amazon S3 \nGlacier Deep Archive 에 직접 씁니다. \nC. 테이프 게이트웨이가 있는 여러 AWS Snowball 디바이스를 주문합니다. Snowball 의 \n가상 테이프에 물리적 테이프를 복사합니다. Snowball 디바이스를 AWS 로 배송합니다. 수명 \n주기 정책을 생성하여 테이프를 Amazon S3 Glacier Deep Archive 로 이동합니다. \nD. 온프레미스 테이프 게이트웨이를 구성합니다. AWS 클라우드에서 가상 테이프를 \n생성합니다. 백업 소프트웨어를 사용하여 물리적 테이프를 가상 테이프에 복사합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/117215-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "584": {"q_num": 584, "question": "한 회사에서 대량의 데이터를 병렬로 처리하는 애플리케이션을 배포하고 있습니다. 회사는 \n워크로드에 Amazon EC2 인스턴스를 사용할 계획입니다. 노드 그룹이 동일한 기본 \n하드웨어를 공유하지 못하도록 네트워크 아키텍처를 구성할 수 있어야 합니다. \n이러한 요구 사항을 충족하는 네트워킹 솔루션은 무엇입니까? \nA. 분산 배치 그룹에서 EC2 인스턴스를 실행합니다. \nB. EC2 인스턴스를 별도의 계정으로 그룹화합니다. \nC. 전용 테넌시로 EC2 인스턴스를 구성합니다. \nD. 공유 테넌시로 EC2 인스턴스를 구성합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/119485-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n이를 통해 회사는 대량의 데이터를 병렬로 처리하고 노드 그룹이 동일한 기본 하드웨어를 \n공유하는 것을 방지하는 애플리케이션을 배포할 수 있습니다. 분산 배치 그룹에서 EC2 \n인스턴스를 실행함으로써 회사는 서로 다른 기본 하드웨어에서 소수의 인스턴스를 시작하여 \n상관 오류를 줄일 수 있습니다. 분산 배치 그룹은 각 인스턴스가 랙 수준에서 서로 \n격리되도록 보장합니다.", "answer_choice": "A"}, "585": {"q_num": 585, "question": "솔루션 아키텍트는 장애 조치 AWS 지역에서 Amazon EC2 용량을 제공하기 위한 재해 \n복구(DR) 전략을 설계하고 있습니다. 비즈니스 요구 사항에 따르면 DR 전략은 장애 조치 \n지역의 용량을 충족해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 장애 조치 지역에서 온디맨드 인스턴스를 구매합니다. \nB. 장애 조치 지역에서 EC2 Savings Plan 을 구매합니다. \nC. 장애 조치 지역에서 지역 예약 인스턴스를 구매합니다. \nD. 장애 조치 지역에서 용량 예약을 구매합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/119642-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "D"}, "586": {"q_num": 586, "question": "회사에는 AWS Organizations 조직의 일부로 5 개의 조직 단위(OU)가 있습니다. 각 OU 는 \n\n회사가 소유한 5 개 비즈니스와 연관되어 있습니다. 회사의 연구개발(R&D) 사업이 회사에서 \n분리되어 자체 조직이 필요할 것입니다. 솔루션 설계자는 이 목적을 위해 별도의 새 관리 \n계정을 생성합니다. \n솔루션 설계자는 새 마스터 계정에서 다음에 무엇을 수행해야 합니까? \nA. 전환하는 동안 R&D AWS 계정이 두 조직의 일부가 되도록 하십시오. \nB. R&D AWS 계정이 이전 조직을 떠난 후 R&D AWS 계정을 새 조직의 일부로 초대합니다. \nC. 새 조직에 새 R&D AWS 계정을 생성합니다. 이전 R&D AWS 계정의 리소스를 새 R&D \nAWS 계정으로 마이그레이션합니다. \nD. R&D AWS 계정이 새 조직에 가입하도록 합니다. 새 마스터 계정을 이전 조직의 \n구성원으로 만드세요.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/119645-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n이를 통해 솔루션 아키텍트는 연구 개발(R&D) 비즈니스를 위한 별도의 조직을 만들고 AWS \n계정을 새 조직으로 이동할 수 있습니다. R&D AWS 계정이 이전 조직을 떠난 후 새 조직의 \n일부가 되도록 초대함으로써 솔루션 아키텍트는 두 조직 간에 중복이나 충돌이 없는지 \n확인할 수 있습니다. R&D AWS 계정은 새 조직에 가입하라는 초대를 수락하거나 거부할 수 \n있습니다. 일단 수락되면 새 조직에서 적용하는 모든 정책과 통제가 적용됩니다.", "answer_choice": "B"}, "587": {"q_num": 587, "question": "한 회사는 분석을 처리하고 예측하기 위해 다양한 웹 애플리케이션에서 고객 활동을 \n캡처하는 솔루션을 설계하고 있습니다. 웹 애플리케이션에서의 고객 활동은 예측할 수 \n없으며 갑자기 증가할 수 있습니다. 회사에는 다른 웹 애플리케이션과 통합되는 솔루션이 \n필요합니다. 솔루션에는 보안 목적을 위한 인증 단계가 포함되어야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 회사가 Amazon Elastic File System(Amazon EFS) 파일 시스템에서 수신하는 정보를 \n저장하는 Amazon Elastic Container Service(Amazon ECS) 컨테이너 인스턴스 앞에 \n게이트웨이 로드 밸런서(GWLB)를 구성합니다. 승인은 GWLB 에서 해결됩니다. \nB. 회사가 Amazon S3 버킷에 수신하는 정보를 저장하는 Amazon Kinesis 데이터 스트림 \n앞에 Amazon API Gateway 엔드포인트를 구성합니다. AWS Lambda 함수를 사용하여 \n인증을 해결합니다. \nC. 회사가 Amazon S3 버킷에 수신하는 정보를 저장하는 Amazon Kinesis Data Firehose \n앞에 Amazon API Gateway 엔드포인트를 구성합니다. API Gateway Lambda 권한 부여자를 \n\n사용하여 권한 부여를 해결합니다. \nD. 회사가 Amazon Elastic File System(Amazon EFS) 파일 시스템에서 수신하는 정보를 \n저장하는 Amazon Elastic Container Service(Amazon ECS) 컨테이너 인스턴스 앞에 \n게이트웨이 로드 밸런서(GWLB)를 구성합니다. AWS Lambda 함수를 사용하여 인증을 \n해결합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/119576-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "588": {"q_num": 588, "question": "한 전자 상거래 회사는 Microsoft SQL Server Enterprise Edition 을 실행하는 Amazon RDS \nDB 인스턴스에 대한 재해 복구 솔루션을 원합니다. 회사의 현재 복구 지점 목표(RPO)와 \n복구 시간 목표(RTO)는 24 시간입니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. 지역 간 읽기 전용 복제본을 생성하고 읽기 전용 복제본을 기본 인스턴스로 승격합니다. \nB. AWS Database Migration Service(AWS DMS)를 사용하여 RDS 교차 지역 복제를 \n생성합니다. \nC. 24 시간마다 교차 리전 복제를 사용하여 기본 백업을 Amazon S3 버킷에 복사합니다. \nD. 24 시간마다 자동 스냅샷을 다른 리전으로 복사합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/119718-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "D"}, "589": {"q_num": 589, "question": "한 회사는 고정 세션이 활성화된 Application Load Balancer 뒤에 있는 Auto Scaling 그룹의 \nAmazon EC2 인스턴스에서 웹 애플리케이션을 실행합니다. 웹 서버는 현재 사용자 세션 \n상태를 호스팅합니다. 회사는 웹 서버 중단 시 고가용성을 보장하고 사용자 세션 상태 \n손실을 방지하기를 원합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. Memcached 인스턴스용 Amazon ElastiCache 를 사용하여 세션 데이터를 저장합니다. \nMemcached\n용 ElastiCache\n를 사용하여 세션 상태를 저장하도록 애플리케이션을 \n업데이트합니다. \nB. Redis\n용 Amazon ElastiCache\n를 사용하여 세션 상태를 저장합니다. Redis\n용 \nElastiCache 를 사용하여 세션 상태를 저장하도록 애플리케이션을 업데이트합니다. \n\nC. AWS Storage Gateway 캐싱 볼륨을 사용하여 세션 데이터를 저장합니다. AWS Storage \nGateway 캐싱 볼륨을 사용하여 세션 상태를 저장하도록 애플리케이션을 업데이트합니다. \nD. Amazon RDS 를 사용하여 세션 상태를 저장합니다. Amazon RDS 를 사용하여 세션 \n상태를 저장하도록 애플리케이션을 업데이트합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/119487-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "590": {"q_num": 590, "question": "한 회사는 회사의 온프레미스 데이터 센터에서 MySQL DB 인스턴스용 Amazon RDS 로 \nMySQL 데이터베이스를 마이그레이션했습니다. 회사는 회사의 일일 평균 워크로드를 \n충족하도록 RDS DB 인스턴스의 크기를 조정했습니다. 한 달에 한 번 회사에서 보고서에 \n대한 쿼리를 실행할 때 데이터베이스 성능이 느려집니다. 회사는 보고서를 실행하고 일일 \n작업 부하의 성능을 유지 관리할 수 있는 기능을 원합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 데이터베이스의 읽기 전용 복제본을 생성합니다. 쿼리를 읽기 전용 복제본으로 \n보냅니다. \nB. 데이터베이스 백업을 생성합니다. 백업을 다른 DB 인스턴스로 복원합니다. 쿼리를 새 \n데이터베이스로 보냅니다. \nC. 데이터를 Amazon S3 로 내보냅니다. Amazon Athena 를 사용하여 S3 버킷을 쿼리합니다. \nD. 추가 워크로드를 수용할 수 있도록 DB 인스턴스의 크기를 조정합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/119719-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "591": {"q_num": 591, "question": "회사는 \nAmazon \nElastic \nKubernetes \nService(Amazon \nEKS)를 \n사용하여 \n컨테이너 \n애플리케이션을 실행합니다. 애플리케이션에는 고객을 관리하고 주문하는 마이크로서비스가 \n포함되어 있습니다. 회사는 들어오는 요청을 적절한 마이크로서비스로 라우팅해야 합니다. \n이 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. AWS 로드 밸런서 컨트롤러를 사용하여 Network Load Balancer 를 프로비저닝하십시오. \nB. AWS Load Balancer Controller\n를 사용하여 Application Load Balancer\n를 \n프로비저닝합니다. \nC. AWS Lambda 함수를 사용하여 요청을 Amazon EKS 에 연결합니다. \n\nD. Amazon API Gateway 를 사용하여 요청을 Amazon EKS 에 연결합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/119574-exam-aws-certified-sol\nutions-architect-associate-saa-c03/]", "answer_choice": "D"}, "592": {"q_num": 592, "question": "회사는 AWS 를 사용하여 저작권이 있는 이미지에 대한 액세스 권한을 판매합니다. 회사의 \n글로벌 고객 기반은 이러한 이미지에 빠르게 액세스할 수 있어야 합니다. 회사는 특정 \n국가의 사용자에 대한 접근을 거부해야 합니다. 회사는 가능한 한 비용을 최소화하려고 \n합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. Amazon S3 를 사용하여 이미지를 저장하십시오. MFA(다단계 인증) 및 퍼블릭 버킷 \n액세스를 활성화합니다. 고객에게 S3 버킷에 대한 링크를 제공합니다. \nB. Amazon S3 를 사용하여 이미지를 저장합니다. 각 고객에 대해 IAM 사용자를 생성합니다. \nS3 버킷에 액세스할 수 있는 권한이 있는 그룹에 사용자를 추가합니다. \nC. ALB(Application Load Balancer) 뒤에 있는 Amazon EC2 인스턴스를 사용하여 이미지를 \n저장합니다. 회사가 서비스를 제공하는 국가에만 인스턴스를 배포하세요. 고객에게 특정 \n국가의 인스턴스에 대한 ALB 에 대한 링크를 제공하십시오. \nD. Amazon S3 를 사용하여 이미지를 저장합니다. 지리적 제한이 있는 이미지를 배포하려면 \nAmazon CloudFront 를 사용하십시오. 각 고객이 CloudFront 의 데이터에 액세스할 수 \n있도록 서명된 URL 을 제공합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/119573-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "D"}, "593": {"q_num": 593, "question": "솔루션 아키텍트는 가용성이 뛰어난 Redis 용 Amazon ElastiCache 기반 솔루션을 설계하고 \n있습니다. 솔루션 아키텍트는 장애로 인해 로컬 및 AWS 리전 내에서 성능 저하 또는 \n데이터 손실이 발생하지 않도록 해야 합니다. 솔루션은 노드 수준과 지역 수준에서 \n고가용성을 제공해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 여러 노드가 포함된 샤드가 있는 다중 AZ Redis 복제 그룹을 사용하십시오. \nB. Redis AOF(Append Only Files)가 활성화된 여러 노드가 포함된 Redis 샤드를 \n사용합니다. \n\nC. 복제 그룹에 두 개 이상의 읽기 전용 복제본이 있는 다중 AZ Redis 클러스터를 \n사용합니다. \nD. Auto Scaling 이 활성화된 여러 노드가 포함된 Redis 샤드를 사용합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/119572-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "594": {"q_num": 594, "question": "회사는 AWS\n로 마이그레이션하고 애플리케이션에 Amazon EC2 온디맨드 인스턴스를 \n사용할 계획입니다. 마이그레이션 테스트 단계에서 기술 팀은 애플리케이션이 완전히 \n생산되기 위해 메모리를 실행하고 로드하는 데 오랜 시간이 걸린다는 사실을 관찰했습니다. \n다음 테스트 단계에서 애플리케이션 실행 시간을 단축할 솔루션은 무엇입니까? \nA. 두 개 이상의 EC2 온디맨드 인스턴스를 시작합니다. Auto Scaling 기능을 활성화하고 \n다음 테스트 단계에서 EC2 온디맨드 인스턴스를 사용할 수 있도록 하십시오. \nB. EC2 스팟 인스턴스를 시작하여 애플리케이션을 지원하고 다음 테스트 단계에서 사용할 \n수 있도록 애플리케이션을 확장합니다. \nC. 최대 절전 모드를 활성화한 상태에서 EC2 온디맨드 인스턴스를 시작합니다. 다음 \n테스트 단계에서 EC2 Auto Scaling 웜 풀을 구성합니다. \nD. 용량 예약을 통해 EC2 온디맨드 인스턴스를 시작합니다. 다음 테스트 단계에서 추가 \nEC2 인스턴스를 시작하십시오.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/119570-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "595": {"q_num": 595, "question": "회사의 애플리케이션은 Auto Scaling 그룹의 Amazon EC2 인스턴스에서 실행됩니다. \n회사는 해당 애플리케이션이 일주일 중 임의의 요일에 갑작스러운 트래픽 증가를 \n경험한다는 사실을 발견했습니다. 회사는 갑작스러운 트래픽 증가 중에도 애플리케이션 \n성능을 유지하려고 합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. Auto Scaling 그룹의 크기를 변경하려면 수동 스케일링을 사용하십시오. \nB. 예측 조정을 사용하여 Auto Scaling 그룹의 크기를 변경합니다. \nC. 동적 스케일링을 사용하여 Auto Scaling 그룹의 크기를 변경합니다. \nD. 일정 조정을 사용하여 Auto Scaling 그룹의 크기를 변경합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/119569-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "596": {"q_num": 596, "question": "전자상거래 \n애플리케이션은 \nAmazon \nEC2 \n인스턴스에서 \n실행되는 \nPostgreSQL \n데이터베이스를 사용합니다. 월별 판매 이벤트 중에 데이터베이스 사용량이 증가하고 \n애플리케이션에 대한 데이터베이스 연결 문제가 발생합니다. 후속 월별 판매 이벤트에 대한 \n트래픽은 예측할 수 없으며 이는 판매 예측에 영향을 미칩니다. 회사는 예측할 수 없는 \n트래픽 증가가 있을 때 성능을 유지해야 합니다. \n가장 비용 효과적인 방법으로 이 문제를 해결하는 솔루션은 무엇입니까? \nA. PostgreSQL 데이터베이스를 Amazon Aurora Serverless v2 로 마이그레이션합니다. \nB. 증가된 사용량을 수용하기 위해 EC2 인스턴스의 PostgreSQL 데이터베이스에 대한 자동 \n크기 조정을 활성화합니다. \nC. 더 큰 인스턴스 유형을 사용하여 PostgreSQL 데이터베이스를 PostgreSQL 용 Amazon \nRDS 로 마이그레이션합니다. \nD. 증가된 사용량을 수용하기 위해 PostgreSQL 데이터베이스를 Amazon Redshift\n로 \n마이그레이션합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/119590-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "597": {"q_num": 597, "question": "회사는 Amazon API Gateway 및 AWS Lambda 를 사용하여 AWS 에서 내부 서버리스 \n애플리케이션을 호스팅합니다. 회사 직원들은 매일 애플리케이션을 사용하기 시작할 때 \n대기 시간이 길어지는 문제를 보고합니다. 회사는 대기 시간을 줄이고 싶어합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. API 게이트웨이 조절 한도를 늘리십시오. \nB. 직원이 매일 애플리케이션을 사용하기 전에 Lambda 프로비저닝 동시성을 높이기 위해 \n예약된 조정을 설정합니다. \nC. Amazon CloudWatch 경보를 생성하여 매일 시작 시 경보 대상으로 Lambda 함수를 \n시작합니다. \nD. Lambda 함수 메모리를 늘립니다.", "answer_block": "Answer: B \n\nhttps://www.examtopics.com/discussions/amazon/view/119465-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "598": {"q_num": 598, "question": "연구 회사에서는 온프레미스 장치를 사용하여 분석용 데이터를 생성합니다. 회사는 AWS \n클라우드를 사용하여 데이터를 분석하려고 합니다. 장치는 .csv 파일을 생성하고 SMB 파일 \n공유에 데이터 쓰기를 지원합니다. 회사 분석가는 SQL 명령을 사용하여 데이터를 쿼리할 \n수 있어야 합니다. 분석가는 하루 종일 주기적으로 쿼리를 실행합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 단계 조합은 무엇입니까? (3 개 선택) \nA. Amazon S3 파일 게이트웨이 모드로 온프레미스에 AWS Storage Gateway 를 배포합니다. \nB. Amazon FSx File Gateway 를 통해 온프레미스에 AWS Storage Gateway 를 배포합니다. \nC. Amazon S3 에 있는 데이터를 기반으로 테이블을 생성하도록 AWS Glue 크롤러를 \n설정합니다. \nD. EMRFS(EMR 파일 시스템)를 사용하여 Amazon EMR 클러스터를 설정하여 Amazon S3 에 \n있는 데이터를 쿼리합니다. 분석가에 대한 액세스를 제공합니다. \nE. Amazon S3 에 있는 데이터를 쿼리하도록 Amazon Redshift 클러스터를 설정합니다. \n분석가에 대한 액세스를 제공합니다. \nF. Amazon S3 에 있는 데이터를 쿼리하도록 Amazon Athena 를 설정합니다. 분석가에 대한 \n액세스를 제공합니다.", "answer_block": "Answer: A, C, F \nhttps://www.examtopics.com/discussions/amazon/view/119563-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n비용 효율적인 방식으로 사용 사례의 요구 사항을 충족하려면 다음 단계를 수행하는 것이 \n좋습니다. \nAmazon S3 파일 게이트웨이 모드로 온프레미스에 AWS Storage Gateway 를 배포합니다. \n이를 통해 회사는 장치에서 생성된 .csv 파일을 SMB 파일 공유에 쓸 수 있으며, 이 파일은 \nAmazon S3 버킷에 객체로 저장됩니다. AWS Storage Gateway 는 온프레미스 환경을 AWS \n스토리지와 통합하는 하이브리드 클라우드 스토리지 서비스입니다. Amazon S3 파일 \n게이트웨이 모드는 Amazon S3 에 연결하고 거의 무제한의 클라우드 스토리지에 액세스할 \n수 있는 원활한 방법을 제공합니다. \nAmazon S3\n에 있는 데이터를 기반으로 테이블을 생성하도록 AWS Glue 크롤러를 \n설정합니다. 이를 통해 회사는 표준 SQL 을 사용하여 Amazon S3 버킷에 저장된 데이터를 \n쿼리할 수 있습니다. AWS Glue 는 데이터 준비 및 분석을 단순화하는 서버리스 데이터 통합 \n\n서비스입니다. AWS Glue 크롤러는 다양한 소스의 데이터를 자동으로 검색 및 분류하고 \nAWS Glue 데이터 카탈로그에 메타데이터 테이블을 생성할 수 있습니다. 데이터 카탈로그는 \n데이터 소스에 대한 정보와 이에 액세스하는 방법을 저장하는 중앙 저장소입니다. \nAmazon S3 에 있는 데이터를 쿼리하도록 Amazon Athena 를 설정합니다. 이는 회사 \n분석가에게 표준 SQL 을 사용하여 Amazon S3 에서 직접 데이터를 분석할 수 있는 서버리스 \n및 대화형 쿼리 서비스를 제공합니다. Amazon Athena 는 AWS Glue 데이터 카탈로그와 \n통합되어 있으므로 사용자는 크롤러가 정의한 데이터 원본 테이블에서 Athena 를 쉽게 \n가리킬 수 있습니다. \nAmazon Athena 는 실행된 쿼리에 대해서만 비용을 청구하고 쿼리당 지불 가격 모델을 \n제공하므로 정기적인 쿼리에 비용 효율적인 옵션입니다. \n다른 옵션은 비용 효율적이지 않거나 사용 사례에 적합하지 않기 때문에 올바르지 않습니다. \nAmazon FSx 파일 게이트웨이 모드에서 온프레미스로 AWS Storage Gateway 를 배포하는 \n것은 올바르지 않습니다. 이 모드는 사용 사례에 필요하지 않은 AWS 의 완전 관리형 \nWindows 파일 공유에 대한 지연 시간이 짧은 액세스를 제공하기 때문입니다. Amazon \nS3 에 있는 데이터를 쿼리하기 위해 EMR 파일 시스템(EMRFS)을 사용하여 Amazon EMR \n클러스터를 설정하는 것은 올바르지 않습니다. 이 옵션에는 EC2 인스턴스 클러스터 설정 \n및 관리가 포함되어 솔루션에 복잡성과 비용이 추가되기 때문입니다. Amazon S3 에 있는 \n데이터를 쿼리하도록 Amazon Redshift 클러스터를 설정하는 것은 올바르지 않습니다. 이 \n옵션에는 솔루션에 오버헤드와 비용을 추가하는 노드 클러스터의 프로비저닝 및 관리도 \n포함되기 때문입니다.", "answer_choice": "A"}, "599": {"q_num": 599, "question": "한 회사에서 Amazon Elastic Container Service(Amazon ECS) 클러스터와 Amazon RDS DB \n인스턴스를 사용하여 결제 처리 애플리케이션을 구축하고 실행하려고 합니다. 회사는 규정 \n준수를 위해 온프레미스 데이터 센터에서 애플리케이션을 실행합니다. \n솔루션 아키텍트는 AWS Outposts 를 솔루션의 일부로 사용하려고 합니다. 솔루션 설계자는 \n회사의 운영 팀과 협력하여 애플리케이션을 구축하고 있습니다. \n회사 운영팀에서는 어떤 활동을 담당하나요? (3 개를 선택하세요.) \nA. Outposts 랙에 탄력적인 전원 및 네트워크 연결을 제공합니다. \nB. Outposts 에서 실행되는 가상화 하이퍼바이저, 스토리지 시스템 및 AWS 서비스를 \n관리합니다. \nC. 데이터 센터 환경의 물리적 보안 및 액세스 제어. \nD. Outposts 랙 내의 전원 공급 장치, 서버 및 네트워킹 장비를 포함한 Outposts 인프라의 \n가용성. \nE. Outposts 구성 요소의 물리적 유지 관리. \n\nF. 서버 오류 및 유지 관리 이벤트를 완화하기 위해 Amazon ECS 클러스터에 추가 용량을 \n제공합니다.", "answer_block": "Answer: A, C, E \nhttps://www.examtopics.com/discussions/amazon/view/119530-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \nA,C,D??", "answer_choice": "A"}, "600": {"q_num": 600, "question": "회사는 \nTCP \n기반 \n애플리케이션을 \n회사의 \nVPC\n로 \n마이그레이션할 \n계획입니다. \n애플리케이션은 회사 데이터 센터의 하드웨어 어플라이언스를 통해 비표준 TCP 포트에서 \n공개적으로 액세스할 수 있습니다. 이 퍼블릭 엔드포인트는 짧은 대기 시간으로 초당 최대 \n300 만 개의 요청을 처리할 수 있습니다. 회사는 AWS 의 새로운 퍼블릭 엔드포인트에 대해 \n동일한 수준의 성능을 요구합니다. \n이 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까? \nA. NLB(Network Load Balancer)를 배포합니다. 애플리케이션에 필요한 TCP 포트를 통해 \n공개적으로 액세스할 수 있도록 NLB 를 구성합니다. \nB. ALB(Application Load Balancer)를 배포합니다. 애플리케이션에 필요한 TCP 포트를 통해 \n공개적으로 액세스할 수 있도록 ALB 를 구성하십시오. \nC. 애플리케이션에 필요한 TCP 포트를 수신하는 Amazon CloudFront 배포를 배포합니다. \nApplication Load Balancer 를 원본으로 사용합니다. \nD. 애플리케이션에 필요한 TCP 포트로 구성된 Amazon API Gateway API 를 배포합니다. \n요청을 처리하기 위해 프로비저닝된 동시성을 사용하여 AWS Lambda 함수를 구성합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/121205-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "601": {"q_num": 601, "question": "회사는 PostgreSQL DB 인스턴스용 Amazon RDS 에서 중요 데이터베이스를 실행합니다. 이 \n회사는 가동 중지 시간과 데이터 손실을 최소화하면서 Amazon Aurora PostgreSQL 로 \n마이그레이션하려고 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. RDS for PostgreSQL DB 인스턴스의 DB 스냅샷을 생성하여 새로운 Aurora PostgreSQL \nDB 클러스터를 채웁니다. \nB. RDS for PostgreSQL DB 인스턴스의 Aurora 읽기 전용 복제본을 생성합니다. Aurora 읽기 \n\n복제를 새로운 Aurora PostgreSQL DB 클러스터로 승격합니다. \nC. Amazon S3 에서 데이터 가져오기를 사용하여 데이터베이스를 Aurora PostgreSQL DB \n클러스터로 마이그레이션합니다. \nD. pg_dump 유틸리티를 사용하여 PostgreSQL 용 RDS 데이터베이스를 백업합니다. 새 \nAurora PostgreSQL DB 클러스터로 백업을 복원합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/121210-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "602": {"q_num": 602, "question": "회사의 인프라는 Amazon Elastic Block Store(Amazon EBS) 스토리지를 사용하는 수백 개의 \nAmazon EC2 인스턴스로 구성됩니다. 솔루션 아키텍트는 재해 발생 후 모든 EC2 \n인스턴스를 복구할 수 있는지 확인해야 합니다. \n최소한의 노력으로 이 요구 사항을 충족하려면 솔루션 설계자가 무엇을 해야 합니까? \nA. 각 EC2 인스턴스에 연결된 EBS 스토리지의 스냅샷을 찍습니다. EBS 스토리지에서 새 \nEC2 인스턴스를 시작하려면 AWS CloudFormation 템플릿을 생성하세요. \nB. 각 EC2 인스턴스에 연결된 EBS 스토리지의 스냅샷을 찍습니다. AWS Elastic \nBeanstalk 를 사용하여 EC2 템플릿 기반으로 환경을 설정하고 EBS 스토리지를 연결하세요. \nC. AWS Backup을 사용하여 전체 EC2 인스턴스 그룹에 대한 백업 계획을 설정합니다. AWS \nBackup API 또는 AWS CLI 를 사용하면 여러 EC2 인스턴스의 복원 프로세스 속도를 높일 \n수 있습니다. \nD. \n각 \nEC2 \n인스턴스에 \n연결된 \nEBS \n스토리지의 \n스냅샷을 \n찍고 \nAmazon \n머신 \n이미지(AMI)를 복사하는 AWS Lambda 함수를 생성합니다. 복사된 AMI 로 복원을 수행하고 \nEBS 스토리지를 연결하는 또 다른 Lambda 함수를 생성합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/121212-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "603": {"q_num": 603, "question": "최근 한 회사가 AWS 클라우드로 마이그레이션했습니다. 회사는 반구조화된 데이터 세트의 \n대규모 병렬 주문형 처리를 위한 서버리스 솔루션을 원합니다. 데이터는 Amazon S3 에 \n저장되는 로그, 미디어 파일, 판매 거래 및 IoT 센서 데이터로 구성됩니다. 회사는 데이터 \n세트에 있는 수천 개의 항목을 병렬로 처리하는 솔루션을 원합니다. \n가장 효율적인 운영 효율성으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \n\nA. 인라인 모드에서 AWS Step Functions 맵 상태를 사용하여 데이터를 병렬로 처리합니다. \nB. 분산 모드에서 AWS Step Functions 맵 상태를 사용하여 데이터를 병렬로 처리합니다. \nC. AWS Glue 를 사용하여 데이터를 병렬로 처리합니다. \nD. 여러 AWS Lambda 함수를 사용하여 데이터를 병렬로 처리합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/121211-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "604": {"q_num": 604, "question": "회사는 6주 안에 10PB 의 데이터를 Amazon S3 로 마이그레이션할 예정입니다. 현재 데이터 \n센터에는 인터넷에 대한 500Mbps 업링크가 있습니다. 다른 온프레미스 애플리케이션은 \n업링크를 공유합니다. 회사는 이 일회성 마이그레이션 작업에 인터넷 대역폭의 80%를 \n사용할 수 있습니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 데이터를 Amazon S3\n로 마이그레이션하고 자동으로 데이터를 확인하도록 AWS \nDataSync 를 구성합니다. \nB. rsync 를 사용하여 데이터를 Amazon S3 로 직접 전송합니다. \nC. AWS CLI 와 여러 복사 프로세스를 사용하여 데이터를 Amazon S3 에 직접 보냅니다. \nD. 여러 AWS Snowball 디바이스를 주문합니다. 데이터를 장치에 복사합니다. 디바이스를 \nAWS 로 보내 데이터를 Amazon S3 에 복사합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/121186-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "D"}, "605": {"q_num": 605, "question": "회사에는 온프레미스 ISCSI(Internet Small Computer Systems Interface) 네트워크 스토리지 \n서버가 여러 대 있습니다. 회사는 AWS 클라우드로 이동하여 이러한 서버의 수를 줄이고 \n싶어합니다. 솔루션 설계자는 자주 사용되는 데이터에 대한 짧은 대기 시간 액세스를 \n제공하고 최소한의 인프라 변경으로 온프레미스 서버에 대한 종속성을 줄여야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. Amazon S3 파일 게이트웨이를 배포합니다. \nB. Amazon S3 에 대한 백업과 함께 Amazon Elastic Block Store(Amazon EBS) 스토리지를 \n배포합니다. \nC. 저장된 볼륨으로 구성된 AWS Storage Gateway 볼륨 게이트웨이를 배포합니다. \n\nD. 캐시된 볼륨으로 구성된 AWS Storage Gateway 볼륨 게이트웨이를 배포합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/121170-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "D"}, "606": {"q_num": 606, "question": "솔루션 아키텍트는 비즈니스 사용자가 Amazon S3\n에 객체를 업로드할 수 있는 \n애플리케이션을 설계하고 있습니다. 솔루션은 객체 내구성을 극대화해야 합니다. 또한 \n객체는 언제든지 언제든지 쉽게 사용할 수 있어야 합니다. 사용자는 객체가 업로드된 후 \n처음 30\n일 이내에 객체에 자주 액세스하지만 30\n일보다 오래된 객체에는 사용자가 \n액세스할 가능성이 훨씬 적습니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. S3 수명 주기 규칙을 사용하여 모든 객체를 S3 Standard 에 저장하여 30 일 후에 객체를 \nS3 Glacier 로 전환합니다. \nB. 30 일 후에 객체를 S3 Standard-Infrequent Access(S3 Standard-IA)로 전환하려면 S3 \n수명 주기 규칙을 사용하여 모든 객체를 S3 Standard 에 저장합니다. \nC. 30 일 후에 객체를 S3 One Zone-Infrequent Access(S3 One Zone-IA)로 전환하는 S3 \n수명 주기 규칙을 사용하여 모든 객체를 S3 Standard 에 저장합니다. \nD. S3 수명 주기 규칙을 사용하여 모든 객체를 S3 Intelligent-Tiering 에 저장하여 30 일 \n후에 객체를 S3 Standard-Infrequent Access(S3 Standard-IA)로 전환합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/121214-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "607": {"q_num": 607, "question": "한 회사가 온프레미스 데이터 센터에서 AWS 클라우드로 2\n계층 애플리케이션을 \n마이그레이션했습니다. 데이터 계층은 12TB\n의 범용 SSD Amazon Elastic Block \nStore(Amazon EBS) 스토리지를 갖춘 Oracle 용 Amazon RDS 의 다중 AZ 배포입니다. 이 \n애플리케이션은 평균 문서 크기가 6MB 인 이진 대형 개체(BLOB)로 데이터베이스의 문서를 \n처리하고 저장하도록 설계되었습니다. \n시간이 지남에 따라 데이터베이스 크기가 증가하여 성능이 저하되고 스토리지 비용이 \n증가했습니다. 회사는 데이터베이스 성능을 개선해야 하며 가용성과 탄력성이 뛰어난 \n솔루션이 필요합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \n\nA. RDS DB 인스턴스 크기를 줄입니다. 스토리지 용량을 24TiB 로 늘립니다. 스토리지 \n유형을 마그네틱으로 변경합니다. \nB. RDS DB 인스턴스 크기를 늘리십시오. 스토리지 용량을 24Ti 로 늘립니다. 스토리지 \n유형을 프로비저닝된 IOPS 로 변경합니다. \nC. Amazon S3 버킷을 생성합니다. S3 버킷에 문서를 저장하도록 애플리케이션을 \n업데이트합니다. 기존 데이터베이스에 개체 메타데이터를 저장합니다. \nD. Amazon DynamoDB 테이블을 생성합니다. DynamoDB 를 사용하도록 애플리케이션을 \n업데이트합니다. AWS Database Migration Service(AWS DMS)를 사용하여 Oracle \n데이터베이스에서 DynamoDB 로 데이터를 마이그레이션합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/121215-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "608": {"q_num": 608, "question": "회사에는 전 세계 20,000\n개 이상의 소매점 위치에 배포된 클라이언트에게 서비스를 \n제공하는 애플리케이션이 있습니다. 애플리케이션은 포트 443에서 HTTPS 를 통해 노출되는 \n백엔드 웹 서비스로 구성됩니다. 애플리케이션은 ALB(Application Load Balancer) 뒤의 \nAmazon EC2 인스턴스에서 호스팅됩니다. 소매점은 공용 인터넷을 통해 웹 애플리케이션과 \n통신합니다. 회사는 각 소매점에서 현지 ISP\n가 할당한 IP 주소를 등록할 수 있도록 \n허용합니다. \n회사 보안팀에서는 소매점에서 등록한 IP 주소로만 접속을 제한하여 애플리케이션 \n엔드포인트의 보안을 강화할 것을 권장합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. AWS WAF 웹 ACL 을 ALB 와 연결합니다. ALB 의 IP 규칙 세트를 사용하여 트래픽을 \n필터링합니다. 등록된 IP 주소를 포함하도록 규칙의 IP 주소를 업데이트합니다. \nB. AWS Firewall Manager 를 배포하여 ALConfigure 방화벽 규칙을 관리하여 AL 로의 \n트래픽을 제한합니다. 등록된 IP 주소를 포함하도록 방화벽 규칙을 수정합니다. \nC. Amazon DynamoDB 테이블에 IP 주소를 저장합니다. ALB 에서 AWS Lambda 인증 \n기능을 구성하여 수신 요청이 등록된 IP 주소에서 오는지 확인합니다. \nD. ALB 의 공용 인터페이스가 포함된 서브넷에서 네트워크 ACL 을 구성합니다. 등록된 각 \nIP 주소에 대한 항목으로 네트워크 ACL 의 수신 규칙을 업데이트합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/121216-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "609": {"q_num": 609, "question": "회사에서 AWS Lake Formation 을 사용하여 AWS 에 데이터 분석 플랫폼을 구축하고 \n있습니다. 플랫폼은 Amazon S3 및 Amazon RDS 와 같은 다양한 소스에서 데이터를 \n수집합니다. 회사는 중요한 정보가 포함된 데이터 부분에 대한 액세스를 방지하기 위한 \n보안 솔루션이 필요합니다. \nA. Lake Formation 테이블에 액세스할 수 있는 권한이 포함된 IAM 역할을 생성합니다. \nB. 데이터 필터를 생성하여 행 수준 보안 및 셀 수준 보안을 구현합니다. \nC. Lake Formation 이 다시 데이터를 수집하기 전에 민감한 정보를 제거하는 AWS Lambda \n함수를 생성합니다. \nD. Lake Formation 테이블에서 민감한 정보를 주기적으로 쿼리하고 제거하는 AWS Lambda \n함수를 생성합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/121162-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n이 옵션은 Lake Formation 과 통합된 엔진 및 쿼리 결과의 특정 데이터에 대한 액세스를 \n제한하는 사양인 데이터 필터를 사용하기 때문에 가장 효율적입니다. 데이터 필터는 중요한 \n정보가 포함된 데이터 부분에 대한 액세스를 방지하는 기술인 행 수준 보안 및 셀 수준 \n보안을 구현하는 데 사용할 수 있습니다. Data Catalog 테이블에 대한 Lake Formation \n권한을 부여할 때 데이터 필터를 적용할 수 있으며 PartiQL 표현식을 사용하여 조건에 따라 \n데이터를 필터링할 수 있습니다. 이 솔루션은 중요한 정보가 포함된 데이터 부분에 대한 \n액세스를 방지하는 보안 솔루션을 제공해야 한다는 요구 사항을 충족합니다. \n \n옵션 A 는 IAM 정책을 사용하여 Lake Formation 의 데이터에 대한 액세스 권한을 부여하는 \n방법인 Lake Formation 테이블에 대한 액세스 권한이 포함된 IAM 역할을 사용하기 때문에 \n효율성이 떨어집니다. 그러나 이것은 중요한 정보가 포함된 데이터 부분에 대한 액세스를 \n방지하는 방법을 제공하지 않습니다. \n \n옵션 C 는 Lake Formation 이 데이터를 수집하기 전에 민감한 정보를 제거하는 AWS \nLambda 함수를 사용하기 때문에 효율성이 떨어집니다. 이는 서버리스 함수를 사용하여 \n데이터 정리 또는 변환을 수행하는 방법입니다. 그러나 여기에는 애플리케이션 코드 및 \n논리에 대한 상당한 변경이 포함될 수 있으며 데이터 손실 또는 불일치가 발생할 수도 \n있습니다. \n \n\n옵션 D 는 서버리스 함수를 사용하여 데이터 정리 또는 변환을 수행하는 방법인 Lake \nFormation 테이블에서 민감한 정보를 주기적으로 쿼리하고 제거하는 AWS Lambda 함수를 \n사용하기 때문에 효율성이 떨어집니다. 그러나 여기에는 애플리케이션 코드 및 논리에 대한 \n상당한 변경이 포함될 수 있으며 데이터 손실 또는 불일치가 발생할 수도 있습니다.", "answer_choice": "B"}, "610": {"q_num": 610, "question": "회사는 VPC 에서 실행되는 Amazon EC2 인스턴스를 배포합니다. EC2 인스턴스는 나중에 \n데이터를 처리할 수 있도록 소스 데이터를 Amazon S3 버킷에 로드합니다. 규정 준수법에 \n따라 데이터는 공용 인터넷을 통해 전송되어서는 안 됩니다. 회사의 온프레미스 데이터 \n센터에 있는 서버는 EC2 인스턴스에서 실행되는 애플리케이션의 출력을 사용합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. Amazon EC2 용 인터페이스 VPC 엔드포인트를 배포합니다. 회사와 VPC 간에 AWS \nSite-to-Site VPN 연결을 생성합니다. \nB. Amazon S3 용 게이트웨이 VPC 엔드포인트를 배포합니다. 온프레미스 네트워크와 VPC \n간에 AWS Direct Connect 연결을 설정합니다. \nC. VPC 에서 S3 버킷으로의 AWS Transit Gateway 연결을 설정합니다. 회사와 VPC 간에 \nAWS Site-to-Site VPN 연결을 생성합니다. \nD. NAT 게이트웨이에 대한 경로가 있는 프록시 EC2 인스턴스를 설정합니다. S3 데이터를 \n가져오고 애플리케이션 인스턴스에 공급하도록 프록시 EC2 인스턴스를 구성합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/121217-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "611": {"q_num": 611, "question": "회사에는 제3 자 공급업체로부터 거의 실시간으로 데이터를 수신할 수 있는 REST 기반 \n인터페이스가 있는 애플리케이션이 있습니다. 일단 수신되면 애플리케이션은 추가 분석을 \n위해 데이터를 처리하고 저장합니다. 애플리케이션이 Amazon EC2 인스턴스에서 실행 \n중입니다. \n타사 공급업체에서 애플리케이션에 데이터를 보낼 때 503 서비스를 사용할 수 없음 오류가 \n많이 발생했습니다. 데이터 볼륨이 급증하면 컴퓨팅 용량이 최대 한도에 도달하고 \n애플리케이션이 모든 요청을 처리할 수 없게 됩니다. \n보다 확장 가능한 솔루션을 제공하기 위해 솔루션 설계자는 어떤 디자인을 권장해야 \n합니까? \nA. Amazon Kinesis Data Streams 를 사용하여 데이터를 수집하십시오. AWS Lambda 함수를 \n\n사용하여 데이터를 처리합니다. \nB. 기존 애플리케이션 위에 Amazon API Gateway 를 사용하십시오. 타사 공급업체에 대한 \n할당량 제한이 있는 사용량 계획을 만듭니다. \nC. Amazon Simple 알림 서비스(Amazon SNS)를 사용하여 데이터를 수집합니다. Application \nLoad Balancer 뒤의 Auto Scaling 그룹에 EC2 인스턴스를 배치합니다. \nD. 애플리케이션을 컨테이너로 다시 패키징합니다. Auto Scaling 그룹과 함께 EC2 시작 \n유형을 \n사용하는 \nAmazon \nElastic \nContainer \nService(Amazon \nECS)를 \n사용하여 \n애플리케이션을 배포합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/121218-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "612": {"q_num": 612, "question": "회사에는 프라이빗 서브넷의 Amazon EC2 인스턴스에서 실행되는 애플리케이션이 있습니다. \n애플리케이션은 Amazon S3 버킷의 민감한 정보를 처리해야 합니다. 애플리케이션은 S3 \n버킷에 연결하기 위해 인터넷을 사용해서는 안 됩니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 인터넷 게이트웨이를 구성하십시오. 인터넷 게이트웨이에서의 액세스를 허용하도록 S3 \n버킷 \n정책을 \n업데이트합니다. \n새 \n인터넷 \n게이트웨이를 \n사용하도록 \n애플리케이션을 \n업데이트합니다. \nB. VPN 연결을 구성합니다. VPN 연결에서 액세스를 허용하도록 S3 버킷 정책을 \n업데이트합니다. 새 VPN 연결을 사용하도록 애플리케이션을 업데이트하세요. \nC. NAT 게이트웨이를 구성합니다. NAT 게이트웨이에서의 액세스를 허용하도록 S3 버킷 \n정책을 업데이트합니다. 새 NAT 게이트웨이를 사용하도록 애플리케이션을 업데이트합니다. \nD. VPC 엔드포인트를 구성합니다. VPC 엔드포인트에서의 액세스를 허용하도록 S3 버킷 \n정책을 업데이트합니다. 새 VPC 엔드포인트를 사용하도록 애플리케이션을 업데이트합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/121159-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "D"}, "613": {"q_num": 613, "question": "회사는 \nAmazon \nElastic \nKubernetes \nService(Amazon \nEKS)를 \n사용하여 \n컨테이너 \n애플리케이션을 실행합니다. EKS 클러스터는 Kubernetes 비밀 객체에 민감한 정보를 \n저장합니다. 회사는 정보가 암호화되었는지 확인하기를 원합니다. 어떤 솔루션이 이러한 \n\n요구 사항을 충족합니까? \n최소한의 운영 오버헤드로 요구 사항을 충족합니까? \nA. 컨테이너 애플리케이션을 사용하여 AWS Key Management Service(AWS KMS)를 \n사용하여 정보를 암호화합니다. \nB. AWS Key Management Service(AWS KMS)를 사용하여 EKS 클러스터에서 비밀 암호화를 \n활성화합니다. \nC. AWS KMS(AWS Key Management Service)를 사용하여 정보를 암호화하는 AWS Lambda \ntuncuon 을 구현합니다. \nD. AWS Systems Manager Parameter Store 를 사용하여 AWS Key Management Service(AWS \nKMS)를 사용하여 정보를 암호화합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/121158-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n이를 통해 회사는 최소한의 운영 오버헤드로 EKS 클러스터의 Kubernetes 비밀 개체를 \n암호화할 수 있습니다. EKS 클러스터에서 비밀 암호화를 활성화함으로써 회사는 AWS Key \nManagement Service(AWS KMS)를 사용하여 저장된 비밀을 암호화하고 해독하기 위한 \n암호화 키를 생성하고 관리할 수 있습니다. 이는 EKS 클러스터의 중요한 정보를 보호하는 \n간단하고 안전한 방법입니다.", "answer_choice": "B"}, "614": {"q_num": 614, "question": "한 회사는 다음 구성 요소로 구성된 새로운 다중 계층 웹 애플리케이션을 설계하고 \n있습니다. \n \n• Auto Scaling 그룹의 일부로 Amazon EC2 인스턴스에서 실행되는 웹 및 애플리케이션 \n서버 \n• 데이터 저장을 위한 Amazon RDS DB 인스턴스 \n \n솔루션 설계자는 웹 서버만 액세스할 수 있도록 애플리케이션 서버에 대한 액세스를 \n제한해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 애플리케이션 서버 앞에 AWS PrivateLink 를 배포합니다. 웹 서버만 애플리케이션 서버에 \n액세스할 수 있도록 네트워크 ACL 을 구성합니다. \nB. 애플리케이션 서버 앞에 VPC 엔드포인트를 배포합니다. 웹 서버만 애플리케이션 서버에 \n\n액세스할 수 있도록 보안 그룹을 구성합니다. \nC. 애플리케이션 서버의 Auto Scaling 그룹이 포함된 대상 그룹으로 Network Load \nBalancer 를 배포합니다. 웹 서버만 애플리케이션 서버에 액세스할 수 있도록 네트워크 \nACL 을 구성합니다. \nD. 애플리케이션 서버의 Auto Scaling 그룹이 포함된 대상 그룹과 함께 Application Load \nBalancer 를 배포합니다. 웹 서버만 애플리케이션 서버에 액세스할 수 있도록 보안 그룹을 \n구성합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/121157-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "D"}, "615": {"q_num": 615, "question": "한 회사가 Amazon Elastic Kubernetes Service(Amazon EKS)에서 고객을 대상으로 하는 \n중요한 애플리케이션을 실행하고 있습니다. 애플리케이션에는 마이크로서비스 아키텍처가 \n있습니다. 회사는 중앙 위치에서 애플리케이션의 측정항목과 로그를 수집, 집계, 요약하는 \n솔루션을 구현해야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 기존 EKS 클러스터에서 Amazon CloudWatch 에이전트를 실행합니다. CloudWatch \n콘솔에서 지표와 로그를 봅니다. \nB. 기존 EKS 클러스터에서 AWS App Mesh 를 실행합니다. App Mesh 콘솔에서 지표와 \n로그를 확인하세요. \nC. 데이터 이벤트를 캡처하도록 AWS CloudTrail 을 구성합니다. Amazon OpenSearch \nService 를 사용하여 CloudTrail 을 쿼리합니다. \nD. 기존 EKS 클러스터에 Amazon CloudWatch Container Insights\n를 구성합니다. \nCloudWatch 콘솔에서 지표와 로그를 봅니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/121154-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "D"}, "616": {"q_num": 616, "question": "한 회사가 AWS 에 최신 제품을 배포했습니다. 제품은 Network Load Balancer 뒤의 Auto \nScaling 그룹에서 실행됩니다. 회사는 제품의 객체를 Amazon S3 버킷에 저장합니다. \n이 회사는 최근 자사 시스템에 대한 악의적인 공격을 경험했습니다. 회사에는 AWS 계정의 \n악의적인 활동, 워크로드 및 S3 버킷에 대한 액세스 패턴을 지속적으로 모니터링하는 \n\n솔루션이 필요합니다. 또한 솔루션은 의심스러운 활동을 보고하고 대시보드에 정보를 \n표시해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 결과를 모니터링하고 AWS Config 에 보고하도록 Amazon Macie 를 구성합니다. \nB. 결과를 모니터링하고 AWS CloudTrail 에 보고하도록 Amazon Inspector 를 구성합니다. \nC. 결과를 모니터링하고 AWS Security Hub\n에 보고하도록 Amazon GuardDuty\n를 \n구성합니다. \nD. 결과를 모니터링하고 Amazon EventBridge 에 보고하도록 AWS Config 를 구성합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/121177-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nAmazon GuardDuty 는 AWS 계정과 워크로드 전체에서 악의적인 활동과 무단 행동을 \n지속적으로 모니터링하는 위협 탐지 서비스입니다. GuardDuty 는 AWS CloudTrail 이벤트 \n로그, Amazon VPC 흐름 로그 및 DNS 로그와 같은 데이터 소스를 분석하여 손상된 \n인스턴스, 정찰, 포트 스캐닝 및 데이터 유출과 같은 잠재적인 위협을 식별합니다. \nGuardDuty 는 AWS 계정 및 워크로드의 보안 상태에 대한 포괄적인 보기를 제공하는 \n서비스인 AWS Security Hub 에 조사 결과를 보고할 수 있습니다. Security Hub 는 여러 AWS \n서비스 및 파트너 솔루션의 보안 경고를 집계, 구성 및 우선순위를 지정하여 대시보드에 \n표시합니다. 이 솔루션은 AWS 계정의 악의적인 활동, 워크로드 및 S3 버킷에 대한 액세스 \n패턴을 지속적으로 모니터링, 보고 및 시각화할 수 있으므로 요구 사항을 충족합니다.", "answer_choice": "C"}, "617": {"q_num": 617, "question": "회사에서 온프레미스 데이터 센터를 AWS 로 마이그레이션하려고 합니다. 데이터 센터는 \nNFS 기반 파일 시스템에 데이터를 저장하는 스토리지 서버를 호스팅합니다. 스토리지 \n서버는 200GB 의 데이터를 보유합니다. 회사는 기존 서비스를 중단하지 않고 데이터를 \n마이그레이션해야 합니다. AWS\n의 여러 리소스는 NFS 프로토콜을 사용하여 데이터에 \n액세스할 수 있어야 합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 단계 조합은 무엇입니까? (2 개 선택) \nA. Lustre 파일 시스템용 Amazon FSx 를 생성합니다. \nB. Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성합니다. \nC. 데이터를 수신할 Amazon S3 버킷을 생성합니다. \nD. 운영 체제 복사 명령을 수동으로 사용하여 데이터를 AWS 대상으로 푸시합니다. \nE. 온프레미스 데이터 센터에 AWS DataSync 에이전트를 설치합니다. 온프레미스 위치와 \n\nAWS 간에 DataSync 작업을 사용합니다.", "answer_block": "Answer: B, E \nhttps://www.examtopics.com/discussions/amazon/view/121176-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n102 문제와 중복", "answer_choice": "B"}, "618": {"q_num": 618, "question": "한 회사에서는 us-east-1 리전에 볼륨으로 마운트된 SMB 파일 공유가 있는 Amazon EC2 \n인스턴스에 Amazon FSx for Windows File Server 를 사용하려고 합니다. 회사는 계획된 \n시스템 유지 관리 또는 계획되지 않은 서비스 중단에 대해 5 분의 복구 지점 목표(RPO)를 \n가지고 있습니다. 회사는 파일 시스템을 us-west-2 리전에 복제해야 합니다. 복제된 \n데이터는 5 년 동안 어떤 사용자도 삭제해서는 안 됩니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 단일 AZ 2 배포 유형을 사용하는 us-east-1 에 FSx for Windows File Server 파일 \n시스템을 생성합니다. AWS Backup 을 사용하여 백업을 us-west-2 에 복사하는 백업 규칙이 \n포함된 일일 백업 계획을 생성합니다. us-west-2 의 대상 볼트에 대해 규정 준수 모드로 \nAWS Backup Vault Lock 을 구성합니다. 최소 기간을 5 년으로 구성합니다. \nB. 다중 AZ 배포 유형이 있는 us-east-1 에 FSx for Windows File Server 파일 시스템을 \n생성합니다. AWS Backup 을 사용하여 백업을 us-west-2 에 복사하는 백업 규칙이 포함된 \n일일 백업 계획을 생성합니다. us-west-2 의 대상 볼트에 대해 거버넌스 모드에서 AWS \nBackup Vault Lock 을 구성합니다. 최소 기간을 5 년으로 구성합니다. \nC. 다중 AZ 배포 유형이 있는 us-east-1 에 FSx for Windows File Server 파일 시스템을 \n생성합니다. AWS Backup 을 사용하여 백업을 us-west-2 에 복사하는 백업 규칙이 포함된 \n일일 백업 계획을 생성합니다. us-west-2 의 대상 볼트에 대해 규정 준수 모드로 AWS \nBackup Vault Lock 을 구성합니다. 최소 기간을 5 년으로 구성합니다. \nD. 단일 AZ 2 배포 유형이 있는 us-east-1 에 FSx for Windows File Server 파일 시스템을 \n생성합니다. AWS Backup 을 사용하여 백업을 us-west-2 에 복사하는 백업 규칙이 포함된 \n일일 백업 계획을 생성합니다. us-west-2 의 대상 볼트에 대해 거버넌스 모드에서 AWS \nBackup Vault Lock 을 구성합니다. 최소 기간을 5 년으로 구성합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/121219-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "619": {"q_num": 619, "question": "솔루션 아키텍트는 표준 보안 제어를 유지하면서 AWS Organizations 를 통해 개발자에게 \n개별 AWS 계정을 제공하려는 회사를 위한 보안 솔루션을 설계하고 있습니다. 개별 \n개발자는 자신의 계정에 대해 AWS 계정 루트 사용자 수준 액세스 권한을 가지게 되므로 \n솔루션 설계자는 새 개발자 계정에 적용되는 필수 AWS CloudTrail 구성이 수정되지 \n않았는지 확인하려고 합니다. \n이러한 요구사항을 충족하는 작업은 무엇인가요? \nA. CloudTrail 변경을 금지하는 IAM 정책을 생성합니다. 루트 사용자에게 연결합니다. \nB. 조직 추적 옵션이 활성화된 개발자 계정 내에서 CloudTrail 에 새 추적을 생성합니다. \nC. CloudTrail 변경을 금지하는 서비스 제어 정책(SCP)을 생성하고 이를 개발자 계정에 \n연결합니다. \nD. 마스터 계정의 Amazon 리소스 이름(ARN)에서만 변경을 허용하는 정책 조건을 \n사용하여 CloudTrail 에 대한 서비스 연결 역할을 생성합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/121220-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "620": {"q_num": 620, "question": "한 회사가 AWS 클라우드에 비즈니스에 중요한 애플리케이션을 배포할 계획입니다. \n애플리케이션에는 일관되고 지연 시간이 짧은 성능을 갖춘 내구성 있는 스토리지가 \n필요합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 유형의 스토리지를 권장해야 \n합니까? \nA. 인스턴스 스토어 볼륨 \nB. Memcached 클러스터용 Amazon ElastiCache \nC. 프로비저닝된 IOPS SSD Amazon Elastic Block Store(Amazon EBS) 볼륨 \nD. 처리량 최적화 HDD Amazon Elastic Block Store(Amazon EBS) 볼륨", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/121221-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "621": {"q_num": 621, "question": "온라인 사진 공유 회사는 us-west-1 지역에 있는 Amazon S3 버킷에 사진을 저장합니다. \n회사는 us-east-1 지역에 모든 새 사진의 사본을 저장해야 합니다. \n최소한의 운영 노력으로 이 요구 사항을 충족할 수 있는 솔루션은 무엇입니까? \n\nA. us-east-1 에 두 번째 S3 버킷을 생성합니다. S3 교차 리전 복제를 사용하여 기존 S3 \n버킷의 사진을 두 번째 S3 버킷으로 복사합니다. \nB. 기존 S3 버킷의 CORS(교차 원본 리소스 공유) 구성을 생성합니다. CORS 규칙의 \nAllowedOrigin 요소에 us-east-1 을 지정합니다. \nC. 여러 가용 영역에 걸쳐 us-east-1 에 두 번째 S3 버킷을 생성합니다. S3 수명 주기 \n규칙을 생성하여 두 번째 S3 버킷에 사진을 저장합니다. \nD. us-east-1 에 두 번째 S3 버킷을 생성합니다. 객체 생성 및 업데이트 이벤트에 대한 S3 \n이벤트 알림을 구성하여 AWS Lambda 함수를 호출하여 기존 S3 버킷의 사진을 두 번째 \nS3 버킷으로 복사합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/121222-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "622": {"q_num": 622, "question": "한 회사에서 구독자를 위한 새로운 웹 애플리케이션을 만들고 있습니다. 애플리케이션은 \n정적 단일 페이지와 영구 데이터베이스 계층으로 구성됩니다. 아침에 4\n시간 동안 \n애플리케이션의 사용자는 수백만 명에 달하지만 나머지 시간에는 애플리케이션의 사용자가 \n수천 명에 불과합니다. 회사의 데이터 설계자는 스키마를 빠르게 발전시킬 수 있는 기능을 \n요청했습니다. \n이러한 요구 사항을 충족하고 가장 뛰어난 확장성을 제공하는 솔루션은 무엇입니까? (2 개 \n선택) \nA. Amazon DynamoDB\n를 데이터베이스 솔루션으로 배포합니다. 온디맨드 용량을 \n프로비저닝합니다. \nB. Amazon Aurora 를 데이터베이스 솔루션으로 배포합니다. 서버리스 DB 엔진 모드를 \n선택합니다. \nC. Amazon DynamoDB 를 데이터베이스 솔루션으로 배포합니다. DynamoDB Auto Scaling 이 \n활성화되어 있는지 확인합니다. \nD. 정적 콘텐츠를 Amazon S3 버킷에 배포합니다. S3 버킷을 원본으로 사용하여 Amazon \nCloudFront 배포를 프로비저닝합니다. \nE. Auto Scaling 그룹의 Amazon EC2 인스턴스 전체에 정적 콘텐츠용 웹 서버를 배포합니다. \nAmazon Elastic File System(Amazon EFS) 볼륨의 콘텐츠를 주기적으로 새로 고치도록 \n인스턴스를 구성합니다.", "answer_block": "Answer: A, D \nhttps://www.examtopics.com/discussions/amazon/view/121223-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "623": {"q_num": 623, "question": "회사는 Amazon API Gateway 를 사용하여 타사 서비스 공급자가 액세스하는 REST API 를 \n관리합니다. 회사는 SQL 주입 및 크로스 사이트 스크립팅 공격으로부터 REST API 를 \n보호해야 합니다. \n이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까? \nA. AWS Shield 를 구성합니다. \nB. AWS WAF 를 구성합니다. \nC. Amazon CloudFront 배포를 사용하여 API 게이트웨이를 설정합니다. CloudFront 에서 \nAWS Shield 를 구성합니다. \nD. Amazon CloudFront 배포로 API 게이트웨이를 설정합니다. CloudFront 에서 AWS WAF 를 \n구성합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/121172-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "624": {"q_num": 624, "question": "회사에서는 사용자에게 AWS 리소스에 대한 액세스 권한을 제공하려고 합니다. 이 회사에는 \n1,500\n명의 사용자가 있으며 회사 네트워크의 Active Directory 사용자 그룹을 통해 \n온프레미스 리소스에 대한 액세스를 관리합니다. 그러나 회사는 사용자가 리소스에 \n액세스하기 위해 다른 ID 를 유지해야 하는 것을 원하지 않습니다. 솔루션 아키텍트는 \n온프레미스 리소스에 대한 액세스를 유지하면서 AWS 리소스에 대한 사용자 액세스를 \n관리해야 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. 회사의 각 사용자에 대해 IAM 사용자를 생성합니다. 각 사용자에게 적절한 정책을 \n연결합니다. \nB. Active Directory 사용자 풀과 함께 Amazon Cognito 를 사용하십시오. 적절한 정책이 \n연결된 역할을 생성합니다. \nC. 적절한 정책이 연결된 교차 계정 역할을 정의합니다. 역할을 Active Directory 그룹에 \n매핑합니다. \nD. SAML(Security Assertion Markup Language) 2 0 기반 페더레이션을 구성합니다. 적절한 \n정책이 연결된 역할을 생성합니다. 역할을 Active Directory 그룹에 매핑합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/125336-exam-aws-certified-sol\n\nutions-architect-associate-saa-c03/", "answer_choice": "D"}, "625": {"q_num": 625, "question": "한 회사가 여러 Application Load Balancer 뒤에 웹사이트를 호스팅하고 있습니다. 회사는 \n전 세계적으로 콘텐츠에 대해 다양한 배포 권한을 가지고 있습니다. 솔루션 설계자는 배포 \n권한을 위반하지 않고 사용자에게 올바른 콘텐츠가 제공되도록 해야 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 구성을 선택해야 합니까? \nA. AWS WAF 로 Amazon CloudFront 를 구성합니다. \nB. AWS WAF 로 Application Load Balancer 구성 \nC. 지리적 위치 정책으로 Amazon Route 53 구성 \nD. 지리 근접 라우팅 정책으로 Amazon Route 53 구성", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/125337-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "626": {"q_num": 626, "question": "회사는 데이터를 온프레미스에 저장합니다. 데이터의 양은 회사가 사용할 수 있는 용량을 \n초과하여 증가하고 있습니다. 회사는 온프레미스 위치에서 Amazon S3 버킷으로 데이터를 \n마이그레이션하려고 합니다. 회사에는 전송 후 데이터 무결성을 자동으로 검증하는 \n솔루션이 필요합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. AWS Snowball Edge 디바이스 주문 S3 버킷으로의 온라인 데이터 전송을 수행하도록 \nSnowball Edge 디바이스를 구성합니다. \nB. AWS DataSync 에이전트를 온프레미스에 배포합니다. S3 버킷으로의 온라인 데이터 \n전송을 수행하도록 DataSync 에이전트를 구성합니다. \nC. 온프레미스에서 Amazon S3 파일 게이트웨이를 생성합니다. S3 버킷으로의 온라인 \n데이터 전송을 수행하도록 S3 파일 게이트웨이를 구성합니다. \nD. 온프레미스에서 Amazon S3 Transfer Acceleration 에 액셀러레이터를 구성합니다. S3 \n버킷으로의 온라인 데이터 전송을 수행하도록 액셀러레이터를 구성합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/125338-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n이를 통해 회사는 온프레미스 위치에서 Amazon S3 버킷으로 데이터를 마이그레이션하고 \n\n전송 후 데이터 무결성을 자동으로 확인할 수 있습니다. AWS DataSync 에이전트를 \n온프레미스에 배포함으로써 회사는 AWS 에서 대량의 데이터를 쉽게 이동할 수 있는 완전 \n관리형 데이터 전송 서비스를 사용할 수 있습니다. S3 버킷으로의 온라인 데이터 전송을 \n수행하도록 DataSync 에이전트를 구성함으로써 회사는 암호화, 압축, 대역폭 조절, 데이터 \n검증과 같은 DataSync 의 기능을 활용할 수 있습니다. DataSync 는 각 전송 작업 후에 \n소스와 대상 모두에서 데이터 무결성을 자동으로 확인합니다.", "answer_choice": "B"}, "627": {"q_num": 627, "question": "한 회사에서 두 대의 DNS 서버를 AWS 로 마이그레이션하려고 합니다. 이 서버는 총 약 \n200 개의 영역을 호스팅하며 매일 평균 1 백만 건의 요청을 수신합니다. 이 회사는 두 \n서버의 관리와 관련된 운영 오버헤드를 최소화하면서 가용성을 최대화하고자 합니다. \n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 추천해야 하나요? \nA. Amazon Route 53 콘솔 가져오기 영역 파일에서 200 개의 새 호스트 영역을 만듭니다. \nB. 하나의 대규모 Amazon EC2 인스턴스를 실행하여 영역 타일을 가져옵니다. 다운타임이 \n발생하면 회사에 알릴 수 있도록 Amazon CloudWatch 알람 및 알림을 구성합니다. \nC. \nAWS \n서버 \n마이그레이션 \n서비스(AWS \nSMS)를 \n사용하여 \n서버를 \nAWS\n로 \n마이그레이션합니다. 다운타임에 대해 회사에 알리도록 Amazon CloudWatch 알람 및 \n알림을 구성합니다. \nD. 두 개의 가용 영역에 걸쳐 자동 확장 그룹에서 Amazon EC2 인스턴스를 시작합니다. \n영역 파일을 가져옵니다. 자동 스케일링 그룹에 대해 원하는 용량을 1 로 설정하고 최대 \n용량을 3 으로 설정합니다. CPU 사용률에 따라 확장하도록 확장 알람을 구성합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/125541-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "D"}, "628": {"q_num": 628, "question": "한 글로벌 기업이 AWS Organizations 의 여러 AWS 계정에서 애플리케이션을 실행합니다. \n회사의 애플리케이션은 멀티파트 업로드를 사용하여 AWS 리전의 여러 Amazon S3 버킷에 \n데이터를 업로드합니다. 회사는 비용 준수 목적으로 불완전한 멀티파트 업로드에 대해 \n보고하려고 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 불완전한 멀티파트 업로드 객체 수를 보고하는 규칙으로 AWS Config 를 구성합니다. \nB. 불완전한 멀티파트 업로드 개체 수를 보고하는 SCP(서비스 제어 정책)를 만듭니다. \nC. 불완전한 멀티파트 업로드 객체 수를 보고하도록 S3 스토리지 렌즈를 구성합니다. \n\nD. S3 다중 지역 액세스 포인트를 생성하여 불완전한 멀티파트 업로드 객체 수를 \n보고합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/125459-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \nS3 Storage Lens 는 AWS Organizations 의 여러 AWS 계정에 걸친 객체 스토리지 사용 및 \n활동에 대한 조직 전체의 가시성을 제공하는 클라우드 스토리지 분석 기능입니다. S3 \n스토리지 렌즈는 수집하여 S3 콘솔의 대화형 대시보드에 표시하는 지표 중 하나로 \n불완전한 멀티파트 업로드 객체 수를 보고할 수 있습니다. S3 Storage Lens 는 추가 분석을 \n위해 CSV 또는 Parquet 형식의 지표를 S3 버킷으로 내보낼 수도 있습니다. 이 솔루션은 \n코드 개발이나 정책 변경이 필요하지 않으므로 최소한의 운영 오버헤드로 요구 사항을 \n충족합니다.", "answer_choice": "C"}, "629": {"q_num": 629, "question": "한 회사가 MySQL 용 Amazon RDS 에서 프로덕션 데이터베이스를 실행하고 있습니다. \n회사에서는 보안 규정 준수를 위해 데이터베이스 버전을 업그레이드하려고 합니다. \n데이터베이스에는 중요한 데이터가 포함되어 있으므로 회사에서는 데이터 손실 없이 기능을 \n업그레이드하고 테스트할 수 있는 빠른 솔루션을 원합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. RDS 수동 스냅샷을 생성합니다. MySQL\n용 Amazon RDS\n의 새 버전으로 \n업그레이드하세요. \nB. 기본 백업 및 복원을 사용합니다. 업그레이드된 새 버전의 MySQL 용 Amazon RDS 로 \n데이터를 복원합니다. \nC. AWS Database Migration Service(AWS DMS)를 사용하여 업그레이드된 새 버전의 \nMySQL 용 Amazon RDS 에 데이터를 복제합니다. \nD. Amazon RDS 블루/그린 배포를 사용하여 프로덕션 변경 사항을 배포하고 테스트합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/125460-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "D"}, "630": {"q_num": 630, "question": "솔루션 설계자가 매일 한 번 실행되고 완료하는 데 최대 2 시간이 걸리는 데이터 처리 \n\n작업을 만들고 있습니다. 작업이 중단되면 처음부터 다시 시작해야 합니다. \n솔루션 설계자가 가장 비용 효율적인 방식으로 이 문제를 해결하려면 어떻게 해야 하나요? \nA. 크론 작업에 의해 트리거되는 Amazon EC2 예약 인스턴스에서 로컬로 실행되는 \n스크립트를 만듭니다. \nB. Amazon EventBridge 예약 이벤트에 의해 트리거되는 AWS Lambda 함수를 생성합니다. \nC. Amazon EventBridge 예약 이벤트에 의해 트리거되는 Amazon ECS(Amazon Elastic \nContainer Service) Fargate 작업을 사용합니다. \nD. Amazon EventBridge 예약 이벤트에 의해 트리거된 Amazon EC2 에서 실행되는 Amazon \nECS(Amazon Elastic Container Service) 작업을 사용합니다.", "answer_block": "Answer: D \nhttps://www.examtopics.com/discussions/amazon/view/125541-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "D"}, "631": {"q_num": 631, "question": "소셜 미디어 회사는 사용자 프로필, 관계 및 상호 작용에 대한 데이터베이스를 AWS \n클라우드에 저장하려고 합니다. 회사에는 데이터베이스의 변경 사항을 모니터링하는 \n애플리케이션이 \n필요합니다. \n애플리케이션은 \n데이터 \n엔터티 \n간의 \n관계를 \n분석하고 \n사용자에게 권장 사항을 제공해야 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Amazon Neptune 을 사용하여 정보를 저장하십시오. Amazon Kinesis Data Streams 를 \n사용하여 데이터베이스의 변경 사항을 처리합니다. \nB. Amazon Neptune 을 사용하여 정보를 저장합니다. Neptune Streams 를 사용하여 \n데이터베이스의 변경 사항을 처리합니다. \nC. Amazon Quantum Ledger Database(Amazon QLDB)를 사용하여 정보를 저장합니다. \nAmazon Kinesis Data Streams 를 사용하여 데이터베이스의 변경 사항을 처리합니다. \nD. Amazon Quantum Ledger Database(Amazon QLDB)를 사용하여 정보를 저장합니다. \nNeptune Streams 를 사용하여 데이터베이스의 변경 사항을 처리합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/125113-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \nB??", "answer_choice": "C"}, "632": {"q_num": 632, "question": "한 회사에서 대량의 데이터를 저장할 새로운 애플리케이션을 만들고 있습니다. 데이터는 \n\n매시간 분석되며 여러 가용 영역에 배포된 여러 Amazon EC2 Linux 인스턴스에 의해 \n수정됩니다. 필요한 저장 공간의 양은 향후 6 개월 동안 계속 증가할 것입니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 스토리지 솔루션을 권장해야 \n합니까? \nA. Amazon S3 Glacier 에 데이터를 저장합니다. 애플리케이션 인스턴스에 대한 액세스를 \n허용하도록 S3 Glacier 볼트 정책을 업데이트합니다. \nB. Amazon Elastic Block Store(Amazon EBS) 볼륨에 데이터를 저장합니다. 애플리케이션 \n인스턴스에 EBS 볼륨을 탑재합니다. \nC. Amazon Elastic File System(Amazon EFS) 파일 시스템에 데이터를 저장합니다. \n애플리케이션 인스턴스에 파일 시스템을 마운트합니다. \nD. 애플리케이션 인스턴스 간에 공유되는 Amazon Elastic Block Store(Amazon EBS) \n프로비저닝된 IOPS 볼륨에 데이터를 저장합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/125114-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "633": {"q_num": 633, "question": "회사는 PostgreSQL 다중 AZ DB 인스턴스용 Amazon RDS\n에 데이터를 저장하는 \n애플리케이션을 관리합니다. 트래픽 증가로 인해 성능 문제가 발생합니다. 회사에서는 \n데이터베이스 쿼리가 성능 저하의 주요 원인이라고 판단합니다. \n솔루션 아키텍트는 애플리케이션 성능을 향상시키기 위해 무엇을 해야 합니까? \nA. 다중 AZ 대기 복제본에서 읽기 트래픽을 제공합니다. \nB. Transfer Acceleration 을 사용하도록 DB 인스턴스를 구성합니다. \nC. 원본 DB 인스턴스에서 읽기 전용 복제본을 생성합니다. 읽기 복제본에서 읽기 트래픽을 \n제공합니다. \nD. 애플리케이션과 Amazon RDS 사이에 Amazon Kinesis Data Firehose 를 사용하여 \n데이터베이스 요청의 동시성을 높입니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/125513-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "634": {"q_num": 634, "question": "한 회사에서 다양한 기계에서 매일 10GB 의 원격 분석 데이터를 수집합니다. 이 회사는 \n소스 데이터 계정의 Amazon S3 버킷에 데이터를 저장합니다. \n\n이 회사는 이 데이터를 분석에 사용하기 위해 여러 컨설팅 기관을 고용했습니다. 각 \n대행사는 분석가를 위해 데이터에 대한 읽기 액세스 권한이 필요합니다. 회사는 보안과 \n운영 효율성을 극대화하는 솔루션을 선택하여 소스 데이터 계정의 데이터를 공유해야 \n합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇인가요? \nA. 각 기관의 데이터를 복제하도록 S3 글로벌 테이블을 구성합니다. \nB. S3 버킷을 제한된 시간 동안 공개합니다. 에이전시에게만 알립니다. \nC. 대행사가 소유한 계정에 대한 S3 버킷의 교차 계정 액세스를 구성합니다. \nD. 소스 데이터 계정의 각 분석가에 대해 IAM 사용자를 설정합니다. 각 사용자에게 S3 \n버킷에 대한 액세스 권한을 부여합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/125544-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "635": {"q_num": 635, "question": "한 회사에서 기본 AWS 리전에서 CIFS 및 NFS 파일 공유를 위해 NetApp ONTAP 용 \nAmazon FSx 를 사용합니다. Amazon EC2 인스턴스에서 실행되는 애플리케이션은 파일 \n공유에 액세스합니다. 이 회사는 보조 리전에 스토리지 재해 복구(DR) 솔루션이 필요합니다. \n보조 리전에 복제된 데이터는 기본 리전과 동일한 프로토콜을 사용하여 액세스해야 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇인가요? \nA. 데이터를 Amazon S3 버킷에 복사하는 AWS 람다 함수를 생성합니다. S3 버킷을 보조 \n리전으로 복제합니다. \nB. AWS 백업을 사용하여 ONTAP 용 FSx 볼륨의 백업을 생성합니다. 볼륨을 보조 리전으로 \n복사합니다. 백업에서 새 FSx for ONTAP 인스턴스를 생성합니다. \nC. 보조 리전에 ONTAP 용 FSx 인스턴스를 생성합니다. NetApp SnapMirror 를 사용하여 \n기본 리전에서 보조 리전으로 데이터를 복제합니다. \nD. Amazon Elastic 파일 시스템(Amazon EFS) 볼륨을 생성합니다. 현재 데이터를 볼륨으로 \n마이그레이션합니다. 볼륨을 보조 리전으로 복제합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/125545-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "636": {"q_num": 636, "question": "개발팀에서 AWS 람다 함수를 사용하는 이벤트 기반 애플리케이션을 만들고 있습니다. \n\nAmazon S3 버킷에 파일이 추가될 때 이벤트가 생성됩니다. 개발팀은 현재 Amazon S3 의 \n이벤트 대상으로 Amazon SNS(Amazon Simple Notification Service)를 구성하고 있습니다. \n확장 가능한 방식으로 Amazon S3 의 이벤트를 처리하기 위해 솔루션 설계자는 무엇을 해야 \n하나요? \nA. 이벤트가 Lambda\n에서 실행되기 전에 Amazon ECS(Amazon Elastic Container \nService)에서 이벤트를 처리하는 SNS 구독을 생성합니다. \nB. 이벤트가 Lambda 에서 실행되기 전에 Amazon Elastic Kubernetes Service(Amazon \nEKS)에서 이벤트를 처리하는 SNS 구독을 생성합니다. \nC. 이벤트를 Amazon SQS(Amazon Simple Queue Service)로 전송하는 SNS 구독을 \n생성합니다. Lambda 함수를 트리거하도록 SOS 대기열을 구성합니다. \nD. AWS 서버 마이그레이션 서비스(AWS SMS)로 이벤트를 전송하는 SNS 구독을 만듭니다. \nSMS 이벤트에서 폴링하도록 람다 함수를 구성합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/125546-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "637": {"q_num": 637, "question": "솔루션 설계자가 Amazon API 게이트웨이를 기반으로 새로운 서비스를 설계하고 있습니다. \n이 서비스의 요청 패턴은 예측할 수 없으며 초당 0 건의 요청에서 500 건 이상으로 갑자기 \n변경될 수 있습니다. 백엔드 데이터베이스에 보존해야 하는 데이터의 총 크기는 현재 1GB \n미만이며 향후 증가를 예측할 수 없습니다. 데이터는 간단한 키-값 요청을 사용하여 쿼리할 \n수 있습니다. \n이러한 요구 사항을 충족하는 AWS 서비스 조합은 무엇인가요? (두 가지 선택) \nA. AWS Fargate \nB. AWS Lambda \nC. Amazon DynamoDB \nD. Amazon EC2 Auto Scaling \nE. MySQL-compatible Amazon Aurora", "answer_block": "Answer: B, C \nhttps://www.examtopics.com/discussions/amazon/view/125547-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "638": {"q_num": 638, "question": "한 회사에서 연구 데이터를 수집하여 전 세계 직원들과 공유하고 있습니다. 이 회사는 \n\n데이터를 수집하여 Amazon S3 버킷에 저장하고 AWS 클라우드에서 데이터를 처리하려고 \n합니다. 회사는 데이터를 회사 직원들과 공유할 것입니다. 이 회사는 운영 오버헤드를 \n최소화하는 AWS 클라우드의 안전한 솔루션이 필요합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇인가요? \nA. AWS 람다 함수를 사용하여 S3 사전 지정 URL 을 생성합니다. 직원들에게 해당 URL 을 \n사용하도록 지시합니다. \nB. 각 직원에 대해 IAM 사용자를 만듭니다. 각 직원에 대해 S3 액세스를 허용하는 IAM \n정책을 만듭니다. 직원들에게 AWS 관리 콘솔을 사용하도록 지시합니다. \nC. S3 파일 게이트웨이를 만듭니다. 업로드용 공유와 다운로드용 공유를 만듭니다. 직원이 \n로컬 컴퓨터에 공유를 마운트하여 S3 파일 게이트웨이를 사용하도록 허용합니다. \nD. AWS Transfer Family SFTP 엔드포인트를 구성합니다. 사용자 지정 ID 공급자 옵션을 \n선택합니다. AWS Secrets Manager 를 사용하여 사용자 자격 증명을 관리합니다. 직원들에게 \nTransfer Family 를 사용하도록 지시합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/125574-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "639": {"q_num": 639, "question": "한 회사에서 새로운 가구 재고 애플리케이션을 구축하고 있습니다. 이 회사는 여러 가용 \n영역에 걸쳐 여러 개의 Amazon EC2 인스턴스에 애플리케이션을 배포했습니다. EC2 \n인스턴스는 VPC 의 애플리케이션 로드 밸런서(ALB) 뒤에서 실행됩니다. \n솔루션 설계자가 들어오는 트래픽이 하나의 EC2 인스턴스에 편중되어 일부 요청에 대한 \n지연 시간이 발생하는 것을 관찰했습니다. \n이 문제를 해결하려면 솔루션 설계자는 어떻게 해야 하나요? \nA. ALB 에서 세션 선호도(스티키 세션)를 비활성화합니다. \nB. ALB 를 네트워크 로드 밸런서로 교체합니다. \nC. 각 가용 영역에서 EC2 인스턴스 수 늘리기 \nD. ALB 의 대상 그룹에 대한 상태 확인 빈도 조정", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/125575-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "640": {"q_num": 640, "question": "한 회사에서 AWS 람다 함수를 사용하여 Amazon S3 에서 파일을 다운로드하고 암호를 \n\n해독하는 애플리케이션 워크플로우가 있습니다. 이러한 파일은 AWS 키 관리 서비스(AWS \nKMS) 키를 사용하여 암호화됩니다. 솔루션 설계자는 필요한 권한이 올바르게 설정되도록 \n보장하는 솔루션을 설계해야 합니다. \n어떤 작업 조합으로 이를 달성할 수 있나요? (두 가지 선택) \nA. 람다 함수의 리소스 정책에 kms:암호 해독 권한을 첨부합니다. \nB. KMS 키의 정책에서 Lambda IAM 역할에 대한 암호 해독 권한을 부여합니다. \nC. KMS 키의 정책에서 Lambda 리소스 정책에 대한 암호 해독 권한을 부여합니다. \nD. kms:암호 해독 권한이 있는 새 IAM 정책을 만들고 이 정책을 Lambda 함수에 \n첨부합니다. \nE. kms:암호 해독 권한이 있는 새 IAM 역할을 만들고 실행 역할을 Lambda 함수에 \n연결합니다.", "answer_block": "Answer: C, E \nhttps://www.examtopics.com/discussions/amazon/view/125579-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n??", "answer_choice": "C"}, "641": {"q_num": 641, "question": "회사에서 재무 검토를 위해 AWS 비용을 모니터링하려고 합니다. 클라우드 운영팀은 AWS \n조직 관리 계정에서 모든 구성원 계정에 대한 AWS 비용 및 사용량 보고서를 쿼리하는 \n아키텍처를 설계하고 있습니다. 팀은 이 쿼리를 한 달에 한 번 실행하고 청구서에 대한 \n자세한 분석을 제공해야 합니다. \n이러한 요구 사항을 충족하는 가장 확장 가능하고 비용 효율적인 방법은 무엇인가요? \nA. 관리 계정에서 비용 및 사용량 보고서를 사용 설정합니다. Amazon Kinesis 에 보고서를 \n전달합니다. 분석을 위해 Amazon EMR 을 사용합니다. \nB. 관리 계정에서 비용 및 사용량 보고서를 활성화합니다. Amazon S3\n에 보고서를 \n전달합니다. 분석을 위해 Amazon Athena 를 사용합니다. \nC. 회원 계정에 대한 비용 및 사용량 보고서를 활성화합니다. Amazon S3 에 보고서를 \n전달합니다. 분석을 위해 Amazon Redshift 를 사용합니다. \nD. 회원 계정에 대한 비용 및 사용량 보고서를 사용하도록 설정합니다. Amazon Kinesis 에 \n보고서를 전달합니다. 분석을 위해 Amazon QuickSight 를 사용합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/125580-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "642": {"q_num": 642, "question": "회사에서 AWS 클라우드의 Auto Scaling 그룹에 속한 Amazon EC2 인스턴스에서 게임 \n애플리케이션을 실행하려고 합니다. 응용 프로그램은 UDP 패킷을 사용하여 데이터를 \n전송합니다. 회사는 트래픽이 증가하거나 감소함에 따라 애플리케이션이 확장 및 축소될 수 \n있도록 하려고 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. Auto Scaling 그룹에 Network Load Balancer 연결 \nB. Auto Scaling 그룹에 Application Load Balancer 를 연결합니다. \nC. 트래픽을 적절하게 라우팅하기 위해 가중치 정책이 있는 Amazon Route 53 레코드 \n세트를 배포합니다. \nD. Auto Scaling 그룹의 EC2 인스턴스에 포트 전달로 구성된 NAT 인스턴스를 배포합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/125215-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \n \n설명: \n이 솔루션은 UDP 패킷을 사용하고 트래픽이 증가 및 감소함에 따라 확장 및 축소하여 \n데이터를 전송하는 게임 애플리케이션 실행 요구 사항을 충족합니다. Network Load \nBalancer 는 매우 낮은 대기 시간으로 높은 처리량을 유지하면서 초당 수백만 건의 요청을 \n처리할 수 있으며 TCP 및 UDP 프로토콜을 모두 지원합니다. Auto Scaling 그룹은 수요 및 \n조정 정책에 따라 EC2 인스턴스 수를 자동으로 조정할 수 있습니다. \n \nApplication Load Balancer 가 UDP 프로토콜을 지원하지 않고 HTTP 및 HTTPS 만 지원하기 \n때문에 옵션 B 는 올바르지 않습니다. \n \nAmazon Route 53\n은 다양한 정책을 기반으로 트래픽을 라우팅할 수 있는 DNS \n서비스이지만 로드 밸런싱 또는 확장 기능을 제공하지 않기 때문에 옵션 C 는 올바르지 \n않습니다. \n \n옵션 D 는 \nNAT 인스턴스는 프라이빗 서브넷의 인스턴스를 인터넷 또는 다른 AWS 서비스에 연결하는 \n데 사용되지만 로드 밸런싱 또는 확장 기능을 제공하지 않기 때문에 올바르지 않습니다. \n참조: \nhttps://aws.amazon.com/blogs/aws/new-udp-load-balancing-for-network-load-balanc\ner/ \nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/AutoScalingGroup.html \n\n \nA : UDP 패킷을 사용한다고 했으니 네트워크 계층 서비스인 NLB 가 적합.", "answer_choice": "A"}, "643": {"q_num": 643, "question": "한 회사에서 여러 브랜드를 위해 AWS\n에서 여러 웹사이트를 운영하고 있습니다. 각 \n웹사이트는 매일 수십 기가바이트의 웹 트래픽 로그를 생성합니다. 솔루션 설계자는 회사의 \n개발자가 회사의 모든 웹사이트에 걸쳐 트래픽 패턴을 분석할 수 있도록 확장 가능한 \n솔루션을 설계해야 합니다. 개발자의 이러한 분석은 몇 달에 걸쳐 일주일에 한 번씩 \n온디맨드 방식으로 수행됩니다. 솔루션은 표준 SQL 로 쿼리를 지원해야 합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇인가요? \nA. Amazon S3 에 로그를 저장합니다. Amazon Athena 를 사용하여 분석합니다. \nB. 로그를 Amazon RDS\n에 저장합니다. 분석을 위해 데이터베이스 클라이언트를 \n사용합니다. \nC. 로그를 Amazon OpenSearch Service 에 저장합니다. 분석을 위해 OpenSearch Service를 \n사용합니다. \nD. 로그를 Amazon EMR 클러스터에 저장합니다. SQL 기반 분석을 위해 지원되는 오픈 \n소스 프레임워크를 사용합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/125581-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "644": {"q_num": 644, "question": "국제적인 회사는 회사가 운영되는 각 국가별로 하위 도메인을 가지고 있습니다. 하위 \n도메인의 형식은 example.com, country1.example.com, country2.example.com\n입니다. \n회사의 워크로드는 애플리케이션 로드 밸런서 뒤에 있습니다. 회사는 전송 중인 웹사이트 \n데이터를 암호화하려고 합니다. \n이러한 요구 사항을 충족하는 단계의 조합은 무엇인가요? (두 가지 선택) \nA. AWS ACM(인증서 관리자) 콘솔을 사용하여 최상위 도메인 example.com 에 대한 일반 \n인증서와 *.example.com 에 대한 와일드카드 인증서를 요청합니다. \nB. AWS ACM(인증서 관리자) 콘솔을 사용하여 최상위 도메인 example.com 에 대한 비공개 \n인증서 및 *.example.com 에 대한 와일드카드 인증서를 요청합니다. \nC. AWS ACM(인증서 관리자) 콘솔을 사용하여 최상위 도메인 example.com 에 대한 공개 \n및 비공개 인증서를 요청합니다. \nD. 이메일 주소로 도메인 소유권을 유효성 검사합니다. 필요한 DNS 레코드를 DNS \n\n공급업체에 추가하여 DNS 유효성 검사로 전환합니다. \nE. DNS 공급업체에 필요한 DNS 레코드를 추가하여 도메인의 도메인 소유권을 유효성 \n검사합니다.", "answer_block": "Answer: A, E \nhttps://www.examtopics.com/discussions/amazon/view/125582-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "645": {"q_num": 645, "question": "회사는 온프레미스 키 관리자에서 암호화 키를 사용해야 합니다. 키 관리자는 규제 및 규정 \n준수 요구 사항으로 인해 AWS 클라우드 외부에 있습니다. 이 회사는 AWS 클라우드 \n외부에 보관되어 있고 여러 공급업체의 다양한 외부 키 관리자를 지원하는 암호화 키를 \n사용하여 암호화 및 암호 해독을 관리하고자 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇인가요? \nA. CloudHSM 클러스터로 지원되는 AWS CloudHSM 키 저장소를 사용합니다. \nB. 외부 키 관리자가 지원하는 AWS 키 관리 서비스(AWS KMS) 외부 키 저장소를 \n사용합니다. \nC. 기본 AWS 키 관리 서비스(AWS KMS) 관리형 키 저장소를 사용합니다. \nD. AWS CloudHSM 클러스터가 지원하는 사용자 지정 키 저장소를 사용합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/125583-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "646": {"q_num": 646, "question": "솔루션 설계자는 AWS 클라우드에서 고성능 컴퓨팅(HPC) 워크로드를 호스팅해야 합니다. \n워크로드는 수백 개의 Amazon EC2 인스턴스에서 실행되며 대규모 데이터 세트의 분산 \n처리를 위해 공유 파일 시스템에 대한 병렬 액세스가 필요합니다. 데이터 세트는 여러 \n인스턴스에서 동시에 액세스됩니다. 워크로드에는 1ms 이내의 액세스 지연 시간이 \n필요합니다. 처리가 완료된 후 엔지니어는 수동 후처리를 위해 데이터 세트에 액세스해야 \n합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇인가요? \nA. 공유 파일 시스템으로 Amazon EFS(Amazon Elastic File System)를 사용하세요. Amazon \nEFS 에서 데이터 세트에 액세스합니다. \nB. 공유 파일 시스템으로 사용할 Amazon S3 버킷을 마운트합니다. S3 버킷에서 직접 \n후처리를 수행합니다. \n\nC. 공유 파일 시스템으로 Lustre 용 Amazon FSx 를 사용합니다. 후처리를 위해 파일 \n시스템을 Amazon S3 버킷에 연결합니다. \nD. 처리 및 후처리를 위해 모든 인스턴스에 마운트할 수 있도록 Amazon S3 버킷을 \n공유하도록 AWS 리소스 액세스 관리자를 구성합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/125584-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "647": {"q_num": 647, "question": "한 게임 회사에서 VoIP(Voice over IP)를 사용하여 애플리케이션을 구축하고 있습니다. \n능력. 이 애플리케이션은 전 세계 사용자에게 트래픽을 제공합니다. 애플리케이션은 AWS \n리전 전체에 걸쳐 자동화된 장애 조치를 통해 가용성이 높아야 합니다. 회사는 사용자 \n장치의 IP 주소 캐싱에 의존하지 않고 사용자의 대기 시간을 최소화하려고 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. 상태 확인과 함께 AWS Global Accelerator 를 사용하십시오. \nB. 지리적 위치 라우팅 정책과 함께 Amazon Route 53 을 사용하십시오. \nC. 여러 오리진을 포함하는 Amazon CloudFront 배포를 생성합니다. \nD. 경로 기반 라우팅을 사용하는 Application Load Balancer 를 생성합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/125212-exam-aws-certified-sol\nutions-architect-associate-saa-c03/ \nC??", "answer_choice": "A"}, "648": {"q_num": 648, "question": "일기 예보 회사는 수백 기가바이트의 데이터를 밀리초 미만의 지연 시간으로 처리해야 \n합니다. 이 회사는 데이터 센터에 고성능 컴퓨팅(HPC) 환경을 갖추고 있으며 예보 기능을 \n확장하고자 합니다. \n솔루션 설계자는 대량의 지속적인 처리량을 처리할 수 있는 고가용성 클라우드 스토리지 \n솔루션을 찾아야 합니다. 솔루션에 저장된 파일은 전체 데이터 세트에 동시에 액세스하고 \n처리할 수 있는 수천 개의 컴퓨팅 인스턴스에서 액세스할 수 있어야 합니다. \n이러한 요구사항을 충족하기 위해 솔루션 설계자는 무엇을 해야 하나요? \nA. Lustre 스크래치 파일 시스템용 Amazon FSx 를 사용합니다. \nB. Lustre 퍼시스턴트 파일 시스템용 Amazon FSx 를 사용합니다. \nC. 버스팅 처리량 모드와 함께 Amazon Elastic 파일 시스템(Amazon EFS)을 사용합니다. \n\nD. 프로비저닝된 처리량 모드와 함께 Amazon EFS(Amazon Elastic File System)를 \n사용합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/125586-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "649": {"q_num": 649, "question": "전자 \n상거래 \n회사는 \n온프레미스에서 \nPostgreSQL \n데이터베이스를 \n운영합니다. \n데이터베이스는 높은 IOPS 의 Amazon EBS(Amazon Elastic Block Store) 블록 스토리지를 \n사용하여 데이터를 저장합니다. 초당 일일 피크 I/O 트랜잭션은 15,000 IOPS 를 초과하지 \n않습니다. 이 회사는 데이터베이스를 PostgreSQL 용 Amazon RDS 로 마이그레이션하고 \n디스크 스토리지 용량과 무관하게 디스크 IOPS 성능을 프로비저닝하려고 합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇인가요? \nA. 범용 SSD(gp2) EBS 볼륨 스토리지 유형을 구성하고 15,000 IOPS 를 프로비저닝합니다. \nB. 프로비저닝된 IOPS SSD(io1) EBS 볼륨 스토리지 유형을 구성하고 15,000 IOPS 를 \n프로비저닝합니다. \nC. 범용 SSD(gp3) EBS 볼륨 스토리지 유형을 구성하고 15,000 IOPS 를 프로비저닝합니다. \nD. EBS 마그네틱 볼륨 유형을 구성하여 최대 IOPS 를 달성합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/125588-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "650": {"q_num": 650, "question": "한 회사에서 온프레미스 Microsoft SQL Server 엔터프라이즈 에디션 데이터베이스를 \nAWS 로 마이그레이션하려고 합니다. 회사의 온라인 애플리케이션은 이 데이터베이스를 \n사용하여 트랜잭션을 처리합니다. 데이터 분석 팀은 동일한 프로덕션 데이터베이스를 \n사용하여 분석 처리를 위한 보고서를 실행합니다. 이 회사는 가능한 한 관리형 서비스로 \n전환하여 운영 오버헤드를 줄이려고 합니다. \n운영 오버헤드가 가장 적으면서 이러한 요구 사항을 충족하는 솔루션은 무엇인가요? \nA. Microsoft SOL Server 용 Amazon RDS 로 마이그레이션합니다. 보고 목적으로 읽기 \n복제본 사용 \nB. Amazon EC2 의 Microsoft SQL Server 로 마이그레이션합니다. 보고 목적으로 항상 켜짐 \n읽기 복제본 사용 \nC. Amazon DynamoDB\n로 마이그레이션합니다. 보고 목적으로 DynamoDB 온디맨드 \n\n복제본을 사용합니다. \nD. Amazon Aurora MySQL 로 마이그레이션합니다. 보고 목적으로 Aurora 읽기 복제본 사용", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/125589-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "A"}, "651": {"q_num": 651, "question": "회사는 Amazon S3 버킷에 대량의 이미지 파일을 저장합니다. 이미지는 처음 180 일 동안 \n쉽게 사용할 수 있어야 합니다. 다음 180 일 동안 이미지에 자주 액세스하지 않습니다. \n360 일이 지나면 이미지를 보관해야 하지만 요청 시 즉시 사용할 수 있어야 합니다. 5 년 \n후에는 감사자만 이미지에 액세스할 수 있습니다. 감사자는 12\n시간 이내에 이미지를 \n검색할 수 있어야 합니다. 이 과정에서 이미지가 손실될 수 없습니다. \n개발자는 처음 180 일 동안 S3 Standard 스토리지를 사용합니다. 개발자는 S3 수명 주기 \n규칙을 구성해야 합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. 180 일 후에 객체를 S3 One Zone-Infrequent Access(S3 One Zone-IA)로 전환합니다. \n360 일 후 S3 Glacier 즉시 검색, 5 년 후 S3 Glacier Deep Archive. \nB. 180 일 후에 객체를 S3 One Zone-Infrequent Access(S3 One Zone-IA)로 전환합니다. \n360 일 후 S3 Glacier 유연한 검색 및 5 년 후 S3 Glacier Deep Archive. \nC. 180 일 후에 객체를 S3 Standard-Infrequent Access(S3 Standard-IA)로 전환하고, 360 일 \n후에 S3 Glacier Instant Retrieval 로 전환하고, 5 년 후에 S3 Glacier Deep Archive 로 \n전환합니다. \nD. 180 일 후에 객체를 S3 Standard-Infrequent Access(S3 Standard-IA)로 전환하고, 360 일 \n후에 S3 Glacier 유연한 검색으로, 5 년 후에 S3 Glacier Deep Archive 로 전환합니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/125244-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "C"}, "652": {"q_num": 652, "question": "매일 6\n시간 동안 실행되는 대규모 데이터 워크로드가 있는 회사입니다. 프로세스가 \n실행되는 동안 데이터가 손실되어서는 안 됩니다. 솔루션 설계자가 이 중요한 데이터 \n워크로드를 지원하기 위해 Amazon EMR 클러스터 구성을 설계하고 있습니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇인가요? \nA. 온디맨드 인스턴스에서 기본 노드 및 코어 노드를 실행하고 스팟 인스턴스에서 작업 \n\n노드를 실행하는 장기 실행 클러스터를 구성합니다. \nB. 온디맨드 인스턴스에서 기본 노드 및 코어 노드를 실행하는 임시 클러스터와 스팟 \n인스턴스에서 작업 노드를 실행하는 임시 클러스터를 구성합니다. \nC. On-Demand 인스턴스에서 기본 노드를 실행하고 스팟 인스턴스에서 코어 노드 및 작업 \n노드를 실행하는 트랜지션 클러스터를 구성합니다. \nD. 온디맨드 인스턴스의 기본 노드, 스팟 인스턴스의 코어 노드 및 스팟 인스턴스의 작업 \n노드를 실행하는 장기 실행 클러스터를 구성합니다.", "answer_block": "Answer: B \nhttps://www.examtopics.com/discussions/amazon/view/125591-exam-aws-certified-sol\nutions-architect-associate-saa-c03/", "answer_choice": "B"}, "653": {"q_num": 653, "question": "한 회사가 회사의 온프레미스 데이터 센터에서 MySQL DB 인스턴스용 Amazon RDS 로 \nMySQL 데이터베이스를 마이그레이션했습니다. 회사는 회사의 평균 일일 워크로드에 맞게 \nRDS DB 인스턴스의 크기를 조정했습니다. 한 달에 한 번 회사에서 보고서에 대한 쿼리를 \n실행할 때 데이터베이스 성능이 느려집니다. 회사는 보고서를 실행하고 일일 워크로드의 \n성능을 유지 관리할 수 있는 기능을 원합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 데이터베이스의 읽기 전용 복제본을 생성합니다. 쿼리를 읽기 전용 복제본으로 \n보냅니다. \nB. 데이터베이스 백업을 생성합니다. 백업을 다른 DB 인스턴스로 복원합니다. 쿼리를 새 \n데이터베이스로 보냅니다. \nC. 데이터를 Amazon S3 로 내보냅니다. Amazon Athena 를 사용하여 S3 버킷을 쿼리합니다. \nD. 추가 워크로드를 수용하도록 DB 인스턴스의 크기를 조정합니다.", "answer_block": "Answer: C \n \n설명 \nAmazon Athena 는 Amazon S3 에 저장된 데이터에 대해 SQL 쿼리를 실행할 수 있는 \n서비스입니다. 서버리스이므로 인프라를 프로비저닝하거나 관리할 필요가 없습니다. 실행한 \n쿼리와 스캔한 데이터 양에 대해서만 비용을 지불하면 됩니다. \nAmazon Athena 를 사용하여 Amazon S3 에서 데이터를 쿼리하면 다음과 같은 이점을 얻을 \n수 있습니다. \n* Amazon RDS for MySQL DB 인스턴스의 성능에 영향을 주지 않고 보고서에 대한 쿼리를 \n실행할 수 있습니다. DB 인스턴스에서 S3 버킷으로 데이터를 내보내고 Athena 를 사용하여 \n버킷의 데이터를 쿼리할 수 있습니다. 이렇게 하면 DB 인스턴스에서 쿼리를 실행하는 \n\n오버헤드와 경합을 피할 수 있습니다. \n* 보고서에 대한 쿼리를 실행하는 비용과 복잡성을 줄일 수 있습니다. 추가 요금이 \n발생하고 유지 관리가 필요한 읽기 전용 복제본이나 DB 인스턴스의 백업을 생성할 필요가 \n없습니다. 또한 운영 오버헤드를 증가시키는 추가 워크로드를 수용하기 위해 DB \n인스턴스의 크기를 조정할 필요가 없습니다. \n* Amazon S3 및 Athena 의 확장성과 유연성을 활용할 수 있습니다. 용량이나 성능 제한에 \n대한 걱정 없이 S3 에 대량의 데이터를 저장하고 Athena 로 쿼리할 수 있습니다. 또한 \n다양한 형식, 압축 방법 및 파티셔닝 체계를 사용하여 데이터 스토리지 및 쿼리 성능을 \n최적화할 수 있습니다.", "answer_choice": "C"}, "654": {"q_num": 654, "question": "회사의 \n데이터 \n플랫폼은 \nAmazon \nAurora \nMySQL \n데이터베이스를 \n사용합니다. \n데이터베이스에는 여러 가용 영역에 걸쳐 여러 읽기 전용 복제본과 여러 DB 인스턴스가 \n있습니다. 사용자는 최근 데이터베이스에서 너무 많은 연결이 있음을 나타내는 오류를 \n보고했습니다. 이 회사는 읽기 복제본이 기본 작성자로 승격될 때 장애 조치 시간을 20% \n줄이려고 합니다. \n이 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 다중 AZ 클러스터 배포를 통해 Aurora 에서 Amazon RDS 로 전환합니다. \nB. Aurora 데이터베이스 앞에서 Amazon RDS Proxy 를 사용합니다. \nC. 읽기 연결을 위해 DAX(DynamoDB Accelerator)가 있는 Amazon DynamoDB\n로 \n전환합니다. \nD. 재배치 기능이 있는 Amazon Redshift 로 전환합니다.", "answer_block": "Answer: B \n \n설명 \nAmazon RDS Proxy 는 Amazon RDS 및 Aurora 데이터베이스를 위한 완전관리형 고가용성 \n데이터베이스 프록시를 제공하는 서비스입니다. 이를 통해 데이터베이스 연결 풀링 및 공유, \n데이터베이스 로드 감소, 애플리케이션 확장성 및 가용성 향상이 가능합니다. \nAurora 데이터베이스 앞에서 Amazon RDS Proxy 를 사용하면 다음과 같은 이점을 얻을 수 \n있습니다. \n* 데이터베이스에 대한 연결 수를 줄이고 너무 많은 연결이 있음을 나타내는 오류를 피할 \n수 있습니다. Amazon RDS Proxy 는 연결 관리 및 멀티플렉싱을 처리하므로 더 적은 수의 \n데이터베이스 연결 및 리소스를 사용할 수 있습니다. \n* 읽기 복제본이 기본 작성자로 승격되면 장애 조치 시간을 20%까지 줄일 수 있습니다. \nAmazon RDS Proxy 는 애플리케이션 코드나 구성을 변경할 필요 없이 장애를 자동으로 \n\n감지하고 새로운 기본 인스턴스로 트래픽을 라우팅합니다. 벤치마크 테스트에 따르면 \nAmazon RDS Proxy 를 사용하면 장애 조치 시간이 66 초에서 53 초로 단축되어 20% \n향상되었습니다. \n* 데이터베이스 액세스의 보안 및 규정 준수를 향상시킬 수 있습니다. Amazon RDS \nProxy 는 AWS Secrets Manager 및 AWS Identity and Access Management(IAM)와 통합되어 \n데이터베이스 연결에 대한 안전하고 세분화된 인증 및 권한 부여를 지원합니다.", "answer_choice": "B"}, "655": {"q_num": 655, "question": "IoT 회사는 사용자의 수면에 대한 데이터를 수집하는 센서가 있는 매트리스를 출시하고 \n있습니다. 센서는 데이터를 Amazon S3 버킷으로 보냅니다. 센서는 각 매트리스에 대해 \n매일 밤 약 2MB 의 데이터를 수집합니다. 회사는 각 매트리스에 대한 데이터를 처리하고 \n요약해야 합니다. 결과는 가능한 한 빨리 사용할 수 있어야 합니다. 데이터 처리에는 \n1GB 의 메모리가 필요하며 30 초 이내에 완료됩니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. Scalajob 과 함께 AWS Glue 를 사용합니다. \nB. Apache Spark 스크립트와 함께 Amazon EMR 을 사용합니다. \nC. Python 스크립트와 함께 AWS Lambda 를 사용합니다. \nD. PySpark 작업과 함께 AWS Glue 를 사용합니다.", "answer_block": "Answer: C \n \n설명 \nAWS Lambda 는 호출 수와 함수 실행 시간에 따라 요금을 부과합니다. 데이터 처리 작업이 \n상대적으로 작기 때문에(데이터 2MB) Lambda 가 비용 효율적인 선택입니다. 인프라를 \n프로비저닝하고 유지 관리할 필요 없이 실제 사용량에 대해서만 비용을 지불하면 됩니다.", "answer_choice": "C"}, "656": {"q_num": 656, "question": "회사에서 고성능 컴퓨팅 및 인공 지능을 사용하여 사기 방지 및 감지 기술을 개선하려고 \n합니다. 회사는 가능한 한 빨리 단일 워크로드를 완료하기 위해 분산 처리가 필요합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Amazon Elastic Kubernetes Service(Amazon EKS) 및 여러 컨테이너를 사용합니다. \nB. AWS ParallelCluster 및 MPI(Message Passing Interface) 라이브러리를 사용합니다. \nC. Application Load Balancer 및 Amazon EC2 인스턴스를 사용합니다. \nD. AWS Lambda 함수를 사용합니다.", "answer_block": "Answer: B \n\n \n설명 \nAWS ParallelCluster 는 AWS 에서 고성능 컴퓨팅(HPC) 클러스터를 생성하고 관리할 수 있는 \n서비스입니다. 여러 EC2 인스턴스에서 분산 워크로드를 실행할 수 있는 AWS Batch 를 \n비롯한 여러 스케줄러를 지원합니다. \nMPI 는 병렬 컴퓨팅에서 프로세스 간 메시지 전달을 위한 표준입니다. 데이터 송수신, \n프로세스 동기화, 통신 그룹 관리 등의 기능을 제공합니다. \nAWS ParallelCluster 및 MPI 라이브러리를 사용하면 다음과 같은 이점을 얻을 수 있습니다. \n* 인스턴스 유형, 노드 수, 네트워크 구성 및 스토리지 옵션과 같은 특정 요구 사항을 \n충족하는 HPC 클러스터를 쉽게 생성하고 구성할 수 있습니다. \n* AWS 의 확장성과 탄력성을 활용하여 서버 프로비저닝이나 관리에 대한 걱정 없이 대규모 \n병렬 워크로드를 실행할 수 있습니다. \n* MPI 라이브러리를 사용하여 프로세스 간 통신 및 데이터 교환을 활성화하여 병렬 \n애플리케이션의 성능과 효율성을 최적화할 수 있습니다. \n* Open MPI, Intel MPI 및 MPICH 와 같이 AWS ParallelCluster 와 호환되는 다양한 MPI 구현 \n중에서 선택할 수 있습니다.", "answer_choice": "B"}, "657": {"q_num": 657, "question": "회사는 \nAmazon \nElastic \nKubernetes \nService(Amazon \nEKS)를 \n사용하여 \n컨테이너 \n애플리케이션을 \n실행합니다. \n이 \n애플리케이션에는 \n고객을 \n관리하고 \n주문하는 \n마이크로서비스가 포함되어 있습니다. 회사는 들어오는 요청을 적절한 마이크로 서비스로 \n라우팅해야 합니다. \n이 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. \nAWS \nLoad \nBalancer \nController\n를 \n사용하여 \nNetwork \nLoad \nBalancer\n를 \n프로비저닝하십시오. \nB. AWS Load Balancer Controller\n를 사용하여 Application Load Balancer\n를 \n프로비저닝합니다. \nC. AWS Lambda 함수를 사용하여 요청을 Amazon EKS 에 연결합니다. \nD. Amazon API Gateway 를 사용하여 요청을 Amazon EKS 에 연결합니다.", "answer_block": "Answer: B \n \n설명 \nApplication Load Balancer 는 OSI 모델의 애플리케이션 계층(계층 7)에서 작동하는 일종의 \nElastic Load Balancer 입니다. Amazon EC2 인스턴스, 컨테이너, IP 주소 및 Lambda 함수와 \n같은 여러 대상에 수신 트래픽을 분산할 수 있습니다. 호스트 이름, 경로 또는 쿼리 \n\n매개변수와 같은 요청 내용을 기반으로 요청을 라우팅할 수도 있습니다. AWS 로드 밸런서 \n컨트롤러는 Kubernetes 클러스터의 Elastic Load Balancer 를 관리하는 데 도움이 되는 \n컨트롤러입니다. Kubernetes 수신 또는 서비스 리소스를 생성할 때 Application Load \nBalancer 또는 Network Load Balancer 를 프로비저닝할 수 있습니다. \nAWS Load Balancer Controller 를 사용하여 Amazon EKS 클러스터용 Application Load \nBalancer 를 프로비저닝하면 다음과 같은 이점을 얻을 수 있습니다. \n* Ingress 리소스에서 정의한 규칙에 따라 수신 요청을 적절한 마이크로서비스로 라우팅할 \n수 있습니다. 예를 들어 호스트 이름이나 경로가 다른 요청을 고객과 주문을 처리하는 다른 \n마이크로 서비스로 라우팅할 수 있습니다. \n* 여러 대상에 부하를 분산하고 상태 확인 및 자동 조정을 활성화하여 컨테이너 \n애플리케이션의 성능과 가용성을 개선할 수 있습니다. \n* Amazon EKS 및 Kubernetes 와 통합되는 단일 컨트롤러를 사용하여 로드 밸런서 관리 \n비용과 복잡성을 줄일 수 있습니다. 로드 밸런서를 수동으로 생성 또는 구성하거나 \n클러스터가 변경될 때 업데이트할 필요가 없습니다.", "answer_choice": "B"}, "658": {"q_num": 658, "question": "한 회사가 다중 계층 온프레미스 애플리케이션을 AWS 로 마이그레이션하고 있습니다. \n애플리케이션은 단일 노드 MySQL 데이터베이스와 다중 노드 웹 계층으로 구성됩니다. \n회사는 마이그레이션 중에 애플리케이션 변경을 최소화해야 합니다. 회사는 마이그레이션 \n후 애플리케이션 복원성을 개선하려고 합니다. \n이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (2 개 선택) \nA. 웹 계층을 Application Load Balancer 뒤에 있는 Auto Scaling 그룹의 Amazon EC2 \n인스턴스로 마이그레이션합니다. \nB. 데이터베이스를 Network Load Balancer 뒤에 있는 Auto Scaling 그룹의 Amazon EC2 \n인스턴스로 마이그레이션합니다. \nC. 데이터베이스를 Amazon RDS 다중 AZ 배포로 마이그레이션합니다. \nD. 웹 계층을 AWS Lambda 함수로 마이그레이션합니다. \nE. 데이터베이스를 Amazon DynamoDB 테이블로 마이그레이션합니다.", "answer_block": "Answer: A, C \n설명: \nAuto Scaling 그룹은 유사한 특성을 공유하고 수요에 따라 자동으로 확장 또는 축소될 수 \n있는 EC2 인스턴스 모음입니다. Auto Scaling 그룹은 여러 가용 영역의 여러 대상에 수신 \n트래픽을 분산시키는 Elastic Load Balancing 로드 밸런서의 일종인 Application Load \nBalancer 뒤에 배치될 수 있습니다. 이 솔루션은 고가용성, 확장성 및 내결함성을 제공하여 \n웹 계층의 복원성을 향상시킵니다. Amazon RDS 다중 AZ 배포는 기본 데이터베이스 \n\n인스턴스를 자동으로 생성하고 다른 가용 영역에 있는 대기 인스턴스에 데이터를 \n동기식으로 복제하는 구성입니다. 오류가 발생하면 Amazon RDS\n는 수동 개입 없이 \n자동으로 대기 인스턴스로 장애 조치됩니다. 이 솔루션은 데이터 중복성, 백업 지원 및 \n가용성을 \n제공하여 \n데이터베이스 \n계층의 \n복원성을 \n향상시킵니다. \n이 \n단계 \n조합은 \n마이그레이션 중에 애플리케이션을 최소한으로 변경하여 요구 사항을 충족합니다.", "answer_choice": "A"}, "659": {"q_num": 659, "question": "한 회사가 프로덕션 Amazon Elastic Kubernetes Service(Amazon EKS) 클러스터에서 실행될 \n애플리케이션을 개발 중입니다. EKS 클러스터에는 온디맨드 인스턴스로 프로비저닝되는 \n관리형 노드 그룹이 있습니다. \n회사에는 개발 작업을 위한 전용 EKS 클러스터가 필요합니다. 회사는 애플리케이션의 \n복원력을 테스트하기 위해 개발 클러스터를 자주 사용하지 않습니다. EKS 클러스터는 모든 \n노드를 관리해야 합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. 스팟 인스턴스만 포함하는 관리형 노드 그룹을 생성합니다. \nB. 두 개의 관리형 노드 그룹을 생성합니다. 온디맨드 인스턴스로 하나의 노드 그룹을 \n프로비저닝합니다. \n스팟 인스턴스로 두 번째 노드 그룹을 프로비저닝합니다. \nC. 스팟 인스턴스를 사용하는 시작 구성이 있는 Auto Scaling 그룹을 생성합니다. EKS \n클러스터에 노드를 추가하도록 사용자 데이터를 구성합니다. \nD. 온디맨드 인스턴스만 포함하는 관리형 노드 그룹을 생성합니다.", "answer_block": "Answer: A \n설명: \n스팟 인스턴스는 온디맨드 가격에 비해 최대 90% 할인된 가격으로 제공되는 EC2 \n인스턴스입니다. 스팟 인스턴스는 중단을 허용할 수 있는 상태 비저장, 내결함성 및 유연한 \n워크로드에 적합합니다. 온디맨드 용량에 대한 수요가 증가하면 스팟 인스턴스를 EC2 에서 \n회수할 수 있지만 종료되기 2 분 전에 경고를 제공합니다. EKS 관리형 노드 그룹은 EKS \n클러스터에 대한 노드의 프로비저닝 및 수명주기 관리를 자동화합니다. 관리형 노드 그룹은 \n스팟 인스턴스를 사용하여 비용을 절감하고 수요에 따라 클러스터를 확장할 수 있습니다. \n관리형 노드 그룹은 스팟 인스턴스의 가용성과 복원력을 향상시키기 위해 용량 재조정 및 \n용량 최적화 할당 전략과 같은 기능도 지원합니다. 이 솔루션은 가장 저렴한 EC2 용량을 \n활용하고 수동 개입이 필요하지 않으므로 가장 비용 효율적으로 요구 사항을 충족합니다.", "answer_choice": "A"}, "660": {"q_num": 660, "question": "한 회사는 데이터 센터에서 SMB 파일 서버를 운영하고 있습니다. 파일서버는 회사가 자주 \n접속하는 대용량 파일을 파일 생성일로부터 최대 7일까지 저장합니다. 7 일이 지나면 회사는 \n최대 24 시간의 검색 시간으로 파일에 액세스할 수 있어야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. AWS DataSync 를 사용하여 SMB 파일 서버에서 AWS 로 7 일보다 오래된 데이터를 \n복사합니다. \nB. 회사의 저장 공간을 늘리려면 Amazon S3 파일 게이트웨이를 생성하십시오. 7 일 후에 \n데이터를 S3 Glacier Deep Archive 로 전환하는 S3 수명 주기 정책을 생성합니다. \nC. 회사의 저장 공간을 늘리기 위해 Amazon FSx 파일 게이트웨이를 생성합니다. 7 일 후에 \n데이터를 전환하는 Amazon S3 수명 주기 정책을 생성합니다. \nD. 각 사용자에 대해 Amazon S3 에 대한 액세스를 구성합니다. 7 일 후에 데이터를 S3 \nGlacier 유연한 검색으로 전환하는 S3 수명 주기 정책을 생성합니다.", "answer_block": "Answer: B \n설명: \nAmazon S3 파일 게이트웨이는 네트워크 파일 공유로 표시되는 Amazon S3 에 파일 기반 \n인터페이스를 제공하는 서비스입니다. SMB 와 같은 표준 파일 스토리지 프로토콜을 통해 \nAmazon S3 객체를 저장하고 검색할 수 있습니다. S3 파일 게이트웨이는 짧은 액세스 \n지연을 위해 자주 액세스하는 데이터를 로컬로 캐시할 수도 있습니다. S3 수명 주기 정책은 \n수명 주기 전반에 걸쳐 객체 관리를 자동화하는 규칙을 정의할 수 있는 기능입니다. S3 \n수명 주기 정책을 사용하면 객체의 수명과 액세스 패턴에 따라 객체를 다양한 스토리지 \n클래스로 전환할 수 있습니다. S3 Glacier Deep Archive 는 검색 시간이 12 시간 또는 \n48 시간으로 가장 저렴한 장기 데이터 보관 비용을 제공하는 스토리지 클래스입니다. 이 \n솔루션은 회사가 SMB 파일 액세스를 통해 S3 에 대용량 파일을 저장하고, 비용 절감 및 \n규정 준수를 위해 7 일 후에 파일을 S3 Glacier Deep Archive 로 이동할 수 있도록 하므로 \n요구 사항을 충족합니다.", "answer_choice": "B"}, "661": {"q_num": 661, "question": "솔루션 아키텍트는 Amazon S3 버킷의 파일을 Amazon Elastic File System(Amazon EFS) \n파일 시스템과 다른 S3 버킷으로 복사해야 합니다. 파일은 계속해서 복사되어야 합니다. 새 \n파일은 원본 S3 버킷에 지속적으로 추가됩니다. 복사된 파일은 원본 파일이 변경된 \n경우에만 덮어써야 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 대상 S3 버킷과 EFS 파일 시스템 모두에 대한 AWS DataSync 위치를 생성합니다. \n대상 S3 버킷 및 EFS 파일 시스템에 대한 작업을 생성합니다. 변경된 데이터만 전송하도록 \n전송 모드를 설정하세요. \n\nB. AWS Lambda 함수를 생성합니다. 파일 시스템을 함수에 마운트합니다. Amazon S3 에서 \n파일이 생성되고 변경될 때 함수를 호출하도록 S3 이벤트 알림을 설정합니다. 파일 \n시스템과 대상 S3 버킷에 파일을 복사하는 기능을 구성합니다. \nC. 대상 S3 버킷과 EFS 파일 시스템 모두에 대한 AWS DataSync 위치를 생성합니다. \n대상 S3 버킷 및 EFS 파일 시스템에 대한 작업을 생성합니다. 모든 데이터를 전송하려면 \n전송 모드를 설정하세요. \nD. 파일 시스템과 동일한 VPC 에서 Amazon EC2 인스턴스를 시작합니다. 파일 시스템을 \n마운트합니다. 원본 S3 버킷에서 변경된 모든 객체를 대상 S3 버킷 및 탑재된 파일 \n시스템과 정기적으로 동기화하는 스크립트를 만듭니다.", "answer_block": "Answer: A \n설명: \nAWS DataSync 는 AWS 스토리지 서비스와 온프레미스 스토리지 시스템 간에 대량의 \n데이터를 쉽게 이동할 수 있게 해주는 서비스입니다. AWS DataSync 는 S3 버킷에서 EFS \n파일 시스템 및 다른 S3 버킷으로 파일을 지속적으로 복사할 수 있을 뿐만 아니라 \n소스에서 변경된 파일만 덮어쓸 수 있습니다. 이 솔루션은 코드 개발이나 수동 개입이 \n필요하지 않으므로 최소한의 운영 오버헤드로 요구 사항을 충족합니다.", "answer_choice": "A"}, "663": {"q_num": 663, "question": "한 \n회사에서 \nAmazon \nDynamoDB\n를 \n데이터베이스 \n계층으로 \n사용하는 \n서버리스 \n애플리케이션을 \n배포했습니다. \n애플리케이션 \n사용자가 \n크게 \n증가했습니다. \n회사는 \n데이터베이스 응답 시간을 밀리초에서 마이크로초로 향상하고 데이터베이스에 대한 요청을 \n캐시하기를 원합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. DynamoDB Accelerator(DAX)를 사용하세요. \nB. 데이터베이스를 Amazon Redshift 로 마이그레이션합니다. \nC. 데이터베이스를 Amazon RDS 로 마이그레이션합니다. \nD. Redis 용 Amazon ElastiCache 를 사용합니다.", "answer_block": "Answer: A \n설명: \nDynamoDB Accelerator(DAX)는 Amazon DynamoDB 용으로 구축된 완전 관리형 고가용성 \n캐싱 서비스입니다. DAX 는 초당 수백만 건의 요청에서도 밀리초에서 마이크로초로 최대 \n10 배의 성능 향상을 제공합니다. DAX 는 개발자가 캐시 무효화, 데이터 채우기 또는 \n클러스터 관리를 관리할 필요 없이 DynamoDB 테이블에 인 메모리 가속을 추가하는 데 \n필요한 모든 무거운 작업을 수행합니다. 이제 대규모 성능에 대한 걱정 없이 고객을 위한 \n\n훌륭한 애플리케이션을 구축하는 데 집중할 수 있습니다. DAX 는 기존 DynamoDB API \n호출과 호환되므로 애플리케이션 로직을 수정할 필요가 없습니다. 이 솔루션은 코드 \n개발이나 수동 개입이 필요하지 않으므로 최소한의 운영 오버헤드로 요구 사항을 \n충족합니다.", "answer_choice": "A"}, "664": {"q_num": 664, "question": "회사는 온프레미스 NAS(Network Attached Storage) 시스템을 사용하여 HPC(고성능 컴퓨팅) \n워크로드에 파일 공유를 제공합니다. 회사는 지연 시간에 민감한 HPC 워크로드와 \n스토리지를 AWS 클라우드로 마이그레이션하려고 합니다. 회사는 파일 시스템에서 NFS 및 \nSMB 다중 프로토콜 액세스를 제공할 수 있어야 합니다. \n가장 짧은 대기 시간으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? (2 개 선택) \nA. 컴퓨팅 최적화 EC2 인스턴스를 클러스터 배치 그룹에 배포합니다. \nB. 컴퓨팅 최적화 EC2 인스턴스를 파티션 배치 그룹에 배포합니다. \nC. EC2 인스턴스를 Amazon FSx for Lustre 파일 시스템에 연결합니다. \nD. EC2 인스턴스를 Amazon FSx for OpenZFS 파일 시스템에 연결합니다. \nE. EC2 인스턴스를 NetApp ONTAP 파일 시스템용 Amazon FSx 에 연결합니다.", "answer_block": "Answer: A, E \n설명: \n클러스터 배치 그룹은 네트워크 지연 시간을 최소화하기 위해 서로 가깝게 배치되는 단일 \n가용 영역 내 EC2 인스턴스의 논리적 그룹입니다. 이는 높은 네트워크 성능이 요구되는 \n대기 시간에 민감한 HPC 워크로드에 적합합니다. 컴퓨팅 최적화 EC2 인스턴스는 vCPU 대 \n메모리 비율이 높은 인스턴스 유형으로, 컴퓨팅 집약적인 애플리케이션에 이상적입니다. \nNetApp ONTAP 용 Amazon FSx 는 파일 시스템에서 NFS 및 SMB 다중 프로토콜 액세스는 \n물론 데이터 중복 제거, 압축, 씬 프로비저닝, 스냅샷과 같은 기능을 제공하는 완전관리형 \n서비스입니다. 이 솔루션은 AWS\n의 짧은 지연 시간 네트워크 및 스토리지 성능을 \n활용하므로 가장 짧은 지연 시간으로 요구 사항을 충족합니다.", "answer_choice": "A"}, "665": {"q_num": 665, "question": "한 회사에서 온프레미스 Microsoft SQL Server Enterprise 에디션 데이터베이스를 AWS 로 \n마이그레이션하려고 합니다. 회사의 온라인 애플리케이션은 데이터베이스를 사용하여 \n거래를 처리합니다. 데이터 분석 팀은 동일한 프로덕션 데이터베이스를 사용하여 분석 \n처리를 위한 보고서를 실행합니다. 회사는 가능한 한 관리형 서비스로 전환하여 운영 \n오버헤드를 줄이고 싶어합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \n\nA. Microsoft SQL Server 용 Amazon RDS 로 마이그레이션하세요. 보고 목적으로 읽기 \n복제본을 사용하세요. \nB. Amazon EC2 의 Microsoft SQL Server 로 마이그레이션합니다. 보고 목적으로 Always On \n읽기 복제본을 사용하세요. \nC. Amazon DynamoDB\n로 마이그레이션합니다. 보고 목적으로 DynamoDB 온디맨드 \n복제본을 사용하세요. \nD. Amazon Aurora MySQL\n로 마이그레이션합니다. 보고 목적으로 Aurora 읽기 전용 \n복제본을 사용하십시오.", "answer_block": "Answer: A \n설명: \nMicrosoft SQL Server 용 Amazon RDS 는 SQL Server 2014, 2016, 2017 및 2019 에디션을 \n제공하는 동시에 백업, 패치, 확장과 같은 데이터베이스 관리 작업을 오프로드하는 \n완전관리형 서비스입니다. Amazon RDS 는 온라인 애플리케이션의 성능에 영향을 주지 않고 \n보고 목적으로 사용할 수 있는 기본 데이터베이스의 읽기 전용 복사본인 읽기 전용 \n복제본을 지원합니다. \n이 솔루션은 코드 변경이나 수동 개입이 필요하지 않으므로 최소한의 운영 오버헤드로 요구 \n사항을 충족합니다.", "answer_choice": "A"}, "666": {"q_num": 666, "question": "회사는 사용자를 비용 센터에 매핑하는 Amazon RDS 데이터베이스를 유지 관리합니다. \n회사는 AWS Organizations 의 조직에 계정을 가지고 있습니다. 회사에는 조직의 특정 AWS \n계정에서 생성된 모든 리소스에 태그를 지정하는 솔루션이 필요합니다. 솔루션은 리소스를 \n생성한 사용자의 비용 센터 ID 로 각 리소스에 태그를 지정해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 특정 AWS 계정을 마스터 계정에서 조직의 새로운 조직 단위(OU)로 이동합니다. \n리소스가 생성되기 전에 모든 기존 리소스에 올바른 비용 센터 태그가 있어야 하는 서비스 \n제어 정책(SCP)을 생성합니다. 새 OU 에 SCP 를 적용합니다. \nB. Lambda 함수가 RDS 데이터베이스에서 적절한 비용 센터를 조회한 후 리소스에 태그를 \n지정하는 AWS Lambda 함수를 생성합니다. AWS CloudTrail 이벤트에 반응하여 Lambda \n함수를 호출하는 Amazon EventBridge 규칙을 구성합니다. \nC. AWS CloudFormation 스택을 생성하여 AWS Lambda 함수를 배포합니다. RDS \n데이터베이스에서 적절한 비용 센터를 조회하고 리소스에 태그를 지정하도록 Lambda \n함수를 구성합니다. CloudFormation 스택을 호출하는 Amazon EventBridge 예약 규칙을 \n생성합니다. \nD. 기본값으로 리소스에 태그를 지정하는 AWS Lambda 함수를 생성합니다. 리소스에 비용 \n\n센터 태그가 누락된 경우 AWS CloudTrail 이벤트에 반응하여 Lambda 함수를 호출하는 \nAmazon EventBridge 규칙을 구성합니다.", "answer_block": "Answer: B \n \n설명: \nAWS Lambda\n는 서버를 프로비저닝하거나 관리하지 않고도 코드를 실행할 수 있는 \n서버리스 컴퓨팅 서비스입니다. Lambda 를 사용하면 사용자를 비용 센터에 매핑하는 RDS \n데이터베이스를 쿼리하여 리소스를 생성한 사용자의 비용 센터 ID 로 리소스에 태그를 \n지정할 수 있습니다. Amazon EventBridge 는 이벤트 중심 아키텍처를 지원하는 서버리스 \n이벤트 버스 서비스입니다. EventBridge 는 AWS 계정에 의해 또는 AWS 계정을 대신하여 \n이루어진 기록된 API 호출인 AWS CloudTrail 이벤트에 반응하도록 구성할 수 있습니다. \nEventBridge 는 특정 AWS 계정에 리소스가 생성될 때 Lambda 함수를 호출하여 사용자 \n자격 증명 및 리소스 정보를 매개 변수로 전달할 수 있습니다. 이 솔루션은 사용자 및 비용 \n센터 매핑을 기반으로 리소스에 자동으로 태그를 지정할 수 있으므로 요구 사항을 \n충족합니다.", "answer_choice": "B"}, "667": {"q_num": 667, "question": "회사는 Amazon EC2 인스턴스와 Amazon Elastic Block Store(Amazon EBS) 볼륨을 \n사용하여 애플리케이션을 실행합니다. 회사는 규정 준수 요구 사항을 충족하기 위해 매일 \n각 EBS 볼륨에 대해 하나의 스냅샷을 생성합니다. 회사는 EBS 볼륨 스냅샷이 실수로 \n삭제되는 것을 방지하는 아키텍처를 구현하려고 합니다. 솔루션은 스토리지 관리자 \n사용자의 관리 권한을 변경해서는 안 됩니다. \n최소한의 관리 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 스냅샷 삭제 권한이 있는 IAM 역할을 생성합니다. 새 EC2 인스턴스에 역할을 \n연결합니다. 스냅샷을 삭제하려면 새 EC2 인스턴스에서 AWS CLI 를 사용하세요. \nB. 스냅샷 삭제를 거부하는 IAM 정책을 생성합니다. 스토리지 관리자 사용자에게 정책을 \n연결합니다. \nC. 스냅샷에 태그를 추가합니다. 태그가 있는 EBS 스냅샷에 대해 휴지통에 보관 규칙을 \n만듭니다. \nD. 삭제를 방지하기 위해 EBS 스냅샷을 잠급니다.", "answer_block": "Answer: D \n설명: \nEBS 스냅샷은 데이터를 복원하거나 새 볼륨을 생성하는 데 사용할 수 있는 EBS 볼륨의 \n특정 시점 백업입니다. EBS 스냅샷 잠금이라는 기능을 사용하여 실수로 삭제되는 것을 \n방지하기 위해 EBS 스냅샷을 잠글 수 있습니다. 스냅샷이 잠겨 있으면 잠금이 해제될 \n\n때까지 루트 사용자를 포함한 어떤 사용자도 삭제할 수 없습니다. 잠금 정책은 스냅샷을 \n삭제할 수 있는 보존 기간을 지정할 수도 있습니다. 이 솔루션은 코드 개발이나 정책 \n변경이 필요하지 않으므로 최소한의 관리 노력으로 요구 사항을 충족합니다.", "answer_choice": "D"}, "668": {"q_num": 668, "question": "회사는 온프레미스 LDAP 디렉터리 서비스를 사용하여 AWS Management Console 에 \n사용자를 \n인증해야 \n합니다. \n디렉터리 \n서비스는 \nSAML(Security \nAssertion \nMarkup \nLanguage)과 호환되지 않습니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. AWS 와 온프레미스 LDAP 간에 AWS IAM Identity Center(AWS Single Sign-On)를 \n활성화합니다. \nB. AWS 자격 증명을 사용하는 IAM 정책을 생성하고 정책을 LDAP 에 통합합니다. \nC. LDAP 자격 증명이 업데이트될 때마다 IAM 자격 증명을 교체하는 프로세스를 \n설정합니다. \nD. AWS Security Token Service(AWS STS)를 사용하여 단기 자격 증명을 얻는 온프레미스 \n사용자 지정 자격 증명 브로커 애플리케이션 또는 프로세스를 개발합니다.", "answer_block": "Answer: D \n설명: \n요구 사항을 충족하는 솔루션은 AWS Security Token Service(AWS STS)를 사용하여 단기 \n자격 증명을 얻는 온프레미스 사용자 지정 자격 증명 브로커 애플리케이션 또는 프로세스를 \n개발하는 것입니다. 이 솔루션을 사용하면 회사는 SAML 호환성 없이도 기존 LDAP \n디렉터리 서비스를 사용하여 AWS Management Console 에 사용자를 인증할 수 있습니다. \n사용자 지정 자격 증명 브로커 애플리케이션 또는 프로세스는 LDAP 디렉터리 서비스와 \nAWS STS 간의 프록시 역할을 할 수 있으며 LDAP 속성 및 역할을 기반으로 사용자에 대한 \n임시 보안 자격 증명을 요청할 수 있습니다. 그런 다음 사용자는 이러한 자격 증명을 \n사용하여 자격 증명 브로커가 생성한 로그인 URL 을 통해 AWS Management Console 에 \n액세스할 수 있습니다. 또한 이 솔루션은 지정된 기간 후에 만료되는 단기 자격 증명을 \n사용하여 보안을 강화합니다. \n다른 솔루션은 SAML 호환성이 필요하거나 AWS Management Console 에 대한 액세스를 \n제공하지 않기 때문에 요구 사항을 충족하지 않습니다. AWS 와 온프레미스 LDAP 간에 \nAWS IAM Identity Center(AWS Single Sign-On)를 활성화하려면 SAML 2.0 을 지원하는 LDAP \n디렉터리 서비스가 필요하지만 이 시나리오에서는 그렇지 않습니다. AWS 자격 증명을 \n사용하는 IAM 정책을 생성하고 정책을 LDAP 에 통합하면 AWS Management Console 에 \n대한 액세스가 제공되지 않고 AWS API 에만 액세스할 수 있습니다. LDAP 자격 증명이 \n업데이트될 때마다 IAM 자격 증명을 교체하는 프로세스를 설정하면 AWS Management \n\n콘솔에 대한 액세스가 제공되지 않고 AWS CLI 에만 액세스할 수 있습니다. 따라서 이러한 \n솔루션은 주어진 요구 사항에 적합하지 않습니다.", "answer_choice": "D"}, "669": {"q_num": 669, "question": "회사의 웹사이트는 대중에게 제품을 판매하는 데 사용됩니다. 이 사이트는 ALB(Application \nLoad Balancer) 뒤에 있는 Auto Scaling 그룹의 Amazon EC2 인스턴스에서 실행됩니다. \nAmazon CloudFront 배포판도 있으며 AWS WAF 는 SQL 주입 공격으로부터 보호하는 데 \n사용되고 있습니다. ALB 는 CloudFront 배포의 오리진입니다. 최근 보안 로그를 검토한 \n결과, 해당 웹사이트에 대한 접근을 차단해야 할 외부 악성 IP 가 발견되었습니다. \n솔루션 설계자는 애플리케이션을 보호하기 위해 무엇을 해야 합니까? \nA. CloudFront 배포의 네트워크 ACL 을 수정하여 악성 IP 주소에 대한 거부 규칙을 \n추가합니다. \nB. AWS WAF 구성을 수정하여 악성 IP 주소를 차단하는 IP 일치 조건을 추가합니다. \nC. ALB 뒤의 대상 그룹에 있는 EC2 인스턴스에 대한 네트워크 ACL 을 수정하여 악성 IP \n주소를 거부합니다. \nD. 악성 IP 주소를 거부하도록 ALB 뒤의 대상 그룹에 있는 EC2 인스턴스에 대한 보안 \n그룹을 수정합니다.", "answer_block": "Answer: B \n설명: \nAWS WAF\n는 애플리케이션 가용성에 영향을 미치거나 보안을 손상시키거나 과도한 \n리소스를 소비할 수 있는 일반적인 웹 공격으로부터 웹 애플리케이션을 보호하는 데 도움이 \n되는 웹 애플리케이션 방화벽입니다. AWS WAF 를 통해 사용자는 사용자 정의 가능한 웹 \n보안 규칙을 기반으로 웹 요청을 차단, 허용 또는 계산하는 규칙을 생성할 수 있습니다. \n생성할 수 있는 규칙 유형 중 하나는 사용자가 허용하거나 차단하려는 IP 주소 또는 IP \n주소 범위 목록을 지정할 수 있는 IP 일치 규칙입니다. 악의적인 IP 주소를 차단하는 IP \n일치 조건을 추가하도록 AWS WAF 의 구성을 수정함으로써 솔루션 아키텍트는 공격자가 \nCloudFront 배포 및 ALB 를 통해 웹 사이트에 액세스하는 것을 방지할 수 있습니다. \n다른 옵션은 악성 IP 주소의 웹 사이트 액세스를 효과적으로 차단하지 못하기 때문에 \n올바르지 않습니다. CloudFront 배포의 네트워크 ACL 또는 ALB 뒤의 대상 그룹에 있는 \nEC2 인스턴스를 수정하는 것은 네트워크 ACL 이 상태 비저장이고 애플리케이션 계층에서 \n트래픽을 평가하지 않기 때문에 작동하지 않습니다. 보안 그룹은 상태 저장형이고 로드 \n밸런서 수준이 아닌 인스턴스 수준에서만 트래픽을 평가하기 때문에 ALB 뒤의 대상 그룹에 \n있는 EC2 인스턴스에 대한 보안 그룹을 수정하면 작동하지 않습니다.", "answer_choice": "B"}, "670": {"q_num": 670, "question": "한 제조 회사가 AWS 에서 보고서 생성 애플리케이션을 실행하고 있습니다. 애플리케이션은 \n약 20 분 안에 각 보고서를 생성합니다. 애플리케이션은 단일 Amazon EC2 인스턴스에서 \n실행되는 모놀리스로 구축되었습니다. 애플리케이션에는 긴밀하게 결합된 모듈을 자주 \n업데이트해야 합니다. 회사에서 새로운 기능을 추가하면 애플리케이션을 유지 관리하기가 \n복잡해집니다. \n회사에서 소프트웨어 모듈을 패치할 때마다 애플리케이션에 가동 중지 시간이 발생합니다. \n보고서 생성은 중단된 후에 처음부터 다시 시작되어야 합니다. 회사는 애플리케이션이 \n유연하고 확장 가능하며 점진적으로 개선될 수 있도록 애플리케이션을 재설계하려고 합니다. \n회사는 애플리케이션 가동 중지 시간을 최소화하려고 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. AWS Lambda\n에서 최대 프로비저닝 동시성을 갖춘 단일 함수로 애플리케이션을 \n실행합니다. \nB. 스팟 집합 기본 할당 전략을 사용하여 Amazon EC2 스팟 인스턴스에서 애플리케이션을 \n마이크로서비스로 실행합니다. \nC. 서비스 자동 조정을 통해 Amazon Elastic Container Service(Amazon ECS)에서 \n애플리케이션을 마이크로서비스로 실행합니다. \nD. 일괄 배포 전략을 사용하여 AWS Elastic Beanstalk\n에서 애플리케이션을 단일 \n애플리케이션 환경으로 실행합니다.", "answer_block": "Answer: C \n설명: \n요구 사항을 충족하는 솔루션은 Amazon Elastic Container Service(Amazon ECS)에서 \n서비스 자동 확장 기능을 갖춘 마이크로서비스로 애플리케이션을 실행하는 것입니다. 이 \n솔루션을 사용하면 애플리케이션을 유연하고 확장 가능하며 점진적으로 개선할 수 있을 \n뿐만 \n아니라 \n애플리케이션 \n가동 \n중지 \n시간도 \n최소화할 \n수 \n있습니다. \n모놀리식 \n애플리케이션을 마이크로서비스로 분할함으로써 회사는 전체 애플리케이션에 영향을 주지 \n않고 \n모듈을 \n분리하고 \n독립적으로 \n업데이트할 \n수 \n있습니다. \nAmazon \nECS\n에서 \n마이크로서비스를 실행함으로써 회사는 이식성, 효율성, 격리와 같은 컨테이너화의 이점을 \n활용할 수 있습니다. 서비스 자동 확장을 활성화함으로써 회사는 수요에 따라 각 \n마이크로서비스에 대해 실행되는 컨테이너 수를 조정하여 최적의 성능과 비용을 보장할 수 \n있습니다. 또한 Amazon ECS 는 업데이트 중 가동 중지 시간을 줄이거나 없앨 수 있는 롤링 \n업데이트 또는 블루/그린 배포와 같은 다양한 배포 전략을 지원합니다. \n다른 솔루션은 요구 사항을 충족하지 않거나 새로운 문제를 야기하기 때문에 첫 번째 \n솔루션만큼 효과적이지 않습니다. 최대 동시성 프로비저닝을 통해 AWS Lambda\n에서 \n애플리케이션을 단일 함수로 실행하면 모놀리스를 마이크로서비스로 분해하지도 않고 유지 \n관리의 복잡성을 줄여주지도 않기 때문에 요구 사항을 충족하지 못합니다. 또한 Lambda \n\n함수는 실행 시간(15 분), 메모리 크기(10GB) 및 동시성 할당량에 의해 제한되는데, 이는 \n보고서 생성 애플리케이션에 충분하지 않을 수 있습니다. 스팟 집합 기본 할당 전략을 \n사용하여 Amazon EC2 스팟 인스턴스에서 마이크로서비스로 애플리케이션을 실행하면 현물 \n가격 변동으로 인해 중단될 위험이 있으므로 요구 사항을 충족하지 못합니다. 스팟 \n인스턴스는 가용성이나 안정성이 보장되지 않으며 AWS 에서 언제든지 2 분 경고 후 회수할 \n수 있습니다. \n이로 인해 보고서 생성이 실패하거나 처음부터 다시 시작될 수 있습니다. 한꺼번에 배포 \n전략을 사용하는 단일 애플리케이션 환경으로 AWS Elastic Beanstalk 에서 애플리케이션을 \n실행하면 모놀리스를 마이크로서비스로 분해하지도 않고 애플리케이션 가동 중지 시간을 \n최소화하지도 않기 때문에 요구 사항을 충족하지 못합니다. 일괄 배포 전략은 업데이트를 \n모든 인스턴스에 동시에 배포하므로 애플리케이션이 잠시 중단됩니다.", "answer_choice": "C"}, "671": {"q_num": 671, "question": "한 회사에서 컨테이너화된 애플리케이션 워크로드를 3 개의 가용 영역에 걸쳐 VPC 에 \n배포하려고 합니다. 회사에는 가용 영역 전반에 걸쳐 가용성이 높은 솔루션이 필요합니다. \n솔루션을 사용하려면 애플리케이션을 최소한으로 변경해야 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. Amazon Elastic Container Service(Amazon ECS)를 사용하세요. 대상 추적 조정을 \n사용하도록 Amazon ECS 서비스 Auto Scaling\n을 구성합니다. 최소 용량을 3\n으로 \n설정합니다. 가용 영역 속성을 사용하여 분산되도록 작업 배치 전략 유형을 설정합니다. \nB. Amazon Elastic Kubernetes Service(Amazon EKS) 자체 관리형 노드를 사용합니다. 대상 \n추적 조정을 사용하도록 Application Auto Scaling 을 구성합니다. 최소 용량을 3 으로 \n설정하세요. \nC. Amazon EC2 예약 인스턴스를 사용하십시오. 분산 배치 그룹에서 3\n개의 EC2 \n인스턴스를 시작합니다. 대상 추적 조정을 사용하도록 Auto Scaling 그룹을 구성합니다. \n최소 용량을 3 으로 설정하세요. \nD. AWS Lambda 함수를 사용하십시오. VPC 에 연결하도록 Lambda 함수를 구성합니다. \nLambda 를 확장 가능한 대상으로 사용하도록 Application Auto Scaling 을 구성합니다. 최소 \n용량을 3 으로 설정하세요.", "answer_block": "Answer: A \n설명: \n이 회사는 고가용성과 애플리케이션 변경을 최소화하면서 3\n개의 가용 영역에 걸쳐 \n컨테이너화된 애플리케이션 워크로드를 VPC\n에 배포하려고 합니다. 최소한의 운영 \n오버헤드로 이러한 요구 사항을 충족하는 솔루션은 다음과 같습니다. \nAmazon Elastic Container Service(Amazon ECS)를 사용하세요. Amazon ECS 는 AWS 에서 \n\n컨테이너화된 \n애플리케이션을 \n실행하고 \n확장할 \n수 \n있는 \n완전관리형 \n컨테이너 \n오케스트레이션 서비스입니다. Amazon ECS 를 사용하면 자체 클러스터 관리 인프라를 설치, \n운영 및 확장할 필요가 없습니다. Amazon ECS 는 VPC, ELB, CloudFormation, CloudWatch, \nIAM 등과 같은 다른 AWS 서비스와도 통합됩니다. \n대상 추적 조정을 사용하도록 Amazon ECS 서비스 Auto Scaling 을 구성합니다. Amazon \nECS 서비스 Auto Scaling 을 사용하면 수요 또는 사용자 지정 지표를 기반으로 서비스의 \n작업 수를 자동으로 조정할 수 있습니다. 목표 추적 조정은 지정된 지표를 목표 값으로 \n유지하기 위해 서비스의 작업 수를 조정하는 정책 유형입니다. 예를 들어, 목표 추적 \n조정을 사용하여 서비스에 대한 목표 CPU 사용률 또는 작업당 요청 수를 유지할 수 \n있습니다. \n최소 용량을 3 으로 설정합니다. 이렇게 하면 서비스가 항상 3 개의 가용 영역에서 3 개 \n이상의 작업을 실행하여 애플리케이션에 고가용성과 내결함성을 제공할 수 있습니다. \n가용 영역 속성을 사용하여 분산되도록 작업 배치 전략 유형을 설정합니다. 이렇게 하면 \n작업이 클러스터의 가용 영역에 고르게 분산되어 서비스 가용성이 극대화됩니다. \n이 솔루션은 가용 영역 전반에 걸쳐 고가용성을 제공하고 애플리케이션 변경을 최소화하며 \n자체 클러스터 인프라 관리에 따른 운영 오버헤드를 줄입니다.", "answer_choice": "A"}, "672": {"q_num": 672, "question": "한 회사는 높은 동시성 AWS Lambda 함수를 사용하여 마케팅 이벤트 중에 메시지 \n대기열에서 지속적으로 증가하는 메시지 수를 처리합니다. Lambda 함수는 CPU 집약적인 \n코드를 사용하여 메시지를 처리합니다. 회사는 컴퓨팅 비용을 줄이고 고객의 서비스 대기 \n시간을 유지하기를 원합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. Lambda 함수에 대해 예약된 동시성을 구성합니다. Lambda 함수에 할당된 메모리를 \n줄입니다. \nB. Lambda 함수에 대한 예약된 동시성을 구성합니다. AWS Compute Optimizer 권장 사항에 \n따라 메모리를 늘리십시오. \nC. Lambda 함수에 대해 프로비저닝된 동시성을 구성합니다. Lambda 함수에 할당된 \n메모리를 줄입니다. \nD. Lambda 함수에 대해 프로비저닝된 동시성을 구성합니다. AWS Compute Optimizer 권장 \n사항에 따라 메모리를 늘리십시오.", "answer_block": "Answer: D \n설명: \n회사는 메시지 대기열에서 지속적으로 증가하는 메시지 수를 처리하는 Lambda 함수에 \n대해 컴퓨팅 비용을 줄이고 서비스 지연 시간을 유지하려고 합니다. \n\nLambda 함수는 CPU 집약적인 코드를 사용하여 메시지를 처리합니다. 이러한 요구 사항을 \n충족하려면 솔루션 설계자는 다음 솔루션을 권장해야 합니다. \nLambda 함수에 대해 프로비저닝된 동시성을 구성합니다. 프로비저닝된 동시성은 Lambda \n함수에 할당된 사전 초기화된 실행 환경의 수입니다. \n이러한 실행 환경은 들어오는 기능 요청에 즉시 응답하여 콜드 스타트 대기 시간을 \n줄입니다. 프로비저닝된 동시성을 구성하면 Lambda 서비스의 동시성 한도 도달로 인한 \n조절 오류를 방지하는 데도 도움이 됩니다. \nAWS Compute Optimizer 권장 사항에 따라 메모리를 늘리십시오. AWS Compute \nOptimizer 는 사용률 데이터를 기반으로 최적의 AWS 리소스 구성에 대한 권장 사항을 \n제공하는 서비스입니다. Lambda 함수에 할당된 메모리를 늘려 CPU 성능을 높이고 CPU \n집약적인 코드의 성능을 향상시킬 수도 있습니다. AWS Compute Optimizer 는 워크로드 \n특성 및 성능 목표를 기반으로 Lambda 함수에 대한 최적의 메모리 크기를 찾는 데 도움이 \n됩니다. \n이 솔루션은 메모리 및 CPU 리소스의 불필요한 과잉 프로비저닝을 방지하여 컴퓨팅 \n비용을 절감하고, 프로비저닝된 동시성 및 Lambda 함수에 대한 최적의 메모리 크기를 \n사용하여 서비스 대기 시간을 유지합니다.", "answer_choice": "D"}, "673": {"q_num": 673, "question": "AWS 를 사용하는 회사에는 매달 제조 프로세스에 필요한 리소스를 예측하는 솔루션이 \n필요합니다. 솔루션은 현재 Amazon S3 버킷에 저장된 기록 값을 사용해야 합니다. 회사는 \n기계 학습(ML) 경험이 없으며 교육 및 예측을 위해 관리형 서비스를 사용하려고 합니다. \n이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (2 개 선택) \nA. Amazon SageMaker 모델을 배포합니다. 추론을 위해 SageMaker 엔드포인트를 \n생성합니다. \nB. Amazon SageMaker 를 사용하여 S3 버킷의 기록 데이터를 사용하여 모델을 교육합니다. \nC. Amazon SageMaker 엔드포인트를 사용하여 입력을 기반으로 예측을 생성하는 함수 \nURL 로 AWS Lambda 함수를 구성합니다. \nD. Amazon Forecast 예측기를 사용하여 입력을 기반으로 예측을 생성하는 함수 URL 로 \nAWS Lambda 함수를 구성합니다. \nE. S3 버킷의 기록 데이터를 사용하여 Amazon Forecast 예측기를 교육합니다.", "answer_block": "Answer: B, E \n설명: \n현재 Amazon S3 버킷에 저장된 기록 값을 사용하여 매월 제조 프로세스에 필요한 \n리소스를 예측하려면 솔루션 설계자는 Amazon SageMaker 를 사용하여 S3 버킷의 기록 \n데이터를 사용하여 모델을 훈련하고 Amazon SageMaker 모델을 배포해야 합니다. 추론을 \n\n위해 SageMaker 엔드포인트를 생성합니다. Amazon SageMaker 는 기계 학습(ML) 모델을 \n쉽게 구축, 교육 및 배포할 수 있는 방법을 제공하는 완전관리형 서비스입니다. 솔루션 \n아키텍트는 SageMaker 에서 제공하는 기본 제공 알고리즘 또는 프레임워크를 사용하거나 \n자체 사용자 지정 코드를 가져와 S3 버킷의 기록 데이터를 입력으로 사용하여 모델을 \n교육할 수 있습니다. 그런 다음 훈련된 모델을 애플리케이션의 예측 요청을 처리할 수 있는 \n확장 가능하고 안전한 웹 서비스인 SageMaker 엔드포인트에 배포할 수 있습니다. 솔루션 \n아키텍트는 SageMaker\n를 사용하기 위해 ML 경험이 있거나 인프라를 관리할 필요가 \n없습니다.", "answer_choice": "B"}, "674": {"q_num": 674, "question": "한 \n회사에는 \n여러 \nAWS \n지역의 \nAmazon \nEC2 \n인스턴스에 \n배포된 \nHTTP \n기반 \n애플리케이션에 액세스하는 전 세계 사용자가 있습니다. 회사는 애플리케이션의 가용성과 \n성능을 개선하려고 합니다. 또한 회사는 가용성에 영향을 미치거나, 보안을 손상시키거나, \n과도한 리소스를 소비할 수 있는 일반적인 웹 공격으로부터 애플리케이션을 보호하려고 \n합니다. 고정 IP 주소가 필요합니다. \n이를 달성하기 위해 솔루션 설계자는 무엇을 권장해야 합니까? \nA. 각 지역의 NLB(Network Load Balancer) 뒤에 EC2 인스턴스를 배치합니다. NLB 에 AWS \nWAF 를 배포합니다. AWS Global Accelerator 를 사용하여 액셀러레이터를 생성하고 NLB 를 \n엔드포인트로 등록합니다. \nB. 각 지역의 ALB(Application Load Balancer) 뒤에 EC2 인스턴스를 배치합니다. ALB 에 \nAWS WAF 를 배포합니다. AWS Global Accelerator 를 사용하여 액셀러레이터를 생성하고 \nALB 를 엔드포인트로 등록합니다. \nC. 각 지역의 NLB(Network Load Balancer) 뒤에 EC2 인스턴스를 배치합니다. NLB 에 AWS \nWAF 를 배포합니다. Amazon Route 53 지연 시간 기반 라우팅을 사용하여 요청을 NLB 로 \n라우팅하는 오리진으로 Amazon CloudFront 배포를 생성합니다. \nD. 각 지역의 ALB(Application Load Balancer) 뒤에 EC2 인스턴스를 배치합니다. Amazon \nRoute 53 지연 시간 기반 라우팅을 사용하여 요청을 ALB\n로 라우팅하는 오리진으로 \nAmazon CloudFront 배포를 생성합니다. CloudFront 배포에 AWS WAF 를 배포합니다.", "answer_block": "Answer: A \n설명: \n회사는 애플리케이션의 가용성과 성능을 향상하는 동시에 일반적인 웹 공격으로부터 \n애플리케이션을 보호하기를 원합니다. 회사에는 애플리케이션에 대한 고정 IP 주소도 \n필요합니다. 이러한 요구 사항을 충족하려면 솔루션 설계자는 다음 솔루션을 권장해야 \n합니다. \n각 리전의 NLB(Network Load Balancer) 뒤에 EC2 인스턴스를 배치합니다. NLB 는 매우 \n\n짧은 대기 시간으로 높은 처리량을 유지하면서 초당 수백만 개의 요청을 처리하도록 \n설계되었습니다. NLB\n는 각 가용 영역에 대한 고정 IP 주소도 지원하는데, 이는 \n화이트리스트 작성이나 방화벽 목적에 유용할 수 있습니다. \nNLB 에 AWS WAF 를 배포합니다. AWS WAF 는 가용성, 보안 또는 성능에 영향을 미칠 수 \n있는 일반적인 웹 공격으로부터 웹 애플리케이션을 보호하는 데 도움이 되는 웹 \n애플리케이션 방화벽입니다. AWS WAF 를 사용하면 웹 애플리케이션에 대해 허용하거나 \n차단할 트래픽을 제어하는 사용자 지정 가능한 웹 보안 규칙을 정의할 수 있습니다. \nAWS Global Accelerator\n를 사용하여 액셀러레이터를 생성하고 NLB\n를 엔드포인트로 \n등록합니다. \nAWS Global Accelerator 는 로컬 또는 글로벌 사용자를 대상으로 애플리케이션의 가용성과 \n성능을 향상시키는 서비스입니다. 모든 AWS 리전의 애플리케이션 엔드포인트에 대한 고정 \n진입점 역할을 하는 고정 IP 주소를 제공합니다. AWS 글로벌 네트워크를 사용하여 \n사용자에서 애플리케이션까지의 경로를 최적화하여 TCP 및 UDP 트래픽의 성능을 \n향상시킵니다. \n이 솔루션은 가용 영역 및 지역 전반에 걸쳐 고가용성을 제공하고, AWS 글로벌 네트워크를 \n통해 트래픽을 라우팅하여 성능을 향상시키며, 일반적인 웹 공격으로부터 애플리케이션을 \n보호하고, 애플리케이션에 고정 IP 주소를 제공합니다.", "answer_choice": "A"}, "675": {"q_num": 675, "question": "전자상거래 회사에서 계절별 온라인 세일을 진행하고 있습니다. 이 회사는 여러 가용 \n영역에 걸쳐 있는 Amazon EC2 인스턴스에서 웹 사이트를 호스팅합니다. 회사는 자사 \n웹사이트에서 세일 기간 동안 급격한 트래픽 증가를 관리할 수 있기를 원합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. 최대 트래픽 로드를 처리할 수 있을 만큼 큰 Auto Scaling 그룹을 생성합니다. Amazon \nEC2 인스턴스의 절반을 중지합니다. 트래픽이 증가하면 중지된 인스턴스를 사용하여 \n확장하도록 Auto Scaling 그룹을 구성합니다. \nB. 웹 사이트에 대한 Auto Scaling 그룹을 생성합니다. 확장할 필요 없이 높은 트래픽 \n볼륨을 처리할 수 있도록 Auto Scaling 그룹의 최소 크기를 설정합니다. \nC. Amazon CIoudFront 및 Amazon ElastiCache 를 사용하여 Auto Scaling 그룹을 원본으로 \n설정하여 동적 콘텐츠를 캐시합니다. CIoudFront 및 ElastiCache 를 채우는 데 필요한 \n인스턴스로 Auto Scaling 그룹을 구성합니다. 캐시가 완전히 채워진 후 규모를 축소합니다. \nD. 트래픽 증가에 따라 확장되도록 Auto Scaling 그룹을 구성합니다. 사전 구성된 Amazon \n머신 이미지(AMI)에서 새 인스턴스를 시작하기 위한 시작 템플릿을 생성합니다.", "answer_block": "Answer: D", "answer_choice": "D"}, "676": {"q_num": 676, "question": "한 회사가 Amazon RDS 데이터베이스를 사용하여 Amazon EC2 인스턴스에 애플리케이션을 \n배포했습니다. 회사는 최소 권한 원칙을 사용하여 데이터베이스 액세스 자격 증명을 \n구성했습니다. 회사의 보안 팀은 SQL 주입 및 기타 웹 기반 공격으로부터 애플리케이션과 \n데이터베이스를 보호하려고 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 보안 그룹과 네트워크 ACL\n을 사용하여 데이터베이스와 애플리케이션 서버를 \n보호하십시오. \nB. AWS WAF 를 사용하여 애플리케이션을 보호하십시오. RDS 매개변수 그룹을 사용하여 \n보안 설정을 구성합니다. \nC. AWS 네트워크 방화벽을 사용하여 애플리케이션과 데이터베이스를 보호하십시오. \nD. 다양한 기능을 위해 애플리케이션 코드에서 다양한 데이터베이스 계정을 사용합니다. \n데이터베이스 사용자에게 과도한 권한을 부여하지 마십시오.", "answer_block": "Answer: B \n설명: \nAWS WAF\n는 애플리케이션 가용성에 영향을 미치거나 보안을 손상시키거나 과도한 \n리소스를 소비할 수 있는 일반적인 웹 공격으로부터 웹 애플리케이션을 보호하는 데 도움이 \n되는 웹 애플리케이션 방화벽입니다. AWS WAF 를 통해 사용자는 사용자 정의 가능한 웹 \n보안 규칙을 기반으로 웹 요청을 차단, 허용 또는 계산하는 규칙을 생성할 수 있습니다. \n생성할 수 있는 규칙 유형 중 하나는 사용자가 허용하거나 차단할 IP 주소 또는 IP 주소 \n범위 목록을 지정할 수 있는 SQL 삽입 규칙입니다. AWS WAF 를 사용하여 애플리케이션을 \n보호함으로써 회사는 SQL 주입 및 기타 웹 기반 공격이 애플리케이션과 데이터베이스에 \n도달하는 것을 방지할 수 있습니다. \nRDS 파라미터 그룹은 데이터베이스 인스턴스 작동 방식을 정의하는 파라미터 모음입니다. \n사용자는 매개변수 그룹의 매개변수를 수정하여 데이터베이스의 동작과 성능을 변경할 수 \n있습니다. RDS 매개변수 그룹을 사용하여 보안 설정을 구성함으로써 회사는 원격 루트 \n로그인 비활성화, SSL 연결 요구, 최대 연결 수 제한과 같은 모범 사례를 적용할 수 \n있습니다. \n다른 옵션은 SQL 주입 및 기타 웹 기반 공격으로부터 애플리케이션과 데이터베이스를 \n효과적으로 보호하지 못하기 때문에 올바르지 않습니다. 보안 그룹과 네트워크 ACL 을 \n사용하여 데이터베이스와 애플리케이션 서버를 보호하는 것만으로는 충분하지 않습니다. \n왜냐하면 애플리케이션 계층이 아닌 네트워크 계층에서만 트래픽을 필터링하기 때문입니다. \nAWS 네트워크 방화벽을 사용하여 애플리케이션과 데이터베이스를 보호할 필요는 없습니다. \n이는 개별 애플리케이션이나 데이터베이스가 아닌 VPC 에 대한 네트워크 보호를 제공하는 \n상태 저장 방화벽 서비스이기 때문입니다. 서로 다른 기능을 위해 애플리케이션 코드에서 \n\n서로 다른 데이터베이스 계정을 사용하는 것은 좋은 습관이지만 SQL 주입 공격이 \n애플리케이션 코드의 취약점을 악용하는 것을 방지할 수는 없습니다.", "answer_choice": "B"}, "677": {"q_num": 677, "question": "회사는 온프레미스 데이터 센터에서 여러 워크로드를 실행합니다. 회사의 데이터 센터는 \n회사의 확장되는 비즈니스 요구 사항을 충족할 만큼 빠르게 확장할 수 없습니다. 회사는 \nAWS 로의 마이그레이션을 계획하기 위해 온프레미스 서버 및 워크로드에 대한 사용량 및 \n구성 데이터를 수집하려고 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. AWS Migration Hub 에서 홈 AWS 리전을 설정합니다. AWS Systems Manager 를 사용하여 \n온프레미스 서버에 대한 데이터를 수집합니다. \nB. AWS Migration Hub 에서 홈 AWS 지역을 설정합니다. AWS Application Discovery \nService 를 사용하여 온프레미스 서버에 대한 데이터를 수집합니다. \nC. AWS Schema Conversion Tool(AWS SCT)을 사용하여 관련 템플릿을 생성합니다. AWS \nTrusted Advisor 를 사용하여 온프레미스 서버에 대한 데이터를 수집합니다. \nD. AWS SCT(AWS Schema Conversion Tool)를 사용하여 관련 템플릿을 생성합니다. AWS \nDatabase Migration Service(AWS DMS)를 사용하여 온프레미스 서버에 대한 데이터를 \n수집합니다.", "answer_block": "Answer: B \n설명: \n회사의 요구 사항에 가장 적합한 솔루션은 AWS Migration Hub 에서 홈 AWS 리전을 \n설정하고 AWS Application Discovery Service 를 사용하여 온프레미스 서버에 대한 데이터를 \n수집하는 것입니다. 이 솔루션을 통해 회사는 온프레미스 서버 및 워크로드의 사용량 및 \n구성 데이터를 수집하고 AWS 로의 마이그레이션을 계획할 수 있습니다. \nAWS Migration Hub 는 마이그레이션 상태 정보를 단일 콘솔에 집계하여 마이그레이션 \n추적을 단순화하고 가속화하는 서비스입니다. 사용자는 검색된 서버를 보고, 이를 \n애플리케이션으로 그룹화하고, 홈 리전의 Migration Hub 콘솔에서 각 애플리케이션의 \n마이그레이션 상태를 추적할 수 있습니다. 홈 리전은 마이그레이션하는 리전과 관계없이 \n사용자가 마이그레이션 데이터를 저장하는 AWS 리전입니다. \nAWS Application Discovery Service 는 온프레미스 서버 및 데이터베이스에 대한 사용량 및 \n구성 데이터를 수집하여 사용자가 AWS 로의 마이그레이션을 계획하는 데 도움을 주는 \n서비스입니다. \nApplication Discovery Service 는 AWS Migration Hub 와 통합되어 에이전트 없는 검색과 \n에이전트 기반 검색이라는 두 가지 검색 수행 방법을 지원합니다. 가상 머신(VM) 및 \n데이터베이스에 대한 정적 구성 데이터와 활용도 데이터를 수집하는 VMware vCenter 를 \n\n통해 Application Discovery Service Agentless Collector 를 배포하여 에이전트 없는 검색을 \n수행할 수 있습니다. 에이전트 기반 검색은 정적 구성 데이터, 상세한 시계열 시스템 성능 \n정보, 인바운드 및 아웃바운드 네트워크 연결, 실행 중인 프로세스를 수집하는 AWS \nApplication Discovery Agent 를 각 VM 및 물리적 서버에 배포하여 수행할 수 있습니다. \n다른 옵션은 요구 사항을 충족하지 않거나 사용 사례와 관련이 없기 때문에 올바르지 \n않습니다. AWS Schema Conversion Tool(AWS SCT)을 사용하여 관련 템플릿을 생성하고 \nAWS Trusted Advisor\n를 사용하여 온프레미스 서버에 대한 데이터를 수집하는 것은 \n올바르지 않습니다. 이 솔루션은 온프레미스 서버의 사용 및 구성 데이터를 수집하는 데 \n적합하지 않기 때문입니다. 작업 부하. AWS SCT 는 사용자가 데이터베이스 스키마와 코드 \n객체를 \n한 \n데이터베이스 \n엔진에서 \n다른 \n데이터베이스 \n엔진(예: \nOracle\n에서 \nPostgreSQL 로)으로 변환하는 데 도움이 되는 도구입니다. AWS Trusted Advisor 는 비용 \n최적화, 성능, 보안, 내결함성 및 서비스 제한에 대한 모범 사례 권장 사항을 제공하는 \n서비스입니다. AWS Schema Conversion Tool(AWS SCT)을 사용하여 관련 템플릿을 \n생성하고 AWS Database Migration Service(AWS DMS)를 사용하여 온프레미스 서버에 대한 \n데이터를 수집하는 것은 올바르지 않습니다. 이 솔루션은 사용 및 구성 데이터를 수집하는 \n데 적합하지 않기 때문입니다. 온프레미스 서버 및 워크로드. 위에서 언급한 것처럼 AWS \nSCT 는 사용자가 데이터베이스 스키마와 코드 객체를 한 데이터베이스 엔진에서 다른 \n데이터베이스 엔진으로 변환하는 데 도움이 되는 도구입니다. AWS DMS 는 사용자가 가동 \n중지 시간을 최소화하면서 관계형 데이터베이스, 비관계형 데이터베이스 및 기타 유형의 \n데이터 스토어를 AWS 로 마이그레이션하는 데 도움이 되는 서비스입니다.", "answer_choice": "B"}, "678": {"q_num": 678, "question": "개발팀이 다른 회사와 협력하여 통합 제품을 만들고 있습니다. 다른 회사는 개발 팀의 \n계정에 포함된 Amazon Simple Queue Service(Amazon SQS) 대기열에 액세스해야 합니다. \n다른 회사는 자신의 계정 권한을 포기하지 않고 대기열을 폴링하려고 합니다. \n솔루션 설계자는 SQS 대기열에 대한 액세스를 어떻게 제공해야 합니까? \nA. 다른 회사에 SQS 대기열에 대한 액세스를 제공하는 인스턴스 프로필을 생성합니다. \nB. SQS 대기열에 대한 다른 회사 액세스를 제공하는 IAM 정책을 생성합니다. \nC. SQS 대기열에 대한 다른 회사 액세스를 제공하는 SQS 액세스 정책을 만듭니다. \nD. \n다른 \n회사에 \nSQS \n대기열에 \n대한 \n액세스를 \n제공하는 \nAmazon \nSimple \n알림 \n서비스(Amazon SNS) 액세스 정책을 생성합니다.", "answer_block": "Answer: C \n설명: \n자체 계정 권한을 포기하지 않고 다른 회사에 SQS 대기열에 대한 액세스를 제공하려면 \n솔루션 설계자는 SQS 대기열에 대한 다른 회사 액세스를 제공하는 SQS 액세스 정책을 \n\n생성해야 합니다. SQS 액세스 정책은 대기열에 액세스할 수 있는 사람과 그들이 수행할 수 \n있는 작업을 정의하는 리소스 기반 정책입니다. 정책은 상대 회사의 AWS 계정 ID 를 \n주체로 지정하고 sqs:ReceiveMessage, sqs:DeleteMessage 및 sqs:GetQueueAttributes 와 \n같은 작업에 대한 권한을 부여할 수 있습니다. 이렇게 하면 다른 회사가 역할을 맡거나 \n교차 계정 액세스 키를 사용할 필요 없이 자체 자격 증명을 사용하여 대기열을 폴링할 수 \n있습니다.", "answer_choice": "C"}, "679": {"q_num": 679, "question": "회사에 스토리지 용량이 부족한 온프레미스 데이터 센터가 있습니다. 회사는 대역폭 비용을 \n최소화하면서 스토리지 인프라를 AWS 로 마이그레이션하려고 합니다. 솔루션은 추가 비용 \n없이 데이터를 즉시 검색할 수 있어야 합니다. \n이러한 요구 사항을 어떻게 충족할 수 있습니까? \nA. Amazon S3 Glacier Vault 를 배포하고 빠른 검색을 활성화합니다. 워크로드에 대해 \n프로비저닝된 검색 용량을 활성화합니다. \nB. 캐시된 볼륨을 사용하여 AWS Storage Gateway 를 배포합니다. Storage Gateway 를 \n사용하면 자주 액세스하는 데이터 하위 집합의 복사본을 로컬에 보관하면서 Amazon S3 에 \n데이터를 저장할 수 있습니다. \nC. 저장된 볼륨을 사용하여 AWS Storage Gateway 를 배포하여 데이터를 로컬에 저장합니다. \nStorage Gateway 를 사용하여 데이터의 특정 시점 스냅샷을 Amazon S3 에 비동기식으로 \n백업합니다. \nD. AWS Direct Connect 를 배포하여 온프레미스 데이터 센터에 연결합니다. 데이터를 \n로컬에 저장하도록 AWS Storage Gateway 를 구성합니다. Storage Gateway 를 사용하여 \n데이터의 특정 시점 스냅샷을 Amazon S3 에 비동기식으로 백업합니다.", "answer_block": "Answer: B \n설명: \n요구 사항을 충족하는 솔루션은 캐시된 볼륨을 사용하여 AWS Storage Gateway 를 배포하고 \nStorage Gateway 를 사용하여 자주 액세스하는 데이터 하위 집합의 복사본을 로컬에서 \n유지하면서 Amazon S3 에 데이터를 저장하는 것입니다. 이 솔루션을 사용하면 회사는 \n로컬에 캐시되지 않은 데이터만 전송하므로 대역폭 비용을 최소화하면서 스토리지 인프라를 \nAWS 로 마이그레이션할 수 있습니다. 또한 이 솔루션을 사용하면 캐시된 볼륨이 가장 \n최근에 사용한 데이터에 대한 짧은 대기 시간 액세스를 제공하므로 추가 비용 없이 \n데이터를 즉시 검색할 수 있습니다. Amazon S3 에 저장된 데이터는 내구성, 확장성 및 \n보안이 유지됩니다. \n다른 솔루션은 요구 사항을 충족하지 못하거나 추가 비용이나 복잡성이 발생하기 때문에 첫 \n번째 솔루션만큼 효과적이지 않습니다. Amazon S3 Glacier Vault 를 배포하고 빠른 검색을 \n\n활성화하면 저장 및 검색 모두에 추가 비용이 발생하므로 요구 사항을 충족하지 못합니다. \nAmazon S3 Glacier 는 데이터 보관 및 백업을 위한 저렴한 스토리지 서비스이지만 Amazon \nS3 보다 검색 시간이 더 깁니다. 신속 검색은 데이터에 더 빠르게 액세스할 수 있는 \n기능이지만 검색된 GB 당 더 높은 요금을 청구합니다. \n프로비저닝된 검색 용량은 신속한 검색을 위해 전용 용량을 예약하는 기능이지만, \n프로비저닝된 용량 단위당 월별 요금도 청구합니다. 저장된 볼륨을 사용하여 데이터를 \n로컬에 저장하고 Storage Gateway 를 사용하여 데이터의 특정 시점 스냅샷을 Amazon S3 에 \n비동기적으로 백업하는 AWS Storage Gateway 를 배포하면 스토리지 인프라를 AWS 로 \n마이그레이션하지 않고 요구 사항을 충족하지 못합니다. 백업을 만듭니다. 저장 볼륨은 \n기본 데이터를 로컬에 저장하고 스냅샷을 Amazon S3 에 백업하는 볼륨입니다. 이 솔루션은 \n온프레미스에 필요한 스토리지 용량을 줄이지 않으며 클라우드 스토리지의 이점을 \n활용하지도 않습니다. 온프레미스 데이터 센터에 연결하기 위해 AWS Direct Connect 를 \n배포하고 데이터를 로컬에 저장하고 Storage Gateway 를 사용하여 데이터의 특정 시점 \n스냅샷을 Amazon S3 에 비동기식으로 백업하도록 AWS Storage Gateway 를 구성하는 것은 \n요구 사항을 충족하지 않습니다. 또한 스토리지 인프라를 AWS 로 마이그레이션하지 않고 \n백업만 생성합니다. AWS Direct Connect 는 온프레미스 데이터 센터와 AWS 간에 전용 \n네트워크 연결을 설정하는 서비스로, 이를 통해 네트워크 비용을 절감하고 대역폭을 늘릴 \n수 있습니다. 그러나 이 솔루션은 온프레미스에 필요한 스토리지 용량을 줄이지 않으며 \n클라우드 스토리지의 이점을 활용하지도 않습니다.", "answer_choice": "B"}, "680": {"q_num": 680, "question": "회사는 AWS\n로 마이그레이션하고 애플리케이션에 Amazon EC2 온디맨드 인스턴스를 \n사용할 계획입니다. 마이그레이션 테스트 단계에서 기술 팀은 애플리케이션이 완전히 \n생산되기 위해 메모리를 실행하고 로드하는 데 오랜 시간이 걸린다는 사실을 관찰했습니다. \n다음 테스트 단계에서 애플리케이션 실행 시간을 단축할 솔루션은 무엇입니까? \nA. 두 개 이상의 EC2 온디맨드 인스턴스를 시작합니다. Auto Scaling 기능을 활성화하고 \n다음 테스트 단계에서 EC2 온디맨드 인스턴스를 사용할 수 있도록 하십시오. \nB. EC2 스팟 인스턴스를 시작하여 애플리케이션을 지원하고 다음 테스트 단계에서 사용할 \n수 있도록 애플리케이션을 확장합니다. \nC. 최대 절전 모드를 활성화한 상태에서 EC2 온디맨드 인스턴스를 시작합니다. 다음 \n테스트 단계에서 EC2 Auto Scaling 웜 풀을 구성합니다. \nD. 용량 예약을 통해 EC2 온디맨드 인스턴스를 시작합니다. 다음 테스트 단계에서 추가 \nEC2 인스턴스를 시작하십시오.", "answer_block": "Answer: C \n설명: \n\n다음 테스트 단계에서 애플리케이션 시작 시간을 줄이는 솔루션은 최대 절전 모드가 설정된 \nEC2 온디맨드 인스턴스를 시작하고 EC2 Auto Scaling 웜 풀을 구성하는 것입니다. 이 \n솔루션을 사용하면 애플리케이션을 처음부터 시작하는 대신 최대 절전 모드에서 다시 \n시작할 수 있으므로 시간과 리소스를 절약할 수 있습니다. 최대 절전 모드는 EC2 \n인스턴스의 메모리(RAM) 상태를 루트 EBS 볼륨에 유지한 다음 인스턴스를 중지합니다. \n인스턴스가 재개되면 EBS 볼륨에서 메모리 상태를 복원하고 빠르게 생산성을 발휘합니다. \nEC2 Auto Scaling 웜 풀은 필요할 때 확장할 준비가 되어 있는 사전 초기화된 인스턴스 \n풀을 유지하는 데 사용할 수 있습니다. Warm 풀은 최대 절전 모드 인스턴스를 지원할 수도 \n있으므로 시작 시간과 확장 비용을 더욱 줄일 수 있습니다. \n다른 솔루션은 시작 시간을 단축하지 않거나, 가용성을 보장하지 않거나, 필요에 따라 \n온디맨드 인스턴스를 사용하지 않기 때문에 첫 번째 솔루션만큼 효과적이지 않습니다. \nAuto Scaling 기능이 있는 두 개 이상의 EC2 온디맨드 인스턴스를 시작해도 각 인스턴스가 \n여전히 초기화 프로세스를 거쳐야 하므로 애플리케이션의 시작 시간이 줄어들지 않습니다. \nEC2 스팟 인스턴스를 시작한다고 해서 가용성이 보장되는 것은 아닙니다. 용량에 대한 \n수요가 높아지면 언제든지 AWS 가 스팟 인스턴스를 중단할 수 있기 때문입니다. 용량 \n예약을 통해 EC2 온디맨드 인스턴스를 시작하면 인스턴스에 사용할 수 있는 용량이 \n충분한지 확인만 할 뿐 사전 초기화는 하지 않으므로 애플리케이션 시작 시간이 줄어들지 \n않습니다.", "answer_choice": "C"}, "681": {"q_num": 681, "question": "보안 요구 사항을 충족하려면 회사는 Amazon RDS MySQL DB 인스턴스와 통신하는 동안 \n전송 중인 모든 애플리케이션 데이터를 암호화해야 합니다. 최근 보안 감사에서는 AWS Key \nManagement Service(AWS KMS)를 사용하여 저장 데이터 암호화가 활성화되었지만 전송 \n중인 데이터는 활성화되지 않은 것으로 나타났습니다. \n솔루션 설계자는 보안 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. 데이터베이스에서 IAM 데이터베이스 인증을 활성화합니다. \nB. 자체 서명된 인증서를 제공합니다. RDS 인스턴스에 대한 모든 연결에 인증서를 \n사용하십시오. \nC. RDS 인스턴스의 스냅샷을 찍습니다. 암호화가 활성화된 새 인스턴스로 스냅샷을 \n복원합니다. \nD. AWS 에서 제공하는 루트 인증서를 다운로드합니다. RDS 인스턴스에 대한 모든 연결에 \n인증서를 제공하십시오.", "answer_block": "Answer: D \n설명: \n보안 요구 사항을 충족하려면 솔루션 아키텍트는 AWS\n에서 제공하는 루트 인증서를 \n\n다운로드하고 RDS 인스턴스에 대한 모든 연결에 인증서를 제공해야 합니다. 이렇게 하면 \n애플리케이션과 \nRDS \n인스턴스 \n간에 \n전송되는 \n데이터에 \n대해 \nSSL/TLS \n암호화가 \n활성화됩니다. \nSSL/TLS 암호화는 클라이언트와 서버 간에 이동하는 데이터를 암호화하여 보안 계층을 \n제공합니다. Amazon RDS\n는 SSL 인증서를 생성하고 인스턴스가 프로비저닝되면 DB \n인스턴스에 인증서를 설치합니다. 애플리케이션은 AWS 가 제공한 루트 인증서를 사용하여 \nDB 인스턴스의 신원을 확인하고 보안 연결을 설정할 수 있습니다. \n다른 옵션은 전송 중인 데이터에 대한 암호화를 활성화하지 않거나 사용 사례와 관련이 \n없기 때문에 올바르지 않습니다. 데이터베이스에서 IAM 데이터베이스 인증을 활성화하는 \n것은 올바르지 않습니다. 이 옵션은 암호화가 아닌 인증 방법만 제공하기 때문입니다. IAM \n데이터베이스 인증을 통해 사용자는 데이터베이스 사용자 이름과 암호를 사용하는 대신 \nAWS Identity and Access Management(IAM) 사용자 및 역할을 사용하여 데이터베이스에 \n액세스할 수 있습니다. 이 옵션은 안전하지 않거나 신뢰할 수 없기 때문에 자체 서명된 \n인증서를 제공하는 것은 올바르지 않습니다. 자체 서명 인증서는 신뢰할 수 있는 인증 \n기관(CA)이 아닌 이를 발급한 동일한 엔터티에 의해 서명된 인증서입니다. 자체 서명된 \n인증서는 쉽게 위조되거나 손상될 수 있으며 대부분의 브라우저 및 애플리케이션에서 \n인식되지 않습니다. \nRDS 인스턴스의 스냅샷을 찍어 암호화가 활성화된 새 인스턴스로 복원하는 것은 올바르지 \n않습니다. 이 옵션은 전송 중 암호화가 아닌 유휴 암호화만 활성화하기 때문입니다. 미사용 \n암호화는 디스크에 저장된 데이터를 보호하지만 클라이언트와 서버 간에 이동하는 데이터는 \n보호하지 않습니다.", "answer_choice": "D"}, "682": {"q_num": 682, "question": "한 회사에서 모바일 장치용 멀티플레이어 게임을 배포했습니다. 이 게임에는 위도와 경도를 \n기반으로 플레이어의 실시간 위치 추적이 필요합니다. 게임의 데이터 저장소는 신속한 \n업데이트와 위치 검색을 지원해야 합니다. \n이 게임은 읽기 전용 복제본이 있는 PostgreSQL DB 인스턴스용 Amazon RDS 를 사용하여 \n위치 데이터를 저장합니다. 사용량이 가장 많은 기간에는 데이터베이스가 업데이트를 읽고 \n쓰는 데 필요한 성능을 유지할 수 없습니다. 게임의 사용자 기반이 빠르게 증가하고 \n있습니다. \n데이터 계층의 성능을 향상하려면 솔루션 설계자가 무엇을 해야 합니까? \nA. 기존 DB 인스턴스의 스냅샷을 찍습니다. 다중 AZ 가 활성화된 스냅샷을 복원합니다. \nB. OpenSearch 대시보드를 사용하여 Amazon RDS 에서 Amazon OpenSearch Service 로 \n마이그레이션합니다. \nC. 기존 DB 인스턴스 앞에 Amazon DynamoDB Accelerator(DAX)를 배포합니다. DAX 를 \n\n사용하도록 게임을 수정합니다. \nD. 기존 DB 인스턴스 앞에 Redis 용 Amazon ElastiCache 클러스터를 배포합니다. Redis 를 \n사용하도록 게임을 수정합니다.", "answer_block": "Answer: D \n설명: \n데이터 계층의 성능을 향상시키는 솔루션은 기존 DB 인스턴스 앞에 Redis 용 Amazon \nElastiCache 클러스터를 배포하고 Redis 를 사용하도록 게임을 수정하는 것입니다. Redis 는 \n지리공간 데이터 유형과 명령을 지원하는 메모리 내 데이터 저장소이므로 이 솔루션을 \n사용하면 게임에서 빠르고 확장 가능한 방식으로 플레이어의 위치 데이터를 저장하고 \n검색할 수 있습니다. Redis 용 ElastiCache 를 사용하면 게임에서 빈도가 높은 업데이트 및 \n위치 데이터 쿼리에 최적화되지 않은 PostgreSQL DB 인스턴스용 RDS 의 로드를 줄일 수 \n있습니다. Redis 용 ElastiCache 는 증가하는 게임 사용자 기반을 처리하기 위해 복제, 샤딩 \n및 자동 크기 조정도 지원합니다. \n다른 솔루션은 성능을 향상시키지 않거나 지리공간 데이터를 지원하지 않거나 캐싱을 \n활용하지 않기 때문에 첫 번째 솔루션만큼 효과적이지 않습니다. 기존 DB 인스턴스의 \n스냅샷을 생성하고 다중 AZ 가 활성화된 상태로 복원하면 데이터 계층의 성능이 향상되지 \n않습니다. 이는 높은 가용성과 내구성만 제공할 뿐 확장성이나 짧은 지연 시간은 제공하지 \n않기 때문입니다. OpenSearch Dashboards\n를 사용하여 Amazon RDS\n에서 Amazon \nOpenSearch Service\n로 마이그레이션해도 데이터 계층의 성능은 향상되지 않습니다. \nOpenSearch Service 는 주로 실시간 위치 추적이 아닌 전체 텍스트 검색 및 분석을 위해 \n설계되었기 때문입니다. OpenSearch 서비스는 Redis 와 달리 기본적으로 지리공간 데이터 \n유형 및 명령을 지원하지 않습니다. 기존 DB 인스턴스 앞에 Amazon DynamoDB \nAccelerator(DAX)를 배포하고 DAX 를 사용하도록 게임을 수정해도 데이터 계층의 성능은 \n향상되지 않습니다. 왜냐하면 DAX 는 PostgreSQL 용 RDS 가 아닌 DynamoDB 하고만 \n호환되기 때문입니다. DAX 는 지리공간 데이터 유형 및 명령도 지원하지 않습니다.", "answer_choice": "D"}, "683": {"q_num": 683, "question": "솔루션 설계자는 보안 그룹이 0.0.0.0/0 의 SSH 를 허용하는 규칙을 포함할 수 없다고 \n명시하는 회사의 규정 준수 정책에 대한 자동화된 솔루션을 제공해야 합니다. 정책을 \n위반한 경우 회사에 통보해야 합니다. 가능한 한 빨리 해결책이 필요합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하려면 솔루션 설계자가 무엇을 해야 \n합니까? \nA. 0.0.0.0/0 주소에 열려 있는 SSH 에 대한 보안 그룹을 모니터링하고 이를 발견할 때마다 \n알림을 생성하는 AWS Lambda 스크립트를 작성합니다. \nB. 제한된 SSH AWS Config 관리형 규칙을 활성화하고 비준수 규칙이 생성되면 Amazon \n\nSimple 알림 서비스(Amazon SNS) 알림을 생성합니다. \nC. 전 세계적으로 보안 그룹 및 네트워크 ACL 을 열 수 있는 권한이 있는 IAM 역할을 \n생성합니다. \n사용자가 역할을 맡을 때마다 알림을 생성하려면 Amazon Simple 알림 서비스(Amazon SNS) \n주제를 생성합니다. \nD. 관리자가 아닌 사용자가 보안 그룹을 생성하거나 편집하는 것을 방지하는 서비스 제어 \n정책(SCP)을 구성합니다. 사용자가 관리자 권한이 필요한 규칙을 요청할 때 티켓팅 \n시스템에 알림을 만듭니다.", "answer_block": "Answer: B \n설명: \n회사의 규정 준수 정책에 가장 적합한 솔루션은 제한된 SSH AWS Config 관리형 규칙을 \n활성화하고 비준수 규칙이 생성될 때 Amazon Simple 알림 서비스(Amazon SNS) 알림을 \n생성하는 것입니다. 이 솔루션은 사용자가 AWS 리소스의 구성을 평가, 감사 및 평가할 수 \n있는 서비스인 AWS Config 에서 이미 사용 가능한 사전 정의된 규칙을 사용하기 때문에 \n운영 오버헤드가 가장 적습니다. 제한된 SSH 규칙은 사용 중인 보안 그룹에 0.0.0.0/0 \n주소에서 SSH 를 허용하는 인바운드 규칙이 있는지 확인하고 이를 비준수로 보고합니다. \n사용자는 규정을 준수하지 않는 변경 사항이 발생할 때 Amazon SNS 주제에 알림을 \n보내도록 규칙을 구성하고 주제를 구독하여 이메일, SMS 또는 기타 방법을 통해 알림을 \n받을 수 있습니다. \n다른 옵션은 운영 오버헤드가 더 많거나 요구 사항을 충족하지 않기 때문에 올바르지 \n않습니다. 0.0.0.0/0 주소에 열려 있는 SSH 에 대한 보안 그룹을 모니터링하고 잘못된 \n주소를 발견할 때마다 알림을 생성하는 AWS Lambda 스크립트를 작성하려면 사용자 지정 \n코드 개발 및 유지 관리가 필요하므로 솔루션에 복잡성과 비용이 추가됩니다. 전역적으로 \n보안 그룹 및 네트워크 ACL 을 열 수 있는 권한이 있는 IAM 역할을 생성하고 사용자가 \n역할을 맡을 때마다 알림을 생성하는 Amazon SNS 주제를 생성하는 것은 올바르지 \n않습니다. 이는 비준수 규칙 생성을 방지하거나 감지하지 못하기 때문입니다. 다른 사용자 \n또는 역할과 관련이 있으며 정책을 위반할 수 있는 기존 규칙을 다루지 않습니다. 관리자가 \n아닌 사용자가 보안 그룹을 생성하거나 편집하는 것을 방지하는 서비스 제어 정책(SCP)을 \n구성하고, 사용자가 관리자 권한이 필요한 규칙을 요청할 때 티켓팅 시스템에서 알림을 \n생성하는 것은 자동화된 솔루션을 제공하지 않기 때문에 올바르지 않습니다. 정책 집행 및 \n통지를 위해 사용자의 유연성과 생산성을 제한할 수 있습니다.", "answer_choice": "B"}, "684": {"q_num": 684, "question": "회사에는 온프레미스 파일 시스템이 SFTP 를 통해 매일 수신하는 보고서 파일을 분석하는 \n야간 일괄 처리 루틴이 있습니다. 회사는 솔루션을 AWS 클라우드로 이전하려고 합니다. \n\n솔루션은 가용성과 복원력이 높아야 합니다. 또한 솔루션은 운영 노력을 최소화해야 \n합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. SFTP 용 AWS 전송 및 스토리지용 Amazon Elastic File System(Amazon EFS) 파일 \n시스템을 배포합니다. 예약된 조정 정책이 있는 Auto Scaling 그룹의 Amazon EC2 \n인스턴스를 사용하여 배치 작업을 실행합니다. \nB. Linux 및 SFTP 서비스를 실행하는 Amazon EC2 인스턴스를 배포합니다. 저장에는 \nAmazon Elastic Block Store(Amazon EBS) 볼륨을 사용하십시오. 최소 인스턴스 수와 \n원하는 인스턴스 수를 1 로 설정한 Auto Scaling 그룹을 사용합니다. \nC. Linux 및 SFTP 서비스를 실행하는 Amazon EC2 인스턴스를 배포합니다. 저장을 위해 \nAmazon Elastic File System(Amazon EFS) 파일 시스템을 사용합니다. 최소 인스턴스 수와 \n원하는 인스턴스 수를 1 로 설정한 Auto Scaling 그룹을 사용합니다. \nD. SFTP 용 AWS 전송과 저장용 Amazon S3 버킷을 배포합니다. 처리를 위해 Amazon \nS3 에서 Amazon EC2 인스턴스로 배치 파일을 가져오도록 애플리케이션을 수정합니다. \n예약된 조정 정책이 있는 Auto Scaling 그룹의 EC2 인스턴스를 사용하여 일괄 작업을 \n실행합니다.", "answer_block": "Answer: D \n설명: \n고가용성, 성능, 보안 및 고정 IP 주소 요구 사항을 충족하는 솔루션은 Amazon CloudFront, \nALB(Application Load Balancer), Amazon Route 53 및 AWS WAF 를 사용하는 것입니다. 이 \n솔루션을 통해 회사는 엣지 로케이션에 콘텐츠를 캐시하고 각 엣지 로케이션에 고정 IP \n주소를 제공하는 CDN(콘텐츠 전송 네트워크) 서비스인 CloudFront 를 사용하여 HTTP 기반 \n애플리케이션을 전 세계적으로 배포할 수 있습니다. 또한 회사는 Route 53 지연 시간 기반 \n라우팅을 사용하여 각 지역에서 가장 가까운 ALB 로 요청을 라우팅하여 EC2 인스턴스 \n전체에 로드 균형을 맞출 수 있습니다. 또한 회사는 정의된 조건에 따라 웹 요청을 허용, \n차단 또는 계산하는 규칙을 생성하여 일반적인 웹 공격으로부터 애플리케이션을 보호하기 \n위해 CloudFront 배포에 AWS WAF 를 배포할 수도 있습니다. 다른 솔루션은 HTTP 기반 \n애플리케이션을 지원하지 않는 NLB(Network Load Balancer)를 사용하거나 AWS Global \nAccelerator 보다 더 나은 성능과 보안을 제공하는 CloudFront 를 사용하지 않기 때문에 \n모든 요구 사항을 충족하지 못합니다.", "answer_choice": "D"}, "685": {"q_num": 685, "question": "온라인 비디오 게임 회사는 게임 서버에 대해 매우 낮은 대기 시간을 유지해야 합니다. \n게임 서버는 Amazon EC2 인스턴스에서 실행됩니다. 회사에는 초당 수백만 건의 UDP \n인터넷 트래픽 요청을 처리할 수 있는 솔루션이 필요합니다. \n\n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. 인터넷 트래픽에 필요한 프로토콜과 포트로 Application Load Balancer 를 구성합니다. \nEC2 인스턴스를 대상으로 지정합니다. \nB. 인터넷 트래픽을 위한 게이트웨이 로드 밸런서를 구성합니다. EC2 인스턴스를 대상으로 \n지정합니다. \nC. 인터넷 트래픽에 필요한 프로토콜과 포트로 Network Load Balancer 를 구성합니다. EC2 \n인스턴스를 대상으로 지정합니다. \nD. 별도의 AWS 지역에 있는 EC2 인스턴스에서 동일한 게임 서버 세트를 시작합니다. \n인터넷 트래픽을 두 EC2 인스턴스 세트로 라우팅합니다.", "answer_block": "Answer: C \n설명: \n온라인 비디오 게임 회사를 위한 가장 비용 효율적인 솔루션은 인터넷 트래픽에 필요한 \n프로토콜과 포트로 Network Load Balancer 를 구성하고 EC2 인스턴스를 대상으로 지정하는 \n것입니다. 이 솔루션을 통해 회사는 매우 짧은 대기 시간과 고성능으로 초당 수백만 개의 \nUDP 요청을 처리할 수 있습니다. \nNetwork Load Balancer 는 연결 수준(계층 4)에서 작동하고 IP 프로토콜 데이터를 기반으로 \nAmazon VPC 내의 대상(EC2 인스턴스, 마이크로서비스 또는 컨테이너)으로 트래픽을 \n라우팅하는 Elastic Load Balancing 의 한 유형입니다. Network Load Balancer 는 매우 짧은 \n대기 시간으로 높은 처리량을 유지하면서 초당 수백만 개의 요청을 처리할 수 있으므로 \nTCP 및 UDP 트래픽의 로드 밸런싱에 이상적입니다. 또한 Network Load Balancer 는 \n백엔드 애플리케이션에 대한 클라이언트의 소스 IP 주소를 보존하므로 로깅이나 보안 \n목적으로 유용할 수 있습니다.", "answer_choice": "C"}, "686": {"q_num": 686, "question": "회사에는 원치 않는 콘텐츠가 포함된 사진이 회사의 웹 애플리케이션에 업로드되는 것을 \n방지하는 솔루션이 필요합니다. 솔루션에는 기계 학습(ML) 모델 교육이 포함되어서는 안 \n됩니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. Amazon SageMaker Autopilot 을 사용하여 모델을 생성하고 배포합니다. 새 사진이 \n업로드될 때 웹 애플리케이션이 호출하는 실시간 엔드포인트를 만듭니다. \nB. Amazon Rekognition 을 사용하여 원치 않는 콘텐츠를 감지하는 AWS Lambda 함수를 \n생성합니다. 새 사진이 업로드될 때 웹 애플리케이션이 호출하는 Lambda 함수 URL 을 \n생성합니다. \nC. Amazon Comprehend 를 사용하여 원치 않는 콘텐츠를 감지하는 Amazon CloudFront \n함수를 생성합니다. 기능을 웹 애플리케이션과 연결합니다. \nD. Amazon Rekognition Video 를 사용하여 원치 않는 콘텐츠를 감지하는 AWS Lambda \n\n함수를 생성합니다. 새 사진이 업로드될 때 웹 애플리케이션이 호출하는 Lambda 함수 \nURL 을 생성합니다.", "answer_block": "Answer: B \n설명: \n요구 사항을 충족하는 솔루션은 Amazon Rekognition 을 사용하여 원치 않는 콘텐츠를 \n감지하는 AWS Lambda 함수를 생성하고 새 사진이 업로드될 때 웹 애플리케이션이 \n호출하는 Lambda 함수 URL 을 생성하는 것입니다. Amazon Rekognition 은 이미지 및 \n비디오 분석을 위해 사전 훈련된 컴퓨터 비전 모델을 제공하는 완전 관리형 서비스이므로 \n이 솔루션에는 기계 학습 모델 훈련이 포함되지 않습니다. Amazon Rekognition\n은 \n노골적이거나 외설적인 성인 콘텐츠, 폭력, 무기, 마약 등과 같은 원치 않는 콘텐츠를 \n탐지할 수 있습니다. AWS Lambda 를 사용하여 회사는 웹 애플리케이션의 HTTP 요청에 \n의해 트리거될 수 있는 서버리스 기능을 생성할 수 있습니다. Lambda 함수는 Amazon \nRekognition API 를 사용하여 업로드된 사진을 분석하고 원치 않는 콘텐츠가 포함되어 \n있는지 여부를 나타내는 응답을 반환할 수 있습니다. \n다른 솔루션은 기계 학습 모델 교육이 포함되거나 이미지 분석을 지원하지 않거나 사진 \n작업을 수행하지 않기 때문에 첫 번째 솔루션만큼 효과적이지 않습니다. Amazon \nSageMaker Autopilot 을 사용하여 모델을 생성하고 배포하려면 기계 학습 모델을 훈련해야 \n하는데, 이는 시나리오에 필요하지 않습니다. Amazon SageMaker Autopilot 은 사용자가 \n제공한 데이터를 기반으로 분류 또는 회귀를 위한 최고의 기계 학습 모델을 자동으로 생성, \n교육 및 조정하는 서비스입니다. Amazon Comprehend 를 사용하여 원치 않는 콘텐츠를 \n감지하는 Amazon CloudFront 함수를 생성하면 이미지 분석이 지원되지 않습니다. Amazon \nComprehend 는 이미지가 아닌 텍스트를 분석하는 자연어 처리 서비스이기 때문입니다. \nAmazon Comprehend 는 언어, 감정, 항목, 주제 등과 같은 텍스트에서 통찰력과 관계를 \n추출할 수 있습니다. Amazon Rekognition Video 를 사용하여 원치 않는 콘텐츠를 감지하는 \nAWS Lambda 함수를 생성하는 것은 사진에서는 작동하지 않습니다. Amazon Rekognition \nVideo 는 정적 이미지가 아닌 비디오 스트림을 분석하도록 설계되었기 때문입니다. Amazon \nRekognition Video 는 비디오 스트림에서 활동, 객체, 얼굴, 유명인, 텍스트 등을 감지할 수 \n있습니다.", "answer_choice": "B"}, "687": {"q_num": 687, "question": "한 회사에 Amazon DynamoDB 테이블을 저장용으로 사용하는 애플리케이션이 있습니다. \n솔루션 설계자는 테이블에 대한 많은 요청이 최신 데이터를 반환하지 않는다는 것을 \n발견했습니다. \n회사 \n사용자는 \n데이터베이스 \n성능과 \n관련된 \n다른 \n문제를 \n보고하지 \n않았습니다. \n지연 시간이 허용 가능한 범위 내에 있습니다. \n\n솔루션 설계자는 어떤 디자인 변경을 권장해야 합니까? \nA. 테이블에 읽기 전용 복제본을 추가합니다. \nB. 글로벌 보조 인덱스(GSI)를 사용합니다. \nC. 테이블에 대해 강력하게 일관된 읽기를 요청합니다. \nD. 테이블에 대한 최종적 일관된 읽기를 요청합니다.", "answer_block": "Answer: C \n설명: \n회사의 애플리케이션에 가장 적합한 디자인 변경은 테이블에 대해 강력하고 일관된 읽기를 \n요청하는 것입니다. 이렇게 변경하면 테이블에 대한 요청이 모든 이전 쓰기 작업의 \n업데이트를 반영하여 최신 데이터를 반환하게 됩니다. \nAmazon DynamoDB 는 원활한 확장성과 함께 빠르고 예측 가능한 성능을 제공하는 완전 \n관리형 NoSQL 데이터베이스 서비스입니다. DynamoDB 는 최종적 일관된 읽기와 강력한 \n일관된 읽기라는 두 가지 유형의 읽기 일관성을 지원합니다. 기본적으로 DynamoDB 는 \n사용자가 달리 지정하지 않는 한 최종적 일관된 읽기를 사용합니다. \n최종 일관성 읽기는 최근 완료된 쓰기 작업의 결과를 반영하지 않을 수 있는 읽기입니다. \n모든 복제본에 데이터를 전파하는 데 지연이 발생하기 때문에 응답에 변경 사항이 포함되지 \n않을 수 있습니다. 사용자가 잠시 후에 읽기 요청을 반복하면 응답은 업데이트된 데이터를 \n반환해야 합니다. 최종 일관성 읽기는 최신 데이터가 필요하지 않거나 최종 일관성을 \n허용할 수 있는 애플리케이션에 적합합니다. Strongly Consistency 읽기는 읽기 전에 \n성공적인 응답을 받은 모든 쓰기를 반영하는 결과를 반환하는 읽기입니다. 사용자는 \nGetItem, Query 또는 Scan 과 같은 읽기 작업에서 ConsistencyRead 매개 변수를 true 로 \n설정하여 강력한 일관된 읽기를 요청할 수 있습니다. 강력한 일관된 읽기는 최신 데이터가 \n필요하거나 최종 일관성을 허용할 수 없는 애플리케이션에 적합합니다. \n다른 옵션은 읽기 일관성 문제를 해결하지 않거나 사용 사례와 관련이 없기 때문에 \n올바르지 않습니다. 이 옵션은 DynamoDB 에서 지원되지 않으므로 테이블에 읽기 전용 \n복제본을 추가하는 것은 올바르지 않습니다. 읽기 복제본은 읽기 전용 트래픽을 제공하고 \n가용성과 성능을 향상시킬 수 있는 기본 데이터베이스 인스턴스의 복사본입니다. 읽기 전용 \n복제본은 Amazon RDS 또는 Amazon Aurora 와 같은 일부 관계형 데이터베이스 서비스에 \n사용할 수 있지만 DynamoDB2 에는 사용할 수 없습니다. GSI(Global Secondary Index)를 \n사용하는 것은 올바르지 않습니다. 이 옵션은 읽기 일관성과 관련이 없기 때문입니다. \nGSI 는 기본 테이블의 것과 다른 파티션 키와 선택적 정렬 키가 있는 인덱스입니다. GSI 를 \n사용하면 사용자는 최종 일관성을 유지하면서 다양한 방식으로 데이터를 쿼리할 수 \n있습니다. 테이블에 대한 최종적 일관된 읽기 요청은 올바르지 않습니다. 이 옵션은 이미 \nDynamoDB 의 기본 동작이고 최신 데이터를 반환하지 않는 요청 문제를 해결하지 못하기 \n때문입니다.", "answer_choice": "C"}, "688": {"q_num": 688, "question": "한 회사가 Amazon S3 에서 데이터 레이크를 호스팅하고 있습니다. 데이터 레이크는 다양한 \n데이터 소스에서 Apache Parquet 형식으로 데이터를 수집합니다. 회사는 수집된 데이터를 \n준비하기 위해 여러 변환 단계를 사용합니다. 이 단계에는 이상 항목 필터링, 데이터를 \n표준 날짜 및 시간 값으로 정규화, 분석을 위한 집계 생성이 포함됩니다. \n회사는 변환된 데이터를 데이터 분석가가 액세스하는 S3 버킷에 저장해야 합니다. \n회사에는 코드가 필요하지 않은 데이터 변환을 위해 사전 구축된 솔루션이 필요합니다. \n솔루션은 데이터 계보 및 데이터 프로파일링을 제공해야 합니다. 회사는 회사 전체의 \n직원과 데이터 변환 단계를 공유해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 데이터를 변환하도록 AWS Glue Studio 시각적 캔버스를 구성합니다. AWS Glue 작업을 \n사용하여 변화 단계를 직원과 공유하세요. \nB. 데이터를 변환하도록 Amazon EMR Serverless 를 구성합니다. EMR Serveriess 작업을 \n사용하여 직원과 변환 단계를 공유하십시오. \nC. 데이터를 변환하도록 AWS Glue DataBrew 를 구성합니다. DataBrew 레시피를 사용하여 \n변환 단계를 직원과 공유하세요. \nD. 데이터용 Amazon Athena 테이블을 생성합니다. Athena SQL 쿼리를 작성하여 데이터를 \n변환합니다. Athena SQL 쿼리를 직원과 공유하세요.", "answer_block": "Answer: C \n설명: \n회사의 요구 사항에 가장 적합한 솔루션은 DataBrew 레시피를 사용하여 데이터를 변환하고 \n변환 단계를 직원과 공유하도록 AWS Glue DataBrew 를 구성하는 것입니다. 이 솔루션은 \n코드가 필요하지 않은 데이터 변환을 위해 사전 구축된 솔루션을 제공하고 데이터 계보 및 \n데이터 프로파일링도 제공합니다. 회사는 DataBrew 레시피를 사용하여 회사 전체의 직원과 \n데이터 변환 단계를 쉽게 공유할 수 있습니다. \nAWS Glue DataBrew 는 데이터 분석가와 데이터 과학자가 분석 또는 기계 학습을 위해 \n데이터를 최대 80% 더 빠르게 정리하고 정규화할 수 있게 해주는 시각적 데이터 준비 \n도구입니다. 사용자는 Amazon S3, Amazon RDS, Amazon Redshift, Amazon Aurora 또는 \nGlue Data Catalog\n와 같은 다양한 소스에서 데이터를 업로드하고 포인트 앤 클릭 \n인터페이스를 사용하여 250 개 이상의 기본 제공 변환을 적용할 수 있습니다. 사용자는 각 \n변환 단계의 결과를 미리 보고 이것이 데이터의 품질과 분포에 어떤 영향을 미치는지 \n확인할 수도 있습니다. \nDataBrew 레시피는 하나 이상의 데이터세트에 적용할 수 있는 재사용 가능한 변환 단계 \n세트입니다. 사용자는 처음부터 레시피를 생성하거나 DataBrew 레시피 라이브러리의 기존 \n레시피를 사용할 수 있습니다. 사용자는 또한 AWS 계정 또는 조직 내의 다른 사용자 또는 \n\n그룹과 레시피를 내보내거나 가져오거나 공유할 수도 있습니다. \nDataBrew 는 또한 사용자가 데이터 품질을 이해하고 개선하는 데 도움이 되는 데이터 계보 \n및 데이터 프로파일링 기능을 제공합니다. 데이터 계보는 각 데이터세트의 소스와 대상, \n그리고 각 레시피 단계에서 데이터가 변환되는 방식을 보여줍니다. 데이터 프로파일링은 \n열과 같은 각 데이터세트에 대한 다양한 통계 및 측정항목을 표시합니다.", "answer_choice": "C"}, "689": {"q_num": 689, "question": "한 회사가 AWS 에서 웹 애플리케이션을 설계하고 있습니다. 애플리케이션은 회사의 기존 \n데이터 센터와 회사의 VPC 간에 VPN 연결을 사용합니다. 이 회사는 DNS 서비스로 \nAmazon Route 53\n을 사용합니다. 애플리케이션은 프라이빗 DNS 레코드를 사용하여 \nVPC 에서 온프레미스 서비스와 통신해야 합니다. 가장 안전한 방식으로 이러한 요구 사항을 \n충족하는 솔루션은 무엇입니까? \nA. Route 53 Resolver 아웃바운드 엔드포인트를 생성합니다. 해석기 규칙을 만듭니다. \n해석기 규칙을 VPC 와 연결합니다. \nB. Route 53 Resolver 인바운드 엔드포인트를 생성합니다. 해석기 규칙을 만듭니다. 해석기 \n규칙을 VPC 와 연결합니다. \nC. Route 53 프라이빗 호스팅 영역을 생성합니다. 프라이빗 호스팅 영역을 VPC\n와 \n연결합니다. \nD. Route 53 퍼블릭 호스팅 영역을 생성합니다. 서비스 통신을 허용하려면 각 서비스에 \n대한 레코드를 만듭니다.", "answer_block": "Answer: A \n설명: \n가장 안전한 방식으로 웹 애플리케이션의 요구 사항을 충족하려면 회사는 Route 53 \nResolver 아웃바운드 엔드포인트를 생성하고, 확인자 규칙을 생성하고, 확인자 규칙을 \nVPC 와 연결해야 합니다. 이 솔루션을 사용하면 애플리케이션이 프라이빗 DNS 레코드를 \n사용하여 VPC\n의 온프레미스 서비스와 통신할 수 있습니다. Route 53 Resolver\n는 \n온프레미스 네트워크와 AWS VPC 간의 DNS 확인을 가능하게 하는 서비스입니다. \n아웃바운드 엔드포인트는 확인자가 VPC 에서 온프레미스 네트워크의 확인자로 DNS 쿼리를 \n전달하는 데 사용하는 IP 주소 집합입니다. 확인자 규칙은 확인자가 규칙에 지정한 IP \n주소로 \nDNS \n쿼리를 \n전달하는 \n도메인 \n이름을 \n지정하는 \n규칙입니다. \n아웃바운드 \n엔드포인트와 확인자 규칙을 생성하고 이를 VPC 와 연결함으로써 회사는 프라이빗 DNS \n레코드를 사용하여 온프레미스 서비스에 대한 DNS 쿼리를 안전하게 확인할 수 있습니다. \n다른 옵션은 요구 사항을 충족하지 않거나 안전하지 않기 때문에 올바르지 않습니다. Route \n53 Resolver 인바운드 엔드포인트 생성, 해석기 규칙 생성 및 해석기 규칙을 VPC 와 \n연결하는 것은 올바르지 않습니다. 왜냐하면 이 솔루션은 온프레미스 네트워크의 DNS \n\n쿼리가 VPC\n의 리소스에 액세스하도록 허용하고 그 반대의 경우는 허용하지 않기 \n때문입니다. 인바운드 엔드포인트는 확인자가 온프레미스 네트워크의 확인자로부터 DNS \n쿼리를 수신하는 데 사용하는 IP 주소 집합입니다. Route 53 프라이빗 호스팅 영역을 \n생성하고 이를 VPC 와 연결하는 것은 올바르지 않습니다. 이 솔루션은 동일한 호스팅 \n영역과 연결된 VPC 또는 다른 VPC 내의 리소스에 대해서만 DNS 확인을 허용하기 \n때문입니다. \n프라이빗 호스팅 영역은 하나 이상의 VPC\n에서만 액세스할 수 있는 DNS 레코드의 \n컨테이너입니다. Route 53 퍼블릭 호스팅 영역을 생성하고 서비스 통신을 허용하기 위해 각 \n서비스에 대한 레코드를 생성하는 것은 올바르지 않습니다. 이 솔루션은 온프레미스 \n서비스를 안전하지 않은 퍼블릭 인터넷에 노출시키기 때문입니다. 퍼블릭 호스팅 영역은 \n인터넷 어디에서나 액세스할 수 있는 DNS 레코드의 컨테이너입니다.", "answer_choice": "A"}, "690": {"q_num": 690, "question": "한 도시에서는 ALB(Application Load Balancer) 뒤에 Amazon EC2 인스턴스에서 실행되는 \n웹 애플리케이션을 배포했습니다. 애플리케이션 사용자는 산발적인 성능을 보고했는데, \n이는 무작위 IP 주소에서 발생하는 DDoS 공격과 관련된 것으로 보입니다. 도시에는 구성 \n변경을 최소화하고 DDoS 소스에 대한 감사 추적을 제공하는 솔루션이 필요합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. ALB 에서 AWS WAF 웹 ACL 을 활성화하고 알 수 없는 소스의 트래픽을 차단하는 규칙을 \n구성합니다. \nB. Amazon Inspector 를 구독하세요. AWS DDoS 대응 팀(DRT)을 참여시켜 완화 제어 \n기능을 서비스에 통합하십시오. \nC. AWS Shield Advanced 를 구독하세요. AWS DDoS 대응 팀(DRT)을 참여시켜 완화 제어 \n기능을 서비스에 통합하십시오. \nD. 애플리케이션에 대한 Amazon CloudFront 배포를 생성하고 ALB\n를 오리진으로 \n설정합니다. 배포에서 AWS WAF 웹 ACL 을 활성화하고 알 수 없는 소스의 트래픽을 \n차단하는 규칙을 구성합니다.", "answer_block": "Answer: C \n설명: \n임의 IP 주소에서 발생하는 DDoS 공격으로부터 웹 애플리케이션을 보호하려면 솔루션 \n아키텍트가 AWS Shield Advanced 를 구독하고 AWS DDoS 대응 팀(DRT)과 협력하여 완화 \n제어 기능을 서비스에 통합해야 합니다. AWS Shield Advanced 는 DRT 의 연중무휴 지원 및 \n대응을 통해 대규모의 정교한 DDoS 공격에 대한 보호를 제공하는 관리형 서비스입니다. \nDRT 는 도시에서 AWS WAF 규칙, 속도 기반 규칙 및 네트워크 ACL 과 같은 사전 및 사후 \n보호 장치를 구성하여 악성 트래픽을 차단하고 애플리케이션의 복원력을 향상시키는 데 \n\n도움을 줄 수 있습니다. \n또한 이 서비스는 자세한 공격 보고서와 Amazon CloudWatch 지표를 통해 DDoS 소스에 \n대한 감사 추적을 제공합니다.", "answer_choice": "C"}, "691": {"q_num": 691, "question": "한 회사가 AWS Fargate 클러스터를 사용하여 Amazon Elastic Kubernetes Service(Amazon \nEKS)에 새 애플리케이션을 배포하고 있습니다. 애플리케이션에는 데이터 지속성을 위한 \n스토리지 솔루션이 필요합니다. 솔루션은 가용성이 높고 내결함성이 있어야 합니다. 또한 \n솔루션은 여러 애플리케이션 컨테이너 간에 공유되어야 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. EKS 작업자 노드가 배치된 동일한 가용 영역에 Amazon Elastic Block Store(Amazon \nEBS) 볼륨을 생성합니다. EKS 클러스터의 StorageClass 객체에 볼륨을 등록합니다. EBS \n다중 연결을 사용하여 컨테이너 간에 데이터를 공유합니다. \nB. Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성합니다. EKS 클러스터의 \nStorageClass 객체에 파일 시스템을 등록합니다. 모든 컨테이너에 동일한 파일 시스템을 \n사용합니다. \nC. Amazon Elastic Block Store(Amazon EBS) 볼륨을 생성합니다. EKS 클러스터의 \nStorageClass 객체에 볼륨을 등록합니다. 모든 용기에 동일한 용량을 사용하십시오. \nD. EKS 작업자 노드가 배치된 동일한 가용 영역에 Amazon Elastic File System(Amazon \nEFS) 파일 시스템을 생성합니다. EKS 클러스터의 StorageClass 객체에 파일 시스템을 \n등록합니다. 파일 시스템 간에 데이터를 동기화하는 AWS Lambda 함수를 생성합니다.", "answer_block": "Answer: B \n설명: \nAmazon EFS 는 여러 컨테이너 간에 공유할 수 있는 탄력적이고 확장 가능한 완전관리형 \n파일 시스템입니다. 여러 가용 영역에 걸쳐 데이터를 복제하여 고가용성과 내결함성을 \n제공합니다. Amazon EFS 는 Amazon EKS 및 AWS Fargate 와 호환되며 EKS 클러스터의 \nStorageClass 객체에 등록할 수 있습니다. Amazon EBS 볼륨은 AWS Fargate 에서 지원되지 \n않으며 EBS 다중 연결을 사용하지 않고는 여러 컨테이너 간에 공유할 수 없습니다. 이는 \n제한 사항과 성능에 영향을 미칩니다. 또한 EBS 다중 연결에서는 볼륨이 작업자 노드와 \n동일한 가용 영역에 있어야 하므로 가용성과 내결함성이 줄어듭니다. AWS Lambda 를 \n사용하여 여러 EFS 파일 시스템 간에 데이터를 동기화하는 것은 불필요하고 복잡하며 \n오류가 발생하기 쉽습니다.", "answer_choice": "B"}, "692": {"q_num": 692, "question": "회사는 3 계층 애플리케이션을 온프레미스에서 AWS 로 마이그레이션하려고 합니다. 웹 \n계층과 애플리케이션 계층은 타사 VM(가상 머신)에서 실행됩니다. 데이터베이스 계층은 \nMySQL 에서 실행됩니다. \n회사는 아키텍처를 최소한으로 변경하여 애플리케이션을 마이그레이션해야 합니다. 또한 \n회사에는 데이터를 특정 시점으로 복원할 수 있는 데이터베이스 솔루션이 필요합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 웹 계층과 애플리케이션 계층을 프라이빗 서브넷의 Amazon EC2 인스턴스로 \n마이그레이션합니다. 데이터베이스 계층을 프라이빗 서브넷의 MySQL 용 Amazon RDS 로 \n마이그레이션합니다. \nB. 웹 계층을 퍼블릭 서브넷의 Amazon EC2 인스턴스로 마이그레이션합니다. 애플리케이션 \n계층을 프라이빗 서브넷의 EC2 인스턴스로 마이그레이션합니다. 데이터베이스 계층을 \n프라이빗 서브넷의 Amazon Aurora MySQL 로 마이그레이션합니다. \nC. 웹 계층을 퍼블릭 서브넷의 Amazon EC2 인스턴스로 마이그레이션합니다. 애플리케이션 \n계층을 프라이빗 서브넷의 EC2 인스턴스로 마이그레이션합니다. 데이터베이스 계층을 \n프라이빗 서브넷의 MySQL 용 Amazon RDS 로 마이그레이션합니다. \nD. \n웹 \n계층과 \n애플리케이션 \n계층을 \n퍼블릭 \n서브넷의 \nAmazon \nEC2 \n인스턴스로 \n마이그레이션합니다. 데이터베이스 계층을 퍼블릭 서브넷의 Amazon Aurora MySQL 로 \n마이그레이션합니다.", "answer_block": "Answer: C \n설명: \n최소한의 운영 오버헤드로 요구 사항을 충족하는 솔루션은 웹 계층을 퍼블릭 서브넷의 \nAmazon EC2 인스턴스로 마이그레이션하고, 애플리케이션 계층을 프라이빗 서브넷의 EC2 \n인스턴스로 마이그레이션하고, 데이터베이스 계층을 프라이빗 서브넷의 Amazon RDS for \nMySQL\n로 마이그레이션하는 것입니다. 이 솔루션을 사용하면 회사는 동일한 웹, \n애플리케이션 및 데이터베이스 계층을 유지하고 동일한 MySQL 데이터베이스 엔진을 \n사용하므로 아키텍처를 최소한으로 변경하여 3계층 애플리케이션을 AWS로 마이그레이션할 \n수 있습니다. 또한 이 솔루션은 Amazon RDS for MySQL 이 자동 백업 및 특정 시점 복구를 \n지원하므로 데이터를 특정 시점으로 복원할 수 있는 데이터베이스 솔루션도 제공합니다. \n또한 이 솔루션은 프로비저닝, 패치, 확장, 모니터링과 같은 작업을 처리하는 Amazon EC2 \n및 Amazon RDS 와 같은 관리형 서비스를 사용하여 운영 오버헤드를 줄입니다. \n다른 솔루션은 아키텍처에 더 많은 변경이 필요하거나 특정 시점 복구를 제공하지 않거나 \n보안 및 가용성에 대한 모범 사례를 따르지 않기 때문에 첫 번째 솔루션과 마찬가지로 요구 \n사항을 \n충족하지 \n않습니다. \n데이터베이스 \n계층을 \nAmazon \nAurora \nMySQL\n로 \n마이그레이션하려면 데이터베이스 엔진을 변경하고 잠재적으로 호환성을 보장하기 위해 \n애플리케이션 코드를 수정해야 합니다. 웹 계층과 애플리케이션 계층을 퍼블릭 서브넷으로 \n마이그레이션하면 더 많은 보안 위험에 노출되고 서브넷 오류가 발생할 경우 가용성이 \n\n줄어듭니다. 데이터베이스 계층을 퍼블릭 서브넷으로 마이그레이션하면 보안과 성능이 \n손상될 수도 있습니다.", "answer_choice": "C"}, "693": {"q_num": 693, "question": "회사에 새로운 모바일 앱이 있습니다. 세계 어디에서나 사용자는 자신이 선택한 주제에 \n대한 지역 뉴스를 볼 수 있습니다. 사용자는 앱 내부에서 사진과 비디오를 게시할 수도 \n있습니다. 사용자는 콘텐츠가 게시된 후 처음 몇 분 안에 콘텐츠에 액세스하는 경우가 \n많습니다. 새로운 콘텐츠가 이전 콘텐츠를 빠르게 대체한 다음 이전 콘텐츠는 사라집니다. \n뉴스의 지역적 특성은 사용자가 뉴스가 업로드되는 AWS 지역 내에서 콘텐츠의 90%를 \n소비한다는 것을 의미합니다. \n콘텐츠 업로드에 가장 짧은 지연 시간을 제공하여 사용자 경험을 최적화하는 솔루션은 \n무엇입니까? \nA. Amazon S3 에 콘텐츠를 업로드하고 저장합니다. 업로드에는 Amazon CloudFront 를 \n사용하십시오. \nB. Amazon S3 에 콘텐츠를 업로드하고 저장합니다. 업로드에는 S3 Transfer Acceleration 을 \n사용하십시오. \nC. 사용자에게 가장 가까운 지역의 Amazon EC2 인스턴스에 콘텐츠를 업로드합니다. \n데이터를 Amazon S3 에 복사합니다. \nD. 사용자에게 가장 가까운 지역의 Amazon S3\n에 콘텐츠를 업로드하고 저장합니다. \nAmazon CloudFront 의 여러 배포판을 사용하십시오.", "answer_block": "Answer: B \n설명: \n콘텐츠 업로드에 대한 지연 시간을 최소화하여 사용자 경험을 최적화하는 가장 적합한 \n솔루션은 Amazon S3 에 콘텐츠를 업로드 및 저장하고 업로드에 S3 Transfer Acceleration 을 \n사용하는 것입니다. 이 솔루션을 통해 회사는 AWS 글로벌 네트워크와 엣지 로케이션을 \n활용하여 사용자와 S3 버킷 간의 데이터 전송 속도를 높일 수 있습니다. \nAmazon S3 는 모든 유형의 데이터에 대해 확장 가능하고 내구성이 뛰어나며 가용성이 높은 \n객체 스토리지를 제공하는 스토리지 서비스입니다. Amazon S3 를 사용하면 사용자는 웹 \n어디에서나 데이터를 저장하고 검색할 수 있으며 암호화, 버전 관리, 수명 주기 관리 및 \n복제와 같은 다양한 기능을 제공합니다. \nS3 Transfer Acceleration 은 사용자가 S3 버킷과 더 빠르게 데이터를 주고받는 데 도움이 \n되는 Amazon S3 의 기능입니다. S3 Transfer Acceleration 은 최적화된 네트워크 경로와 \nAmazon 의 백본 네트워크를 사용하여 데이터 전송 속도를 가속화하는 방식으로 작동합니다. \n사용자는 \n버킷에 \n대해 \nS3 \nTransfer \nAcceleration\n을 \n활성화하고 \n<bucket>.s3-accelerate.amazonaws.com\n과 같은 고유한 URL\n을 사용하여 버킷에 \n\n액세스할 수 있습니다. \n다른 옵션은 가장 낮은 대기 시간을 제공하지 않거나 사용 사례에 적합하지 않기 때문에 \n올바르지 않습니다. Amazon S3\n에 콘텐츠를 업로드 및 저장하고 업로드에 Amazon \nCloudFront 를 사용하는 것은 올바르지 않습니다. 이 솔루션은 업로드 최적화가 아니라 \n다운로드 최적화를 위해 설계되었기 때문입니다. Amazon CloudFront 는 사용자가 짧은 지연 \n시간과 높은 전송 속도로 콘텐츠를 전 세계에 배포할 수 있도록 지원하는 콘텐츠 전송 \n네트워크(CDN)입니다. CloudFront\n는 전 세계 엣지 로케이션에서 콘텐츠를 캐싱하는 \n방식으로 작동하므로 사용자는 어디에서나 빠르고 쉽게 콘텐츠에 액세스할 수 있습니다3. \n사용자에게 가장 가까운 지역의 Amazon EC2 인스턴스에 콘텐츠를 업로드하고 Amazon \nS3 에 데이터를 복사하는 것은 프로세스에 불필요한 복잡성과 비용을 추가하므로 올바르지 \n않습니다. Amazon EC2 는 클라우드에서 확장 가능하고 안전한 가상 서버를 제공하는 \n컴퓨팅 서비스입니다. 사용자는 필요에 따라 EC2 인스턴스를 시작, 중지 또는 종료할 수 \n있으며 다양한 인스턴스 유형, 운영 체제 및 구성 중에서 선택할 수 있습니다4. 사용자에게 \n가장 가까운 지역의 Amazon S3 에 콘텐츠를 업로드하고 저장하며 Amazon CloudFront 의 \n여러 배포를 사용하는 것은 사용 사례에 비해 비용 효율적이거나 효율적이지 않기 때문에 \n올바르지 않습니다. 위에서 언급했듯이 Amazon CloudFront 는 사용자가 짧은 지연 시간과 \n높은 전송 속도로 콘텐츠를 전 세계에 배포할 수 있도록 지원하는 CDN 입니다. 그러나 각 \n지역에 대해 여러 CloudFront 배포를 생성하면 추가 비용과 관리 오버헤드가 발생하고 \n콘텐츠의 90%가 업로드된 동일한 지역 내에서 소비되므로 필요하지 않습니다.", "answer_choice": "B"}, "694": {"q_num": 694, "question": "한 회사의 온프레미스 데이터 센터에 소량의 데이터를 Amazon S3 에 정기적으로 백업해야 \n하는 NFS 서버가 있습니다. 이러한 요구 사항을 충족하고 가장 비용 효율적인 솔루션은 \n무엇입니까? \nA. 온프레미스 서버의 데이터를 Amazon S3 에 복사하도록 AWS Glue 를 설정합니다. \nB. 온프레미스 서버에 AWS DataSync 에이전트를 설정하고 데이터를 Amazon S3\n에 \n동기화합니다. \nC. AWS Transfer for SFTP 를 사용하여 SFTP 동기화를 설정하여 온프레미스에서 Amazon \nS3 로 데이터를 동기화합니다. \nD. 온프레미스 데이터 센터와 VPC 간에 AWS Direct Connect 연결을 설정하고 데이터를 \nAmazon S3 에 복사합니다.", "answer_block": "Answer: B \n설명: \nAWS DataSync 는 온프레미스 스토리지와 AWS 스토리지 서비스 간에 대량의 데이터를 \n온라인으로 쉽게 이동할 수 있게 해주는 서비스입니다. AWS DataSync 는 특별히 구축된 \n\n네트워크 프로토콜을 사용하고 데이터 전송을 병렬화하여 오픈 소스 도구보다 최대 10 배 \n빠른 속도로 데이터를 전송할 수 있습니다. AWS DataSync 는 암호화, 데이터 무결성 확인 \n및 대역폭 최적화도 처리합니다. AWS DataSync 를 사용하려면 사용자는 NFS 서버에 \n연결하고 데이터를 Amazon S3 에 동기화하는 온프레미스 서버에 DataSync 에이전트를 \n배포해야 합니다. 사용자는 정기적 또는 일회성 동기화 작업을 예약하고 전송 진행 상황과 \n상태를 모니터링할 수 있습니다. \n다른 옵션은 비용 효율적이지 않거나 사용 사례에 적합하지 않기 때문에 올바르지 않습니다. \n온프레미스 서버에서 Amazon S3 로 데이터를 복사하도록 AWS Glue 를 설정하는 것은 비용 \n효율적이지 않습니다. AWS Glue 는 단순 작업이 아닌 추출, 변환 및 로드(ETL) 작업에 주로 \n사용되는 서버리스 데이터 통합 서비스이기 때문입니다. 데이터 백업. 온프레미스에서 \nAmazon S3 로 데이터를 동기화하기 위해 AWS Transfer for SFTP 를 사용하여 SFTP \n동기화를 설정하는 것은 비용 효율적이지 않습니다. 왜냐하면 AWS Transfer for SFTP 는 \n교환에 더 적합한 SFTP 프로토콜을 사용하여 안전한 파일 전송을 제공하는 완전관리형 \n서비스이기 때문입니다. 데이터를 백업하는 것보다 제3자에게 데이터를 제공하는 것입니다. \n온프레미스 데이터 센터와 VPC 간에 AWS Direct Connect 연결을 설정하고 Amazon S3 에 \n데이터를 복사하는 것은 비용 효율적이지 않습니다. 왜냐하면 AWS Direct Connect 는 \nAWS 와 온프레미스 위치 간의 전용 네트워크 연결이기 때문입니다. 초기 비용이 높고 추가 \n구성이 필요합니다.", "answer_choice": "B"}, "695": {"q_num": 695, "question": "한 회사의 전자상거래 웹사이트에 예측할 수 없는 트래픽이 있으며 AWS Lambda 기능을 \n사용하여 PostgreSQL 용 프라이빗 Amazon RDS DB 인스턴스에 직접 액세스합니다. 회사는 \n예측 가능한 데이터베이스 성능을 유지하고 Lambda 호출이 너무 많은 연결로 인해 \n데이터베이스에 과부하가 걸리지 않도록 하려고 합니다. \n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? \nA. RDS 사용자 지정 끝점에서 클라이언트 드라이버를 가리킵니다. VPC 내부에 Lambda \n함수를 배포합니다. \nB. RDS 프록시 엔드포인트에서 클라이언트 드라이버를 가리킵니다. VPC 내부에 Lambda \n함수를 배포합니다. \nC. RDS 사용자 지정 엔드포인트에서 클라이언트 드라이버를 가리킵니다. VPC 외부에 \nLambda 함수를 배포합니다. \nD. RDS 프록시 엔드포인트에서 클라이언트 드라이버를 가리킵니다. VPC 외부에 Lambda \n함수를 배포합니다.", "answer_block": "Answer: B \n설명: \n\n예측 가능한 데이터베이스 성능을 유지하고 Lambda 호출이 너무 많은 연결로 인해 \n데이터베이스에 \n과부하를 \n주지 \n않도록 \n하려면 \n솔루션 \n설계자는 \nRDS \n프록시 \n엔드포인트에서 클라이언트 드라이버를 가리키고 VPC 내부에 Lambda 함수를 배포해야 \n합니다. RDS 프록시는 애플리케이션이 데이터베이스에 대한 연결을 공유할 수 있도록 하여 \n데이터베이스 가용성과 확장성을 향상시키는 완전 관리형 데이터베이스 프록시입니다. RDS \n프록시를 사용하면 Lambda 함수는 호출할 때마다 새 연결을 생성하는 대신 기존 연결을 \n재사용하여 연결 오버헤드와 지연 시간을 줄일 수 있습니다. VPC 내부에 Lambda 함수를 \n배포하면 퍼블릭 인터넷에 노출하지 않고도 프라이빗 RDS DB 인스턴스에 안전하고 \n효율적으로 액세스할 수 있습니다. 참조: \nAWS Lambda 와 함께 Amazon RDS 프록시 사용 VPC 의 리소스에 액세스하도록 Lambda \n함수를 구성합니다.", "answer_choice": "B"}, "696": {"q_num": 696, "question": "회사의 애플리케이션은 여러 가용 영역에 있는 Amazon EC2 인스턴스에서 실행됩니다. \n애플리케이션은 타사 애플리케이션에서 실시간 데이터를 수집해야 합니다. 회사에는 수집된 \n원시 데이터를 Amazon S3 버킷에 배치하는 데이터 수집 솔루션이 필요합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 데이터 수집을 위해 Amazon Kinesis 데이터 스트림을 생성합니다. Kinesis 데이터 \n스트림을 사용하기 위해 Amazon Kinesis Data Firehose 전송 스트림을 생성합니다. S3 \n버킷을 전송 스트림의 대상으로 지정합니다. \nB. AWS Database Migration Service(AWS DMS)에서 데이터베이스 마이그레이션 작업을 \n생성합니다. EC2 인스턴스의 복제 인스턴스를 소스 엔드포인트로 지정합니다. S3 버킷을 \n대상 엔드포인트로 지정합니다. 기존 데이터를 마이그레이션하고 지속적인 변경 사항을 \n복제하도록 마이그레이션 유형을 설정합니다. \nC. EC2 인스턴스에서 AWS DataSync 에이전트를 생성하고 구성합니다. EC2 인스턴스에서 \nS3 버킷으로 데이터를 전송하도록 DataSync 작업을 구성합니다. \nD. 데이터 수집을 위해 애플리케이션에 대한 AWS Direct Connect 연결을 생성합니다. \nAmazon Kinesis Data Firehose 전송 스트림을 생성하여 애플리케이션에서 직접 PUT 작업을 \n사용합니다. S3 버킷을 전송 스트림의 대상으로 지정합니다.", "answer_block": "Answer: A \n설명: \n요구 사항을 충족하는 솔루션은 데이터 수집을 위한 Amazon Kinesis 데이터 스트림을 \n생성하고, Kinesis 데이터 스트림을 사용하기 위한 Amazon Kinesis Data Firehose 전송 \n스트림을 생성하고, S3 버킷을 전송 스트림의 대상으로 지정하는 것입니다. \n이 솔루션을 사용하면 회사의 애플리케이션이 타사 애플리케이션에서 실시간 데이터를 \n\n수집하고 수집된 원시 데이터를 S3 버킷에 배치할 수 있습니다. Amazon Kinesis 데이터 \n스트림은 수십만 개의 소스에서 데이터를 캡처하고 저장할 수 있는 확장 가능하고 내구성이 \n뛰어난 스트림입니다. Amazon Kinesis Data Firehose 는 스트리밍 데이터를 S3, Amazon \nRedshift, Amazon OpenSearch Service 및 Splunk 와 같은 대상으로 전달할 수 있는 \n완전관리형 서비스입니다. Amazon Kinesis Data Firehose 는 데이터를 S3 에 전달하기 전에 \n변환하고 압축할 수도 있습니다. \n다른 솔루션은 실시간 데이터 수집을 지원하지 않거나, 타사 애플리케이션과 작동하지 \n않거나, S3 를 대상으로 사용하지 않기 때문에 첫 번째 솔루션만큼 효과적이지 않습니다. \nAWS Database Migration Service(AWS DMS)에서 데이터베이스 마이그레이션 작업을 \n생성하면 실시간 데이터 수집이 지원되지 않습니다. AWS DMS 는 주로 스트리밍 데이터가 \n아닌 관계형 데이터베이스 마이그레이션을 위해 설계되었기 때문입니다. 또한 AWS \nDMS 에서는 복제 인스턴스, 소스 엔드포인트 및 대상 엔드포인트가 특정 데이터베이스 \n엔진 및 버전과 호환되어야 합니다. AWS DataSync 는 애플리케이션 간이 아닌 온프레미스 \n스토리지 시스템과 AWS 스토리지 서비스 간에 데이터를 전송하는 서비스이므로 EC2 \n인스턴스에서 AWS DataSync 에이전트를 생성하고 구성하는 것은 타사 애플리케이션에서 \n작동하지 않습니다. 또한 AWS DataSync\n에서는 소스 또는 대상 서버에 에이전트를 \n설치해야 합니다. 데이터 수집을 위해 애플리케이션에 대한 AWS Direct Connect 연결을 \n생성하면 S3 가 대상으로 사용되지 않습니다. AWS Direct Connect 는 애플리케이션과 \n스토리지 서비스 간이 아니라 온프레미스와 AWS 간에 전용 네트워크 연결을 설정하는 \n서비스이기 때문입니다. \nAWS Direct Connect 를 사용하려면 AWS Direct Connect 위치에 대한 물리적 연결도 \n필요합니다.", "answer_choice": "A"}, "697": {"q_num": 697, "question": "회사는 AWS 에 웹 애플리케이션을 배포할 것입니다. 이 회사는 확장 요구 사항을 지원하기 \n위해 기본 DB 인스턴스와 5 개의 읽기 전용 복제본을 사용하여 MySQL 용 Amazon \nRDS 에서 백엔드 데이터베이스를 호스팅합니다. 읽기 전용 복제본은 기본 DB 인스턴스 \n뒤에서 1\n초 이상 기록해서는 안 됩니다. 데이터베이스는 정기적으로 예약된 저장 \n프로시저를 실행합니다. \n웹 사이트의 트래픽이 증가함에 따라 리드가 가장 많은 기간 동안 복제본에 추가 지연이 \n발생합니다. 솔루션 설계자는 복제 지연을 최대한 줄여야 합니다. 솔루션 설계자는 \n애플리케이션 코드 변경을 최소화하고 지속적인 오버헤드를 최소화해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \n데이터베이스를 Amazon Aurora MySQL 로 마이그레이션합니다. 읽기 전용 복제본을 Aurora \n복제본으로 교체하고 Aurora Auto Scaling 을 구성합니다. 저장 프로시저를 Aurora MySQL \n\n기본 함수로 바꿉니다. \n데이터베이스 앞에 Redis 클러스터용 Amazon ElasticCache 를 배포합니다. 애플리케이션이 \n데이터베이스를 쿼리하기 전에 캐시를 확인하도록 애플리케이션을 수정합니다. 저장 \n프로시저를 AWS Lambda 기능으로 바꿉니다. \nA. \nAmazon \nEC2 \n인스턴스에서 \n실행되는 \nMYSQL \n데이터베이스로 \n데이터베이스를 \n마이그레이션합니다. 모든 복제본 노드에 최적화된 대규모 컴퓨팅을 선택하세요. EC2 \n인스턴스에서 저장 프로시저를 유지 관리합니다. \nB. 데이터베이스 형식으로 Redis\n용 Amazon ElastiCache 클러스터를 배포합니다. \n애플리케이션이 \n데이터베이스를 \n쿼리하기 \n전에 \n캐시를 \n확인하도록 \n애플리케이션을 \n수정합니다. 저장 프로시저를 AWS Lambda 함수로 바꿉니다. \nC. \n데이터베이스를 \nAmazon \nEC2 \n인스턴스에서 \n실행되는 \nMySQL \n데이터베이스로 \n마이그레이션합니다. 모든 복제본 노드에 대해 컴퓨팅 최적화된 대규모 EC2 인스턴스를 \n선택하고, EC2 인스턴스에서 저장 프로시저를 유지합니다. \nD. 데이터베이스를 Amazon DynamoDB 로 마이그레이션하고, 필요한 처리량을 지원하기 \n위해 읽기 용량 단위(RCU) 수를 프로비저닝하고, 온디맨드 용량 확장을 구성합니다. 저장 \n프로시저를 DynamoDB 스트림으로 바꿉니다.", "answer_block": "Answer: A \n설명: \n옵션 A 는 애플리케이션 코드를 크게 변경하지 않고도 복제 지연을 줄이고 지속적인 운영 \n오버헤드를 최소화하는 데 가장 적합한 솔루션입니다. 데이터베이스를 Amazon Aurora \nMySQL 로 마이그레이션하면 Amazon RDS for MySQL 에 비해 복제 성능이 향상되고 \n확장성이 높아집니다. Aurora 복제본은 더 빠른 복제를 제공하여 복제 지연을 줄이고, \nAurora Auto Scaling 은 들어오는 트래픽을 처리하기에 충분한 Aurora 복제본이 있는지 \n확인합니다. 또한 Aurora MySQL 기본 기능은 저장 프로시저를 대체하여 데이터베이스의 \n로드를 줄이고 성능을 향상시킬 수 있습니다.", "answer_choice": "A"}, "698": {"q_num": 698, "question": "한 회사가 AWS 에서 실시간 데이터 수집 솔루션을 실행하고 있습니다. 이 솔루션은 최신 \n버전의 Amazon Managed Streaming for Apache Kafka(Amazon MSK)로 구성됩니다. 이 \n솔루션은 3 개의 가용 영역에 걸쳐 프라이빗 서브넷의 VPC 에 배포됩니다. \n솔루션 설계자는 인터넷을 통해 공개적으로 사용할 수 있도록 데이터 수집 솔루션을 \n재설계해야 합니다. 전송 중인 데이터도 암호화되어야 합니다. \n가장 효율적인 운영 효율성으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 기존 VPC\n에서 퍼블릭 서브넷을 구성합니다. 퍼블릭 서브넷에 MSK 클러스터를 \n배포합니다. 상호 TLS 인증을 활성화하려면 MSK 클러스터 보안 설정을 업데이트하세요. \n\nB. 퍼블릭 서브넷이 있는 새 VPC\n를 생성합니다. 퍼블릭 서브넷에 MSK 클러스터를 \n배포합니다. 상호 TLS 인증을 활성화하려면 MSK 클러스터 보안 설정을 업데이트하세요. \nC. 프라이빗 서브넷을 사용하는 ALB(Application Load Balancer)를 배포합니다. HTTPS \n프로토콜에 대한 VPC CIDR 블록의 인바운드 트래픽을 허용하도록 ALB 보안 그룹 인바운드 \n규칙을 구성합니다. \nD. 프라이빗 서브넷을 사용하는 NLB(Network Load Balancer)를 배포합니다. 인터넷을 통한 \nHTTPS 통신을 위해 NLB 수신기를 구성합니다.", "answer_block": "Answer: A \n설명: \n가장 운영 효율성이 뛰어나며 요구 사항을 충족하는 솔루션은 기존 VPC\n에 퍼블릭 \n서브넷을 구성하고 퍼블릭 서브넷에 MSK 클러스터를 배포하는 것입니다. 이 솔루션을 \n사용하면 새 VPC 를 생성하거나 로드 밸런서를 배포하지 않고도 인터넷을 통해 데이터 \n수집 솔루션을 공개적으로 사용할 수 있습니다. 또한 이 솔루션은 상호 TLS 인증을 \n활성화하여 전송 중인 데이터가 암호화되도록 보장합니다. 이를 위해서는 클라이언트와 \n서버 모두 확인을 위해 인증서를 제시해야 합니다. 이 솔루션은 Apache Kafka 2.6.0 이상 \n버전을 실행하는 클러스터에서 사용할 수 있는 Amazon MSK 의 퍼블릭 액세스 기능을 \n활용합니다. \n다른 솔루션은 불필요한 리소스를 생성하거나 전송 중인 데이터를 암호화하지 않기 때문에 \n첫 번째 솔루션만큼 효율적이지 않습니다. 퍼블릭 서브넷이 있는 새 VPC 를 생성하면 \n네트워크 리소스 및 라우팅 관리에 추가 비용과 복잡성이 발생합니다. ALB 또는 NLB 를 \n배포하면 데이터 수집 솔루션에 더 많은 비용과 대기 시간이 추가됩니다. 또한 ALB 또는 \nNLB 는 추가 단계와 유지 관리가 필요한 HTTPS 리스너 및 인증서로 구성되지 않는 한 \n전송 중인 데이터를 자체적으로 암호화하지 않습니다. 따라서 이러한 솔루션은 주어진 요구 \n사항에 최적이 아닙니다.", "answer_choice": "A"}, "699": {"q_num": 699, "question": "회사가 AWS Business Support 플랜에 가입되어 있습니다. 규정 준수 규칙에 따라 회사는 \n배포를 진행하기 전에 AWS 인프라 상태를 확인해야 합니다. 회사에는 새로운 배포를 \n시작할 때 인프라 상태를 확인하기 위한 프로그래밍 방식의 자동화된 방법이 필요합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 각 배포를 시작할 때 AWS Trusted Advisor API 를 사용하십시오. API 가 문제를 반환하는 \n경우 모든 새 배포를 일시 중지합니다. \nB. 각 배포를 시작할 때 AWS 상태 API 를 사용하십시오. API 가 문제를 반환하는 경우 모든 \n새 배포를 일시 중지합니다. \nC. 각 배포 시작 시 AWS Support API 를 쿼리합니다. API 가 미해결 문제를 반환하는 경우 \n\n모든 새 배포를 일시 중지합니다. \nD. 배포에 앞서 각 워크로드에 API 호출을 보냅니다. API 호출이 실패하면 배포를 일시 \n중지합니다.", "answer_block": "Answer: B \n설명: \nAWS 상태 API 는 AWS Personal Health Dashboard 에 표시되는 AWS 상태 정보에 대한 \n프로그래밍 방식의 액세스를 제공합니다. API 작업을 사용하여 AWS 서비스 및 리소스에 \n영향을 미치는 AWS 상태 이벤트에 대한 정보를 얻을 수 있습니다. API 를 사용하여 조직의 \n상태 기반 통찰력을 활성화하거나 비활성화할 수도 있습니다. 각 배포 시작 시 AWS 상태 \nAPI 를 사용하여 AWS 인프라 상태를 확인하고 API 가 문제를 반환하는 경우 모든 새 \n배포를 일시 중지할 수 있습니다. \n참조: \nhttps://docs.aws.amazon.com/health/latest/APIReference/Welcome.html", "answer_choice": "B"}, "700": {"q_num": 700, "question": "회사는 회사의 Amazon RDS 데이터베이스에 연결되는 애플리케이션을 AWS\n에서 \n실행합니다. \n애플리케이션은 \n주말과 \n연중 \n피크 \n시간대에 \n확장됩니다. \n회사는 \n데이터베이스에 연결하는 애플리케이션에 대해 데이터베이스를 보다 효과적으로 확장하려고 \n합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 데이터베이스에 대한 대상 그룹 구성과 함께 연결 풀링과 함께 Amazon DynamoDB 를 \n사용하십시오. DynamoDB 엔드포인트를 사용하도록 애플리케이션을 변경합니다. \nB. 데이터베이스의 대상 그룹과 함께 Amazon RDS Proxy 를 사용하십시오. RDS Proxy \n엔드포인트를 사용하도록 애플리케이션을 변경합니다. \nC. Amazon EC2 에서 실행되는 사용자 지정 프록시를 데이터베이스의 중개자로 사용합니다. \n사용자 정의 프록시 엔드포인트를 사용하도록 애플리케이션을 변경하십시오. \nD. AWS Lambda 함수를 사용하여 데이터베이스에 대한 대상 그룹 구성과 함께 연결 풀링을 \n제공합니다. Lambda 함수를 사용하도록 애플리케이션을 변경합니다.", "answer_block": "Answer: B \n설명: \nAmazon RDS 프록시는 Amazon Relational Database Service(RDS)를 위한 완전 관리형 \n고가용성 데이터베이스 프록시로, 애플리케이션의 확장성과 데이터베이스 오류에 대한 \n복원력 및 보안을 더욱 강화합니다. RDS Proxy 를 사용하면 애플리케이션이 데이터베이스와 \n설정된 연결을 풀링하고 공유할 수 있어 데이터베이스 효율성과 애플리케이션 확장성이 \n향상됩니다. 또한 RDS Proxy 는 Aurora 및 RDS 데이터베이스의 장애 조치 시간을 최대 \n\n66%까지 줄이고 데이터베이스 액세스를 위한 IAM 인증 및 Secrets Manager 통합을 \n지원합니다. 코드 변경 없이 대부분의 애플리케이션에 대해 RDS Proxy 를 활성화할 수 \n있습니다.", "answer_choice": "B"}, "701": {"q_num": 701, "question": "회사는 Amazon Elastic Block Store(Amazon EBS)가 지원하는 Amazon EC2 인스턴스에서 \n애플리케이션을 실행합니다. EC2 인스턴스는 최신 Amazon Linux 릴리스를 실행합니다. \n회사 직원이 25GB 이상의 파일을 저장하고 검색할 때 애플리케이션에 가용성 문제가 \n발생합니다. 회사에는 EC2 인스턴스 간에 파일을 전송할 필요가 없는 솔루션이 필요합니다. \n파일은 여러 EC2 인스턴스와 여러 가용 영역에서 사용할 수 있어야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 모든 파일을 Amazon S3 버킷으로 마이그레이션합니다. 직원에게 S3 버킷의 파일에 \n액세스하도록 지시합니다. \nB. 기존 EBS 볼륨의 스냅샷을 찍습니다. EC2 인스턴스 전반에 걸쳐 스냅샷을 EBS \n볼륨으로 탑재합니다. 직원에게 EC2 인스턴스의 파일에 액세스하도록 지시합니다. \nC. 모든 EC2 인스턴스에 Amazon Elastic File System(Amazon EFS) 파일 시스템을 \n탑재합니다. 직원에게 EC2 인스턴스의 파일에 액세스하도록 지시합니다. \nD. EC2 인스턴스에서 Amazon 머신 이미지(AMI)를 생성합니다. 인스턴스 스토어 볼륨을 \n사용하는 AMI 에서 새 EC2 인스턴스를 구성합니다. 직원에게 EC2 인스턴스의 파일에 \n액세스하도록 지시합니다.", "answer_block": "Answer: C \n설명: \n여러 EC2 인스턴스와 여러 가용 영역에 걸쳐 25GB 이상의 파일을 저장하고 액세스하려면 \nAmazon Elastic File System(Amazon EFS)이 적합한 솔루션입니다. Amazon EFS 는 여러 \nEC2 인스턴스에 동시에 탑재할 수 있는 간단하고 확장 가능하며 탄력적인 파일 시스템을 \n제공합니다. Amazon EFS 는 한 지역 내의 여러 가용 영역에 데이터를 저장하여 고가용성과 \n내구성을 지원합니다.", "answer_choice": "C"}, "702": {"q_num": 702, "question": "솔루션 설계자가 다중 서브넷 VPC 아키텍처를 개발 중입니다. 솔루션은 2 개의 가용 영역에 \n있는 6\n개의 서브넷으로 구성됩니다. 서브넷은 공용, 사설 및 데이터베이스 전용으로 \n정의됩니다. 프라이빗 서브넷에서 실행되는 Amazon EC2 인스턴스만 데이터베이스에 \n액세스할 수 있어야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \n\nA. 퍼블릭 서브넷의 CIDR 블록에 대한 경로를 제외하는 now route table 을 생성합니다. \n라우팅 테이블을 데이터베이스 서브넷에 연결합니다. \nB. 퍼블릭 서브넷의 인스턴스가 사용하는 보안 그룹으로부터의 수신을 거부하는 보안 \n그룹을 생성합니다. 보안 그룹을 Amazon RDS DB 인스턴스에 연결합니다. \nC. 프라이빗 서브넷의 인스턴스가 사용하는 보안 그룹으로부터의 수신을 허용하는 보안 \n그룹을 생성합니다. 보안 그룹을 Amazon RDS DB 인스턴스에 연결합니다. \nD. 퍼블릭 서브넷과 프라이빗 서브넷 사이에 새로운 피어링 연결을 생성합니다. 프라이빗 \n서브넷과 데이터베이스 서브넷 간에 다른 피어링 연결을 만듭니다.", "answer_block": "Answer: C \nhttps://www.examtopics.com/discussions/amazon/view/85409-exam-aws-certified-solut\nions-architect-associate-saa-c03/ \n \n설명1: \n전체적인 프로세스는 퍼블릭 서브넷 -> 프라이빗 서브넷(EC2 인스턴스가 있는 곳) -> \n데이터베이스 전용 서브넷. \n데이터베이스를 구동하는 인스턴스의 보안은 Security Group 이 담당. Security Group 은 \n허용 설정만 가능하고 차단 설정은 불가능하며, 기본적으로 모든 인바운드 트래픽을 차단. \n따라서 허용할 곳만 등록시켜두면 나머지는 자동으로 다 차단하는 셈. \n보안 그룹은 연결된 리소스에 도달하고 나갈 수 있는 트래픽을 제어합니다. 예를 들어 보안 \n그룹을 EC2 인스턴스와 연결하면 인스턴스에 대한 인바운드 및 아웃바운드 트래픽을 \n제어합니다. 허용 규칙을 지정할 수 있지만 거부 규칙은 지정할 수 없습니다. 보안 그룹을 \n처음 만들 때 인바운드 규칙이 없습니다. 따라서 보안 그룹에 인바운드 규칙을 추가하기 \n전에는 어떤 인바운드 트래픽도 허용되지 않습니다. \nhttps://docs.aws.amazon.com/ko_kr/vpc/latest/userguide/VPC_SecurityGroups.html \n \n \n설명2: \n보안 그룹은 상태 저장입니다. 모든 인바운드 트래픽은 기본적으로 차단됩니다. 트래픽 \n인바운드를 허용하는 인바운드 규칙을 생성하면 해당 트래픽이 자동으로 다시 백아웃됩니다. \n보안 그룹을 사용하여 특정 IP 주소를 차단할 수 없습니다(대신 네트워크 액세스 제어 목록 \n사용). \n허용 규칙은 지정할 수 있지만 거부 규칙은 지정할 수 없습니다. 보안 그룹을 처음 \n생성하면 인바운드 규칙이 없습니다. 따라서 인바운드 규칙을 보안 그룹에 추가할 때까지 \n다른 호스트에서 시작하여 인스턴스로 들어오는 인바운드 트래픽은 허용되지 않습니다. \nhttps://docs.aws.amazon.com/ko_kr/vpc/latest/userguide/vpc-security-groups.html#VPC\nSecurityGroups", "answer_choice": "C"}, "703": {"q_num": 703, "question": "회사에서 Amazon Elastic Container Service(Amazon ECS) 클러스터와 Amazon RDS DB \n인스턴스를 사용하여 결제 처리 애플리케이션을 구축하고 실행하려고 합니다. 회사는 규정 \n준수를 위해 온프레미스 데이터 센터에서 애플리케이션을 실행합니다. \n솔루션 설계자는 AWS Outposts 를 솔루션의 일부로 사용하려고 합니다. 솔루션 아키텍트는 \n회사의 운영 팀과 협력하여 애플리케이션을 구축하고 있습니다. \n회사 운영팀의 책임 활동은 무엇입니까? (3 개 선택) \nA. Outposts 랙에 탄력적인 전원 및 네트워크 연결을 제공합니다. \nB. Outposts 에서 실행되는 가상화 하이퍼바이저, 스토리지 시스템 및 AWS 서비스 관리. \nC. 데이터 센터 환경의 물리적 보안 및 액세스 제어. \nD. Outposts 랙 내 전원 공급 장치, 서버 및 네트워킹 장비를 포함한 Outposts 인프라의 \n가용성. \nE. Outposts 구성 요소의 물리적 유지 관리. \nF. 서버 장애 및 유지 관리 이벤트를 완화하기 위해 Amazon ECS 클러스터에 추가 용량을 \n제공합니다.", "answer_block": "Answer: A, C, F \n설명: \n이러한 답변은 솔루션의 일부로 AWS Outposts\n를 사용하는 데 대한 고객의 책임을 \n반영하기 때문에 정확합니다. AWS 공유 책임 모델에 따르면 고객은 Outposts 랙에 \n탄력적인 전력 및 네트워크 연결을 제공하고, 데이터 센터 환경의 물리적 보안 및 액세스 \n제어를 보장하며, 서버 오류 및 유지 관리를 완화하기 위해 Amazon ECS 클러스터에 추가 \n용량을 제공할 책임이 있습니다. 이벤트. AWS 는 가상화 하이퍼바이저, 스토리지 시스템 및 \nOutposts 에서 실행되는 AWS 서비스를 관리할 뿐만 아니라 Outposts 랙 내 전원 공급 \n장치, 서버 및 네트워킹 장비를 포함한 Outposts 인프라의 가용성 및 물리적 유지 관리를 \n담당합니다. 전초기지 구성 요소. \n참조: \nhttps://docs.aws.amazon.com/outposts/latest/userguide/what-is-outposts.html \nhttps://www.contino.io/insights/the-sandwich-responsibility-model-aws-outposts/", "answer_choice": "A"}, "704": {"q_num": 704, "question": "회사는 \n단일 \n가용 \n영역에서 \n실행되는 \nAmazon \nEC2 \n인스턴스에 \n애플리케이션을 \n호스팅합니다. \nOSI(Open \nSystems \nInterconnection) \n모델의 \n전송 \n계층을 \n사용하여 \n애플리케이션에 액세스할 수 있습니다. 회사는 고가용성을 갖기 위해 애플리케이션 \n\n아키텍처가 필요합니다. 이러한 요구 사항을 가장 비용 효율적으로 충족할 수 있는 단계 \n조합은 무엇입니까? (2 개 선택) \nA. 다른 가용 영역에서 새 EC2 인스턴스를 구성합니다. Amazon Route 53 을 사용하여 \n트래픽을 모든 인스턴스로 라우팅합니다. \nB. EC2 인스턴스 앞에 Network Load Balancer 를 구성합니다. \nC. 인스턴스에 대한 TCP 트래픽을 전송하도록 Network Load Balancer 를 구성합니다. \n인스턴스에 대한 HTTP 및 HTTPS 트래픽을 위해 Application Load Balancer 를 구성합니다. \nD. EC2 인스턴스에 대한 Auto Scaling 그룹을 생성합니다. 여러 가용 영역을 사용하도록 \nAuto Scaling 그룹을 구성합니다. 인스턴스에서 애플리케이션 상태 확인을 실행하도록 Auto \nScaling 그룹을 구성합니다. \nE. Amazon CloudWatch 경보를 생성합니다. 중지된 상태로 전환되는 EC2 인스턴스를 다시 \n시작하도록 경보를 구성합니다.", "answer_block": "Answer: A, D \n설명: \nEC2 인스턴스에서 실행되는 애플리케이션의 고가용성을 달성하려면 애플리케이션을 여러 \n가용 영역에 배포하고 로드 밸런서를 사용하여 트래픽을 분산해야 합니다. Auto Scaling \n그룹을 사용하면 여러 가용 영역에서 EC2 인스턴스를 시작 및 관리하고 상태 확인을 \n수행할 수 있습니다. Network Load Balancer 를 사용하여 EC2 인스턴스에 대한 전송 계층 \n트래픽을 처리할 수 있습니다.", "answer_choice": "A"}, "705": {"q_num": 705, "question": "회사는 Amazon EC2 인스턴스에서 애플리케이션을 실행합니다. 회사는 AWS 비용에 대해 \n정기적인 재무 평가를 수행합니다. 회사는 최근 비정상적인 지출을 확인했습니다. 회사는 \n비정상적인 지출을 방지하기 위한 솔루션이 필요합니다. 솔루션은 비용을 모니터링하고 \n비정상적인 지출이 발생할 경우 책임 있는 이해관계자에게 알려야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 지출이 없는 예산을 생성하려면 AWS Budgets 템플릿을 사용하십시오. \nB. AWS Billing and Cost Management 콘솔에서 AWS 비용 이상 탐지 모니터를 생성합니다. \nC. 현재 실행 중인 워크로드 가격 세부 정보에 대한 AWS 가격 계산기 추정치를 \n생성합니다. \nD. Amazon CloudWatch 를 사용하여 비용을 모니터링하고 비정상적인 지출을 식별합니다.", "answer_block": "Answer: B \n설명: \n이를 통해 회사는 비용을 모니터링하고 비정상적인 지출이 발생할 경우 책임 있는 \n이해관계자에게 알릴 수 있습니다. AWS Billing and Cost Management 콘솔에서 AWS 비용 \n\n이상 탐지 모니터를 생성함으로써 회사는 비정상적인 지출을 자동으로 탐지하고 경고하는 \n기계 학습 서비스를 사용할 수 있습니다. 경고 임계값, 알림 기본 설정 및 근본 원인 \n분석을 구성함으로써 회사는 비정상적인 지출을 방지하고 그 출처를 식별할 수 있습니다.", "answer_choice": "B"}, "706": {"q_num": 706, "question": "한 회사에서 역사적 사건의 이미지를 저장하는 웹사이트를 운영하고 있습니다. 웹사이트 \n사용자는 이미지 속 사건이 발생한 연도를 기준으로 이미지를 검색하고 볼 수 있는 기능이 \n필요합니다. 평균적으로 사용자는 각 이미지를 1\n년에 한두 번만 요청합니다. 회사는 \n가용성이 높은 이미지를 원합니다. \n이미지를 저장하고 사용자에게 전달하는 솔루션입니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. Amazon Elastic Block Store(Amazon EBS)에 이미지를 저장합니다. Amazon EC2 에서 \n실행되는 웹 서버를 사용하십시오. \nB. Amazon Elastic File System(Amazon EFS)에 이미지를 저장합니다. Amazon EC2 에서 \n실행되는 웹 서버를 사용하십시오. \nC. Amazon S3 Standard 에 이미지를 저장합니다. S3 Standard 를 사용하면 정적 웹사이트를 \n통해 이미지를 직접 전달할 수 있습니다. \nD. Amazon S3 Standard-InfrequentAccess(S3 Standard-IA)에 이미지를 저장합니다. S3 \nStandard-IA 를 사용하면 정적 웹 사이트를 통해 이미지를 직접 전달할 수 있습니다.", "answer_block": "Answer: C \n설명: \n이를 통해 회사는 가용성이 높고 비용 효율적인 방식으로 이미지를 저장하고 사용자에게 \n전달할 수 있습니다. Amazon S3 Standard 에 이미지를 저장함으로써 회사는 고가용성과 \n성능을 제공하는 내구성 있고 확장 가능하며 안전한 개체 스토리지 서비스를 사용할 수 \n있습니다. S3 Standard 를 사용하여 정적 웹 사이트를 통해 이미지를 직접 전달함으로써 \n회사는 웹 서버 실행을 방지하고 운영 오버헤드를 줄일 수 있습니다. S3 Standard 는 또한 \nAWS 리전 내에서 저렴한 스토리지 가격과 무료 데이터 전송을 제공합니다.", "answer_choice": "C"}, "707": {"q_num": 707, "question": "한 회사에서 테스트 환경의 애플리케이션에 AWS CloudFormatlon 스택을 사용하려고 \n합니다. 회사는 공개 액세스를 차단하는 Amazon S3 버킷에 CloudFormation 템플릿을 \n저장합니다. 회사는 테스트 환경을 생성하기 위한 특정 사용자 요청을 기반으로 S3 버킷의 \n템플릿에 CloudFormation 액세스 권한을 부여하려고 합니다. 솔루션은 보안 모범 사례를 \n따라야 합니다. \n\n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. Amazon S3 용 게이트웨이 VPC 엔드포인트를 생성합니다. S3 객체 URL 을 사용하도록 \nCloudFormation 스택을 구성합니다. \nB. S3 버킷을 대상으로 하는 Amazon API Gateway REST API 를 생성합니다. API 게이트웨이 \nURL 을 사용하도록 CloudFormat10n 스택을 구성합니다. \nC. 템플릿 객체에 대해 미리 서명된 URL 을 생성합니다. 미리 서명된 URL 을 사용하도록 \nCloudFormation 스택을 구성합니다. \nD. S3 버킷의 템플릿 객체에 대한 공개 액세스를 허용합니다. 테스트 환경이 생성된 후 \n공개 접근을 차단합니다.", "answer_block": "Answer: C \n설명: \n이를 통해 CloudFormation 은 공개 액세스 권한을 부여하거나 추가 리소스를 생성하지 \n않고도 S3 버킷의 템플릿에 액세스할 수 있습니다. 미리 서명된 URL 은 객체에 액세스할 \n권한이 있는 IAM 사용자 또는 역할의 액세스 키로 서명된 URL 입니다. 미리 서명된 URL 은 \n이를 수신하는 누구나 사용할 수 있지만 지정된 시간이 지나면 만료됩니다. 템플릿 객체에 \n대해 미리 서명된 URL 을 생성하고 이를 사용하도록 CloudFormation 스택을 구성함으로써 \n회사는 특정 사용자 요청에 따라 템플릿에 대한 CloudFormation 액세스 권한을 부여하고 \n보안 모범 사례를 따를 수 있습니다.", "answer_choice": "C"}, "708": {"q_num": 708, "question": "회사는 여러 AWS 계정의 AWS CloudTrail 로그를 중앙 집중식 계정의 Amazon S3 버킷으로 \n보냅니다. 회사는 CloudTrail 로그를 보관해야 합니다. 회사는 언제든지 CloudTrail 로그를 \n쿼리할 수 있어야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 중앙 집중식 계정의 CloudTraiI 이벤트 기록을 사용하여 Amazon Athena 테이블을 \n생성합니다. Athena 에서 CloudTrail 로그를 쿼리합니다. \nB. CloudTrail 로그를 관리하도록 Amazon Neptune 인스턴스를 구성합니다. Neptune 에서 \nCloudTraiI 로그를 쿼리합니다. \nC. 로그를 Amazon DynamoDB 테이블로 보내도록 CloudTrail 을 구성합니다. Amazon \nQulCkSight 에서 대시보드를 생성하여 테이블의 로그를 쿼리합니다. \nD. Amazon Athena 를 사용하여 Athena 노트북을 생성합니다. 로그를 노트북으로 보내도록 \nCloudTrail 을 구성합니다. Athena 에서 쿼리를 실행합니다.", "answer_block": "Answer: A \n설명: \n이를 통해 회사는 CloudTrail 로그를 유지하고 언제든지 쿼리할 수 있습니다. 회사는 중앙 \n집중식 계정의 CloudTrail 이벤트 기록을 사용하여 여러 AWS 계정의 최근 API 활동을 보고, \n\n필터링하고, 다운로드할 수 있습니다. CloudTrail 이벤트 기록에서 Amazon Athena 테이블을 \n생성함으로써 회사는 표준 SQL 을 사용하여 S3 의 데이터를 쉽게 분석할 수 있는 서버리스 \n대화형 쿼리 서비스를 사용할 수 있습니다. Athena 에서 CloudTrail 로그를 쿼리함으로써 \n회사는 사용자 활동 및 리소스 변경 사항에 대한 통찰력을 얻을 수 있습니다.", "answer_choice": "A"}, "709": {"q_num": 709, "question": "회사는 두 개의 AWS 리전에서 3 티어 애플리케이션을 실행합니다. 웹 계층, 애플리케이션 \n계층 및 데이터베이스 계층은 Amazon EC2 인스턴스에서 실행됩니다. 회사는 데이터베이스 \n계층에 Microsoft SQL Server Enterprise 용 Amazon RDS 를 사용합니다. 주간 및 월간 \n보고서를 실행할 때 데이터베이스 계층에 높은 로드가 발생합니다. 회사는 데이터베이스 \n계층의 로드를 줄이고 싶어합니다. \n최소한의 관리 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. \n읽기 \n전용 \n복제본을 \n생성합니다. \n새로운 \n읽기 \n복제본을 \n사용하도록 \n보고서를 \n구성합니다. \nB. RDS 데이터베이스를 Amazon DynamoDB 로 변환_ DynamoDB 를 사용하도록 보고서를 \n구성합니다. \nC. 더 큰 인스턴스 크기를 선택하여 기존 RDS DB 인스턴스를 수정합니다. \nD. 기존 ROS DB 인스턴스를 수정하고 인스턴스를 Auto Scaling 그룹에 넣습니다.", "answer_block": "Answer: A \n설명: \n이를 통해 회사는 RDS 데이터베이스의 읽기 전용 복제본을 생성하고 데이터베이스 계층의 \n로드를 줄일 수 있습니다. 읽기 전용 복제본을 생성하면 회사는 기본 데이터베이스 \n인스턴스의 읽기 트래픽을 하나 이상의 복제본으로 오프로드할 수 있습니다. 새로운 읽기 \n전용 복제본을 사용하도록 보고서를 구성함으로써 회사는 데이터베이스 계층의 성능과 \n가용성을 향상시킬 수 있습니다.", "answer_choice": "A"}, "710": {"q_num": 710, "question": "한 기업에서 CompanyConfidential Amazon S3 버킷에 대한 액세스 권한이 없어야 하는 새 \n클라우드 엔지니어를 모집했습니다. 클라우드 엔지니어는 AdminTools 라는 S3 버킷에 대한 \n읽기 및 쓰기 권한이 있어야 합니다. \n어떤 IAM 정책이 이러한 기준을 충족합니까? \nA.\n\n \nB. \n \nC. \n\n \nD.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/46383-exam-aws-certified-solut\nions-architect-associate-saa-c02/ \n \n설명1: \nA(O) : arn:aws:s3:::AdminTools 는 버킷 자체를 의미. arn:aws:s3:::AdminTools/* 는 버킷 \n내 모든 객체를 의미 \n\n다음은 특정 Amazon S3 버킷 내에 포함된 모든 항목을 나타낸 예제입니다. 이하의 내용 \n참고. \nhttps://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/reference_policies_elements_r\nesource.html \nB(X) : CompanyConfidention 버킷에 권한이 없어야 하는데 s3:ListBucket 권한이 있으므로 \n오답. \nC(X) : AdminTools 버킷에 s3:ListBucket 권한이 있어야 하는데 \n없으므로 오답. \ns3:ListBucket 권한이 없이 읽고 쓰는 권한만 가지는 것은 무의미. 아래 링크 참고. \nhttps://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/reference_policies_examples_s\n3_rw-bucket.html \nD(X) : Allow, Deny 에 모두 AdminTools/*가 등록되어있으므로 오답. Deny 문은 Allow 문보다 \n우선시 되기 때문. \n정책이 Allow 설명문과 Deny 설명문을 포함한 요청에 적용된다면 Deny 설명문은 Allow \n설명문에 우선합니다. 이 요청은 명시적으로 거부됩니다. \nhttps://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/reference_policies_evaluation-\nlogic.html \n \n설명2: \nhttps://docs.amazonaws.cn/en_us/IAM/latest/UserGuide/reference_policies_examples_s3\n_rwbucket.html \nListBucket 작업에는 버킷에 대한 권한이 필요하고 다른 작업에는 버킷의 객체에 대한 \n권한이 필요하기 때문에 정책은 두 부분으로 구분됩니다. \n버킷 수준 및 객체 수준 권한을 지정하려면 서로 다른 두 개의 ARN(Amazon 리소스 \n이름)을 사용해야 합니다. \n첫 번째 Resource 요소는 애플리케이션이 AdminTools 버킷의 모든 객체를 나열할 수 \n있도록 ListBucket 작업에 대해 arn:aws:s3:::AdminTools 를 지정합니다.", "answer_choice": "A"}, "711": {"q_num": 711, "question": "한 회사가 여러 대륙의 도시에서 온도, 습도 및 기압 데이터를 수집합니다. 매일 사이트당 \n수집되는 평균 데이터 양은 500GB 입니다. 각 사이트에는 고속 인터넷 연결이 있습니다. 이 \n회사의 일기 예보 애플리케이션은 단일 지역을 기반으로 하며 매일 데이터를 분석합니다. \n이러한 모든 글로벌 사이트에서 데이터를 집계하는 가장 빠른 방법은 무엇입니까? \nA. 대상 버킷에서 Amazon S3 Transfer Acceleration 을 활성화합니다. 멀티파트 업로드를 \n사용하여 사이트 데이터를 대상 버킷에 직접 업로드합니다. \nB. 가장 가까운 AWS 지역의 Amazon S3 버킷에 사이트 데이터를 업로드합니다. S3 교차 \n\n리전 복제를 사용하여 객체를 대상 버킷에 복사합니다. \nC. 가장 가까운 AWS 리전으로 데이터를 전송하도록 매일 AWS Snowball 작업을 \n예약합니다. S3 교차 리전 복제를 사용하여 객체를 대상 버킷에 복사합니다. \nD. 가장 가까운 리전의 Amazon EC2 인스턴스에 데이터를 업로드합니다. Amazon Elastic \nBlock Store(Amazon EBS) 볼륨에 데이터를 저장합니다. 하루에 한 번 EBS 스냅샷을 찍어 \n중앙 집중식 리전에 복사합니다. 중앙 집중식 리전에서 EBS 볼륨을 복원하고 매일 \n데이터에 대한 분석을 실행합니다.", "answer_block": "Answer: A \n \n설명 \n다음과 같은 다양한 이유로 버킷에서 Transfer Acceleration 을 사용할 수 있습니다. \n전 세계에서 중앙 집중식 버킷에 업로드하는 고객이 있습니다. \n대륙 간에 정기적으로 기가바이트에서 테라바이트의 데이터를 전송합니다. \nAmazon S3 에 업로드할 때 인터넷을 통해 사용 가능한 모든 대역폭을 활용할 수 없습니다. \nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/transfer-acceleration.html \n\"Amazon S3 Transfer Acceleration 은 더 큰 객체의 장거리 전송을 위해 Amazon S3 와의 \n콘텐츠 전송 속도를 50~500%까지 높일 수 있습니다. \n광범위한 사용자가 있는 웹 또는 모바일 애플리케이션이 있거나 S3 버킷에서 멀리 떨어진 \n애플리케이션을 호스팅하는 고객은 인터넷을 통해 길고 가변적인 업로드 및 다운로드 \n속도를 경험할 수 있습니다.\" \nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/mpuoverview.html \n\"개선된 처리량 - 처리량을 개선하기 위해 부품을 병렬로 업로드할 수 있습니다.\" \n \n여러 대륙의 도시에서 온도, 습도 및 대기압 데이터를 수집한다고 했으므로 여러 지역에서 \n업로드를 하는 상황. 즉 S3 Transfer Acceleration 을 사용하는 A 가 정답.", "answer_choice": "A"}, "712": {"q_num": 712, "question": "회사는 AWS 에서 호스팅되는 서비스 솔루션으로 고성능 컴퓨팅(HPC) 워크로드를 구축할 \n계획입니다. 16 개의 Amazon EC2 Linux 인스턴스 그룹에는 노드 간 통신에 가장 낮은 지연 \n시간이 필요합니다. 인스턴스에는 고성능 스토리지를 위한 공유 블록 장치 볼륨도 \n필요합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 클러스터 배치 그룹을 사용합니다. Amazon EBS 다중 연결을 사용하여 단일 \n프로비저닝된 IOPS SSD Amazon Elastic Block Store(Amazon EBS) 볼륨을 모든 인스턴스에 \n연결합니다. \n\nB. 클러스터 배치 그룹을 사용합니다. Amazon Elastic File System(Amazon EFS)을 사용하여 \n인스턴스 간에 공유 파일 시스템을 생성합니다. \nC. 파티션 배치 그룹을 사용합니다. Amazon Elastic File System(Amazon EFS)을 사용하여 \n인스턴스 간에 공유 파일 시스템을 생성합니다. \nD. 스프레드 배치 그룹을 사용합니다. Amazon EBS 다중 연결을 사용하여 단일 \n프로비저닝된 IOPS SSD Amazon Elastic Block Store(Amazon EBS) 볼륨을 모든 인스턴스에 \n연결합니다.", "answer_block": "Answer: A \n \n설명  \n노드 간 통신에 가장 낮은 지연 시간 = 클러스터 배치 그룹. A,B 둘 중 하나가 정답. \nA(O) : Amazon EBS 다중 연결을 사용하면 단일 프로비저닝된 IOPS SSD(io1 또는 io2) \n볼륨을 동일한 가용 영역에 있는 여러 인스턴스에 연결할 수 있습니다. 여러 다중 연결 \n지원 볼륨을 인스턴스 또는 인스턴스 집합에 연결할 수 있습니다....다중 연결을 사용하면 \n동시 쓰기 작업을 관리하는 클러스터링된 Linux 애플리케이션에서 더 쉽게 더 높은 \n애플리케이션 가용성을 얻을 수 있습니다.....다중 연결 지원 볼륨은 동일한 가용 영역에 \n있는 최대 16 개의 Nitro 시스템 기반 Linux 인스턴스에 연결할 수 있습니다.....다중 연결은 \n프로비저닝된 IOPS SSD(io1 및 io2) 볼륨에만 지원됩니다 \nhttps://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/ebs-volumes-multi.html \nProvisioned IOPS SSD 볼륨의 크기는 4GiB 에서 16TiB 사이가 될 수 있고 볼륨당 100 \nIOPS\n에서 최대 64,000 IOPS\n가 프로비저닝될 수 있습니다. Nitro 시스템에 구축된 \n인스턴스에서만 최대 64,000 IOPS 를 달성할 수 있습니다. 다른 인스턴스 패밀리에서는 \n최대 32,000 IOPS 성능을 얻을 수 있습니다. \nhttps://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/provisioned-iops.html#E\nBSVolumeTypes_piops \nB(X) : 공유 블록 장치 볼륨이라고 했으므로 오답. 블록 스토리지는 EBS. 그래도 IOPS \n자체는 EBS 보다 더 높은 편. \nAmazon EFS 범용 및 최대 I/O 라는 두 가지 성능 모드를 제공합니다. \n◎범용 모드 : 최대 35,000 IOPS 를 지원하며 작업당 지연 시간이 가장 낮습니다. EFS One \nZone 스토리지 클래스가 있는 파일 시스템은 항상 범용 성능 모드를 사용합니다. EFS \nStandard 스토리지 클래스가 있는 파일 시스템의 경우 기본 범용 성능 모드 또는 최대 I/O \n성능 모드를 사용할 수 있습니다. \n◎최대 I/O 모드 : 500,000+ IOPS 를 지원하며 범용 모드에 비해 작업당 지연 시간이 더 \n깁니다. https://docs.aws.amazon.com/ko_kr/efs/latest/ug/performance.html", "answer_choice": "A"}, "713": {"q_num": 713, "question": "회사에 다양한 런타임으로 AWS Lambda 함수를 분당 최대 800 번 호출하는 이벤트 기반 \n애플리케이션이 있습니다. Lambda 함수는 Amazon Aurora MySQL OB 클러스터에 저장된 \n데이터에 액세스합니다. 회사는 사용자 활동이 증가함에 따라 연결 시간 초과를 인지하고 \n있습니다. 데이터베이스에 과부하가 걸린 흔적이 없습니다. CPU, 메모리 및 디스크 액세스 \n메트릭이 모두 낮습니다. \n어떤 솔루션이 운영 오버헤드를 최소화하면서 이 문제를 해결할 것입니까? \nA. 더 많은 연결을 처리하려면 Aurora MySQL 노드의 크기를 조정하십시오. 데이터베이스 \n연결 시도에 대해 Lambda 함수에서 재시도 논리를 구성합니다. \nB. 데이터베이스에서 일반적으로 읽는 항목을 캐시하도록 읽기용 Amazon ElastiCache 를 \n설정합니다. 읽기를 위해 ElastiCache 에 연결하도록 Lambda 함수를 구성합니다. \nC. Aurora 복제본을 리더 노드로 추가합니다. 작성기 엔드포인트가 아닌 OB 클러스터의 \n판독기 엔드포인트에 연결하도록 Lambda 함수를 구성합니다. \nD. Amazon ROS 프록시를 사용하여 프록시를 생성합니다. DB 클러스터를 대상 \n데이터베이스로 \n설정 \nDB \n클러스터가 \n아닌 \n프록시에 \n연결하도록 \nLambda \n함수를 \n구성합니다.", "answer_block": "Answer: D \n \n설명1: \nA(X) : 노드 크기 조절은 아무 상관 없음. \nB(X) : 데이터베이스 자체에 부하가 걸리는 것이 아니므로 읽기 부하를 분산하는 \nElastiCache 는 솔루션으로 적합하지 않음. \nC(X) : 데이터베이스 자체에 부하가 걸리는 것이 아니므로 읽기 부하를 분산하는 복제본은 \n솔루션으로 적합하지 않음. \nD(O) : RDS 프록시를 사용하여 예기치 않은 데이터베이스 트래픽 급증을 처리할 수 \n있습니다. 급증을 처리하지 않으면 연결 초과 구독 또는 빠른 속도의 새 연결 생성으로 \n인한 문제가 발생할 수 있습니다. RDS 프록시는 데이터베이스 연결 풀을 설정하고 이 \n풀에서 연결을 재사용합니다.  \nhttps://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/rds-proxy.html \n \n설명2: \n1. 데이터베이스가 과부하의 징후를 보이지 않습니다. CPU, 메모리 및 디스크 액세스 \n메트릭은 모두 낮음==>A 및 C 출력입니다. 노드 인스턴스를 추가하거나 읽기 전용 \n복제본을 추가할 수는 없습니다. \n2. \"최소 운영 오버헤드\"==>B 출력, b 는 람다를 구성해야 하기 때문입니다. \n3. ROS 프록시: 자주 사용되지 않는 연결을 공유합니다. 장애 조치를 통한 고가용성. \n\n효율성 향상==>프록시는 장애 조치를 활용하여 시간 초과 rds 인스턴스에서 정상 rds \n인스턴스로 트래픽을 리디렉션할 수 있습니다. 그래서 D 가 맞습니다.", "answer_choice": "D"}, "714": {"q_num": 714, "question": "회사는 Amazon EC2 인스턴스 및 Amazon RDS 에서 2 계층 애플리케이션을 호스팅합니다. \n응용 프로그램의 요구 사항은 시간에 따라 다릅니다. 업무 시간 이후와 주말에는 부하가 \n최소화됩니다. EC2 인스턴스는 최소 2 개의 인스턴스와 최대 5 개의 인스턴스로 구성된 EC2 \nAuto Scaling 그룹에서 실행됩니다. 응용 프로그램은 항상 사용할 수 있어야 하지만 회사는 \n전체 비용을 걱정합니다. \n가용성 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. 모든 EC2 스팟 인스턴스를 사용합니다. 사용하지 않을 때는 RDS 데이터베이스를 \n중지합니다. \nB. 5 개의 EC2 인스턴스에 적용되는 EC2 Instance Savings Plan 을 구매합니다. RDS 예약 \nDB 인스턴스를 구매합니다. \nC. 두 개의 EC2 예약 인스턴스를 구매합니다. 필요에 따라 최대 3 개의 추가 EC2 스팟 \n인스턴스를 사용합니다. 사용하지 않을 때는 RDS 데이터베이스를 중지합니다. \nD. 2 개의 EC2 인스턴스를 포함하는 EC2 Instance Savings Plan 을 구매합니다. 필요에 따라 \n최대 3\n개의 추가 EC2 온디맨드 인스턴스를 사용합니다. RDS 예약 DB 인스턴스를 \n구매합니다.", "answer_block": "Answer: C \n \n설명: \n이 솔루션은 하루 중 시간에 따라 수요가 가변적이며 전체 비용을 최소화하면서 항상 \n사용할 수 있어야 하는 2\n계층 애플리케이션의 요구 사항을 충족합니다. EC2 예약 \n인스턴스는 기본 사용 수준에 대해 온디맨드 인스턴스에 비해 상당한 비용 절감을 제공할 \n수 있으며 필요할 때 용량 예약을 보장할 수 있습니다. EC2 스팟 인스턴스는 피크 시간 \n동안 애플리케이션에 필요한 추가 용량에 대해 온디맨드 인스턴스에 비해 최대 90% 절감 \n효과를 제공할 수 있습니다. 스팟 인스턴스는 중단을 허용하고 다른 인스턴스로 교체할 수 \n있는 상태 비저장 애플리케이션에 적합합니다. RDS 데이터베이스를 사용하지 않을 때 \n중지하면 데이터베이스 계층 실행 비용을 줄일 수 있습니다. \n여분의 용량이 충분하지 않거나 스팟 가격이 최대 가격을 초과하는 경우 모든 EC2 스팟 \n인스턴스를 사용하면 애플리케이션의 가용성에 영향을 미칠 수 있으므로 옵션 A\n는 \n올바르지 않습니다. RDS 데이터베이스를 사용하지 않을 때 중지하면 데이터베이스 계층 \n실행 비용을 줄일 수 있지만 애플리케이션의 가용성에도 영향을 미칠 수 있습니다. \n5 개의 EC2 인스턴스에 적용되는 EC2 Instance Savings Plans 를 구매하면 시간당 컴퓨팅 \n\n사용량이 고정되어 애플리케이션의 실제 사용 패턴과 일치하지 않을 수 있으므로 옵션 B 는 \n올바르지 않습니다. RDS 예약 DB 인스턴스를 구매하면 데이터베이스 계층을 절약할 수 \n있지만 사용하지 않을 때 데이터베이스를 중지할 수는 없습니다. \n두 개의 EC2 인스턴스에 적용되는 EC2 Instance Savings Plans 를 구매하면 시간당 컴퓨팅 \n사용량이 고정되어 애플리케이션의 실제 사용 패턴과 일치하지 않을 수 있으므로 옵션 D 는 \n올바르지 않습니다. 필요에 따라 최대 3 개의 추가 EC2 온디맨드 인스턴스를 사용하면 스팟 \n인스턴스를 사용하는 것보다 더 많은 비용이 발생할 수 있습니다. \n참조: \nhttps://aws.amazon.com/ec2/pricing/reserved-instances/ \nhttps://aws.amazon.com/ec2/spot/ \nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_StopInstance.html", "answer_choice": "C"}, "715": {"q_num": 715, "question": "회사의 애플리케이션이 AWS 에서 실행됩니다. 애플리케이션은 S3 Standard-infrequent \nAccess(S3 Standard-IA) 스토리지 클래스를 사용하는 Amazon S3 버킷에 대용량 문서를 \n저장합니다. 회사는 데이터 저장 비용을 계속 지불하지만 총 S3 비용을 절감하고자 합니다. \n회사는 승인된 외부 사용자가 밀리초 단위로 문서에 액세스할 수 있기를 원합니다. 이러한 \n요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. 요청자 지불 버킷이 되도록 S3 버킷을 구성합니다. \nB. 모든 기존 객체와 향후 객체에 대해 스토리지 계층을 S3 Standard 로 변경합니다. \nC. S3 Docket 에서 S3 Transfer Acceleration 을 켭니다. \nD. Amazon CloudFront 를 사용하여 S3 버킷에 대한 모든 요청을 처리합니다.", "answer_block": "Answer: D \n \n설명: \n이 옵션은 .html, .css, .js 및 이미지 파일과 같은 정적 및 동적 웹 콘텐츠를 사용자에게 \n빠르게 배포하는 웹 서비스인 Amazon CloudFront 를 사용하기 때문에 가장 효율적입니다. \n또한 CloudFront 를 사용하여 S3 버킷에 대한 모든 요청을 처리하므로 에지 위치에서 \n콘텐츠를 캐싱하고 거기에서 콘텐츠를 제공하여 S3 비용을 줄입니다. 또한 CloudFront 가 \n지연 시간이 짧고 데이터 전송 속도가 빠른 콘텐츠를 제공하므로 인증된 외부 사용자가 \n밀리초 안에 문서에 액세스할 수 있습니다. 이 솔루션은 데이터 저장 비용을 계속 \n지불하면서 총 S3 비용을 절감해야 한다는 요구 사항을 충족합니다. \n옵션 A 는 S3 버킷을 요청자 지불 버킷으로 구성하기 때문에 덜 효율적입니다. 이는 데이터 \n전송 및 요청 비용을 버킷 소유자에서 요청자에게 이전하는 방법입니다. 그러나 이것은 \n회사가 여전히 데이터 저장 및 자체 사용자의 요청에 대해 비용을 지불해야 하므로 총 S3 \n\n비용을 줄이지 않습니다. \n옵션 B 는 높은 내구성과 가용성으로 자주 액세스하는 데이터를 저장하는 방법인 모든 기존 \n및 향후 객체에 대해 스토리지 계층을 S3 Standard\n로 변경하기 때문에 효율성이 \n떨어집니다. \n그러나 S3 Standard 는 S3 Standard-IA 보다 스토리지 비용이 높기 때문에 총 S3 비용은 \n줄어들지 않습니다. \n옵션 C 는 CloudFront 엣지 로케이션을 통해 요청을 라우팅하여 S3 버킷 안팎으로 전송 \n속도를 높이는 방법인 S3 버킷에 대해 S3 Transfer Acceleration 을 활성화하기 때문에 \n효율성이 떨어집니다. 그러나 S3 Transfer Acceleration 에는 데이터 전송 및 요청에 대한 \n추가 요금이 있으므로 총 S3 비용은 줄어들지 않습니다.", "answer_choice": "D"}, "716": {"q_num": 716, "question": "회사에서 1PB 온프레미스 이미지 리포지토리를 AWS\n로 마이그레이션하려고 합니다. \n이미지는 서버리스 웹 애플리케이션에서 사용됩니다. 리포지토리에 저장된 이미지는 거의 \n액세스되지 않지만 즉시 사용할 수 있어야 합니다. 또한 미사용 이미지를 암호화하고 \n우발적인 삭제로부터 보호해야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. 클라이언트 측 암호화를 구현하고 이미지를 Amazon S3 Glacier 볼트에 저장합니다. \n우발적인 삭제를 방지하기 위해 볼트 잠금을 설정합니다. \nB. S3 Standard-Infrequent Access(S3 Standard-IA) 스토리지 클래스의 Amazon S3 버킷에 \n이미지를 저장합니다. S3 버킷에서 버전 관리, 기본 암호화 및 MFA 삭제를 활성화합니다. \nC. Amazon FSx for Windows File Server 파일 공유에 이미지를 저장합니다. AWS Key \nManagement Service(AWS KMS) 고객 마스터 키(CMK)를 사용하여 파일 공유의 이미지를 \n암호화하도록 Amazon FSx 파일 공유를 구성합니다. 우발적인 삭제를 방지하려면 이미지에 \nNTFS 권한 집합을 사용하십시오. \nD. Infrequent Access 스토리지 클래스의 Amazon Elastic File System(Amazon EFS) 파일 \n공유에 이미지를 저장합니다. AWS Key Management Service(AWS KMS) 고객 마스터 \n키(CMK)를 사용하여 파일 공유의 이미지를 암호화하도록 EFS 파일 공유를 구성합니다. \n우발적인 삭제를 방지하려면 이미지에 NFS 권한 집합을 사용하십시오.", "answer_block": "Answer: B \n \n설명: \n서버리스 웹 애플리케이션과 호환되는 온프레미스 파일 공유에 대한 탄력적이고 내구성 \n있는 대체를 제공하기 때문에 이 대답은 정확합니다. Amazon S3 는 모든 양의 데이터를 \n저장하고 인터넷을 통해 제공할 수 있는 완전관리형 객체 스토리지 서비스입니다. 다음 \n\n기능을 지원합니다. \n복원력: Amazon S3 는 리전 내의 여러 가용 영역에 데이터를 저장하고 99.999999999%(11 \n9)의 내구성을 제공합니다. 또한 서로 다른 AWS 리전에 있는 버킷 간에 객체를 자동 및 \n비동기식으로 복사할 수 있는 교차 리전 복제를 지원합니다. \n내구성: Amazon S3 는 Amazon S3 관리형 키(SSE-S3), AWS KMS 키(SSE-KMS) 또는 고객 \n제공 키(SSE-C)로 서버 측 암호화를 사용하여 유휴 데이터를 암호화합니다. 또한 \nSSL/TLS 를 사용하여 전송 중 암호화를 지원합니다. 또한 Amazon S3 는 동일한 버킷에 \n객체의 여러 버전을 유지하는 버전 관리 및 객체 버전을 삭제하거나 버킷의 버전 관리 \n상태를 변경하기 위해 추가 인증이 필요한 MFA 삭제와 같은 데이터 보호 기능을 \n제공합니다. \n성능: Amazon S3\n는 정적 및 동적 웹 콘텐츠를 제공하기 위한 고성능 및 확장성을 \n제공합니다. 또한 요청을 AWS 엣지 로케이션으로 라우팅하여 데이터 전송 속도를 높이는 \nS3 Transfer Acceleration 및 간단한 SQL 표현식을 사용하여 객체에서 데이터의 하위 \n집합만 검색할 수 있는 S3 Select 와 같은 기능을 지원합니다. \nS3 Standard-Infrequent Access(S3 Standard-IA) 스토리지 클래스는 거의 액세스하지 \n않지만 필요할 때 즉시 사용할 수 있어야 하는 이미지를 저장하는 데 적합합니다. S3 \nStandard 와 동일한 높은 내구성, 처리량 및 짧은 대기 시간을 제공하지만 GB 당 스토리지 \n비용은 더 낮고 요청당 비용은 더 높습니다.", "answer_choice": "B"}, "717": {"q_num": 717, "question": "회사에서 최근 마케팅 캠페인의 효과를 측정하려고 합니다. 회사는 판매 데이터의 csv \n파일에 대해 일괄 처리를 수행하고 그 결과를 1 시간에 한 번씩 Amazon S3 버킷에 \n저장합니다. S3 는 페타바이트 단위의 개체입니다. 이 회사는 Amazon Athena 에서 일회성 \n쿼리를 실행하여 특정 지역의 특정 날짜에 가장 인기 있는 제품을 확인합니다. 쿼리가 \n실패하거나 완료되는 데 예상보다 오래 걸리는 경우가 있습니다. \n쿼리 성능과 안정성을 개선하기 위해 솔루션 설계자는 어떤 조치를 취해야 합니까? (2 개 \n선택) \nA. S3 객체 크기를 128MB 미만으로 줄입니다. \nB. Amazon S3 의 날짜 및 지역별로 데이터를 분할합니다. \nC. 파일을 Amazon S3 에 큰 단일 객체로 저장합니다. \nD. Amazon Kinesis Data Analytics 를 사용하여 일괄 처리 작업의 팬으로 쿼리를 실행합니다. \nE. AWS Glue 추출, 변환 및 로드(ETL) 프로세스를 사용하여 csv 파일을 Apache Parquet \n형식으로 변환합니다.", "answer_block": "Answer: C, E \nhttps://www.examtopics.com/discussions/amazon/view/86458-exam-aws-certified-solut\n\nions-architect-associate-saa-c02/ \n \n문제에서 보면 S3 2 페타바이트의 개체이고 쿼리 실행이 예상보다 오래 걸리는 상황입니다. \n이를 위한 조치로는 먼저 파일을 Amazon S3 큰 단일 객체로 저장하여 AWS SDK, REST API \n또는 AWS CLI 를 사용하여 객체를 부분적으로 업로드합니다. \n다음으로 Apache Parquet 출력 형식으로 이용할 수 있습니다. Amazon S3 Inventory 는 \n객체의 플랫 파일 목록과 버킷 또는 공유된 접두사에 대해 선택한 메타데이터를 제공합니다. \nS3 Inventory 를 사용하여 객체 상태를 목록화, 감사 및 보고하거나 비즈니스 워크플로 및 \n빅 데이터 작업을 간소화하고 속도를 높일 수 있습니다. \n따라서 답은 C, E 로 보입니다.  \nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/upload-objects.html \nhttps://aws.amazon.com/ko/about-aws/whats-new/2018/12/amazon-s3-announces-par\nquet-output-format-for-inventory/ \n객체의 크기가 100MB 를 넘는 경우, 멀티파트 업로드 기능을 사용하는 방법을 고려해야 \n합니다. https://aws.amazon.com/ko/s3/faqs/ 따라서 A 는 오답.", "answer_choice": "C"}, "718": {"q_num": 718, "question": "회사는 여러 벤더를 사용하여 Amazon S3 버킷에 저장된 디지털 자산을 배포합니다. 이 \n회사는 공급업체 AWS 계정에 이러한 S3 버킷의 객체를 다운로드하는 데 필요한 최소한의 \n액세스 권한이 있는지 확인하려고 합니다. \n최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 익명의 읽기 권한과 모든 버킷을 나열할 수 있는 권한이 있는 버킷 정책을 설계합니다. \nB. 사용자에게 읽기 전용 액세스 권한을 부여하는 버킷 정책을 설계합니다. IAM 엔터티를 \n보안 주체로 지정합니다. \nC. IAM 역할에 대해 지정된 읽기 전용 액세스 정책이 있는 교차 계정 IAM 역할을 \n생성합니다. \nD. 공급업체 사용자에게 읽기 전용 액세스 권한을 부여하는 사용자 정책 및 공급업체 \n사용자 그룹을 만듭니다.", "answer_block": "Answer: C \n설명: \n교차 계정 IAM 역할은 한 AWS 계정의 사용자에게 다른 AWS 계정의 리소스에 대한 \n액세스 권한을 부여하는 방법입니다. 교차 계정 IAM 역할에는 읽기 전용 액세스 정책이 \n연결되어 있어 사용자가 객체를 수정하거나 삭제하지 않고도 S3 버킷에서 객체를 \n다운로드할 수 있습니다. 교차 계정 IAM 역할은 또한 각 계정에서 여러 IAM 사용자 및 \n정책을 관리하는 운영 오버헤드를 줄입니다. 교차 계정 IAM 역할은 질문의 모든 요구 \n\n사항을 충족하지만 다른 옵션은 그렇지 않습니다. \n참조: \nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/example-walkthroughs-mana\nging-accessexample2.html \nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-user_externalid.h\ntml", "answer_choice": "C"}, "719": {"q_num": 719, "question": "솔루션 설계자는 회사의 고객 대면 애플리케이션을 설계하고 있습니다. 애플리케이션의 \n데이터베이스는 일년 내내 명확하게 정의된 액세스 패턴을 가지며 연중 시간에 따라 다양한 \n읽기 및 쓰기 횟수를 갖게 됩니다. 회사는 데이터베이스에 대한 감사 기록을 7 일 동안 \n보관해야 합니다. RPO(복구 지점 목표)는 5 시간 미만이어야 합니다. \n어떤 솔루션이 이러한 요구 사항을 충족합니까? \nA. Auto Scaling 과 함께 Amazon DynamoDB 를 사용하십시오. 온디맨드 백업 및 Amazon \nDynamoDB Streams 를 사용합니다. \nB. Amazon Redshift 를 사용합니다. 동시성 확장을 구성합니다. 감사 로깅을 활성화합니다. \n4 시간마다 데이터베이스 스냅샷을 수행합니다. \nC. 프로비저닝된 IOPS 와 함께 Amazon RDS 를 사용합니다. 데이터베이스 감사 매개변수 \n활성화 5 시간마다 데이터베이스 스냅샷을 수행합니다. \nD. Auto Scaling 과 함께 Amazon Aurora MySQL 을 사용합니다. 데이터베이스 감사 \n매개변수를 활성화하십시오.", "answer_block": "Answer: D \n \n설명1: \nA(X) : DynamoDB Streams 는 수정/변경 사항을 최대 24 시간까지밖에 로그에 저장할 수 \n없음. 이를 변경할 수도 없음. \nDynamoDB Streams 의 모든 데이터는 24 시간 동안 유지됩니다. 특정 테이블에 대한 지난 \n24 시간 동안의 활동을 조회하고 분석할 수 있습니다. 그러나 24 시간이 지난 데이터는 \n언제든 트리밍(제거)될 수 있습니다....기존 스트림을 수동으로 삭제하기 위한 메커니즘은 \n없습니다. 보유 제한이 만료(24\n시간)될 때까지 기다려야 하며, 모든 스트림 레코드가 \n삭제됩니다. \nhttps://docs.aws.amazon.com/ko_kr/amazondynamodb/latest/developerguide/Streams.ht\nml \nB(X) : Redshift 는 데이터베이스 서비스가 아니라 데이터 웨어하우스 서비스. \nC(X) : 프로비저닝되었으므로 확장성이 떨어짐. \n\nD(O) : Amazon Aurora MySQL 은 기본적으로 Auto Scaling 기능이 켜져있음. 복구 시간도 \n매우 짧음. 데이터베이스 감사 로그 또한 다운로드 가능 \nAurora 는 단일 AWS 리전에서 다중 가용 영역에 걸쳐 DB 클러스터에 데이터 복사본을 \n저장합니다. DB 클러스터에 Aurora 복제본이 하나 이상인 경우에는 장애가 발생하더라도 \nAurora 복제본이 기본 인스턴스로 승격됩니다. 이 실패 이벤트로 인해 예외적으로 실패하는 \n읽기 및 쓰기 작업 동안 짧은 중단이 발생합니다. 하지만, 일반적인 서비스 복구 시간은 \n120 초 미만이지만 대부분 60 초 미만에 복원됩니다. \nhttps://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/AuroraUserGuide/Concepts.Auror\naHighAvailability.html#Concepts.AuroraHighAvailability.Data \nAmazon Aurora MySQL 의 고성능 고급 감사 기능을 사용하여 데이터베이스 활동을 감사할 \n수 있습니다. 이를 위해 여러 DB 클러스터 파라미터를 설정하여 감사 로그 수집을 \n활성화합니다. 콘솔을 사용하여 감사 로그를 확인하고 다운로드할 수 있습니다. \nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Auditin\ng.html", "answer_choice": "D"}, "720": {"q_num": 720, "question": "회사의 애플리케이션은 Auto Scaling 그룹의 Amazon EC2 인스턴스에서 실행됩니다. \n회사는 애플리케이션에서 임의의 요일에 트래픽이 갑자기 증가한다는 사실을 알게 \n되었습니다. 회사는 트래픽이 갑자기 증가하는 동안 애플리케이션 성능을 유지하려고 \n합니다. \n이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까? \nA. 수동 스케일링을 사용하여 Auto Scaling 그룹의 크기를 변경합니다. \nB. 예측 조정을 사용하여 Auto Scaling 그룹의 크기를 변경합니다. \nC. 동적 스케일링을 사용하여 Auto Scaling 그룹의 크기를 변경합니다. \nD. 일정 조정을 사용하여 Auto Scaling 그룹의 크기를 변경합니다.", "answer_block": "Answer: C \n \n설명: \n동적 조정은 수요 또는 부하에 따라 Auto Scaling 그룹의 EC2 인스턴스 수를 자동으로 \n조정하는 일종의 자동 조정입니다. 지정된 지표가 임계값을 초과하면 CloudWatch 경보를 \n사용하여 조정 작업을 트리거합니다. 필요에 따라 확장(인스턴스 추가) 또는 축소(인스턴스 \n제거)할 수 있습니다1. 솔루션은 동적 확장을 사용하여 갑작스러운 트래픽 증가 중에 가장 \n비용 효율적으로 애플리케이션 성능을 유지할 수 있습니다. \n1. 수동 조정을 사용하여 Auto Scaling 그룹의 크기를 변경합니다. 수동 확장은 사용자가 \nCLI 또는 콘솔을 통해 인스턴스 수를 수동으로 늘리거나 줄여야 하므로 이 솔루션은 \n\n트래픽이 갑자기 증가하는 동안 애플리케이션 성능을 유지해야 하는 요구 사항을 충족하지 \n않습니다. 수요나 부하의 변화에 자동으로 반응하지 않습니다. \n2. 예측 조정을 사용하여 Auto Scaling 그룹의 크기를 변경합니다. 이 솔루션은 예측 \n확장이 기계 학습 및 인공 지능 도구를 사용하여 트래픽 부하를 평가하고 더 많거나 적은 \n리소스가 필요할 때를 예상하므로 대부분의 비용 효율성 요구 사항을 충족하지 않습니다. \n주어진 시간에 실제 수요 또는 로드와 일치하지 않을 수 있는 예측을 기반으로 예약된 조정 \n작업을 수행합니다. 예측 조정은 예측 가능한 트래픽 패턴이 있거나 트래픽 부하의 알려진 \n변경 사항이 있는 시나리오에 더 적합합니다. \n3. 일정 조정을 사용하여 Auto Scaling 그룹의 크기를 변경합니다. 일정 조정은 사용자가 \n예약한 특정 시간에 조정 작업을 수행하므로 이 솔루션은 트래픽이 갑자기 증가하는 동안 \n애플리케이션 성능을 유지해야 하는 요구 사항을 충족하지 않습니다. 수요나 부하의 변화에 \n자동으로 반응하지 않습니다. 일정 조정은 하루 중 특정 시간에 예측 가능한 트래픽 감소 \n또는 급증이 있는 시나리오에 더 적합합니다. \n \n참조: \nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scale-based-ondemand.ht\nml", "answer_choice": "C"}, "721": {"q_num": 721, "question": "회사는 Amazon RDS 를 백엔드 데이터베이스로 사용하는 서버리스 애플리케이션을 AWS 에 \n보유하고 있습니다. 애플리케이션에서 트래픽이 예기치 않게 갑자기 증가하는 경우가 \n있습니다. 트래픽이 증가하는 동안 애플리케이션은 데이터베이스에 대한 연결을 자주 열고 \n닫으므로 애플리케이션이 데이터베이스에서 오류를 수신하거나 연결이 끊어집니다. 회사는 \n애플리케이션이 항상 확장 가능하고 가용성이 높은지 확인해야 합니다. \n애플리케이션에 대한 코드 변경 없이 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 서버리스 애플리케이션의 RDS 데이터베이스 옵션 그룹에서 최대 연결 수를 늘리십시오. \nB. 최대 로드 트래픽을 충족하도록 RDS DB 인스턴스의 인스턴스 크기를 늘립니다. \nC. 서버리스 애플리케이션과 Amazon RDS 간에 Amazon RDS 프록시를 배포합니다. \nD. Amazon RDS 용 예약 인스턴스를 구입하여 피크 로드 트래픽 동안 데이터베이스의 \n가용성을 높입니다.", "answer_block": "Answer: C \n \n설명: \nAmazon RDS Proxy 는 애플리케이션의 확장성, 데이터베이스 장애에 대한 복원력, 보안을 \n강화하는 완전 관리형 데이터베이스 프록시입니다. RDS Proxy 는 애플리케이션과 관계형 \n\n데이터베이스 \n사이에 \n위치하여 \n설정된 \n데이터베이스 \n연결을 \n풀링하고 \n공유하여 \n데이터베이스 효율성과 애플리케이션 확장성을 개선합니다. 또한 RDS Proxy 는 일시적인 \n오류에 대한 연결 관리 및 쿼리 재시도를 처리하여 데이터베이스의 부하를 줄입니다. \n서버리스 애플리케이션과 Amazon RDS 사이에 RDS Proxy 를 배포하면 오류가 발생하거나 \n연결이 끊어질 수 있는 데이터베이스 연결을 자주 열고 닫는 것을 방지할 수 있습니다. 이 \n솔루션은 또한 운영 비용을 절감하고 애플리케이션의 가용성을 향상시킵니다. \n \n참조: \nhttps://aws.amazon.com/rds/proxy/", "answer_choice": "C"}, "722": {"q_num": 722, "question": "회사에서 SSL/TLS 인증서를 사용하도록 Amazon CloudFront 배포를 구성하려고 합니다. \n회사는 배포에 기본 도메인 이름을 사용하기를 원하지 않습니다. 대신 회사는 배포에 다른 \n도메인 이름을 사용하려고 합니다. \n추가 비용을 발생시키면서 인증서를 배포하는 솔루션은 무엇입니까? \nA. useast-1 지역의 AWS Certificate Manager(ACM)에서 Amazon\n에서 발급한 사설 \n인증서를 요청합니다. \nB. uswest-1 리전의 AWS Certificate Manager(ACM)에서 Amazon 발급 사설 인증서를 \n요청합니다. \nC. us-east-1 지역의 AWS Certificate Manager(ACU)에서 Amazon 발급 공인 인증서를 \n요청합니다. \nD. us-west-1 지역의 AWS Certificate Manager(ACU)에서 Amazon 발급 공인 인증서를 \n요청합니다.", "answer_block": "Answer: C \n \n설명: \n이 옵션은 AWS 서비스와 함께 사용할 공개 및 비공개 SSL/TLS 인증서를 쉽게 프로비저닝, \n관리 및 배포할 수 있는 서비스인 AWS Certificate Manager(ACM)에서 Amazon 에서 발급한 \n공개 인증서를 요청하기 때문에 가장 효율적입니다. 내부 연결 자원. 또한 CloudFront 에서 \nACM 인증서를 사용하는 데 필요한 us-east-1 리전에서 인증서를 요청합니다. 또한 \nACM 은 지원되는 AWS 서비스와 함께 사용되는 인증서에 대해 비용을 청구하지 않으므로 \n추가 비용 없이 인증서를 배포해야 한다는 요구 사항을 충족합니다. 이 솔루션은 SSL/TLS \n인증서를 사용하고 배포에 다른 도메인 이름을 사용하도록 CloudFront 배포를 구성해야 \n하는 요구 사항을 충족합니다. \n \n\n옵션 A 는 조직 또는 Virtual Private Cloud(VPC) 내에서만 사용할 수 있는 인증서 유형인 \nACM 에서 Amazon 에서 발급한 사설 인증서를 요청하기 때문에 효율성이 떨어집니다. \n그러나 CloudFront 에는 공개 인증서가 필요하므로 이는 SSL/TLS 인증서를 사용하도록 \nCloudFront 배포를 구성해야 하는 요구 사항을 충족하지 않습니다. 또한 올바른 us-east-1 \n리전에서 인증서를 요청합니다. \n \n옵션 B 는 옵션 A 와 같은 이유로 올바르지 않은 ACM 에서 Amazon 에서 발급한 사설 \n인증서를 요청하기 때문에 효율성이 떨어집니다. 또한 us-west-1 리전에서 인증서를 \n요청합니다. us-east-1 지역. \n \n옵션 D\n는 ACM\n에서 Amazon\n이 발행한 공용 인증서를 요청하기 때문에 효율성이 \n떨어집니다. 이는 올바른 것입니다. \n하지만 us-west-1 리전에서 인증서를 요청합니다. 이는 CloudFront 가 us-east-1 리전의 \n인증서를 요구하기 때문에 올바르지 않습니다.", "answer_choice": "C"}, "723": {"q_num": 723, "question": "회사는 AWS 에서 고성능 컴퓨팅(HPC) 워크로드를 실행합니다. 워크로드에는 긴밀하게 \n연결된 노드 간 통신을 통해 대기 시간이 짧은 네트워크 성능과 높은 네트워크 처리량이 \n필요했습니다. Amazon EC2 인스턴스는 컴퓨팅 및 스토리지 용량에 적합한 크기이며 기본 \n옵션을 사용하여 시작됩니다. \n솔루션 설계자는 워크로드의 성능을 개선하기 위해 무엇을 제안해야 합니까? \nA. Amazon EC2 인스턴스를 시작하는 동안 클러스터 배치 그룹을 선택하십시오. \nB. Amazon EC2 인스턴스를 시작하는 동안 전용 인스턴스 테넌시를 선택합니다. \nC. Amazon EC2 인스턴스를 시작하는 동안 Elastic Inference 액셀러레이터를 선택합니다. \nD. Amazon EC2 인스턴스를 시작하는 동안 필요한 용량 예약을 선택합니다.", "answer_block": "Answer: A \nhttps://www.examtopics.com/discussions/amazon/view/35884-exam-aws-certified-solut\nions-architect-associate-saa-c02/ \n \n설명 \nhttps://docs.aws.amazon.com/ko_kr/AWSCloudFormation/latest/UserGuide/aws-resource\n-ec2-placementgroup.html \n\"클러스터 배치 그룹은 네트워크 대기 시간이 짧고 네트워크 처리량이 높은 단일 가용 영역 \n내 인스턴스의 논리적 그룹입니다.\" \n-> 긴밀하게 결합된 노드 = Cluster Deployment Group.", "answer_choice": "A"}, "724": {"q_num": 724, "question": "회사는 Amazon API Gateway 및 AWS Lambda 를 사용하여 AWS 에서 내부 서버리스 \n애플리케이션을 호스팅합니다. 회사 직원은 매일 애플리케이션을 사용하기 시작할 때 대기 \n시간이 긴 문제를 보고합니다. 회사는 대기 시간을 줄이려고 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. API Gateway 조절 제한을 늘립니다. \nB. 직원이 매일 애플리케이션을 사용하기 전에 Lambda 프로비저닝된 동시성을 높이기 \n위해 예약된 조정을 설정합니다. \nC. Amazon CloudWatch 경보를 생성하여 매일 시작 시 경보 대상으로 Lambda 함수를 \n시작합니다. \nD. Lambda 함수 메모리를 늘립니다.", "answer_block": "Answer: B \n \n설명: \nAWS Lambda\n는 서버를 프로비저닝하거나 관리하지 않고도 코드를 실행할 수 있는 \n서버리스 컴퓨팅 서비스입니다. Lambda 는 들어오는 요청에 따라 자동으로 확장되지만 \n수요가 갑자기 증가하면 함수의 새 인스턴스를 초기화하는 데 시간이 걸릴 수 있습니다. \n이로 인해 애플리케이션의 대기 시간이 길어지거나 콜드 스타트가 발생할 수 있습니다. \n이를 방지하기 위해 함수가 초기화되고 언제든지 응답할 준비가 되도록 프로비저닝된 \n동시성을 \n사용할 \n수 \n있습니다. \n또한 \n직원이 \n매일 \n애플리케이션을 \n사용하기 \n전에 \n프로비저닝된 동시성을 늘리고 수요가 적을 때 줄이는 예약된 조정 정책을 설정할 수도 \n있습니다. \n \n참조: \nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-concurrency.html", "answer_choice": "B"}, "725": {"q_num": 725, "question": "솔루션 설계자는 가용성이 높은 Amazon ElastiCache for Redis 기반 솔루션을 설계하고 \n있습니다. 솔루션 설계자는 장애로 인해 로컬 및 AWS 리전 내에서 성능 저하 또는 데이터 \n손실이 발생하지 않도록 해야 합니다. 솔루션은 노드 수준과 지역 수준에서 고가용성을 \n제공해야 합니다. \n이러한 요구 사항을 충족하는 솔루션은 무엇입니까? \nA. 여러 노드가 포함된 샤드와 함께 다중 AZ Redis 복제 그룹을 사용합니다. \n\nB. Redis AOF(추가 전용 파일)가 설정된 여러 노드를 포함하는 Redis 샤드를 사용합니다. \nC. 복제 그룹에 둘 이상의 읽기 전용 복제본이 있는 다중 AZ Redis 클러스터를 사용합니다. \nD. Auto Scaling 이 켜진 여러 노드를 포함하는 Redis 샤드를 사용합니다.", "answer_block": "Answer: A \n \n설명: \nRedis 솔루션용 ElastiCache 에 대해 노드 수준 및 리전 수준에서 고가용성을 제공하기 \n때문에 이 대답은 정확합니다. 다중 AZ Redis 복제 그룹은 각각 다른 가용 영역에 있는 \n기본 클러스터와 최대 5 개의 읽기 전용 복제본 클러스터로 구성됩니다. 기본 클러스터에 \n장애가 발생하면 읽기 전용 복제본 중 하나가 자동으로 새 기본 클러스터로 승격됩니다. \n샤드가 있는 Redis 복제 그룹을 사용하면 여러 노드에 걸쳐 데이터를 분할할 수 있으므로 \n솔루션의 확장성과 성능이 향상됩니다. 각 샤드는 중복성과 읽기 확장성을 제공하기 위해 \n하나 이상의 복제본을 가질 수 있습니다. \n \n참조: \nhttps://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/AutoFailover.html \nhttps://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Shards.html", "answer_choice": "A"}};
